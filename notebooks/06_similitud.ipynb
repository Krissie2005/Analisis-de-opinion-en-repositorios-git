{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7053b1",
   "metadata": {},
   "source": [
    "# 06 - Similitud textual (Cosine Similarity)\n",
    "\n",
    "Objetivo:\n",
    "- Calcular similitud entre mensajes usando TF-IDF.\n",
    "- Encontrar los mensajes más parecidos a un mensaje dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5d2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys #Esto es para importar la función de src\n",
    "import os\n",
    "\n",
    "#Añadimos src al path de python<\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3501a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentiment_utils import sentimiento_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f75f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_similitud(slug):\n",
    "    df = pd.read_csv(f\"../data/{slug}/messages_clean_ready.csv\") #ruta donde está el archivo generado en el file 3\n",
    "    with open(f\"../data/{slug}/X_tfidf.pkl\", \"rb\") as f: #Cargar matriz TF-IDF númerica\n",
    "        X = pickle.load(f)\n",
    "    with open(f\"../data/{slug}/tfidf_vectorizer.pkl\", \"rb\") as f: #Carga vectorizador para interpretar términos\n",
    "        vectorizer = pickle.load(f)\n",
    "\n",
    "    S = cosine_similarity(X) #Compara cada documento con todos los demás.\n",
    "    return df, X, vectorizer, S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7d5ac",
   "metadata": {},
   "source": [
    "Esta función es la que toma un texto nuevo del usuario y busca los mensajes más parecidos dentro del repositorio usando TF-IDF + similitud coseno. Además, le saca sentimiento automático al texto del usuario y a los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b57e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similares_por_texto(df, X, vectorizer, texto_usuario, top_n=5, max_chars=240):\n",
    "    X_user = vectorizer.transform([texto_usuario]) #Vectoriza el texto del usuario\n",
    "    sims = cosine_similarity(X_user, X).flatten() #Similitud del usuario vs todos\n",
    "    best = np.argsort(sims)[::-1][:top_n] #Obtener los mejores índices\n",
    "\n",
    "    # Sentimiento del texto ingresado\n",
    "    sent_user = sentimiento_auto(texto_usuario) #Calcula el sentimiento con la función de lexicon.\n",
    "    print(\"\\nTEXTO INGRESADO:\")\n",
    "    print(texto_usuario[:max_chars])\n",
    "    print(\"Sentimiento (auto):\", sent_user)\n",
    "\n",
    "    print(\"\\nMAS SIMILARES:\")\n",
    "    for idx in best:\n",
    "        sim = float(sims[idx]) #Puntuación de similitud con el texto del usuario\n",
    "        issue = df.loc[idx, \"issue_number\"] #Recupera el número de issue asociado a ese documento\n",
    "\n",
    "        # Si existe la columna sentiment, la usa; si no, la calcula al vuelo\n",
    "        if \"sentiment\" in df.columns:\n",
    "            sent = df.loc[idx, \"sentiment\"]\n",
    "        else:\n",
    "            sent = sentimiento_auto(df.loc[idx, \"text_clean\"]) #Si no hay la calcula con text_clean\n",
    "\n",
    "        print(f\"\\nSim={sim:.3f} | issue={issue} | sentimiento={sent}\")\n",
    "        print(df.loc[idx, \"text_clean\"][:max_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47587339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_por_keyword(df, keyword, n=5): #Dataframe con los mensajes, palabra clave y cantidad de resultados a mostrar\n",
    "    kw = keyword.lower().strip() #La convierte a minusculas por si la puse en mys\n",
    "    indices = df[df[\"text_clean\"].str.contains(kw, na=False)].index.tolist() #Busca coincidencias\n",
    "    print(f\"\\nKeyword='{kw}' | encontrados={len(indices)}\")\n",
    "    for idx in indices[:n]: #Mostrar primeros resultados\n",
    "        print(f\"- idx={idx} | issue={df.loc[idx,'issue_number']} | {df.loc[idx,'text_clean'][:180]}\")\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a467d52",
   "metadata": {},
   "source": [
    "Texto de prueba aleatorio\n",
    "\n",
    "Positivo : Thank you so much, very helpful. Would it be possible to add important information to the Repos homepage? I think many people would benefit.\n",
    "\n",
    "Negativo: ROCM version error, it becomes unresponsive, very low quality, checklist steps are skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c6a53",
   "metadata": {},
   "source": [
    "# PRUEBA CON EL REPO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f3c3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXTO INGRESADO:\n",
      "ROCM version error, it becomes unresponsive, very low quality, checklist steps are skipped\n",
      "Sentimiento (auto): negativo\n",
      "\n",
      "MAS SIMILARES:\n",
      "\n",
      "Sim=0.145 | issue=16954 | sentimiento=negativo\n",
      "bug rocm version turns stupid super low quality skipping steps checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issu\n",
      "\n",
      "Sim=0.136 | issue=17031 | sentimiento=negativo\n",
      "error practically specs steps also reproduced error stable version v cloning master branch\n",
      "\n",
      "Sim=0.134 | issue=16807 | sentimiento=positivo\n",
      "might better using fork made support amd gpu rocm using rx user compiled rocm libs etc works well\n",
      "\n",
      "Sim=0.122 | issue=16807 | sentimiento=neutral\n",
      "update using guess rocm must even earlier version python\n",
      "\n",
      "Sim=0.120 | issue=17031 | sentimiento=negativo\n",
      "bug error trying install pytorch checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue report\n",
      "\n",
      "Keyword='error' | encontrados=155\n",
      "- idx=0 | issue=17255 | bug runtimeerror clone stable diffusion checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issu\n",
      "- idx=3 | issue=17255 | similar issue im issues code lines also different install clicking webui user bat looks like log venv c ai stable diffusion webui venv scripts python exe python tags v c b bd aug m\n",
      "- idx=6 | issue=17255 | got error youre seeing explained log remote repository found fatal repository found webui trying clone fetch old repository longer exists common issue newer versions sd webui stabl\n",
      "- idx=7 | issue=17251 | bug error executing run bat checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current v\n",
      "- idx=14 | issue=17236 | bug assertionerror torch compiled cuda enabled checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui\n"
     ]
    }
   ],
   "source": [
    "slug = \"auto1111_webui\"    #ytdlp #auto1111_webui\n",
    "df, X, vectorizer, S = preparar_similitud(slug)\n",
    "\n",
    "# 1) Probar con un texto aleatorio\n",
    "mi_mensaje = \"ROCM version error, it becomes unresponsive, very low quality, checklist steps are skipped\"\n",
    "\n",
    "similares_por_texto(df, X, vectorizer, mi_mensaje, top_n=5)\n",
    "\n",
    "# 2) Probar por keyword\n",
    "idxs = buscar_por_keyword(df, \"error\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87db07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXTO INGRESADO:\n",
      "bug runtimeerror clone stable diffusion checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently iss\n",
      "Sentimiento (auto): negativo\n",
      "\n",
      "MAS SIMILARES:\n",
      "\n",
      "Sim=1.000 | issue=17255 | sentimiento=negativo\n",
      "bug runtimeerror clone stable diffusion checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently iss\n",
      "\n",
      "Sim=0.951 | issue=17216 | sentimiento=negativo\n",
      "bug repository found checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happe\n",
      "\n",
      "Sim=0.903 | issue=16861 | sentimiento=negativo\n",
      "bug torch able use gpu add skip torch cuda test commandline args variable disable check checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists c\n",
      "\n",
      "Sim=0.769 | issue=16809 | sentimiento=negativo\n",
      "tried fresh install auto python got install creating venv directory j ai stable diffusion webui venv using python c users cain appdata local microsoft windowsapps pythonsoftwarefoundation python qbz n kfra p python exe requirement already s\n",
      "\n",
      "Sim=0.581 | issue=16881 | sentimiento=negativo\n",
      "bug failed install requirements checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reporte\n"
     ]
    }
   ],
   "source": [
    "# Si hay resultados, buscar similares del PRIMER resultado encontrado\n",
    "if idxs:\n",
    "    base = df.loc[idxs[0], \"text_clean\"]\n",
    "    similares_por_texto(df, X, vectorizer, base, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7036f",
   "metadata": {},
   "source": [
    "# PRUEBA CON EL REPO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb44e5",
   "metadata": {},
   "source": [
    "Texto de prueba aleatorio\n",
    "\n",
    "Positivo : Thanks a lot, this works perfectly now after the update. Great job!\n",
    "\n",
    "Negativo: Caution: This comment may contain links with malicious content. Everything is still failing. A ytdlp dump file is being generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef28a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXTO INGRESADO:\n",
      "Caution: The comment may contain links with malicious content. Everything is still failing. A ytdlp dump file is generated\n",
      "Sentimiento (auto): negativo\n",
      "\n",
      "MAS SIMILARES:\n",
      "\n",
      "Sim=0.679 | issue=15287 | sentimiento=negativo\n",
      "caution comment may contain links malicious content follow links since html contains dash url everything still fails dump file generated ytdlp\n",
      "\n",
      "Sim=0.179 | issue=15740 | sentimiento=neutral\n",
      "sure coincidence happen links sites\n",
      "\n",
      "Sim=0.139 | issue=15774 | sentimiento=neutral\n",
      "yep content targeting protected drm yt dlp support downloading drm content extractor still work non drm content like stuff national geographic everything could find abc drm thus downloadable\n",
      "\n",
      "Sim=0.113 | issue=15520 | sentimiento=negativo\n",
      "bashonly assuming maintainer commands failing morning work without changes done side sure test reddit side bug right longer issues\n",
      "\n",
      "Sim=0.113 | issue=15660 | sentimiento=negativo\n",
      "updates still issue\n",
      "\n",
      "Keyword='cuda' | encontrados=1\n",
      "- idx=150 | issue=15784 | stripchat preview checklist x reporting yt dlp broken supported site x verified updated yt dlp nightly master update instructions x checked provided urls playable browser ip login \n"
     ]
    }
   ],
   "source": [
    "slug = \"ytdlp\"  \n",
    "df, X, vectorizer, S = preparar_similitud(slug)\n",
    "\n",
    "# 1) Probar con un texto tuyo\n",
    "mi_mensaje = \"Caution: The comment may contain links with malicious content. Everything is still failing. A ytdlp dump file is generated\"\n",
    "similares_por_texto(df, X, vectorizer, mi_mensaje, top_n=5)\n",
    "\n",
    "# 2) Probar por keyword\n",
    "idxs = buscar_por_keyword(df, \"cuda\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b4829d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXTO INGRESADO:\n",
      "stripchat preview checklist x reporting yt dlp broken supported site x verified updated yt dlp nightly master update instructions x checked provided urls playable browser ip login details x checked urls arguments special characters properly\n",
      "Sentimiento (auto): negativo\n",
      "\n",
      "MAS SIMILARES:\n",
      "\n",
      "Sim=1.000 | issue=15784 | sentimiento=negativo\n",
      "stripchat preview checklist x reporting yt dlp broken supported site x verified updated yt dlp nightly master update instructions x checked provided urls playable browser ip login details x checked urls arguments special characters properly\n",
      "\n",
      "Sim=0.649 | issue=15891 | sentimiento=negativo\n",
      "please add f command cookies show output debug command line config vu f cookies mp cookies cookies txt debug system config etc yt dlp conf debug encodings locale utf fs utf pref utf utf ansi error utf ansi screen utf ansi debug yt dlp versi\n",
      "\n",
      "Sim=0.645 | issue=15891 | sentimiento=negativo\n",
      "hessijames please show output yt dlp f bytevc p cookies cookies txt withcookies ext exec ffprobe vm tiktok extracting url vm tiktok zgdm k rk downloading webpage tiktok extracting url tiktok downloading webpage warning tiktok extractor atte\n",
      "\n",
      "Sim=0.253 | issue=15886 | sentimiento=negativo\n",
      "add support redzidzirdilatviju lv checklist x reporting new site support request x verified updated yt dlp nightly master update instructions x checked provided urls playable browser ip login details x checked none provided urls violate cop\n",
      "\n",
      "Sim=0.248 | issue=15289 | sentimiento=negativo\n",
      "jwplatform alldaf org extractor handoff broken checklist x reporting yt dlp broken supported site x verified updated yt dlp nightly master update instructions x checked provided urls playable browser ip login details x checked urls argument\n"
     ]
    }
   ],
   "source": [
    "# Si hay resultados, buscar similares del PRIMER resultado encontrado\n",
    "if idxs:\n",
    "    base = df.loc[idxs[0], \"text_clean\"]\n",
    "    similares_por_texto(df, X, vectorizer, base, top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
