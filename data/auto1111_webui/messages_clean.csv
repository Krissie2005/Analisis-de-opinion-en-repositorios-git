repo_slug,type,issue_number,title,body,created_at,user,url,text,text_clean
auto1111_webui,issue,17255,[Bug]: RuntimeError: Couldn't clone Stable Diffusion.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The ""auto-install"" can't find the repository for stablediffusion: Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

I checked they repository and they not moved. They deleted the repository. Looks like this is dead now?

### Steps to reproduce the problem

Just try to install

### What should have happened?

Clean install

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no need for the problem

### Console logs

```Shell
Creating venv in directory D:\Auto\stable-diffusion-webui\venv using python ""C:\Program Files\Python310\python.exe""
Requirement already satisfied: pip in d:\auto\stable-diffusion-webui\venv\lib\site-packages (22.2.1)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.2.1
    Uninstalling pip-22.2.1:
      Successfully uninstalled pip-22.2.1
Successfully installed pip-25.3
venv ""D:\Auto\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.3-py3-none-any.whl (16 kB)
Using cached fsspec-2026.1.0-py3-none-any.whl (201 kB)
Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)
Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2026.1.4 charset_normalizer-3.4.4 filelock-3.20.3 fsspec-2026.1.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.1.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.3
Installing clip
Installing open_clip
Cloning assets into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.47 MiB/s, done.
Cloning Stable Diffusion into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Press any key to continue . . .
```

### Additional information

Alternative: Forge or ComfyUI",2026-01-19T20:59:37Z,KaityTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255,"[Bug]: RuntimeError: Couldn't clone Stable Diffusion. ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The ""auto-install"" can't find the repository for stablediffusion: Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

I checked they repository and they not moved. They deleted the repository. Looks like this is dead now?

### Steps to reproduce the problem

Just try to install

### What should have happened?

Clean install

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no need for the problem

### Console logs

```Shell
Creating venv in directory D:\Auto\stable-diffusion-webui\venv using python ""C:\Program Files\Python310\python.exe""
Requirement already satisfied: pip in d:\auto\stable-diffusion-webui\venv\lib\site-packages (22.2.1)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.2.1
    Uninstalling pip-22.2.1:
      Successfully uninstalled pip-22.2.1
Successfully installed pip-25.3
venv ""D:\Auto\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.3-py3-none-any.whl (16 kB)
Using cached fsspec-2026.1.0-py3-none-any.whl (201 kB)
Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)
Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2026.1.4 charset_normalizer-3.4.4 filelock-3.20.3 fsspec-2026.1.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.1.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.3
Installing clip
Installing open_clip
Cloning assets into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.47 MiB/s, done.
Cloning Stable Diffusion into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Press any key to continue . . .
```

### Additional information

Alternative: Forge or ComfyUI",bug runtimeerror clone stable diffusion checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened auto install find repository stablediffusion cloning auto stable diffusion webui repositories stable diffusion stability ai remote repository found fatal repository found checked repository moved deleted repository looks like dead steps reproduce problem try install happened clean install browsers use access ui response sysinfo need problem console logs shell creating venv directory auto stable diffusion webui venv using python c program files python python exe requirement already satisfied pip auto stable diffusion webui venv lib site packages collecting pip using cached pip py none whl mb installing collected packages pip attempting uninstall pip found existing installation pip uninstalling pip successfully uninstalled pip successfully installed pip venv auto stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes collecting torch using cached mb collecting torchvision using cached mb collecting filelock torch using cached filelock py none whl metadata kb collecting typing extensions torch using cached kb collecting sympy torch using cached sympy py none whl metadata kb collecting networkx torch using cached networkx py none whl metadata kb collecting jinja torch using cached kb collecting fsspec torch using cached fsspec py none whl metadata kb collecting numpy torchvision using cached numpy cp cp win amd whl metadata kb collecting requests torchvision using cached requests py none whl metadata kb collecting pillow torchvision using cached pillow cp cp win amd whl metadata kb collecting markupsafe jinja torch using cached markupsafe cp cp win amd whl metadata kb collecting charset normalizer requests torchvision using cached charset normalizer cp cp win amd whl metadata kb collecting idna requests torchvision using cached idna py none whl metadata kb collecting urllib requests torchvision using cached urllib py none whl metadata kb collecting certifi requests torchvision using cached certifi py none whl metadata kb collecting mpmath sympy torch using cached mpmath py none whl metadata kb using cached pillow cp cp win amd whl mb using cached filelock py none whl kb using cached fsspec py none whl kb using cached kb using cached markupsafe cp cp win amd whl kb using cached networkx py none whl mb using cached numpy cp cp win amd whl mb using cached requests py none whl kb using cached charset normalizer cp cp win amd whl kb using cached idna py none whl kb using cached urllib py none whl kb using cached certifi py none whl kb using cached sympy py none whl mb using cached mpmath py none whl kb using cached kb installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna fsspec filelock charset normalizer certifi requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock fsspec idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu typing extensions urllib installing clip installing open clip cloning assets auto stable diffusion webui repositories stable diffusion webui assets cloning auto stable diffusion webui repositories stable diffusion webui assets remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done cloning stable diffusion auto stable diffusion webui repositories stable diffusion stability ai cloning auto stable diffusion webui repositories stable diffusion stability ai remote repository found fatal repository found traceback recent call last file auto stable diffusion webui launch py line module main file auto stable diffusion webui launch py line main prepare environment file auto stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file auto stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file auto stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false auto stable diffusion webui repositories stable diffusion stability ai error code press key continue additional information alternative forge comfyui
auto1111_webui,comment,17255,,"open modules/launch_utils.py， edit 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")
to 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")",2026-01-20T01:47:27Z,zhangchang725,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3770666470,"open modules/launch_utils.py， edit 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")
to 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")",open modules launch utils py edit stable diffusion repo os environ get stable diffusion repo stable diffusion repo os environ get stable diffusion repo
auto1111_webui,comment,17255,,switch to dev branch,2026-01-31T18:09:51Z,AlexPetrusca,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3828950541,switch to dev branch,switch dev branch
auto1111_webui,comment,17255,,"Having a similar issue. Im having some issues in the same code lines as yours, but some are also different. After install and clicking webui-user.bat It looks like this on the log 

venv ""C:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Fetching updates for Stable Diffusion...
info: please complete authentication in your browser...
Traceback (most recent call last):
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 160, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""C:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch
Error code: 128
stderr: remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Press any key to continue . . .",2026-02-01T03:07:55Z,ForgottenLogic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3830195522,"Having a similar issue. Im having some issues in the same code lines as yours, but some are also different. After install and clicking webui-user.bat It looks like this on the log 

venv ""C:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Fetching updates for Stable Diffusion...
info: please complete authentication in your browser...
Traceback (most recent call last):
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 160, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""C:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch
Error code: 128
stderr: remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Press any key to continue . . .",similar issue im issues code lines also different install clicking webui user bat looks like log venv c ai stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e fetching updates stable diffusion info please complete authentication browser traceback recent call last file c ai stable diffusion webui launch py line module main file c ai stable diffusion webui launch py line main prepare environment file c ai stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file c ai stable diffusion webui modules launch utils py line git clone run git dir name fetch f fetching updates name f fetch name autofix false file c ai stable diffusion webui modules launch utils py line run git return run f git c dir command desc desc errdesc errdesc custom env custom env live live file c ai stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch stable diffusion command git c c ai stable diffusion webui repositories stable diffusion stability ai fetch error code stderr remote repository found fatal repository found press key continue
auto1111_webui,comment,17255,,Using this as a core reference for my startup. Pushed some useful extensions to my profile if anyone needs them.,2026-02-05T17:28:39Z,oil666oil,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3855092828,Using this as a core reference for my startup. Pushed some useful extensions to my profile if anyone needs them.,using core reference startup pushed useful extensions profile anyone needs
auto1111_webui,comment,17255,,"Same issue, install on main doesn't work. Can you please fix so main be working?",2026-02-08T23:57:13Z,Ignalion,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3868592841,"Same issue, install on main doesn't work. Can you please fix so main be working?",issue install main work please fix main working
auto1111_webui,comment,17255,,"Got it! The error you’re seeing is explained in the log itself:
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Your WebUI is trying to clone/fetch the old repository https://github.com/Stability-AI/stablediffusion.git,
which no longer exists. This is a common issue with newer versions of
SD WebUI if the STABLE_DIFFUSION_REPO is set incorrectly.

You mentioned in your webui-user.bat:

set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

That’s correct for the w-e-w version. However, your WebUI is still trying to use the old Stability-AI/stablediffusion repo. This usually happens if the variable wasn’t picked up correctly or an old repository already exists.

**Step-by-Step Fix**

**_Delete the old repository_**

Go to:
C:\AI\stable-diffusion-webui\repositories\

- Delete the folder stable-diffusion-stability-ai.
- This prevents WebUI from trying to fetch the old repo.

**_Make sure the environment variable is correct_**

In webui-user.bat, it should be:
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

- Make sure there are no typos or extra spaces.

Restart WebUI
- Run webui.bat again.
- It should now clone/fetch the w-e-w repository.

Optional: test cloning manually

cd C:\AI\stable-diffusion-webui\repositories
git clone https://github.com/w-e-w/stablediffusion.git stable-diffusion-stability-a


Violà!",2026-02-09T20:19:26Z,sageliebi-maker,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3873635028,"Got it! The error you’re seeing is explained in the log itself:
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Your WebUI is trying to clone/fetch the old repository https://github.com/Stability-AI/stablediffusion.git,
which no longer exists. This is a common issue with newer versions of
SD WebUI if the STABLE_DIFFUSION_REPO is set incorrectly.

You mentioned in your webui-user.bat:

set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

That’s correct for the w-e-w version. However, your WebUI is still trying to use the old Stability-AI/stablediffusion repo. This usually happens if the variable wasn’t picked up correctly or an old repository already exists.

**Step-by-Step Fix**

**_Delete the old repository_**

Go to:
C:\AI\stable-diffusion-webui\repositories\

- Delete the folder stable-diffusion-stability-ai.
- This prevents WebUI from trying to fetch the old repo.

**_Make sure the environment variable is correct_**

In webui-user.bat, it should be:
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

- Make sure there are no typos or extra spaces.

Restart WebUI
- Run webui.bat again.
- It should now clone/fetch the w-e-w repository.

Optional: test cloning manually

cd C:\AI\stable-diffusion-webui\repositories
git clone https://github.com/w-e-w/stablediffusion.git stable-diffusion-stability-a


Violà!",got error youre seeing explained log remote repository found fatal repository found webui trying clone fetch old repository longer exists common issue newer versions sd webui stable diffusion repo set incorrectly mentioned webui user bat set stable diffusion repo thats correct w e w version however webui still trying use old stability ai stablediffusion repo usually happens variable wasnt picked correctly old repository already exists step step fix delete old repository go c ai stable diffusion webui repositories delete folder stable diffusion stability ai prevents webui trying fetch old repo make sure environment variable correct webui user bat set stable diffusion repo make sure typos extra spaces restart webui run webui bat clone fetch w e w repository optional test cloning manually cd c ai stable diffusion webui repositories git clone stable diffusion stability viola
auto1111_webui,issue,17251,[Bug]: Error while executing run.bat,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

Download the sd.webui.zip > run update.bat and execute run.bat

### What should have happened?

The webUI should be oppened on localhost:7860

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

None

### Console logs

```Shell
stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",2026-01-17T01:18:39Z,alvvos,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251,"[Bug]: Error while executing run.bat ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

Download the sd.webui.zip > run update.bat and execute run.bat

### What should have happened?

The webUI should be oppened on localhost:7860

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

None

### Console logs

```Shell
stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",bug error executing run bat checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened stderr error exception traceback recent call last file c users alvar downloads sd webui system python lib site packages pip internal cli base command py line run wrapper status inner run file c users alvar downloads sd webui system python lib site packages pip internal cli base command py line inner run return self run options args file c users alvar downloads sd webui system python lib site packages pip internal cli req command py line wrapper return func self options args file c users alvar downloads sd webui system python lib site packages pip internal commands install py line run requirement set resolver resolve file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib resolver py line resolve collected self factory collect root requirements root reqs file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line collect root requirements reqs list file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make requirements install req cand self make base candidate link file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init super init file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs build env installer file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file c users alvar downloads sd webui system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file c users alvar downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file c users alvar downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta steps reproduce problem download sd webui zip run update bat execute run bat happened webui oppened localhost browsers use access ui response sysinfo none console logs shell stderr error exception traceback recent call last file c users alvar downloads sd webui system python lib site packages pip internal cli base command py line run wrapper status inner run file c users alvar downloads sd webui system python lib site packages pip internal cli base command py line inner run return self run options args file c users alvar downloads sd webui system python lib site packages pip internal cli req command py line wrapper return func self options args file c users alvar downloads sd webui system python lib site packages pip internal commands install py line run requirement set resolver resolve file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib resolver py line resolve collected self factory collect root requirements root reqs file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line collect root requirements reqs list file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make requirements install req cand self make base candidate link file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init super init file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file c users alvar downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file c users alvar downloads sd webui system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs build env installer file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file c users alvar downloads sd webui system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file c users alvar downloads sd webui system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file c users alvar downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file c users alvar downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta additional information response
auto1111_webui,comment,17251,,I am facing the same issue.,2026-02-01T13:24:28Z,TheDamnedScientist,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251#issuecomment-3831041657,I am facing the same issue.,facing issue
auto1111_webui,comment,17251,,"I am also facing the same issue

<img width=""1702"" height=""1025"" alt=""Image"" src=""https://github.com/user-attachments/assets/139eabf4-364a-4caa-b0f2-9432929ef970"" />",2026-02-06T07:37:13Z,vaemsdev,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251#issuecomment-3858546960,"I am also facing the same issue

<img width=""1702"" height=""1025"" alt=""Image"" src=""https://github.com/user-attachments/assets/139eabf4-364a-4caa-b0f2-9432929ef970"" />",also facing issue img width height alt image src
auto1111_webui,issue,17245,[Feature Request]:Some sort of Options in the Settings for Automating Various Things if Possible,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature/Enhancement Request:
Could we Possibly Get some sort of Options in the Settings of the Webui to Automate These because its getting a Bit Tiresome to Find the Right ones for these every time 

<img width=""1222"" height=""64"" alt=""Image"" src=""https://github.com/user-attachments/assets/5d147f1b-6010-44fb-bca2-0583b93cf40d"" />
<img width=""937"" height=""97"" alt=""Image"" src=""https://github.com/user-attachments/assets/687ee083-e821-47a5-8abf-022bb8c1b7c1"" />
<img width=""1231"" height=""45"" alt=""Image"" src=""https://github.com/user-attachments/assets/8ccc3784-2b4e-4274-a50e-d046bf5e1869"" />

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2026-01-09T16:31:41Z,LadyFlames,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17245,"[Feature Request]:Some sort of Options in the Settings for Automating Various Things if Possible ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature/Enhancement Request:
Could we Possibly Get some sort of Options in the Settings of the Webui to Automate These because its getting a Bit Tiresome to Find the Right ones for these every time 

<img width=""1222"" height=""64"" alt=""Image"" src=""https://github.com/user-attachments/assets/5d147f1b-6010-44fb-bca2-0583b93cf40d"" />
<img width=""937"" height=""97"" alt=""Image"" src=""https://github.com/user-attachments/assets/687ee083-e821-47a5-8abf-022bb8c1b7c1"" />
<img width=""1231"" height=""45"" alt=""Image"" src=""https://github.com/user-attachments/assets/8ccc3784-2b4e-4274-a50e-d046bf5e1869"" />

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request sort options settings automating various things possible existing issue x searched existing issues checked recent builds commits would feature feature enhancement request could possibly get sort options settings webui automate getting bit tiresome find right ones every time img width height alt image src img width height alt image src img width height alt image src proposed workflow go press additional information response
auto1111_webui,comment,17245,,"this might be what you're looking for https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/User-Interface-Customizations
specifically section on `UI item order`
you can customize the orders of the options to a certain degree
",2026-01-12T07:20:28Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17245#issuecomment-3737187907,"this might be what you're looking for https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/User-Interface-Customizations
specifically section on `UI item order`
you can customize the orders of the options to a certain degree",might looking specifically section ui item order customize orders options certain degree
auto1111_webui,issue,17244,[Feature Request]: appimage,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

stable-diffusion-webui in appimage???????????????

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2026-01-09T00:48:43Z,kmnnmk212-source,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17244,"[Feature Request]: appimage ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

stable-diffusion-webui in appimage???????????????

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request appimage existing issue x searched existing issues checked recent builds commits would feature stable diffusion webui appimage proposed workflow go press additional information response
auto1111_webui,comment,17244,,Okay what the hell?how would an appimage even work with stabel diffusion? it can but its very stupid idea since appimages have prebuild dependencys in it but the files still have to cloned somewhere the only thing different is just running an appimage and what reason you need an appimage.(Im not the developer or helper of the project just a guy giving an opinion and the confusion of the feature enhancement),2026-01-19T19:52:18Z,FemBoyGamerTechGuy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17244#issuecomment-3769900390,Okay what the hell?how would an appimage even work with stabel diffusion? it can but its very stupid idea since appimages have prebuild dependencys in it but the files still have to cloned somewhere the only thing different is just running an appimage and what reason you need an appimage.(Im not the developer or helper of the project just a guy giving an opinion and the confusion of the feature enhancement),okay hell would appimage even work stabel diffusion stupid idea since appimages prebuild dependencys files still cloned somewhere thing different running appimage reason need appimage im developer helper project guy giving opinion confusion feature enhancement
auto1111_webui,issue,17236,[Bug]:  AssertionError: Torch not compiled with CUDA enabled,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when starting web-ui.bat it shows error:
`RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`
when adding argument to variable its not generating and shows error:
`AssertionError: Torch not compiled with CUDA enabled`

### Steps to reproduce the problem

1. get runtimeerror above
2. add --skip-torch-cuda-test to COMMANDLINE_ARGS var
3. generate img2img

### What should have happened?

work

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2026-01-04-08-13.json](https://github.com/user-attachments/files/24420699/sysinfo-2026-01-04-08-13.json)

### Console logs

```Shell
venv ""C:\Users\elmar_86\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [cc6cb27103] from C:\Users\elmar_86\stable-diffusion-webui\models\Stable-diffusion\v1-5-pruned-emaonly.ckpt
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.3s (prepare environment: 0.4s, import torch: 2.6s, import gradio: 0.6s, setup paths: 0.4s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.3s).
Creating model from config: C:\Users\elmar_86\stable-diffusion-webui\configs\v1-inference.yaml
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: AssertionError
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
    _lazy_init()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
    raise AssertionError(""Torch not compiled with CUDA enabled"")
AssertionError: Torch not compiled with CUDA enabled


Stable diffusion model failed to load
Exception in thread Thread-16 (load_model):
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 154, in load_model
    devices.first_time_calculation()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 277, in first_time_calculation
    linear(x)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\extensions-builtin\Lora\networks.py"", line 584, in network_Linear_forward
    return originals.Linear_forward(self, input)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: ""addmm_impl_cpu_"" not implemented for 'Half'
Using already loaded model v1-5-pruned-emaonly.ckpt [cc6cb27103]: done in 0.0s
*** Error completing request
*** Arguments: ('task(iba2sr0ecdrv7hs)', <gradio.routes.Request object at 0x0000020525B6FC40>, 0, 'improve quality', 'sketch art, worse quality', [], <PIL.Image.Image image mode=RGBA size=423x525 at 0x20525B6FBE0>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 512, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
        _lazy_init()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
        raise AssertionError(""Torch not compiled with CUDA enabled"")
    AssertionError: Torch not compiled with CUDA enabled

---
```

### Additional information

_No response_",2026-01-04T08:16:38Z,WhO2022,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17236,"[Bug]:  AssertionError: Torch not compiled with CUDA enabled ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when starting web-ui.bat it shows error:
`RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`
when adding argument to variable its not generating and shows error:
`AssertionError: Torch not compiled with CUDA enabled`

### Steps to reproduce the problem

1. get runtimeerror above
2. add --skip-torch-cuda-test to COMMANDLINE_ARGS var
3. generate img2img

### What should have happened?

work

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2026-01-04-08-13.json](https://github.com/user-attachments/files/24420699/sysinfo-2026-01-04-08-13.json)

### Console logs

```Shell
venv ""C:\Users\elmar_86\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [cc6cb27103] from C:\Users\elmar_86\stable-diffusion-webui\models\Stable-diffusion\v1-5-pruned-emaonly.ckpt
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.3s (prepare environment: 0.4s, import torch: 2.6s, import gradio: 0.6s, setup paths: 0.4s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.3s).
Creating model from config: C:\Users\elmar_86\stable-diffusion-webui\configs\v1-inference.yaml
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: AssertionError
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
    _lazy_init()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
    raise AssertionError(""Torch not compiled with CUDA enabled"")
AssertionError: Torch not compiled with CUDA enabled


Stable diffusion model failed to load
Exception in thread Thread-16 (load_model):
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 154, in load_model
    devices.first_time_calculation()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 277, in first_time_calculation
    linear(x)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\extensions-builtin\Lora\networks.py"", line 584, in network_Linear_forward
    return originals.Linear_forward(self, input)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: ""addmm_impl_cpu_"" not implemented for 'Half'
Using already loaded model v1-5-pruned-emaonly.ckpt [cc6cb27103]: done in 0.0s
*** Error completing request
*** Arguments: ('task(iba2sr0ecdrv7hs)', <gradio.routes.Request object at 0x0000020525B6FC40>, 0, 'improve quality', 'sketch art, worse quality', [], <PIL.Image.Image image mode=RGBA size=423x525 at 0x20525B6FBE0>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 512, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
        _lazy_init()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
        raise AssertionError(""Torch not compiled with CUDA enabled"")
    AssertionError: Torch not compiled with CUDA enabled

---
```

### Additional information

_No response_",bug assertionerror torch compiled cuda enabled checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened starting web ui bat shows error runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check adding argument variable generating shows error assertionerror torch compiled cuda enabled steps reproduce problem get runtimeerror add skip torch cuda test commandline args var generate img img happened work browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell venv c users elmar stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments skip torch cuda test c users elmar stable diffusion webui venv lib site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without warning caught exception torch compiled cuda enabled memory monitor disabled loading weights cc cb c users elmar stable diffusion webui models stable diffusion v pruned emaonly ckpt running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths imports load scripts create ui gradio launch creating model config c users elmar stable diffusion webui configs v inference yaml c users elmar stable diffusion webui venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn applying attention optimization invokeai done loading stable diffusion model assertionerror traceback recent call last file c users elmar appdata local programs python python lib threading py line bootstrap self bootstrap inner file c users elmar appdata local programs python python lib threading py line bootstrap inner self run file c users elmar appdata local programs python python lib threading py line run self target self args self kwargs file c users elmar stable diffusion webui modules initialize py line load model shared sd model noqa b file c users elmar stable diffusion webui modules shared items py line sd model return modules sd models model data get sd model file c users elmar stable diffusion webui modules sd models py line get sd model load model file c users elmar stable diffusion webui modules sd models py line load model devices autocast torch grad file c users elmar stable diffusion webui modules devices py line autocast xpu mps cuda autocast file c users elmar stable diffusion webui modules devices py line cuda autocast device id get cuda device id file c users elmar stable diffusion webui modules devices py line get cuda device id torch cuda current device file c users elmar stable diffusion webui venv lib site packages torch cuda init py line current device lazy init file c users elmar stable diffusion webui venv lib site packages torch cuda init py line lazy init raise assertionerror torch compiled cuda enabled assertionerror torch compiled cuda enabled stable diffusion model failed load exception thread thread load model traceback recent call last file c users elmar appdata local programs python python lib threading py line bootstrap inner self run file c users elmar appdata local programs python python lib threading py line run self target self args self kwargs file c users elmar stable diffusion webui modules initialize py line load model devices first time calculation file c users elmar stable diffusion webui modules devices py line first time calculation linear x file c users elmar stable diffusion webui venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users elmar stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users elmar stable diffusion webui extensions builtin lora networks py line network linear forward return originals linear forward self input file c users elmar stable diffusion webui venv lib site packages torch nn modules linear py line forward return f linear input self weight self bias runtimeerror addmm impl cpu implemented half using already loaded model v pruned emaonly ckpt cc cb done error completing request arguments task iba sr ecdrv hs gradio routes request object x b fc improve quality sketch art worse quality pil image image image mode rgba size x x b fbe none none none none none none false upload none false dpm automatic false false cfg scale lower true true true true false linear none p style margin bottom em recommended settings sampling steps sampler euler denoising strength p left right left right false false positive comma false false start p style margin bottom em upscale image selected scale factor use width height sliders set tile size p true false false false false false false false traceback recent call last file c users elmar stable diffusion webui modules call queue py line f res list func args kwargs file c users elmar stable diffusion webui modules call queue py line f res func args kwargs file c users elmar stable diffusion webui modules call queue py line f res func args kwargs file c users elmar stable diffusion webui modules img img py line img img processed process images p file c users elmar stable diffusion webui modules processing py line process images res process images inner p file c users elmar stable diffusion webui modules processing py line process images inner devices autocast file c users elmar stable diffusion webui modules devices py line autocast xpu mps cuda autocast file c users elmar stable diffusion webui modules devices py line cuda autocast device id get cuda device id file c users elmar stable diffusion webui modules devices py line get cuda device id torch cuda current device file c users elmar stable diffusion webui venv lib site packages torch cuda init py line current device lazy init file c users elmar stable diffusion webui venv lib site packages torch cuda init py line lazy init raise assertionerror torch compiled cuda enabled assertionerror torch compiled cuda enabled additional information response
auto1111_webui,comment,17235,,"This is a known issue with downloading the zip folder. A fix has been merged into the dev branch, which updates webui to clone from a working fork. 
Be sure to clone the repository, and not download the zip file. 
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
#17213 ",2026-01-04T08:17:51Z,grilledpanini,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3707856241,"This is a known issue with downloading the zip folder. A fix has been merged into the dev branch, which updates webui to clone from a working fork. 
Be sure to clone the repository, and not download the zip file. 
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
#17213",known issue downloading zip folder fix merged dev branch updates webui clone working fork sure clone repository download zip file git clone cd stable diffusion webui git switch dev git pull
auto1111_webui,comment,17235,,"Thanks a lot! This is super helpful! Would it be possible to add this important information to the repo’s homepage? I think a lot of people would benefit from it.

<img width=""1061"" height=""278"" alt=""Image"" src=""https://github.com/user-attachments/assets/7b4aff98-39e2-4d7c-97fa-93a27e28d3a5"" />",2026-01-15T14:57:05Z,crawlingsnail9,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3755268912,"Thanks a lot! This is super helpful! Would it be possible to add this important information to the repo’s homepage? I think a lot of people would benefit from it.

<img width=""1061"" height=""278"" alt=""Image"" src=""https://github.com/user-attachments/assets/7b4aff98-39e2-4d7c-97fa-93a27e28d3a5"" />",thanks lot super helpful would possible add important information repos homepage think lot people would benefit img width height alt image src
auto1111_webui,comment,17235,,"Thank you for this issue, i got a lot of error but now it works!",2026-01-17T18:09:40Z,DaniNotFound702,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3764172511,"Thank you for this issue, i got a lot of error but now it works!",thank issue got lot error works
auto1111_webui,comment,17235,,"> git pull

It seems that the dev version Pytorch version has become 2.7.0，and doesn't support my V100 GPU any more

RuntimeError: CUDA error: no kernel image is available for execution on the device

I‘m using Ubuntu and Tesla V100",2026-01-19T17:00:48Z,Cryghast,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3769378299,"> git pull

It seems that the dev version Pytorch version has become 2.7.0，and doesn't support my V100 GPU any more

RuntimeError: CUDA error: no kernel image is available for execution on the device

I‘m using Ubuntu and Tesla V100",git pull seems dev version pytorch version become support v gpu runtimeerror cuda error kernel image available execution device im using ubuntu tesla v
auto1111_webui,issue,17227,[Bug]: Installation fails due to missing Git submodule https://github.com/Stability-AI/stablediffusion.git,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installation fails immediately because the launcher tries to clone a GitHub repository that no longer exists (https://github.com/Stability-AI/stablediffusion.git). This causes a fatal Git error and prevents the WebUI from starting, even with a correct Python setup or when using the release ZIP. This blocks new users from installing the software.

### Steps to reproduce the problem


Download the latest official release ZIP of stable-diffusion-webui from the AUTOMATIC1111 GitHub.
Extract the ZIP on Windows.
Run webui-user.bat.
During startup, the launcher attempts to clone https://github.com/Stability-AI/stablediffusion.git.
The repository does not exist, causing a Git error (Error 128).
The WebUI stops and does not launch.

### What should have happened?

The WebUI should launch successfully without Git errors, complete setup automatically, and open the user interface in the browser.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Sysinfo unavailable:
WebUI cannot be started due to a fatal Git clone error during initial launch (Stability-AI/stablediffusion.git repository not found). The installation folder was removed after repeated failed attempts, so a sysinfo file could not be generated.

### Console logs

```Shell
Console logs unavailable:
The WebUI fails during initial startup before the interface or logging system initializes. The process stops with a fatal Git error while attempting to clone https://github.com/Stability-AI/stablediffusion.git (repository not found). Because the UI never successfully starts and the installation folder was removed after repeated failures, full console logs cannot be provided.
```

### Additional information

This issue occurs on a clean setup following the official installation instructions, with no local modifications. The failure happens consistently on first launch and appears to be caused by a hard-coded reference to a deleted GitHub repository, not by environment configuration.",2025-12-29T06:00:36Z,nellappli-nell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227,"[Bug]: Installation fails due to missing Git submodule https://github.com/Stability-AI/stablediffusion.git ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installation fails immediately because the launcher tries to clone a GitHub repository that no longer exists (https://github.com/Stability-AI/stablediffusion.git). This causes a fatal Git error and prevents the WebUI from starting, even with a correct Python setup or when using the release ZIP. This blocks new users from installing the software.

### Steps to reproduce the problem


Download the latest official release ZIP of stable-diffusion-webui from the AUTOMATIC1111 GitHub.
Extract the ZIP on Windows.
Run webui-user.bat.
During startup, the launcher attempts to clone https://github.com/Stability-AI/stablediffusion.git.
The repository does not exist, causing a Git error (Error 128).
The WebUI stops and does not launch.

### What should have happened?

The WebUI should launch successfully without Git errors, complete setup automatically, and open the user interface in the browser.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Sysinfo unavailable:
WebUI cannot be started due to a fatal Git clone error during initial launch (Stability-AI/stablediffusion.git repository not found). The installation folder was removed after repeated failed attempts, so a sysinfo file could not be generated.

### Console logs

```Shell
Console logs unavailable:
The WebUI fails during initial startup before the interface or logging system initializes. The process stops with a fatal Git error while attempting to clone https://github.com/Stability-AI/stablediffusion.git (repository not found). Because the UI never successfully starts and the installation folder was removed after repeated failures, full console logs cannot be provided.
```

### Additional information

This issue occurs on a clean setup following the official installation instructions, with no local modifications. The failure happens consistently on first launch and appears to be caused by a hard-coded reference to a deleted GitHub repository, not by environment configuration.",bug installation fails due missing git submodule checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened installation fails immediately launcher tries clone github repository longer exists causes fatal git error prevents webui starting even correct python setup using release zip blocks new users installing software steps reproduce problem download latest official release zip stable diffusion webui automatic github extract zip windows run webui user bat startup launcher attempts clone repository exist causing git error error webui stops launch happened webui launch successfully without git errors complete setup automatically open user interface browser browsers use access ui mozilla firefox sysinfo sysinfo unavailable webui cannot started due fatal git clone error initial launch stability ai stablediffusion git repository found installation folder removed repeated failed attempts sysinfo file could generated console logs shell console logs unavailable webui fails initial startup interface logging system initializes process stops fatal git error attempting clone repository found ui never successfully starts installation folder removed repeated failures full console logs cannot provided additional information issue occurs clean setup following official installation instructions local modifications failure happens consistently first launch appears caused hard coded reference deleted github repository environment configuration
auto1111_webui,comment,17227,,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17213

This worked for me.",2025-12-29T10:15:25Z,Arcxsun,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696072020,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17213

This worked for me.",worked
auto1111_webui,comment,17227,,"It appears that all new fixes go to the dev branch now, not master.",2025-12-29T10:41:57Z,nick-morhun,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696135080,"It appears that all new fixes go to the dev branch now, not master.",appears new fixes go dev branch master
auto1111_webui,comment,17227,,"Thanks for the clarification.
This confirms the issue: the default install still targets master, which is currently broken, while fixes only exist on dev.
This causes fresh installs to fail before the UI can start. Either master needs to be fixed, or the installer/docs should explicitly default to dev to prevent broken first-time installs.",2025-12-29T14:22:31Z,nellappli-nell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696664541,"Thanks for the clarification.
This confirms the issue: the default install still targets master, which is currently broken, while fixes only exist on dev.
This causes fresh installs to fail before the UI can start. Either master needs to be fixed, or the installer/docs should explicitly default to dev to prevent broken first-time installs.",thanks clarification confirms issue default install still targets master currently broken fixes exist dev causes fresh installs fail ui start either master needs fixed installer docs explicitly default dev prevent broken first time installs
auto1111_webui,comment,17227,,"You've provided excellent documentation of this issue. This is indeed the same Stability-AI repository problem affecting many users today.

The repository https://github.com/Stability-AI/stablediffusion.git has been taken down (404), breaking all new installations.

Since you mentioned this affects even the official release ZIP, the issue is in the hardcoded repository URL in the codebase. The maintainers need to update this to point to an alternative repository.

For now, there's no clean workaround for new installations. Keep watching the repo for an official fix - this is a critical blocker affecting everyone trying to install.",2025-12-30T00:48:14Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3697937491,"You've provided excellent documentation of this issue. This is indeed the same Stability-AI repository problem affecting many users today.

The repository https://github.com/Stability-AI/stablediffusion.git has been taken down (404), breaking all new installations.

Since you mentioned this affects even the official release ZIP, the issue is in the hardcoded repository URL in the codebase. The maintainers need to update this to point to an alternative repository.

For now, there's no clean workaround for new installations. Keep watching the repo for an official fix - this is a critical blocker affecting everyone trying to install.",provided excellent documentation issue indeed stability ai repository problem affecting many users today repository taken breaking new installations since mentioned affects even official release zip issue hardcoded repository url codebase maintainers need update point alternative repository clean workaround new installations keep watching repo official fix critical blocker affecting everyone trying install
auto1111_webui,comment,17227,,duplicate from [https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204),2025-12-30T13:05:33Z,xoxefdp,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3699304399,duplicate from [https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204),duplicate
auto1111_webui,comment,17227,,"@nellappli-nell  You can try add on `webui.bat`, it works for me

```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```",2026-01-01T15:17:23Z,yassershahofficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3703816303,"@nellappli-nell  You can try add on `webui.bat`, it works for me

```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```",nellappli nell try add webui bat works set stable diffusion repo set stable diffusion commit hash f e b e eb b
auto1111_webui,comment,17227,,"I updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) so the fix is included by default
uses who use that package (assuming that package works for them) don't need to add the add
```bat
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```
if they launch using `run.bat`

---

for people manually cloning and installing the master branch there's nothing much we can do
AUTOMATIC1111 is the only one with the privileges to update the master branch and he's gone silent
me and one other collaborator only have access to the dev branch, and we have fixed dev branch
I have pinned a guide on how to fix ths issue, but people don't read it
",2026-01-05T21:49:31Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3712204689,"I updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) so the fix is included by default
uses who use that package (assuming that package works for them) don't need to add the add
```bat
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```
if they launch using `run.bat`

---

for people manually cloning and installing the master branch there's nothing much we can do
AUTOMATIC1111 is the only one with the privileges to update the master branch and he's gone silent
me and one other collaborator only have access to the dev branch, and we have fixed dev branch
I have pinned a guide on how to fix ths issue, but people don't read it",updated sd webui zip fix included default uses use package assuming package works need add add bat set stable diffusion repo launch using run bat people manually cloning installing master branch nothing much automatic one privileges update master branch gone silent one collaborator access dev branch fixed dev branch pinned guide fix ths issue people read
auto1111_webui,comment,17227,,"There no way to install ? always have a error and open a window of login git hub, ",2026-01-07T13:54:56Z,ZIGAIBNX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3719006593,"There no way to install ? always have a error and open a window of login git hub,",way install always error open window login git hub
auto1111_webui,comment,17227,,"> [@nellappli-nell](https://github.com/nellappli-nell) You can try add on `webui.bat`, it works for me
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```

yes this worked for me thx :)",2026-01-17T05:21:03Z,god-sriji,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3762685158,"> [@nellappli-nell](https://github.com/nellappli-nell) You can try add on `webui.bat`, it works for me
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```

yes this worked for me thx :)",nellappli nell try add webui bat works set stable diffusion repo set stable diffusion commit hash f e b e eb b yes worked thx
auto1111_webui,comment,17227,,"**我的报错：**
stderr: fatal: unable to access 'https://github.com/Stability-AI/stablediffusion.git/': Recv failure: Connection was reset
[Exited, code 1 (0x00000001)]

**解决方法：**

步骤 1：找到目标文件
打开路径：...\sd-webui-aki-v4.11.1-cu128\modules\launch_utils.py
步骤 2：替换 git_clone 函数代码
将文件中原始的 git_clone 函数全部删除，替换为以下修改后的代码（已注释所有网络操作，保留本地文件夹判断）：
`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful
    # 核心修改：本地文件夹存在则直接返回，跳过所有网络操作（fetch/checkout/remote）
    if os.path.exists(dir):
        print(f""本地已存在{name}仓库，跳过所有Git网络操作，直接使用本地文件"")
        return

    # 仅当本地无文件夹时，才执行克隆（可选：注释掉克隆，彻底禁用网络）
    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    # 注释掉哈希校验，避免后续网络请求
    # if commithash is not None:
    #     run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, f""Couldn't checkout {name}'s hash: {commithash}"")
`

步骤 3：确保本地有完整的仓库文件夹
确认repositories下有完整的stable-diffusion-stability-ai文件夹（若没有，按以下方式获取）：
    下载国内镜像包：https://github.com/w-e-w/stablediffusion/archive/refs/heads/main.zip
    解压后将文件夹重命名为stable-diffusion-stability-ai
    放到路径：...\sd-webui-aki-v4.11.1-cu128\repositories\

步骤 4：保存文件并启动
    保存launch_utils.py（若提示权限不足，右键文件→属性→安全，给当前用户添加写入权限）
    双击 SD-WebUI 启动器，此时会直接跳过 Git 网络操作，无报错启动。


附：
被替换的那段原代码：

`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful

    if os.path.exists(dir):
        if commithash is None:
            return

        current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
        if current_hash == commithash:
            return

        if run_git(dir, name, 'config --get remote.origin.url', None, f""Couldn't determine {name}'s origin URL"", live=False).strip() != url:
            run_git(dir, name, f'remote set-url origin ""{url}""', None, f""Failed to set {name}'s origin URL"", live=False)

        run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)

        run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)

        return

    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    if commithash is not None:
        run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, ""Couldn't checkout {name}'s hash: {commithash}"")
`",2026-02-07T04:16:19Z,renxingblack,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3863540453,"**我的报错：**
stderr: fatal: unable to access 'https://github.com/Stability-AI/stablediffusion.git/': Recv failure: Connection was reset
[Exited, code 1 (0x00000001)]

**解决方法：**

步骤 1：找到目标文件
打开路径：...\sd-webui-aki-v4.11.1-cu128\modules\launch_utils.py
步骤 2：替换 git_clone 函数代码
将文件中原始的 git_clone 函数全部删除，替换为以下修改后的代码（已注释所有网络操作，保留本地文件夹判断）：
`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful
    # 核心修改：本地文件夹存在则直接返回，跳过所有网络操作（fetch/checkout/remote）
    if os.path.exists(dir):
        print(f""本地已存在{name}仓库，跳过所有Git网络操作，直接使用本地文件"")
        return

    # 仅当本地无文件夹时，才执行克隆（可选：注释掉克隆，彻底禁用网络）
    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    # 注释掉哈希校验，避免后续网络请求
    # if commithash is not None:
    #     run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, f""Couldn't checkout {name}'s hash: {commithash}"")
`

步骤 3：确保本地有完整的仓库文件夹
确认repositories下有完整的stable-diffusion-stability-ai文件夹（若没有，按以下方式获取）：
    下载国内镜像包：https://github.com/w-e-w/stablediffusion/archive/refs/heads/main.zip
    解压后将文件夹重命名为stable-diffusion-stability-ai
    放到路径：...\sd-webui-aki-v4.11.1-cu128\repositories\

步骤 4：保存文件并启动
    保存launch_utils.py（若提示权限不足，右键文件→属性→安全，给当前用户添加写入权限）
    双击 SD-WebUI 启动器，此时会直接跳过 Git 网络操作，无报错启动。


附：
被替换的那段原代码：

`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful

    if os.path.exists(dir):
        if commithash is None:
            return

        current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
        if current_hash == commithash:
            return

        if run_git(dir, name, 'config --get remote.origin.url', None, f""Couldn't determine {name}'s origin URL"", live=False).strip() != url:
            run_git(dir, name, f'remote set-url origin ""{url}""', None, f""Failed to set {name}'s origin URL"", live=False)

        run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)

        run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)

        return

    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    if commithash is not None:
        run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, ""Couldn't checkout {name}'s hash: {commithash}"")
`",stderr fatal unable access recv failure connection reset exited code x sd webui aki v cu modules launch utils py git clone git clone def git clone url dir name commithash none todo clone temporary dir move successful fetch checkout remote os path exists dir print f name git return try run f git clone config core filemode false url dir f cloning name dir f clone name live true except runtimeerror shutil rmtree dir ignore errors true raise commithash none run f git c dir checkout commithash none f checkout name hash commithash repositoriesstable diffusion stability ai stable diffusion stability ai sd webui aki v cu repositories launch utils py sd webui git def git clone url dir name commithash none todo clone temporary dir move successful os path exists dir commithash none return current hash run git dir name rev parse head none f determine name hash commithash live false strip current hash commithash return run git dir name config get remote origin url none f determine name origin url live false strip url run git dir name f remote set url origin url none f failed set name origin url live false run git dir name fetch f fetching updates name f fetch name autofix false run git dir name f checkout commithash f checking commit name hash commithash f checkout commit commithash name live true return try run f git clone config core filemode false url dir f cloning name dir f clone name live true except runtimeerror shutil rmtree dir ignore errors true raise commithash none run f git c dir checkout commithash none checkout name hash commithash
auto1111_webui,issue,17225,[Bug]: RuntimeError: Couldn't clone assets.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Cloning assets into /root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
正克隆到 '/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
fatal: 无法访问 'https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git/'：Failed to connect to github.com port 443 after 133654 ms: 连接超时
Traceback (most recent call last):
  File ""/root/stable-diffusion-webui/launch.py"", line 53, in <module>
    main()
  File ""/root/stable-diffusion-webui/launch.py"", line 44, in main
    prepare_environment()
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 443, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 190, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone assets.
Command: ""git"" clone --config core.filemode=false ""https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git"" ""/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets""
Error code: 128

### Steps to reproduce the problem

An error was reported when starting the project

### What should have happened?

The project was successfully launched.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

-

### Console logs

```Shell
-
```

### Additional information

_No response_",2025-12-27T14:17:32Z,Kysen121,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17225,"[Bug]: RuntimeError: Couldn't clone assets. ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Cloning assets into /root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
正克隆到 '/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
fatal: 无法访问 'https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git/'：Failed to connect to github.com port 443 after 133654 ms: 连接超时
Traceback (most recent call last):
  File ""/root/stable-diffusion-webui/launch.py"", line 53, in <module>
    main()
  File ""/root/stable-diffusion-webui/launch.py"", line 44, in main
    prepare_environment()
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 443, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 190, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone assets.
Command: ""git"" clone --config core.filemode=false ""https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git"" ""/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets""
Error code: 128

### Steps to reproduce the problem

An error was reported when starting the project

### What should have happened?

The project was successfully launched.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

-

### Console logs

```Shell
-
```

### Additional information

_No response_",bug runtimeerror clone assets checklist issue exists disabling extensions issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened cannot locate tcmalloc tcmalloc google perftool installed system improves cpu memory usage python main oct gcc version v gfd e c commit hash fd e c b c c b c f c cloning assets root stable diffusion webui repositories stable diffusion webui assets root stable diffusion webui repositories stable diffusion webui assets fatal connect github com port ms traceback recent call last file root stable diffusion webui launch py line module main file root stable diffusion webui launch py line main prepare environment file root stable diffusion webui modules launch utils py line prepare environment git clone assets repo repo dir stable diffusion webui assets assets assets commit hash file root stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file root stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone assets command git clone config core filemode false root stable diffusion webui repositories stable diffusion webui assets error code steps reproduce problem error reported starting project happened project successfully launched browsers use access ui microsoft edge sysinfo console logs shell additional information response
auto1111_webui,comment,17225,,"Thanks for opening this issue! I'm interested in contributing to this. 👋

## 🤔 Understanding the Requirements

To provide the best solution, I'd like to understand:

**Context:**
- What's the current behavior?
- What's the expected/desired behavior?
- What's the impact or use case?

**Scope:**
- Are there any specific requirements or constraints?
- Any preferences for implementation approach?
- Related issues or PRs?

**Success Criteria:**
- What would ""done"" look like for this issue?
- Any specific metrics or tests needed?

## 💪 How I Can Help

I have experience with AUTOMATIC1111 projects and can contribute:

- 🔍 **Investigation**: Research and propose solutions
- 💻 **Implementation**: Write clean, tested code
- ✅ **Testing**: Comprehensive test coverage
- 📚 **Documentation**: Clear docs and examples
- 👀 **Review**: Iterate based on feedback

## 🚀 My Approach

1. Understand requirements thoroughly
2. Research best practices and similar solutions
3. Design before implementing
4. Write tests first (TDD)
5. Implement incrementally
6. Document clearly
7. Iterate based on review

Let me know if this is still open and how I can help! I'm excited to contribute. 🎯

**My relevant experience:**
- Similar projects and features
- Modern development practices
- Open source contribution
- Production system experience

Feel free to assign this to me if you'd like me to work on it! 🙌",2025-12-30T00:48:23Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17225#issuecomment-3697937639,"Thanks for opening this issue! I'm interested in contributing to this. 👋

## 🤔 Understanding the Requirements

To provide the best solution, I'd like to understand:

**Context:**
- What's the current behavior?
- What's the expected/desired behavior?
- What's the impact or use case?

**Scope:**
- Are there any specific requirements or constraints?
- Any preferences for implementation approach?
- Related issues or PRs?

**Success Criteria:**
- What would ""done"" look like for this issue?
- Any specific metrics or tests needed?

## 💪 How I Can Help

I have experience with AUTOMATIC1111 projects and can contribute:

- 🔍 **Investigation**: Research and propose solutions
- 💻 **Implementation**: Write clean, tested code
- ✅ **Testing**: Comprehensive test coverage
- 📚 **Documentation**: Clear docs and examples
- 👀 **Review**: Iterate based on feedback

## 🚀 My Approach

1. Understand requirements thoroughly
2. Research best practices and similar solutions
3. Design before implementing
4. Write tests first (TDD)
5. Implement incrementally
6. Document clearly
7. Iterate based on review

Let me know if this is still open and how I can help! I'm excited to contribute. 🎯

**My relevant experience:**
- Similar projects and features
- Modern development practices
- Open source contribution
- Production system experience

Feel free to assign this to me if you'd like me to work on it! 🙌",thanks opening issue interested contributing understanding requirements provide best solution like understand context current behavior expected desired behavior impact use case scope specific requirements constraints preferences implementation approach related issues prs success criteria would done look like issue specific metrics tests needed help experience automatic projects contribute investigation research propose solutions implementation write clean tested code testing comprehensive test coverage documentation clear docs examples review iterate based feedback approach understand requirements thoroughly research best practices similar solutions design implementing write tests first tdd implement incrementally document clearly iterate based review let know still open help excited contribute relevant experience similar projects features modern development practices open source contribution production system experience feel free assign like work
auto1111_webui,issue,17218,[Bug]: RuntimeError: Couldn't clone Stable Diffusion.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Can't find Repository 

### Steps to reproduce the problem

just start webui-user.bat

### What should have happened?

start webui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't get to WebUI

### Console logs

```Shell
:\AI\stable-diffusion-webui>git pull
Already up to date.
venv ""D:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

_No response_",2025-12-21T17:30:23Z,FireTheHedge,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218,"[Bug]: RuntimeError: Couldn't clone Stable Diffusion. ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Can't find Repository 

### Steps to reproduce the problem

just start webui-user.bat

### What should have happened?

start webui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't get to WebUI

### Console logs

```Shell
:\AI\stable-diffusion-webui>git pull
Already up to date.
venv ""D:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

_No response_",bug runtimeerror clone stable diffusion checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened find repository steps reproduce problem start webui user bat happened start webui browsers use access ui google chrome sysinfo get webui console logs shell ai stable diffusion webui git pull already date venv ai stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e cloning stable diffusion ai stable diffusion webui repositories stable diffusion stability ai cloning ai stable diffusion webui repositories stable diffusion stability ai remote repository found fatal repository found traceback recent call last file ai stable diffusion webui launch py line module main file ai stable diffusion webui launch py line main prepare environment file ai stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file ai stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file ai stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false ai stable diffusion webui repositories stable diffusion stability ai error code additional information response
auto1111_webui,comment,17218,,Same.  The repository has been deleted.,2025-12-21T23:07:14Z,TorvaldUtne,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3679661710,Same.  The repository has been deleted.,repository deleted
auto1111_webui,comment,17218,,"404 not found, any ideas?
",2025-12-22T07:57:17Z,Lizuardi612,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3680908953,"404 not found, any ideas?",found ideas
auto1111_webui,comment,17218,,Where can I get these swap files now?,2025-12-22T08:17:36Z,Desync-Using,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3680975423,Where can I get these swap files now?,get swap files
auto1111_webui,comment,17218,,"> Same. The repository has been deleted.

gave up， plan to use comfyui",2025-12-22T12:01:22Z,903345072,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3681773815,"> Same. The repository has been deleted.

gave up， plan to use comfyui",repository deleted gave plan use comfyui
auto1111_webui,comment,17218,,"Read this discussion, there is a way to fix it https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212",2025-12-22T16:26:58Z,Laura7277,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3682812080,"Read this discussion, there is a way to fix it https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212",read discussion way fix
auto1111_webui,comment,17218,,"Modify the contents of webui-user.bat

@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

call webui.bat",2025-12-23T08:12:10Z,akunone,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3685657243,"Modify the contents of webui-user.bat

@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

call webui.bat",modify contents webui user bat echo set python set git set venv dir set commandline args set stable diffusion repo call webui bat
auto1111_webui,comment,17218,,"Switch to the ```dev``` branch, or do this:

Delete the ```repositories``` folder.

Open modules>launch_utils.py

Change Line 349 from

 ```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")```

to

```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")```

Launch webui-user.bat again.


",2025-12-23T12:36:47Z,kavyamali,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3686500416,"Switch to the ```dev``` branch, or do this:

Delete the ```repositories``` folder.

Open modules>launch_utils.py

Change Line 349 from

 ```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")```

to

```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")```

Launch webui-user.bat again.",switch dev branch delete repositories folder open modules launch utils py change line stable diffusion repo os environ get stable diffusion repo stable diffusion repo os environ get stable diffusion repo launch webui user bat
auto1111_webui,comment,17218,,"For Mac users:
in `webui-user.sh` file add this line: 
```bash
export STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```",2025-12-24T22:18:05Z,zjor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3690560549,"For Mac users:
in `webui-user.sh` file add this line: 
```bash
export STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```",mac users webui user sh file add line bash export stable diffusion repo
auto1111_webui,comment,17218,,"Me, too!
我修改到了dev分支：
cd /d C:\Users\Administrator\Desktop\Projects\stable-diffusion-webui
git switch dev
git pull",2025-12-26T01:36:06Z,zhhehe8,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3691899786,"Me, too!
我修改到了dev分支：
cd /d C:\Users\Administrator\Desktop\Projects\stable-diffusion-webui
git switch dev
git pull",dev cd c users administrator desktop projects stable diffusion webui git switch dev git pull
auto1111_webui,comment,17218,,"Another user hit by the Stability-AI repo being down. This is the main issue affecting fresh installs today.

Error 128 indicates git failed to clone because the repository at https://github.com/Stability-AI/stablediffusion.git no longer exists (404).

This needs to be fixed at the project level - the repo URL needs to be updated to a working alternative. Keep checking the main repo for updates from the maintainers.",2025-12-30T00:48:33Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3697937780,"Another user hit by the Stability-AI repo being down. This is the main issue affecting fresh installs today.

Error 128 indicates git failed to clone because the repository at https://github.com/Stability-AI/stablediffusion.git no longer exists (404).

This needs to be fixed at the project level - the repo URL needs to be updated to a working alternative. Keep checking the main repo for updates from the maintainers.",another user hit stability ai repo main issue affecting fresh installs today error indicates git failed clone repository longer exists needs fixed project level repo url needs updated working alternative keep checking main repo updates maintainers
auto1111_webui,comment,17218,,Same issue. Please fix it.,2026-01-17T16:48:08Z,tianxuanliu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3764096436,Same issue. Please fix it.,issue please fix
auto1111_webui,issue,17217,[Bug]: Cannot import 'setuptools.build_meta',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

It's sayed I need Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

use run.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't go in it

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 2
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\fires\appdata\local\temp\pip-req-build-4j1bd_oe
  Resolved https://github.com/TencentARC/GFPGAN.git to commit 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\fires\AppData\Local\Temp\pip-req-build-4j1bd_oe'
  Running command git rev-parse -q --verify 'sha^8d2447a2d918f8eba5a4a01463fd48e45126a379'
  Running command git fetch -q https://github.com/TencentARC/GFPGAN.git 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Running command git checkout -q 8d2447a2d918f8eba5a4a01463fd48e45126a379
ERROR: Exception:
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'


Для продолжения нажмите любую клавишу . . .
```

### Additional information

_No response_",2025-12-21T16:11:15Z,FireTheHedge,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217,"[Bug]: Cannot import 'setuptools.build_meta' ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

It's sayed I need Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

use run.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't go in it

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 2
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\fires\appdata\local\temp\pip-req-build-4j1bd_oe
  Resolved https://github.com/TencentARC/GFPGAN.git to commit 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\fires\AppData\Local\Temp\pip-req-build-4j1bd_oe'
  Running command git rev-parse -q --verify 'sha^8d2447a2d918f8eba5a4a01463fd48e45126a379'
  Running command git fetch -q https://github.com/TencentARC/GFPGAN.git 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Running command git checkout -q 8d2447a2d918f8eba5a4a01463fd48e45126a379
ERROR: Exception:
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'


Для продолжения нажмите любую клавишу . . .
```

### Additional information

_No response_",bug cannot import setuptools build meta checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened sayed need cannot import setuptools build meta steps reproduce problem use run bat happened know browsers use access ui google chrome sysinfo go console logs shell python tags v c b bd aug msc v bit amd commit hash de fea e f df df fddf f b installing gfpgan traceback recent call last file programs windows tools python ai sd webui webui launch py line module prepare environment file programs windows tools python ai sd webui webui launch py line prepare environment run pip f install gfpgan package gfpgan file programs windows tools python ai sd webui webui launch py line run pip return run f python pip args prefer binary index url line desc f installing desc errdesc f install desc file programs windows tools python ai sd webui webui launch py line run raise runtimeerror message runtimeerror install gfpgan command programs windows tools python ai sd webui system python python exe pip install git prefer binary error code stdout collecting git cloning revision f eba fd e c users fires appdata local temp pip req build j bd oe resolved commit f eba fd e installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done stderr running command git clone filter blob none quiet c users fires appdata local temp pip req build j bd oe running command git rev parse q verify sha f eba fd e running command git fetch q f eba fd e running command git checkout q f eba fd e error exception traceback recent call last file programs windows tools python ai sd webui system python lib site packages pip internal cli base command py line run wrapper status inner run file programs windows tools python ai sd webui system python lib site packages pip internal cli base command py line inner run return self run options args file programs windows tools python ai sd webui system python lib site packages pip internal cli req command py line wrapper return func self options args file programs windows tools python ai sd webui system python lib site packages pip internal commands install py line run requirement set resolver resolve file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib resolver py line resolve collected self factory collect root requirements root reqs file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib factory py line collect root requirements reqs list file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib factory py line make requirements install req cand self make base candidate link file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib candidates py line init super init file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file programs windows tools python ai sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file programs windows tools python ai sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file programs windows tools python ai sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file programs windows tools python ai sd webui system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file programs windows tools python ai sd webui system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs build env installer file programs windows tools python ai sd webui system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file programs windows tools python ai sd webui system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file programs windows tools python ai sd webui system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file programs windows tools python ai sd webui system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file programs windows tools python ai sd webui system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta additional information response
auto1111_webui,comment,17217,,Duplicate of #17162 ,2025-12-25T05:59:42Z,4piu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3690975975,Duplicate of #17162,duplicate
auto1111_webui,comment,17217,,"This is a different issue from the repository 404 errors others are experiencing. Your error is about setuptools.

The issue is that pip can't import 'setuptools.build_meta' when trying to install GFPGAN. This typically happens when setuptools is outdated or corrupted.

Try this fix:
1. Navigate to your webui directory
2. Run: 
3. Then try running webui-user.bat again

If that doesn't work, you might need to delete the venv folder and let it rebuild from scratch.",2025-12-30T00:48:42Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3697937922,"This is a different issue from the repository 404 errors others are experiencing. Your error is about setuptools.

The issue is that pip can't import 'setuptools.build_meta' when trying to install GFPGAN. This typically happens when setuptools is outdated or corrupted.

Try this fix:
1. Navigate to your webui directory
2. Run: 
3. Then try running webui-user.bat again

If that doesn't work, you might need to delete the venv folder and let it rebuild from scratch.",different issue repository errors others experiencing error setuptools issue pip import setuptools build meta trying install gfpgan typically happens setuptools outdated corrupted try fix navigate webui directory run try running webui user bat work might need delete venv folder let rebuild scratch
auto1111_webui,comment,17217,,"Maybe Python is just not installed on that OS installation ? 
I know it is my case, with the same error message. ",2026-01-18T01:05:45Z,Baraz-Siriel,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3764555160,"Maybe Python is just not installed on that OS installation ? 
I know it is my case, with the same error message.",maybe python installed os installation know case error message
auto1111_webui,issue,17216,[Bug]: Repository not found.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when I run webui-user.bat, I get an error saying that there is no such repository! I tried to fix it using chatGPT, but it didn't work...

<img width=""983"" height=""860"" alt=""Image"" src=""https://github.com/user-attachments/assets/3aa51a46-dfc8-4716-9298-66f20e19e80f"" />

### Steps to reproduce the problem

clone the repository and open webui-user.bat

### What should have happened?

localhost and neural network will be launched

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

.

### Console logs

```Shell
Creating venv in directory E:\!2\stable-diffusion-webui\venv using python ""C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe""
Requirement already satisfied: pip in e:\!2\stable-diffusion-webui\venv\lib\site-packages (22.0.4)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.0.4
    Uninstalling pip-22.0.4:
      Successfully uninstalled pip-22.0.4
Successfully installed pip-25.3
venv ""E:\!2\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.1-py3-none-any.whl (16 kB)
Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)
Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.1 fsspec-2025.12.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.0.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.2
Installing clip
Installing open_clip
Installing xformers
Cloning Stable Diffusion into E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

webui-user.bat :
@echo off
set PYTHON=C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe
set COMMANDLINE_ARGS=--medvram --xformers --listen
call webui.bat
",2025-12-21T09:21:18Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216,"[Bug]: Repository not found. ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when I run webui-user.bat, I get an error saying that there is no such repository! I tried to fix it using chatGPT, but it didn't work...

<img width=""983"" height=""860"" alt=""Image"" src=""https://github.com/user-attachments/assets/3aa51a46-dfc8-4716-9298-66f20e19e80f"" />

### Steps to reproduce the problem

clone the repository and open webui-user.bat

### What should have happened?

localhost and neural network will be launched

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

.

### Console logs

```Shell
Creating venv in directory E:\!2\stable-diffusion-webui\venv using python ""C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe""
Requirement already satisfied: pip in e:\!2\stable-diffusion-webui\venv\lib\site-packages (22.0.4)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.0.4
    Uninstalling pip-22.0.4:
      Successfully uninstalled pip-22.0.4
Successfully installed pip-25.3
venv ""E:\!2\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.1-py3-none-any.whl (16 kB)
Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)
Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.1 fsspec-2025.12.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.0.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.2
Installing clip
Installing open_clip
Installing xformers
Cloning Stable Diffusion into E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

webui-user.bat :
@echo off
set PYTHON=C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe
set COMMANDLINE_ARGS=--medvram --xformers --listen
call webui.bat",bug repository found checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened run webui user bat get error saying repository tried fix using chatgpt work img width height alt image src steps reproduce problem clone repository open webui user bat happened localhost neural network launched browsers use access ui response sysinfo console logs shell creating venv directory e stable diffusion webui venv using python c users harin appdata local programs python python python exe requirement already satisfied pip e stable diffusion webui venv lib site packages collecting pip using cached pip py none whl mb installing collected packages pip attempting uninstall pip found existing installation pip uninstalling pip successfully uninstalled pip successfully installed pip venv e stable diffusion webui venv scripts python exe python tags v f jun msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes collecting torch using cached mb collecting torchvision using cached mb collecting filelock torch using cached filelock py none whl metadata kb collecting typing extensions torch using cached kb collecting sympy torch using cached sympy py none whl metadata kb collecting networkx torch using cached networkx py none whl metadata kb collecting jinja torch using cached kb collecting fsspec torch using cached fsspec py none whl metadata kb collecting numpy torchvision using cached numpy cp cp win amd whl metadata kb collecting requests torchvision using cached requests py none whl metadata kb collecting pillow torchvision using cached pillow cp cp win amd whl metadata kb collecting markupsafe jinja torch using cached markupsafe cp cp win amd whl metadata kb collecting charset normalizer requests torchvision using cached charset normalizer cp cp win amd whl metadata kb collecting idna requests torchvision using cached idna py none whl metadata kb collecting urllib requests torchvision using cached urllib py none whl metadata kb collecting certifi requests torchvision using cached certifi py none whl metadata kb collecting mpmath sympy torch using cached mpmath py none whl metadata kb using cached pillow cp cp win amd whl mb using cached filelock py none whl kb using cached fsspec py none whl kb using cached kb using cached markupsafe cp cp win amd whl kb using cached networkx py none whl mb using cached numpy cp cp win amd whl mb using cached requests py none whl kb using cached charset normalizer cp cp win amd whl kb using cached idna py none whl kb using cached urllib py none whl kb using cached certifi py none whl kb using cached sympy py none whl mb using cached mpmath py none whl kb using cached kb installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna fsspec filelock charset normalizer certifi requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock fsspec idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu typing extensions urllib installing clip installing open clip installing xformers cloning stable diffusion e stable diffusion webui repositories stable diffusion stability ai cloning e stable diffusion webui repositories stable diffusion stability ai remote repository found fatal repository found traceback recent call last file e stable diffusion webui launch py line module main file e stable diffusion webui launch py line main prepare environment file e stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file e stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file e stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false e stable diffusion webui repositories stable diffusion stability ai error code additional information webui user bat echo set python c users harin appdata local programs python python python exe set commandline args medvram xformers listen call webui bat
auto1111_webui,comment,17216,,"I'm sorry, I don't know what to write in ""Sysinfo""",2025-12-21T09:22:19Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3678629683,"I'm sorry, I don't know what to write in ""Sysinfo""",sorry know write sysinfo
auto1111_webui,comment,17216,,"<img width=""1218"" height=""670"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b16e864-059c-45fa-ad34-5cf207333c7a"" />",2025-12-21T09:22:50Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3678629985,"<img width=""1218"" height=""670"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b16e864-059c-45fa-ad34-5cf207333c7a"" />",img width height alt image src
auto1111_webui,comment,17216,,"Looking at the screenshot, the error shows git is failing to find a repository, which typically happens when there's a network/proxy issue or the stable-diffusion-webui-assets repo is being blocked. The path `E:\!2\stable-diffusion-webui` with the exclamation mark could also be causing issues since special characters in paths sometimes break scripts. Try moving your installation to a simpler path like `E:\sd-webui` without special characters. If that doesn't help, check if you can manually run `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git` from command line to see the actual error message, which would tell us if it's a network or authentication problem.",2025-12-30T01:11:01Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3697977733,"Looking at the screenshot, the error shows git is failing to find a repository, which typically happens when there's a network/proxy issue or the stable-diffusion-webui-assets repo is being blocked. The path `E:\!2\stable-diffusion-webui` with the exclamation mark could also be causing issues since special characters in paths sometimes break scripts. Try moving your installation to a simpler path like `E:\sd-webui` without special characters. If that doesn't help, check if you can manually run `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git` from command line to see the actual error message, which would tell us if it's a network or authentication problem.",looking screenshot error shows git failing find repository typically happens network proxy issue stable diffusion webui assets repo blocked path e stable diffusion webui exclamation mark could also causing issues since special characters paths sometimes break scripts try moving installation simpler path like e sd webui without special characters help check manually run git clone command line see actual error message would tell us network authentication problem
auto1111_webui,issue,17214,[Bug]: RuntimeError: Couldn't fetch Stable Diffusion.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

What should I do?



### Steps to reproduce the problem

/

### What should have happened?

Can't open web UI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

/

### Console logs

```Shell
venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
```

### Additional information

_No response_",2025-12-20T15:19:37Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214,"[Bug]: RuntimeError: Couldn't fetch Stable Diffusion. ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

What should I do?



### Steps to reproduce the problem

/

### What should have happened?

Can't open web UI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

/

### Console logs

```Shell
venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
```

### Additional information

_No response_",bug runtimeerror fetch stable diffusion checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened steps reproduce problem happened open web ui browsers use access ui response sysinfo console logs shell venv stablediffusion stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e determine stable diffusion hash cf fd ea aa c df e b da f bdbf attempting autofix fetching contents stable diffusion info please complete authentication browser remote repository found fatal repository found traceback recent call last file stablediffusion stable diffusion webui launch py line module main file stablediffusion stable diffusion webui launch py line main prepare environment file stablediffusion stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file stablediffusion stable diffusion webui modules launch utils py line git clone current hash run git dir name rev parse head none f determine name hash commithash live false strip file stablediffusion stable diffusion webui modules launch utils py line run git git fix workspace dir name file stablediffusion stable diffusion webui modules launch utils py line git fix workspace run f git c dir fetch refetch auto gc f fetching contents name f fetch name live true file stablediffusion stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch stable diffusion command git c stablediffusion stable diffusion webui repositories stable diffusion stability ai fetch refetch auto gc error code additional information response
auto1111_webui,comment,17214,,"I'm still getting the error.

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 176, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 164, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 151, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128

",2025-12-23T14:53:24Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3686918979,"I'm still getting the error.

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 176, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 164, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 151, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128",still getting error venv stablediffusion stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v gfd e c commit hash fd e c b c c b c f c determine stable diffusion hash cf fd ea aa c df e b da f bdbf attempting autofix fetching contents stable diffusion info please complete authentication browser remote repository found fatal repository found traceback recent call last file stablediffusion stable diffusion webui launch py line module main file stablediffusion stable diffusion webui launch py line main prepare environment file stablediffusion stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file stablediffusion stable diffusion webui modules launch utils py line git clone current hash run git dir name rev parse head none f determine name hash commithash live false strip file stablediffusion stable diffusion webui modules launch utils py line run git git fix workspace dir name file stablediffusion stable diffusion webui modules launch utils py line git fix workspace run f git c dir fetch refetch auto gc f fetching contents name f fetch name live true file stablediffusion stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch stable diffusion command git c stablediffusion stable diffusion webui repositories stable diffusion stability ai fetch refetch auto gc error code
auto1111_webui,comment,17214,,"my bad, you have this line in the logs
```sh
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
```
basically webui thinks there is something wrong with your currently downloaded
`stable-diffusion-webui\repositories\stable-diffusion-stability-ai`
so it's calling to GitHub to the original repository to fix it

the fix I provide only works if the for new installs, because when trying to `autofix` the updated url is ignored

in this case the simplest thing to do is to just delete the existing folder `stable-diffusion-webui\repositories\stable-diffusion-stability-ai` then try again, and it will re-clone it
> deleting the folder basically bring you to the same state as a new install",2025-12-23T15:42:44Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687084974,"my bad, you have this line in the logs
```sh
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
```
basically webui thinks there is something wrong with your currently downloaded
`stable-diffusion-webui\repositories\stable-diffusion-stability-ai`
so it's calling to GitHub to the original repository to fix it

the fix I provide only works if the for new installs, because when trying to `autofix` the updated url is ignored

in this case the simplest thing to do is to just delete the existing folder `stable-diffusion-webui\repositories\stable-diffusion-stability-ai` then try again, and it will re-clone it
> deleting the folder basically bring you to the same state as a new install",bad line logs sh determine stable diffusion hash cf fd ea aa c df e b da f bdbf attempting autofix basically webui thinks something wrong currently downloaded stable diffusion webui repositories stable diffusion stability ai calling github original repository fix fix provide works new installs trying autofix updated url ignored case simplest thing delete existing folder stable diffusion webui repositories stable diffusion stability ai try clone deleting folder basically bring state new install
auto1111_webui,comment,17214,,"Thank you! I was able to install it successfully, but I can't generate images.

RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.",2025-12-23T17:49:23Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687475087,"Thank you! I was able to install it successfully, but I can't generate images.

RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.",thank able install successfully generate images runtimeerror cuda error kernel image available execution device cuda kernel errors might asynchronously reported api call stacktrace might incorrect debugging consider passing cuda launch blocking compile torch use cuda dsa enable device side assertions
auto1111_webui,comment,17214,,"you're really not giving me much information to work with other than ""most likely it's not working because of GPU related issue"" 
I can't help you unless you give me more information upload sysinfo
what GPU do you have",2025-12-23T19:54:09Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687817910,"you're really not giving me much information to work with other than ""most likely it's not working because of GPU related issue"" 
I can't help you unless you give me more information upload sysinfo
what GPU do you have",really giving much information work likely working gpu related issue help unless give information upload sysinfo gpu
auto1111_webui,comment,17214,,I'm using a GeForce RTX 5080.,2025-12-23T23:29:01Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3688205043,I'm using a GeForce RTX 5080.,using geforce rtx
auto1111_webui,comment,17214,,"> I'm using a GeForce RTX 5080.

pretty sure you are in the same situation as this person
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199#issuecomment-3687812778

without your assist info I can only guess at your situation
my guess is that currently the torch version installed is on compatible with older gpus

I would try delete venv and try again

base on your log
```
Version: v1.10.1-93-gfd68e0c3
```
you're on dev branch
so it should install the correct version of torch",2025-12-24T07:34:06Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3688946657,"> I'm using a GeForce RTX 5080.

pretty sure you are in the same situation as this person
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199#issuecomment-3687812778

without your assist info I can only guess at your situation
my guess is that currently the torch version installed is on compatible with older gpus

I would try delete venv and try again

base on your log
```
Version: v1.10.1-93-gfd68e0c3
```
you're on dev branch
so it should install the correct version of torch",using geforce rtx pretty sure situation person without assist info guess situation guess currently torch version installed compatible older gpus would try delete venv try base log version v gfd e c dev branch install correct version torch
auto1111_webui,comment,17214,,"I deleted the stable diffusion venv folder and ran it again, but this time I got a different error.
Is there any other information I need?

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 49, in main
    start()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 497, in start
    import webui
  File ""D:\StableDiffusion\stable-diffusion-webui\webui.py"", line 13, in <module>
    initialize.imports()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'",2025-12-24T19:39:24Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3690422253,"I deleted the stable diffusion venv folder and ran it again, but this time I got a different error.
Is there any other information I need?

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 49, in main
    start()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 497, in start
    import webui
  File ""D:\StableDiffusion\stable-diffusion-webui\webui.py"", line 13, in <module>
    initialize.imports()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'",deleted stable diffusion venv folder ran time got different error information need venv stablediffusion stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v gfd e c commit hash fd e c b c c b c f c installing requirements launching web ui arguments traceback recent call last file stablediffusion stable diffusion webui launch py line module main file stablediffusion stable diffusion webui launch py line main start file stablediffusion stable diffusion webui modules launch utils py line start import webui file stablediffusion stable diffusion webui webui py line module initialize imports file stablediffusion stable diffusion webui modules initialize py line imports import pytorch lightning noqa f modulenotfounderror module named pytorch lightning
auto1111_webui,comment,17214,,I restarted it and it worked fine! Thank you for your support so far.,2025-12-24T21:44:58Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3690534342,I restarted it and it worked fine! Thank you for your support so far.,restarted worked fine thank support far
auto1111_webui,comment,17214,,I'm facing the same problem; please tell me how you were able to solve it.,2025-12-25T18:12:33Z,rafee1997,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3691648720,I'm facing the same problem; please tell me how you were able to solve it.,facing problem please tell able solve
auto1111_webui,comment,17214,,"Same issue here - the Stability-AI repository is down. You're getting error 128 because git can't clone from a non-existent repo.

This is affecting multiple users today (see #17205, #17208, #17218). The core problem is https://github.com/Stability-AI/stablediffusion.git returning 404.

Until there's an official fix, your options are limited. The project maintainers will need to update the repository URL in the codebase. Watch for updates in the main repo.",2025-12-30T00:48:59Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3697938204,"Same issue here - the Stability-AI repository is down. You're getting error 128 because git can't clone from a non-existent repo.

This is affecting multiple users today (see #17205, #17208, #17218). The core problem is https://github.com/Stability-AI/stablediffusion.git returning 404.

Until there's an official fix, your options are limited. The project maintainers will need to update the repository URL in the codebase. Watch for updates in the main repo.",issue stability ai repository getting error git clone non existent repo affecting multiple users today see core problem returning official fix options limited project maintainers need update repository url codebase watch updates main repo
auto1111_webui,comment,17214,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:36:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3700286508,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",essentially solved issue written detailed explanation fix see issues questions please make comment post
auto1111_webui,issue,17208,[Bug]: The StableDiffusion Repository is offline.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The StableDiffision Repository is offline, so I cannot use Automatic1111 anymore.

### Steps to reproduce the problem

Run the webui-user.bat and the install breaks when it tries to clone the StableDiffusion git.

### What should have happened?

Automatic1111 should just installed fine.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Not needed

### Console logs

```Shell
Not needed
```

### Additional information

_No response_",2025-12-18T15:21:22Z,RichieRich1891,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208,"[Bug]: The StableDiffusion Repository is offline. ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The StableDiffision Repository is offline, so I cannot use Automatic1111 anymore.

### Steps to reproduce the problem

Run the webui-user.bat and the install breaks when it tries to clone the StableDiffusion git.

### What should have happened?

Automatic1111 should just installed fine.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Not needed

### Console logs

```Shell
Not needed
```

### Additional information

_No response_",bug stablediffusion repository offline checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened stablediffision repository offline cannot use automatic anymore steps reproduce problem run webui user bat install breaks tries clone stablediffusion git happened automatic installed fine browsers use access ui microsoft edge sysinfo needed console logs shell needed additional information response
auto1111_webui,comment,17208,,Same problem,2025-12-19T04:11:27Z,LifeCheckpoint,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3673404975,Same problem,problem
auto1111_webui,comment,17208,,"Please see this link
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3669833420",2025-12-19T12:20:41Z,alles,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3674876261,"Please see this link
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3669833420",please see link
auto1111_webui,comment,17208,,"The Stability-AI repository being offline is affecting everyone right now. This is the root cause preventing new installations.

The immediate issue is that https://github.com/Stability-AI/stablediffusion.git returns 404. This affects all fresh installs and anyone trying to update.

For now, you might want to:
- Use an existing installation if you have one
- Wait for the maintainers to update to a new repository URL
- Or manually modify the launch scripts to skip or use an alternative repo

This seems to be the same issue affecting #17205, #17214, #17218 and others today.",2025-12-30T00:49:08Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3697938339,"The Stability-AI repository being offline is affecting everyone right now. This is the root cause preventing new installations.

The immediate issue is that https://github.com/Stability-AI/stablediffusion.git returns 404. This affects all fresh installs and anyone trying to update.

For now, you might want to:
- Use an existing installation if you have one
- Wait for the maintainers to update to a new repository URL
- Or manually modify the launch scripts to skip or use an alternative repo

This seems to be the same issue affecting #17205, #17214, #17218 and others today.",stability ai repository offline affecting everyone right root cause preventing new installations immediate issue returns affects fresh installs anyone trying update might want use existing installation one wait maintainers update new repository url manually modify launch scripts skip use alternative repo seems issue affecting others today
auto1111_webui,comment,17208,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:34:38Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3700281878,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",essentially solved issue written detailed explanation fix see issues questions please make comment post
auto1111_webui,issue,17205,"[Bug]: Repository not found, error 128","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I run a1111 in the terminal, I see error 128. I tried a clean reinstall of stable diffusion, it didn't help

### Steps to reproduce the problem

1. Launch webui-user.bat
2. You will see GitHub login window
3. Login
4. See error 128

### What should have happened?

You will get this error

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cant lauch webui to produce Sysinfo

### Console logs

```Shell
venv ""E:\Python\stable_diffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: f16630a927e00098b524d687640719e4eb469b76, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""E:\Python\stable_diffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

https://github.com/Stability-AI/stablediffusion - 404 page not found",2025-12-17T10:41:11Z,shyameli,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205,"[Bug]: Repository not found, error 128 ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I run a1111 in the terminal, I see error 128. I tried a clean reinstall of stable diffusion, it didn't help

### Steps to reproduce the problem

1. Launch webui-user.bat
2. You will see GitHub login window
3. Login
4. See error 128

### What should have happened?

You will get this error

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cant lauch webui to produce Sysinfo

### Console logs

```Shell
venv ""E:\Python\stable_diffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: f16630a927e00098b524d687640719e4eb469b76, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""E:\Python\stable_diffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

https://github.com/Stability-AI/stablediffusion - 404 page not found",bug repository found error checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened run terminal see error tried clean reinstall stable diffusion help steps reproduce problem launch webui user bat see github login window login see error happened get error browsers use access ui response sysinfo cant lauch webui produce sysinfo console logs shell venv e python stable diffusion stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e determine stable diffusion hash f e b e eb b attempting autofix fetching contents stable diffusion info please complete authentication browser remote repository found fatal repository found traceback recent call last file e python stable diffusion stable diffusion webui launch py line module main file e python stable diffusion stable diffusion webui launch py line main prepare environment file e python stable diffusion stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file e python stable diffusion stable diffusion webui modules launch utils py line git clone current hash run git dir name rev parse head none f determine name hash commithash live false strip file e python stable diffusion stable diffusion webui modules launch utils py line run git git fix workspace dir name file e python stable diffusion stable diffusion webui modules launch utils py line git fix workspace run f git c dir fetch refetch auto gc f fetching contents name f fetch name live true file e python stable diffusion stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch stable diffusion command git c e python stable diffusion stable diffusion webui repositories stable diffusion stability ai fetch refetch auto gc error code additional information page found
auto1111_webui,comment,17205,,"I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private",2025-12-17T15:26:31Z,khaledadrani,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3665862775,"I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private",think needs done change url latest stable fork original repository looks like went private
auto1111_webui,comment,17205,,"if anyone is looking for a fork, I have a fork under my account
https://github.com/w-e-w/stablediffusion.git

I also made a pr to update it on the dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/17207
",2025-12-18T11:27:25Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3669833420,"if anyone is looking for a fork, I have a fork under my account
https://github.com/w-e-w/stablediffusion.git

I also made a pr to update it on the dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/17207",anyone looking fork fork account also made pr update dev branch
auto1111_webui,comment,17205,,![Image](https://github.com/user-attachments/assets/c87a5c89-79cd-4cf8-b94b-3e6a543943da),2025-12-18T15:16:13Z,bilalaliyu3892-rgb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3670802993,![Image](https://github.com/user-attachments/assets/c87a5c89-79cd-4cf8-b94b-3e6a543943da),image
auto1111_webui,comment,17205,,"Solution:

1. go to stable_diffusion\stable-diffusion-webui\repositories\
2. remove folder stable-diffusion-stability-ai
3. use git bash in repositories\ - git clone https://github.com/Stability-AI/generative-models.git stable-diffusion-stability-ai
4. run webui-user.bat",2025-12-19T03:29:57Z,shyameli,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3673335848,"Solution:

1. go to stable_diffusion\stable-diffusion-webui\repositories\
2. remove folder stable-diffusion-stability-ai
3. use git bash in repositories\ - git clone https://github.com/Stability-AI/generative-models.git stable-diffusion-stability-ai
4. run webui-user.bat",solution go stable diffusion stable diffusion webui repositories remove folder stable diffusion stability ai use git bash repositories git clone stable diffusion stability ai run webui user bat
auto1111_webui,comment,17205,,"> I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private

how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one
",2025-12-21T06:18:31Z,ritz33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3678506194,"> I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private

how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one",think needs done change url latest stable fork original repository looks like went private change url im new shi troubleshooting entirely without knowledge guide change url new one
auto1111_webui,comment,17205,,"> how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one

@ritz33 
I believe you have read
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

what part are you having trouble understanding

---

if you have already figured out is there anything I can add to the post I made to make it more clearer",2025-12-21T08:46:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3678603767,"> how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one

@ritz33 
I believe you have read
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

what part are you having trouble understanding

---

if you have already figured out is there anything I can add to the post I made to make it more clearer",change url im new shi troubleshooting entirely without knowledge guide change url new one ritz believe read part trouble understanding already figured anything add post made make clearer
auto1111_webui,comment,17205,,"I see you're hitting error 128 with the missing Stability-AI repository. This is a widespread issue right now - the original repo appears to be down (404).

The error happens because webui tries to clone https://github.com/Stability-AI/stablediffusion.git/ which no longer exists.

As a quick workaround, you can:
1. Edit  around line 412
2. Change the repo URL to point to a fork or mirror
3. Or comment out the git_clone line for stable-diffusion-stability-ai temporarily

The maintainers will likely need to update the default repo URL. Keep an eye on the repo for an official fix\!",2025-12-30T00:49:17Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3697938481,"I see you're hitting error 128 with the missing Stability-AI repository. This is a widespread issue right now - the original repo appears to be down (404).

The error happens because webui tries to clone https://github.com/Stability-AI/stablediffusion.git/ which no longer exists.

As a quick workaround, you can:
1. Edit  around line 412
2. Change the repo URL to point to a fork or mirror
3. Or comment out the git_clone line for stable-diffusion-stability-ai temporarily

The maintainers will likely need to update the default repo URL. Keep an eye on the repo for an official fix\!",see hitting error missing stability ai repository widespread issue right original repo appears error happens webui tries clone longer exists quick workaround edit around line change repo url point fork mirror comment git clone line stable diffusion stability ai temporarily maintainers likely need update default repo url keep eye repo official fix
auto1111_webui,comment,17205,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:34:02Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3700280265,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",essentially solved issue written detailed explanation fix see issues questions please make comment post
auto1111_webui,issue,17204,[Bug]: Repository not found: Stability-AI/stablediffusion (public clone fails),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When trying to install Stable Diffusion WebUI on Ubuntu 24.04, the installation script fails with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".
This happens even when using a GitHub Personal Access Token. The installation cannot proceed because the required repository is not accessible.

```
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': *****
Password for 'https://*****': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
```


### Steps to reproduce the problem

Install dependencies:
```
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
```

Install Python 3.11:

```
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11
```
Create a new directory and download the webui.sh script:

```
mkdir stable-diffusion
cd stable-diffusion
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
chmod +x webui.sh
```

Run the installation script:
```
./webui.sh
```
`The script will attempt to clone the repository https://github.com/Stability-AI/stablediffusion.git, but it will fail with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".

### What should have happened?


The installation script should have successfully cloned the required Stable Diffusion repository and continued with the setup. 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Unable to generate sysinfo file because WebUI fails to start due to repository not found error. If needed, I can provide system details manually (Ubuntu 24.04, Python 3.11, RTX 5070 Ti).

### Console logs

```Shell
aleksei@ubusteam:~/stable-diffusion$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on aleksei user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': ****
Password for 'https://****github.com': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
aleksei@ubusteam:~/stable-diffusion$
```

### Additional information

_No response_",2025-12-16T20:50:33Z,AlexeyMRX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204,"[Bug]: Repository not found: Stability-AI/stablediffusion (public clone fails) ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When trying to install Stable Diffusion WebUI on Ubuntu 24.04, the installation script fails with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".
This happens even when using a GitHub Personal Access Token. The installation cannot proceed because the required repository is not accessible.

```
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': *****
Password for 'https://*****': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
```


### Steps to reproduce the problem

Install dependencies:
```
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
```

Install Python 3.11:

```
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11
```
Create a new directory and download the webui.sh script:

```
mkdir stable-diffusion
cd stable-diffusion
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
chmod +x webui.sh
```

Run the installation script:
```
./webui.sh
```
`The script will attempt to clone the repository https://github.com/Stability-AI/stablediffusion.git, but it will fail with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".

### What should have happened?


The installation script should have successfully cloned the required Stable Diffusion repository and continued with the setup. 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Unable to generate sysinfo file because WebUI fails to start due to repository not found error. If needed, I can provide system details manually (Ubuntu 24.04, Python 3.11, RTX 5070 Ti).

### Console logs

```Shell
aleksei@ubusteam:~/stable-diffusion$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on aleksei user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': ****
Password for 'https://****github.com': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
aleksei@ubusteam:~/stable-diffusion$
```

### Additional information

_No response_",bug repository found stability ai stablediffusion public clone fails checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui x issue reported recently issue reported fixed yet happened trying install stable diffusion webui ubuntu installation script fails error remote repository found fatal repository found happens even using github personal access token installation cannot proceed required repository accessible python main oct gcc version v commit hash c ae bd abdf eda b e cloning stable diffusion home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai cloning home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai username password remote repository found fatal repository found traceback recent call last file home aleksei stable diffusion stable diffusion webui launch py line module main file home aleksei stable diffusion stable diffusion webui launch py line main prepare environment file home aleksei stable diffusion stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file home aleksei stable diffusion stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file home aleksei stable diffusion stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai error code steps reproduce problem install dependencies sudo apt install wget git python python venv libgl libglib install python sudo add apt repository ppa deadsnakes ppa sudo apt update sudo apt install python create new directory download webui sh script mkdir stable diffusion cd stable diffusion wget q chmod x webui sh run installation script webui sh script attempt clone repository fail error remote repository found fatal repository found happened installation script successfully cloned required stable diffusion repository continued setup browsers use access ui response sysinfo unable generate sysinfo file webui fails start due repository found error needed provide system details manually ubuntu python rtx ti console logs shell aleksei ubusteam stable diffusion webui sh install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running aleksei user create activate python venv launching launch py glibc version cannot locate tcmalloc tcmalloc google perftool installed system improves cpu memory usage python main oct gcc version v commit hash c ae bd abdf eda b e cloning stable diffusion home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai cloning home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai username password remote repository found fatal repository found traceback recent call last file home aleksei stable diffusion stable diffusion webui launch py line module main file home aleksei stable diffusion stable diffusion webui launch py line main prepare environment file home aleksei stable diffusion stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file home aleksei stable diffusion stable diffusion webui modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file home aleksei stable diffusion stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false home aleksei stable diffusion stable diffusion webui repositories stable diffusion stability ai error code aleksei ubusteam stable diffusion additional information response
auto1111_webui,comment,17204,,"Same issue here, the repository does not seem to exist on github anymore:
https://github.com/Stability-AI/stablediffusion.git
Delivers a 404 page not found error
",2025-12-16T21:23:30Z,bauerwer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662434500,"Same issue here, the repository does not seem to exist on github anymore:
https://github.com/Stability-AI/stablediffusion.git
Delivers a 404 page not found error",issue repository seem exist github anymore delivers page found error
auto1111_webui,comment,17204,,"It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result

As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py

Exact lines are 349 and 355

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`

Change to 

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`

**This is in no way a permanent solution. I don't know the dev behind that repository.**

_**DO THIS AT YOUR OWN RISK !!!!**_

",2025-12-16T22:42:03Z,BlackCharon142,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662743174,"It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result

As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py

Exact lines are 349 and 355

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`

Change to 

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`

**This is in no way a permanent solution. I don't know the dev behind that repository.**

_**DO THIS AT YOUR OWN RISK !!!!**_",seems changed private closed since every search engine try comes repository number result temporary solution changed url hash repo fork made quite recently file edit modules folder file edit launch utils py exact lines stable diffusion repo os environ get stable diffusion repo stable diffusion commit hash os environ get stable diffusion commit hash cf fd ea aa c df e b da f bdbf change stable diffusion repo os environ get stable diffusion repo stable diffusion commit hash os environ get stable diffusion commit hash ef b ee way permanent solution know dev behind repository risk
auto1111_webui,comment,17204,,"> It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result
> 
> As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py
> 
> Exact lines are 349 and 355
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`
> 
> Change to
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`
> 
> **This is in no way a permanent solution. I don't know the dev behind that repository.**
> 
> _**DO THIS AT YOUR OWN RISK !!!!**_

it's safer replacing it in the ~~webui.sh~~ (correction: there are multiple files for this purpose already, suggested is webui-user.sh) or wrap the sh with another sh file setting the envs",2025-12-16T23:21:30Z,marco-porru,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662854834,"> It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result
> 
> As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py
> 
> Exact lines are 349 and 355
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`
> 
> Change to
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`
> 
> **This is in no way a permanent solution. I don't know the dev behind that repository.**
> 
> _**DO THIS AT YOUR OWN RISK !!!!**_

it's safer replacing it in the ~~webui.sh~~ (correction: there are multiple files for this purpose already, suggested is webui-user.sh) or wrap the sh with another sh file setting the envs",seems changed private closed since every search engine try comes repository number result temporary solution changed url hash repo fork made quite recently file edit modules folder file edit launch utils py exact lines stable diffusion repo os environ get stable diffusion repo stable diffusion commit hash os environ get stable diffusion commit hash cf fd ea aa c df e b da f bdbf change stable diffusion repo os environ get stable diffusion repo stable diffusion commit hash os environ get stable diffusion commit hash ef b ee way permanent solution know dev behind repository risk safer replacing webui sh correction multiple files purpose already suggested webui user sh wrap sh another sh file setting envs
auto1111_webui,comment,17204,,"I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):

https://github.com/joypaul162/Stability-AI-stablediffusion

Commit hash: `f16630a927e00098b524d687640719e4eb469b76`

So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.",2025-12-17T01:38:50Z,thenickdude,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663211808,"I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):

https://github.com/joypaul162/Stability-AI-stablediffusion

Commit hash: `f16630a927e00098b524d687640719e4eb469b76`

So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash
auto1111_webui,comment,17204,,"Thanks Nick, that modification in modules/launch_utils.py fixed the issue for me.",2025-12-17T03:26:42Z,Galvinox,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663471355,"Thanks Nick, that modification in modules/launch_utils.py fixed the issue for me.",thanks nick modification modules launch utils py fixed issue
auto1111_webui,comment,17204,,"Thanks Nick, worked for me too

> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, worked for me too",2025-12-17T03:43:35Z,Edderou,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663507706,"Thanks Nick, worked for me too

> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, worked for me too",thanks nick worked found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash thanks worked
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, I added the following to `webui-user.bat`:
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and ran `run.bat` again. This fixed the issue for me.",2025-12-17T03:53:46Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663524626,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, I added the following to `webui-user.bat`:
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and ran `run.bat` again. This fixed the issue for me.",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash thanks added following webui user bat set stable diffusion repo set stable diffusion commit hash f e b e eb b ran run bat fixed issue
auto1111_webui,comment,17204,,"I am alos running Stable Diffusion WebUI (but on Windows 11), and I am facing the same problem with the ""stable-diffusion-stability-ai"" repository not being found. Hopefully, the official team can make improvements. QAQ",2025-12-17T10:28:53Z,wateryuen,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3664697139,"I am alos running Stable Diffusion WebUI (but on Windows 11), and I am facing the same problem with the ""stable-diffusion-stability-ai"" repository not being found. Hopefully, the official team can make improvements. QAQ",alos running stable diffusion webui windows facing problem stable diffusion stability ai repository found hopefully official team make improvements qaq
auto1111_webui,comment,17204,,"This is from a reddit post from a month ago and could be related to the repositories here and on huggingface going down:


> StableITAdmin posted the following message a day after the platform was brought down:
> 
> ""...it looks like our team has decided to deprecate SD 2.0 and 2.1. We were told this official statement:
> 
> 'We have officially deprecated Stable Diffusion 2.0 and 2.1. This is part of our effort to clean up and consolidate our model offering and to get ahead of upcoming compliance requirements for the EU AI Act in 2026. These models have been outpaced by newer architectures that offer far stronger performance, safety, and alignment, and continuing to maintain them does not fit our long-term roadmap.
> 
> 'If you currently rely on SD 2.0 or 2.1 for an active business use case, please reach out and share your workflow and requirements. While these models will no longer be part of our public lineup, we want to make sure that any legitimate business dependencies are surfaced so we can explore the right path forward with you.' ",2025-12-17T12:41:45Z,azolash,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3665175573,"This is from a reddit post from a month ago and could be related to the repositories here and on huggingface going down:


> StableITAdmin posted the following message a day after the platform was brought down:
> 
> ""...it looks like our team has decided to deprecate SD 2.0 and 2.1. We were told this official statement:
> 
> 'We have officially deprecated Stable Diffusion 2.0 and 2.1. This is part of our effort to clean up and consolidate our model offering and to get ahead of upcoming compliance requirements for the EU AI Act in 2026. These models have been outpaced by newer architectures that offer far stronger performance, safety, and alignment, and continuing to maintain them does not fit our long-term roadmap.
> 
> 'If you currently rely on SD 2.0 or 2.1 for an active business use case, please reach out and share your workflow and requirements. While these models will no longer be part of our public lineup, we want to make sure that any legitimate business dependencies are surfaced so we can explore the right path forward with you.'",reddit post month ago could related repositories huggingface going stableitadmin posted following message day platform brought looks like team decided deprecate sd told official statement officially deprecated stable diffusion part effort clean consolidate model offering get ahead upcoming compliance requirements eu ai act models outpaced newer architectures offer far stronger performance safety alignment continuing maintain fit long term roadmap currently rely sd active business use case please reach share workflow requirements models longer part public lineup want make sure legitimate business dependencies surfaced explore right path forward
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

I also just forked if anyone needs a backup option, same commit hash.

https://github.com/glens/Stability-AI-stablediffusion.git",2025-12-18T07:40:40Z,glens,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3668819570,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

I also just forked if anyone needs a backup option, same commit hash.

https://github.com/glens/Stability-AI-stablediffusion.git",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash also forked anyone needs backup option commit hash
auto1111_webui,comment,17204,,"i changed the git url the commit hash, nothing is happening, not able to run this, please anyone help",2025-12-19T03:18:28Z,zsyborg,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3673316896,"i changed the git url the commit hash, nothing is happening, not able to run this, please anyone help",changed git url commit hash nothing happening able run please anyone help
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks bro, it helps",2025-12-20T06:58:43Z,crowthek4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3677489800,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks bro, it helps",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash thanks bro helps
auto1111_webui,comment,17204,," File ""D:\stable-diffusion-portable-main\venv\lib\site-packages\torch\_meta_registrations.py"", line 5351, in zeros_like
        res.fill_(0)
    torch.AcceleratorError: CUDA error: no kernel image is available for execution on the device
    Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
    CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
    For debugging consider passing CUDA_LAUNCH_BLOCKING=1
    Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


It gave me this error, but it ran in the browser. Images aren't generated.",2025-12-21T11:55:05Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3678727081,"File ""D:\stable-diffusion-portable-main\venv\lib\site-packages\torch\_meta_registrations.py"", line 5351, in zeros_like
        res.fill_(0)
    torch.AcceleratorError: CUDA error: no kernel image is available for execution on the device
    Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
    CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
    For debugging consider passing CUDA_LAUNCH_BLOCKING=1
    Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


It gave me this error, but it ran in the browser. Images aren't generated.",file stable diffusion portable main venv lib site packages torch meta registrations py line zeros like res fill torch acceleratorerror cuda error kernel image available execution device search cudaerrornokernelimagefordevice information cuda kernel errors might asynchronously reported api call stacktrace might incorrect debugging consider passing cuda launch blocking compile torch use cuda dsa enable device side assertions gave error ran browser images generated
auto1111_webui,comment,17204,,"I think SD2 has long been used in both AIGC community and AI research community. I hope even if stabilityai take it down, the community is going to maintain an official repo of SD2 including checkpoints, codes etc. (also I want SD1.4 SD1.5 back)

I have both sd2-1-base and sd1-5-base checkpoints locally , contact me if any need it.",2025-12-22T09:08:44Z,Bili-Sakura,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3681130624,"I think SD2 has long been used in both AIGC community and AI research community. I hope even if stabilityai take it down, the community is going to maintain an official repo of SD2 including checkpoints, codes etc. (also I want SD1.4 SD1.5 back)

I have both sd2-1-base and sd1-5-base checkpoints locally , contact me if any need it.",think sd long used aigc community ai research community hope even stabilityai take community going maintain official repo sd including checkpoints codes etc also want sd sd back sd base sd base checkpoints locally contact need
auto1111_webui,comment,17204,,"Hello,
is it neccessarry to download that Repo if I downloaded my own model from Huggingface? Could I just completely disable cloning it?",2025-12-22T10:52:53Z,axoking,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3681554788,"Hello,
is it neccessarry to download that Repo if I downloaded my own model from Huggingface? Could I just completely disable cloning it?",hello neccessarry download repo downloaded model huggingface could completely disable cloning
auto1111_webui,comment,17204,,"AcceleratorError: CUDA error: no kernel image is available for execution on the device Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information. CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Can you suggest what to do about this?",2025-12-25T15:16:25Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3691532265,"AcceleratorError: CUDA error: no kernel image is available for execution on the device Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information. CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Can you suggest what to do about this?",acceleratorerror cuda error kernel image available execution device search cudaerrornokernelimagefordevice information cuda kernel errors might asynchronously reported api call stacktrace might incorrect debugging consider passing cuda launch blocking compile torch use cuda dsa enable device side assertions suggest
auto1111_webui,comment,17204,,"
Fix Windows:
```bash
clear;
cd /d stable-diffusion-webui\modules

powershell -Command ""(Get-Content launch_utils.py) -replace 'https://github.com/Stability-AI/stablediffusion.git', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui.git' | Set-Content launch_utils.py""

powershell -Command ""(Get-Content launch_utils.py) -replace 'cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf', '82a973c04367123ae98bd9abdf80d9eda9b910e2' | Set-Content launch_utils.py""
```

Fix Linux (not tested)
```bash
clear;
cd stable-diffusion-webui/modules
sed -i -e ""s/https\:\/\/github.com\/Stability\-AI\/stablediffusion\.git/https\:\/\/github.com\/AUTOMATIC1111\/stable\-diffusion\-webui\.git/g"" launch_utils.py 
sed -i -e ""s/cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf/82a973c04367123ae98bd9abdf80d9eda9b910e2/g""  launch_utils.py
```",2025-12-25T16:49:29Z,dexter74,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3691596954,"Fix Windows:
```bash
clear;
cd /d stable-diffusion-webui\modules

powershell -Command ""(Get-Content launch_utils.py) -replace 'https://github.com/Stability-AI/stablediffusion.git', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui.git' | Set-Content launch_utils.py""

powershell -Command ""(Get-Content launch_utils.py) -replace 'cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf', '82a973c04367123ae98bd9abdf80d9eda9b910e2' | Set-Content launch_utils.py""
```

Fix Linux (not tested)
```bash
clear;
cd stable-diffusion-webui/modules
sed -i -e ""s/https\:\/\/github.com\/Stability\-AI\/stablediffusion\.git/https\:\/\/github.com\/AUTOMATIC1111\/stable\-diffusion\-webui\.git/g"" launch_utils.py 
sed -i -e ""s/cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf/82a973c04367123ae98bd9abdf80d9eda9b910e2/g""  launch_utils.py
```",fix windows bash clear cd stable diffusion webui modules powershell command get content launch utils py replace set content launch utils py powershell command get content launch utils py replace cf fd ea aa c df e b da f bdbf c ae bd abdf eda b e set content launch utils py fix linux tested bash clear cd stable diffusion webui modules sed e launch utils py sed e cf fd ea aa c df e b da f bdbf c ae bd abdf eda b e g launch utils py
auto1111_webui,comment,17204,,"From https://github.com/AUTOMATIC1111/stable-diffusion-webui
 * branch              dev        -> FETCH_HEAD
Already up to date.
venv ""venv\Scripts\Python.exe""
fatal: No names found, cannot describe anything.
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Version: 1.10.1
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Fetching updates for Stable Diffusion...
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion, attempting autofix...
Fetching all contents for Stable Diffusion
remote: Enumerating objects: 586, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 586 (delta 2), reused 0 (delta 0), pack-reused 581 (from 1)
Receiving objects:  99% (581/586), 72.44 MiB | 5.59 MiB/s
Receiving objects: 100% (586/586), 73.45 MiB | 5.56 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Pruning Stable Diffusion
Enumerating objects: 592, done.
Counting objects: 100% (592/592), done.
Delta compression using up to 12 threads
Compressing objects: 100% (571/571), done.
Writing objects: 100% (592/592), done.
Total 592 (delta 309), reused 283 (delta 0), pack-reused 0
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""D:\stable-diffusion-portable-main\launch.py"", line 53, in <module>
    main()
  File ""D:\stable-diffusion-portable-main\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 166, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion.
Command: ""git\cmd\git.exe"" -C ""D:\stable-diffusion-portable-main\repositories\stable-diffusion-stability-ai"" checkout 82a973c04367123ae98bd9abdf80d9eda9b910e2
Error code: 128


New error",2025-12-27T12:32:05Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3693948552,"From https://github.com/AUTOMATIC1111/stable-diffusion-webui
 * branch              dev        -> FETCH_HEAD
Already up to date.
venv ""venv\Scripts\Python.exe""
fatal: No names found, cannot describe anything.
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Version: 1.10.1
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Fetching updates for Stable Diffusion...
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion, attempting autofix...
Fetching all contents for Stable Diffusion
remote: Enumerating objects: 586, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 586 (delta 2), reused 0 (delta 0), pack-reused 581 (from 1)
Receiving objects:  99% (581/586), 72.44 MiB | 5.59 MiB/s
Receiving objects: 100% (586/586), 73.45 MiB | 5.56 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Pruning Stable Diffusion
Enumerating objects: 592, done.
Counting objects: 100% (592/592), done.
Delta compression using up to 12 threads
Compressing objects: 100% (571/571), done.
Writing objects: 100% (592/592), done.
Total 592 (delta 309), reused 283 (delta 0), pack-reused 0
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""D:\stable-diffusion-portable-main\launch.py"", line 53, in <module>
    main()
  File ""D:\stable-diffusion-portable-main\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 166, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion.
Command: ""git\cmd\git.exe"" -C ""D:\stable-diffusion-portable-main\repositories\stable-diffusion-stability-ai"" checkout 82a973c04367123ae98bd9abdf80d9eda9b910e2
Error code: 128


New error",branch dev fetch head already date venv venv scripts python exe fatal names found cannot describe anything python tags v dd dec msc v bit amd version commit hash fd e c b c c b c f c fetching updates stable diffusion checking commit stable diffusion hash c ae bd abdf eda b e fatal reference tree c ae bd abdf eda b e checkout commit c ae bd abdf eda b e stable diffusion attempting autofix fetching contents stable diffusion remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib receiving objects mib mib done resolving deltas done pruning stable diffusion enumerating objects done counting objects done delta compression using threads compressing objects done writing objects done total delta reused delta pack reused checking commit stable diffusion hash c ae bd abdf eda b e fatal reference tree c ae bd abdf eda b e traceback recent call last file stable diffusion portable main launch py line module main file stable diffusion portable main launch py line main prepare environment file stable diffusion portable main modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file stable diffusion portable main modules launch utils py line git clone run git dir name f checkout commithash f checking commit name hash commithash f checkout commit commithash name live true file stable diffusion portable main modules launch utils py line run git return run f git c dir command desc desc errdesc errdesc custom env custom env live live file stable diffusion portable main modules launch utils py line run raise runtimeerror n join error bits runtimeerror checkout commit c ae bd abdf eda b e stable diffusion command git cmd git exe c stable diffusion portable main repositories stable diffusion stability ai checkout c ae bd abdf eda b e error code new error
auto1111_webui,comment,17204,,"> > I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> > https://github.com/joypaul162/Stability-AI-stablediffusion
> > Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> > So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.
> 
> Thanks, I added the following to `webui-user.bat`:
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> and ran `run.bat` again. This fixed the issue for me.


well u guys right! just add these command into webui.user.bat: 
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and it fix !",2025-12-28T13:53:33Z,meokinh000,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3694763842,"> > I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> > https://github.com/joypaul162/Stability-AI-stablediffusion
> > Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> > So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.
> 
> Thanks, I added the following to `webui-user.bat`:
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> and ran `run.bat` again. This fixed the issue for me.


well u guys right! just add these command into webui.user.bat: 
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and it fix !",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash thanks added following webui user bat set stable diffusion repo set stable diffusion commit hash f e b e eb b ran run bat fixed issue well u guys right add command webui user bat set stable diffusion repo set stable diffusion commit hash f e b e eb b fix
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

thank you lifesaver!",2025-12-28T15:46:40Z,crisricc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3694839706,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

thank you lifesaver!",found fork commit matches last hash official repo commit hash f e b e eb b one exact match original able change url leave commit hash thank lifesaver
auto1111_webui,comment,17204,,"This isn't a bug in the webui itself - the upstream Stability-AI/stablediffusion repository has been removed or made private by Stability AI, so no amount of authentication will help here. This is affecting all new installations that depend on that repo. The maintainers will need to either mirror the required code somewhere else, bundle it directly, or point to an alternative source. As a temporary workaround, you might be able to manually clone from a community mirror or fork into the expected path before running the installer, though I'd wait to see if there's an official fix coming since this is likely impacting a lot of users right now.",2025-12-30T01:11:31Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3697978211,"This isn't a bug in the webui itself - the upstream Stability-AI/stablediffusion repository has been removed or made private by Stability AI, so no amount of authentication will help here. This is affecting all new installations that depend on that repo. The maintainers will need to either mirror the required code somewhere else, bundle it directly, or point to an alternative source. As a temporary workaround, you might be able to manually clone from a community mirror or fork into the expected path before running the installer, though I'd wait to see if there's an official fix coming since this is likely impacting a lot of users right now.",bug webui upstream stability ai stablediffusion repository removed made private stability ai amount authentication help affecting new installations depend repo maintainers need either mirror required code somewhere else bundle directly point alternative source temporary workaround might able manually clone community mirror fork expected path running installer though wait see official fix coming since likely impacting lot users right
auto1111_webui,comment,17204,,"> > > 我找到一个分支，提交的哈[希值和官方仓库的最后一个哈希](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/)一致：https://github.com/joypaul162/Stability-AI-stablediffusion 提交哈希：这个和原来完全匹配，你应该只把URL改成，提交哈希保持原样。`f16630a927e00098b524d687640719e4eb469b76``https://github.com/joypaul162/Stability-AI-stablediffusion.git`
> > 
> > 
> > 谢谢，我补充了以下内容：`webui-user.bat`
> > ```
> > set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> > set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> > ```
> > 
> > 
> >     
> >       
> >     
> > 
> >       
> >     
> > 
> >     
> >   
> > 然后又跑了一次。这解决了我的问题。`run.bat`
> 
> 你们说得对！只需在 webui.user.bat 中添加以下命令：
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> 而且它修好了！

<img width=""2394"" height=""66"" alt=""Image"" src=""https://github.com/user-attachments/assets/e4ed17fc-0808-4559-817f-126f2409ca33"" />  , also directly modify the launch_utils.py file.",2025-12-30T16:23:19Z,zhugeshenren,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3699862614,"> > > 我找到一个分支，提交的哈[希值和官方仓库的最后一个哈希](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/)一致：https://github.com/joypaul162/Stability-AI-stablediffusion 提交哈希：这个和原来完全匹配，你应该只把URL改成，提交哈希保持原样。`f16630a927e00098b524d687640719e4eb469b76``https://github.com/joypaul162/Stability-AI-stablediffusion.git`
> > 
> > 
> > 谢谢，我补充了以下内容：`webui-user.bat`
> > ```
> > set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> > set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> > ```
> > 
> > 
> >     
> >       
> >     
> > 
> >       
> >     
> > 
> >     
> >   
> > 然后又跑了一次。这解决了我的问题。`run.bat`
> 
> 你们说得对！只需在 webui.user.bat 中添加以下命令：
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> 而且它修好了！

<img width=""2394"" height=""66"" alt=""Image"" src=""https://github.com/user-attachments/assets/e4ed17fc-0808-4559-817f-126f2409ca33"" />  , also directly modify the launch_utils.py file.",url f e b e eb b webui user bat set stable diffusion repo set stable diffusion commit hash f e b e eb b run bat webui user bat set stable diffusion repo set stable diffusion commit hash f e b e eb b img width height alt image src also directly modify launch utils py file
auto1111_webui,comment,17204,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:31:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3700272985,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",essentially solved issue written detailed explanation fix see issues questions please make comment post
auto1111_webui,issue,17201,[Bug]: Couldn't Install Clip,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I used the NVidia Automatic for Windows method with the sd.webui.zip. 
When attempting to set up using the ""run.bat"" file, it eventually gets to the point where it attempts to install ""clip"". After that it will give me a ""Press and key to continue..."" which will close the Command Window and nothing else will happen.

I've seen others bring this issue up before, however their error codes are different than mine. I'm not very well versed in python to know exactly what is going on here. I've seen some solutions mention running a script in the ""venv"" folder, but I don't even have that, just a ""tmp"" folder.

I have done two clean installs, as well installing in fresh locations, however the same issue arises. I also ran the ""update.bat"" before running ""run.bat"".

### Steps to reproduce the problem

1. Double click ""run.bat""
2. Get error saying it cannot install clip.

### What should have happened?

Install clip and open the WebUI I guess.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

I cannot even get to the WebUI.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash:
Installing clip
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 48, in
main()
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 39, in main
prepare_environment()
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
run_pip(f""install {clip_package}"", ""clip"")
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""M:\AI\Stable Diffusion\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
Installing build dependencies: started
Installing build dependencies: finished with status 'done'
Getting requirements to build wheel: started
Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 107, in _run_wrapper
status = _inner_run()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 98, in _inner_run
return self.run(options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\req_command.py"", line 85, in wrapper
return func(self, options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\commands\install.py"", line 388, in run
requirement_set = resolver.resolve(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
collected = self.factory.collect_root_requirements(root_reqs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
reqs = list(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
cand = self._make_base_candidate_from_link(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
self._link_candidate_cache[link] = LinkCandidate(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 318, in init
super().init(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 161, in init
self.dist = self._prepare()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
dist = self._prepare_distribution()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
return self._prepare_linked_requirement(req, parallel_builds)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
dist = _get_prepared_distribution(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
abstract_dist.prepare_distribution_metadata(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
self._install_build_reqs(build_env_installer)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 132, in _install_build_reqs
build_reqs = self._get_build_requires_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
return backend.get_requires_for_build_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
return super().get_requires_for_build_wheel(config_settings=cs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 196, in get_requires_for_build_wheel
return self._call_hook(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 402, in _call_hook
raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

I have a newer version of Python, but am using pyenv-win to downgrade from 3.12.4 to 3.10.6. Both the Command Prompt from run.bat as well as PowerShell recognize 3.10.6 as the version.

Using an RTX 3090 if that makes any difference.",2025-12-13T05:58:13Z,ZurokSlayer7X9,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201,"[Bug]: Couldn't Install Clip ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I used the NVidia Automatic for Windows method with the sd.webui.zip. 
When attempting to set up using the ""run.bat"" file, it eventually gets to the point where it attempts to install ""clip"". After that it will give me a ""Press and key to continue..."" which will close the Command Window and nothing else will happen.

I've seen others bring this issue up before, however their error codes are different than mine. I'm not very well versed in python to know exactly what is going on here. I've seen some solutions mention running a script in the ""venv"" folder, but I don't even have that, just a ""tmp"" folder.

I have done two clean installs, as well installing in fresh locations, however the same issue arises. I also ran the ""update.bat"" before running ""run.bat"".

### Steps to reproduce the problem

1. Double click ""run.bat""
2. Get error saying it cannot install clip.

### What should have happened?

Install clip and open the WebUI I guess.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

I cannot even get to the WebUI.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash:
Installing clip
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 48, in
main()
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 39, in main
prepare_environment()
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
run_pip(f""install {clip_package}"", ""clip"")
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""M:\AI\Stable Diffusion\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
Installing build dependencies: started
Installing build dependencies: finished with status 'done'
Getting requirements to build wheel: started
Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 107, in _run_wrapper
status = _inner_run()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 98, in _inner_run
return self.run(options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\req_command.py"", line 85, in wrapper
return func(self, options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\commands\install.py"", line 388, in run
requirement_set = resolver.resolve(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
collected = self.factory.collect_root_requirements(root_reqs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
reqs = list(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
cand = self._make_base_candidate_from_link(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
self._link_candidate_cache[link] = LinkCandidate(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 318, in init
super().init(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 161, in init
self.dist = self._prepare()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
dist = self._prepare_distribution()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
return self._prepare_linked_requirement(req, parallel_builds)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
dist = _get_prepared_distribution(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
abstract_dist.prepare_distribution_metadata(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
self._install_build_reqs(build_env_installer)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 132, in _install_build_reqs
build_reqs = self._get_build_requires_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
return backend.get_requires_for_build_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
return super().get_requires_for_build_wheel(config_settings=cs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 196, in get_requires_for_build_wheel
return self._call_hook(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 402, in _call_hook
raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

I have a newer version of Python, but am using pyenv-win to downgrade from 3.12.4 to 3.10.6. Both the Command Prompt from run.bat as well as PowerShell recognize 3.10.6 as the version.

Using an RTX 3090 if that makes any difference.",bug install clip checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened used nvidia automatic windows method sd webui zip attempting set using run bat file eventually gets point attempts install clip give press key continue close command window nothing else happen seen others bring issue however error codes different mine well versed python know exactly going seen solutions mention running script venv folder even tmp folder done two clean installs well installing fresh locations however issue arises also ran update bat running run bat steps reproduce problem double click run bat get error saying cannot install clip happened install clip open webui guess browsers use access ui brave sysinfo cannot even get webui console logs shell python tags v c b bd aug msc v bit amd version v commit hash installing clip traceback recent call last file ai stable diffusion sd webui webui launch py line main file ai stable diffusion sd webui webui launch py line main prepare environment file ai stable diffusion sd webui webui modules launch utils py line prepare environment run pip f install clip package clip file ai stable diffusion sd webui webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file ai stable diffusion sd webui webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install clip command ai stable diffusion sd webui system python python exe pip install prefer binary error code stdout collecting using cached mb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done stderr error exception traceback recent call last file ai stable diffusion sd webui system python lib site packages pip internal cli base command py line run wrapper status inner run file ai stable diffusion sd webui system python lib site packages pip internal cli base command py line inner run return self run options args file ai stable diffusion sd webui system python lib site packages pip internal cli req command py line wrapper return func self options args file ai stable diffusion sd webui system python lib site packages pip internal commands install py line run requirement set resolver resolve file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib resolver py line resolve collected self factory collect root requirements root reqs file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib factory py line collect root requirements reqs list file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib factory py line make requirements install req cand self make base candidate link file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib candidates py line init super init file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file ai stable diffusion sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file ai stable diffusion sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file ai stable diffusion sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file ai stable diffusion sd webui system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file ai stable diffusion sd webui system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs build env installer file ai stable diffusion sd webui system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file ai stable diffusion sd webui system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file ai stable diffusion sd webui system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file ai stable diffusion sd webui system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file ai stable diffusion sd webui system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta additional information newer version python using pyenv win downgrade command prompt run bat well powershell recognize version using rtx makes difference
auto1111_webui,comment,17201,,"安装 OpenAI CLIP： D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation ""git+ https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1#egg=clip"" 


安装 OpenCLIP： D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation  https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip",2025-12-15T02:26:57Z,jarvonH,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3652638081,"安装 OpenAI CLIP： D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation ""git+ https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1#egg=clip"" 


安装 OpenCLIP： D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation  https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip",openai clip proj sd webui system python python exe pip install build isolation git openclip proj sd webui system python python exe pip install build isolation
auto1111_webui,comment,17201,,"Looking at this issue, the problem is almost certainly network-related or a Python environment issue rather than a clip-specific bug. The fact that you don't have a venv folder yet suggests the installation is failing very early, before the virtual environment is even fully created. Can you try running run.bat from an administrator command prompt and paste the full console output here? The ""Press any key to continue"" message appears when there's a fatal error, but we need to see what comes before it. Also check if you have Python 3.10.x installed system-wide and that it's in your PATH - the webui requires a specific Python version range and will fail silently if it can't find a compatible interpreter.",2025-12-30T01:11:52Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3697978592,"Looking at this issue, the problem is almost certainly network-related or a Python environment issue rather than a clip-specific bug. The fact that you don't have a venv folder yet suggests the installation is failing very early, before the virtual environment is even fully created. Can you try running run.bat from an administrator command prompt and paste the full console output here? The ""Press any key to continue"" message appears when there's a fatal error, but we need to see what comes before it. Also check if you have Python 3.10.x installed system-wide and that it's in your PATH - the webui requires a specific Python version range and will fail silently if it can't find a compatible interpreter.",looking issue problem almost certainly network related python environment issue rather clip specific bug fact venv folder yet suggests installation failing early virtual environment even fully created try running run bat administrator command prompt paste full console output press key continue message appears fatal error need see comes also check python x installed system wide path webui requires specific python version range fail silently find compatible interpreter
auto1111_webui,comment,17201,,"i have the same issue and when i run run.bat from an administrator command prompt this is appears 

INCOMPATIBLE PYTHON VERSION

This program is tested with 3.10.6 Python, but you have 3.14.2.
If you encounter an error with ""RuntimeError: Couldn't install torch."" message,
or any other error regarding unsuccessful package (library) installation,
please downgrade (or upgrade) to the latest version of 3.10 Python
and delete current Python and ""venv"" folder in WebUI's directory.

You can download 3.10 Python from here: https://www.python.org/downloads/release/python-3106/

Alternatively, use a binary release of WebUI: https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre

Use --skip-python-version-check to suppress this warning.
=============================================================================================================================
Python 3.14.2 (tags/v3.14.2:df79316, Dec  5 2025, 17:18:21) [MSC v.1944 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu128
ERROR: Could not find a version that satisfies the requirement torch==2.7.0 (from versions: 2.9.0, 2.9.0+cu128, 2.9.1, 2.9.1+cu128)
ERROR: No matching distribution found for torch==2.7.0
Traceback (most recent call last):
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 53, in <module>
    main()
    ~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 44, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 413, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\venv\Scripts\python.exe"" -m pip install torch==2.7.0 torchvision==0.22.0 --extra-index-url https://download.pytorch.org/whl/cu128
Error code: 1",2026-01-01T13:13:15Z,muhsandi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3703679767,"i have the same issue and when i run run.bat from an administrator command prompt this is appears 

INCOMPATIBLE PYTHON VERSION

This program is tested with 3.10.6 Python, but you have 3.14.2.
If you encounter an error with ""RuntimeError: Couldn't install torch."" message,
or any other error regarding unsuccessful package (library) installation,
please downgrade (or upgrade) to the latest version of 3.10 Python
and delete current Python and ""venv"" folder in WebUI's directory.

You can download 3.10 Python from here: https://www.python.org/downloads/release/python-3106/

Alternatively, use a binary release of WebUI: https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre

Use --skip-python-version-check to suppress this warning.
=============================================================================================================================
Python 3.14.2 (tags/v3.14.2:df79316, Dec  5 2025, 17:18:21) [MSC v.1944 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu128
ERROR: Could not find a version that satisfies the requirement torch==2.7.0 (from versions: 2.9.0, 2.9.0+cu128, 2.9.1, 2.9.1+cu128)
ERROR: No matching distribution found for torch==2.7.0
Traceback (most recent call last):
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 53, in <module>
    main()
    ~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 44, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 413, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\venv\Scripts\python.exe"" -m pip install torch==2.7.0 torchvision==0.22.0 --extra-index-url https://download.pytorch.org/whl/cu128
Error code: 1",issue run run bat administrator command prompt appears incompatible python version program tested python encounter error runtimeerror install torch message error regarding unsuccessful package library installation please downgrade upgrade latest version python delete current python venv folder webui directory download python alternatively use binary release webui use skip python version check suppress warning python tags v df dec msc v bit amd version commit hash none installing torch torchvision looking indexes error could find version satisfies requirement torch versions cu cu error matching distribution found torch traceback recent call last file c users personal onedrive desktop webui launch py line module main file c users personal onedrive desktop webui launch py line main prepare environment file c users personal onedrive desktop webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file c users personal onedrive desktop webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command c users personal onedrive desktop webui venv scripts python exe pip install torch torchvision extra index url error code
auto1111_webui,comment,17201,,It absolutely is a wrong version of Python issue. Just had to fix my own. I had to track it down in appdata local and just delete the old files then manually install just the 3.10.6 once I got it and installed + added to path it's working fine. ,2026-01-08T20:39:06Z,OmegaVenus32,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3725693079,It absolutely is a wrong version of Python issue. Just had to fix my own. I had to track it down in appdata local and just delete the old files then manually install just the 3.10.6 once I got it and installed + added to path it's working fine.,absolutely wrong version python issue fix track appdata local delete old files manually install got installed added path working fine
auto1111_webui,comment,17201,,"1. Clone the Repository

Note: The main branch was last updated two years ago (2024), while the dev branch was last updated on December 18, 2025. According to feedback from issues #17213 and #17235, the dev branch works correctly, so we'll use it.

Option 1: Clone then switch to dev branch
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
Option 2: Directly clone dev branch
```
git clone -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
```
2. Python Environment (Choose One Option)

Option A: Use Conda (Recommended for environment isolation)
```
conda create -n sd_webui python=3.10.6 -y
conda activate sd_webui
```
Option B: Directly install Python 3.10.6
- Download: https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe
- Important: During installation, check ""Add Python to PATH""

3. Run the Installation Script

This process will create a venv virtual environment.

Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```
4. Fix CLIP Installation Failure (If Encountered)

If you encounter CLIP installation errors like:

- Couldn't Install Clip

- ERROR: Failed to build 'https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip'

First repair the build tools in the venv environment, then install CLIP:

Windows:
```
.\venv\Scripts\python.exe -m pip install wheel
.\venv\Scripts\Python.exe -m pip install ""setuptools<70""
.\venv\Scripts\python.exe -m pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
```
Linux/Mac:
```
source venv/bin/activate
pip install wheel
pip install ""setuptools<70""
pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
deactivate
```
5. Continue Running the Installation Script

After fixing CLIP, run the installation script again:
Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```

PS: Linux/Mac steps have not been tested personally.
",2026-02-11T04:10:59Z,WhizZest,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3882017097,"1. Clone the Repository

Note: The main branch was last updated two years ago (2024), while the dev branch was last updated on December 18, 2025. According to feedback from issues #17213 and #17235, the dev branch works correctly, so we'll use it.

Option 1: Clone then switch to dev branch
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
Option 2: Directly clone dev branch
```
git clone -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
```
2. Python Environment (Choose One Option)

Option A: Use Conda (Recommended for environment isolation)
```
conda create -n sd_webui python=3.10.6 -y
conda activate sd_webui
```
Option B: Directly install Python 3.10.6
- Download: https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe
- Important: During installation, check ""Add Python to PATH""

3. Run the Installation Script

This process will create a venv virtual environment.

Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```
4. Fix CLIP Installation Failure (If Encountered)

If you encounter CLIP installation errors like:

- Couldn't Install Clip

- ERROR: Failed to build 'https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip'

First repair the build tools in the venv environment, then install CLIP:

Windows:
```
.\venv\Scripts\python.exe -m pip install wheel
.\venv\Scripts\Python.exe -m pip install ""setuptools<70""
.\venv\Scripts\python.exe -m pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
```
Linux/Mac:
```
source venv/bin/activate
pip install wheel
pip install ""setuptools<70""
pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
deactivate
```
5. Continue Running the Installation Script

After fixing CLIP, run the installation script again:
Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```

PS: Linux/Mac steps have not been tested personally.",clone repository note main branch last updated two years ago dev branch last updated december according feedback issues dev branch works correctly use option clone switch dev branch git clone cd stable diffusion webui git switch dev git pull option directly clone dev branch git clone b dev cd stable diffusion webui python environment choose one option option use conda recommended environment isolation conda create n sd webui python conda activate sd webui option b directly install python download important installation check add python path run installation script process create venv virtual environment windows webui user bat linux mac webui sh fix clip installation failure encountered encounter clip installation errors like install clip error failed build first repair build tools venv environment install clip windows venv scripts python exe pip install wheel venv scripts python exe pip install setuptools venv scripts python exe pip install build isolation git linux mac source venv bin activate pip install wheel pip install setuptools pip install build isolation git deactivate continue running installation script fixing clip run installation script windows webui user bat linux mac webui sh ps linux mac steps tested personally
auto1111_webui,issue,17199,[Bug]: RuntimeError: CUDA error,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello. I need some advice. When I try to generate an image, I get this error.
RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

### Steps to reproduce the problem

 When I try to generate an image

### What should have happened?

<img width=""898"" height=""155"" alt=""Image"" src=""https://github.com/user-attachments/assets/dc86e89c-a6ee-4807-91fc-b2d495b30f2e"" />

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://pastebin.com/clone/up4rC9L1

### Console logs

https://pastebin.com/rh4vKdGV

### Additional information

_No response_",2025-12-07T09:33:20Z,Jakewh,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199,"[Bug]: RuntimeError: CUDA error ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello. I need some advice. When I try to generate an image, I get this error.
RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

### Steps to reproduce the problem

 When I try to generate an image

### What should have happened?

<img width=""898"" height=""155"" alt=""Image"" src=""https://github.com/user-attachments/assets/dc86e89c-a6ee-4807-91fc-b2d495b30f2e"" />

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://pastebin.com/clone/up4rC9L1

### Console logs

https://pastebin.com/rh4vKdGV

### Additional information

_No response_",bug runtimeerror cuda error checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened hello need advice try generate image get error runtimeerror cuda error kernel image available execution device cuda kernel errors might asynchronously reported api call stacktrace might incorrect debugging consider passing cuda launch blocking compile torch use cuda dsa enable device side assertions steps reproduce problem try generate image happened img width height alt image src browsers use access ui response sysinfo console logs additional information response
auto1111_webui,comment,17199,,"you have from sysinfo

""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
you need to use new PyTorch 2.7.0 +
use `dev` branch and tell it to `--reinstall-torch` or reinstall everything by deleting `venv` dir
or manually install compatible torch version

- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818",2025-12-23T19:51:50Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199#issuecomment-3687812778,"you have from sysinfo

""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
you need to use new PyTorch 2.7.0 +
use `dev` branch and tell it to `--reinstall-torch` or reinstall everything by deleting `venv` dir
or manually install compatible torch version

- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818",sysinfo nvidia gpu models gpu nvidia geforce rtx ti need use new pytorch use dev branch tell reinstall torch reinstall everything deleting venv dir manually install compatible torch version see
auto1111_webui,issue,17197,[Feature Request]: How to support multi-GPU parallel computing.,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

How to support multi-GPU parallel computing.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-12-05T09:08:42Z,wanglujun86,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17197,"[Feature Request]: How to support multi-GPU parallel computing. ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

How to support multi-GPU parallel computing.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request support multi gpu parallel computing existing issue x searched existing issues checked recent builds commits would feature support multi gpu parallel computing proposed workflow go press additional information response
auto1111_webui,issue,17194,[Feature Request]:  zimage_turbo support?,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Runing [Z-Image-Turbo](https://hf-mirror.com/Tongyi-MAI/Z-Image-Turbo) on webui.

### Proposed workflow

User download model and run it.

### Additional information

_No response_",2025-12-02T01:25:29Z,NaughtDZ,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17194,"[Feature Request]:  zimage_turbo support? ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Runing [Z-Image-Turbo](https://hf-mirror.com/Tongyi-MAI/Z-Image-Turbo) on webui.

### Proposed workflow

User download model and run it.

### Additional information

_No response_",feature request zimage turbo support existing issue x searched existing issues checked recent builds commits would feature runing z image turbo webui proposed workflow user download model run additional information response
auto1111_webui,issue,17184,[Bug]: GFPAN Error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Getting an error even though I installed it correctly.

### Steps to reproduce the problem

1. Install sd.webui.zip
2. Update
3. Run

### What should have happened?

it should work after those steps.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

I can't launch webui

### Console logs

```Shell
I just installed this on a new PC but I am not sure what the error is and I am stuck trying to fix it.

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""C:\Users\HOME\Desktop\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 1
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s'
  remote: Internal Server Error
  fatal: unable to access 'https://github.com/TencentARC/GFPGAN.git/': The requested URL returned error: 500
  error: subprocess-exited-with-error

  git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s' did not run successfully.
  exit code: 128

  No available output.

  note: This error originates from a subprocess, and is likely not a problem with pip.
ERROR: Failed to build 'git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379' when git clone --filter=blob:none --quiet https://github.com/tencentarc/gfpgan.git 'c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s'
```

### Additional information

_No response_",2025-11-18T21:09:01Z,TeraTyrantShadic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17184,"[Bug]: GFPAN Error ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Getting an error even though I installed it correctly.

### Steps to reproduce the problem

1. Install sd.webui.zip
2. Update
3. Run

### What should have happened?

it should work after those steps.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

I can't launch webui

### Console logs

```Shell
I just installed this on a new PC but I am not sure what the error is and I am stuck trying to fix it.

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""C:\Users\HOME\Desktop\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 1
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s'
  remote: Internal Server Error
  fatal: unable to access 'https://github.com/TencentARC/GFPGAN.git/': The requested URL returned error: 500
  error: subprocess-exited-with-error

  git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s' did not run successfully.
  exit code: 128

  No available output.

  note: This error originates from a subprocess, and is likely not a problem with pip.
ERROR: Failed to build 'git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379' when git clone --filter=blob:none --quiet https://github.com/tencentarc/gfpgan.git 'c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s'
```

### Additional information

_No response_",bug gfpan error checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened getting error even though installed correctly steps reproduce problem install sd webui zip update run happened work steps browsers use access ui mozilla firefox sysinfo launch webui console logs shell installed new pc sure error stuck trying fix python tags v c b bd aug msc v bit amd commit hash de fea e f df df fddf f b installing gfpgan traceback recent call last file c users home desktop sd webui webui launch py line module prepare environment file c users home desktop sd webui webui launch py line prepare environment run pip f install gfpgan package gfpgan file c users home desktop sd webui webui launch py line run pip return run f python pip args prefer binary index url line desc f installing desc errdesc f install desc file c users home desktop sd webui webui launch py line run raise runtimeerror message runtimeerror install gfpgan command c users home desktop sd webui system python python exe pip install git prefer binary error code stdout collecting git cloning revision f eba fd e c users home appdata local temp pip req build kf lt stderr running command git clone filter blob none quiet c users home appdata local temp pip req build kf lt remote internal server error fatal unable access requested url returned error error subprocess exited error git clone filter blob none quiet c users home appdata local temp pip req build kf lt run successfully exit code available output note error originates subprocess likely problem pip error failed build git git clone filter blob none quiet c users home appdata local temp pip req build kf lt additional information response
auto1111_webui,issue,17180,[Bug]: ModuleNotFoundError: No module named '_lzma',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

After following the Apple Silicon installation instructions at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon, I have run into an error that I cannot seem to resolve. It is looking for a module `_lzma` and not finding it.

The only deviation in the instructions is that I installed `python 3.10` via `pyenv` instead of homebrew. I'm currently running 3.10.10 to try and run the web ui.

I found another discussion on this issue that suggested installing the `xz` libraries via homebrew, and then re-installing (rebuilding) the python being used. I have tried this but it did not resolve the error.

Any advice on how to fix this error and get up and running with the web ui?


Thanks for your time.

### Steps to reproduce the problem

1. Git clone repository for `stable-diffusion-webui`
2. Install `pyenv` and install python 3.10 (3.10.10) with pyenv using `pyenv install 3.10.10 && pyenv global 3.10.10`
3. Run web ui script from project root directory: `./webui.sh`
4. Observe the error trying and failing to import module `_lzma`

### What should have happened?

The `webui.sh` script should have completed successfully and the application be visible in a browser.

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

Unable to load web ui and thus unable to load system info as requested.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on wagnar user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.11.8 (main, Sep 11 2025, 17:27:21) [Clang 17.0.0 (clang-1700.0.13.5)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Users/wagnar/projects/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/__init__.py"", line 35, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/batch_size_finder.py"", line 24, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/types.py"", line 27, in <module>
    from torchmetrics import Metric
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/__init__.py"", line 37, in <module>
    from torchmetrics import functional  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/__init__.py"", line 56, in <module>
    from torchmetrics.functional.image._deprecated import (
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/__init__.py"", line 14, in <module>
    from torchmetrics.functional.image.arniqa import arniqa
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/arniqa.py"", line 31, in <module>
    from torchvision import transforms
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/__init__.py"", line 6, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/__init__.py"", line 1, in <module>
    from ._optical_flow import FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/_optical_flow.py"", line 13, in <module>
    from .utils import _read_pfm, verify_str_arg
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/utils.py"", line 4, in <module>
    import lzma
  File ""/Users/wagnar/.pyenv/versions/3.11.8/lib/python3.11/lzma.py"", line 27, in <module>
    from _lzma import *
ModuleNotFoundError: No module named '_lzma'
```

### Additional information

Issue occurred on a clean clone/install of `stable-diffusion-webui`.",2025-11-15T02:23:05Z,sotekllc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180,"[Bug]: ModuleNotFoundError: No module named '_lzma' ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

After following the Apple Silicon installation instructions at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon, I have run into an error that I cannot seem to resolve. It is looking for a module `_lzma` and not finding it.

The only deviation in the instructions is that I installed `python 3.10` via `pyenv` instead of homebrew. I'm currently running 3.10.10 to try and run the web ui.

I found another discussion on this issue that suggested installing the `xz` libraries via homebrew, and then re-installing (rebuilding) the python being used. I have tried this but it did not resolve the error.

Any advice on how to fix this error and get up and running with the web ui?


Thanks for your time.

### Steps to reproduce the problem

1. Git clone repository for `stable-diffusion-webui`
2. Install `pyenv` and install python 3.10 (3.10.10) with pyenv using `pyenv install 3.10.10 && pyenv global 3.10.10`
3. Run web ui script from project root directory: `./webui.sh`
4. Observe the error trying and failing to import module `_lzma`

### What should have happened?

The `webui.sh` script should have completed successfully and the application be visible in a browser.

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

Unable to load web ui and thus unable to load system info as requested.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on wagnar user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.11.8 (main, Sep 11 2025, 17:27:21) [Clang 17.0.0 (clang-1700.0.13.5)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Users/wagnar/projects/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/__init__.py"", line 35, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/batch_size_finder.py"", line 24, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/types.py"", line 27, in <module>
    from torchmetrics import Metric
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/__init__.py"", line 37, in <module>
    from torchmetrics import functional  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/__init__.py"", line 56, in <module>
    from torchmetrics.functional.image._deprecated import (
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/__init__.py"", line 14, in <module>
    from torchmetrics.functional.image.arniqa import arniqa
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/arniqa.py"", line 31, in <module>
    from torchvision import transforms
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/__init__.py"", line 6, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/__init__.py"", line 1, in <module>
    from ._optical_flow import FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/_optical_flow.py"", line 13, in <module>
    from .utils import _read_pfm, verify_str_arg
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/utils.py"", line 4, in <module>
    import lzma
  File ""/Users/wagnar/.pyenv/versions/3.11.8/lib/python3.11/lzma.py"", line 27, in <module>
    from _lzma import *
ModuleNotFoundError: No module named '_lzma'
```

### Additional information

Issue occurred on a clean clone/install of `stable-diffusion-webui`.",bug modulenotfounderror module named lzma checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened following apple silicon installation instructions run error cannot seem resolve looking module lzma finding deviation instructions installed python via pyenv instead homebrew currently running try run web ui found another discussion issue suggested installing xz libraries via homebrew installing rebuilding python used tried resolve error advice fix error get running web ui thanks time steps reproduce problem git clone repository stable diffusion webui install pyenv install python pyenv using pyenv install pyenv global run web ui script project root directory webui sh observe error trying failing import module lzma happened webui sh script completed successfully application visible browser browsers use access ui apple safari sysinfo unable load web ui thus unable load system info requested console logs shell install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running wagnar user repo already cloned using install directory create activate python venv launching launch py python main sep clang clang version v commit hash c ae bd abdf eda b e launching web ui arguments skip torch cuda test upcast sampling half vae use cpu interrogate traceback recent call last file users wagnar projects stable diffusion webui launch py line module main file users wagnar projects stable diffusion webui launch py line main start file users wagnar projects stable diffusion webui modules launch utils py line start import webui file users wagnar projects stable diffusion webui webui py line module initialize imports file users wagnar projects stable diffusion webui modules initialize py line imports import pytorch lightning noqa f file users wagnar projects stable diffusion webui venv lib python site packages pytorch lightning init py line module pytorch lightning callbacks import callback noqa e file users wagnar projects stable diffusion webui venv lib python site packages pytorch lightning callbacks init py line module pytorch lightning callbacks batch size finder import batchsizefinder file users wagnar projects stable diffusion webui venv lib python site packages pytorch lightning callbacks batch size finder py line module pytorch lightning callbacks callback import callback file users wagnar projects stable diffusion webui venv lib python site packages pytorch lightning callbacks callback py line module pytorch lightning utilities types import step output file users wagnar projects stable diffusion webui venv lib python site packages pytorch lightning utilities types py line module torchmetrics import metric file users wagnar projects stable diffusion webui venv lib python site packages torchmetrics init py line module torchmetrics import functional noqa e file users wagnar projects stable diffusion webui venv lib python site packages torchmetrics functional init py line module torchmetrics functional image deprecated import file users wagnar projects stable diffusion webui venv lib python site packages torchmetrics functional image init py line module torchmetrics functional image arniqa import arniqa file users wagnar projects stable diffusion webui venv lib python site packages torchmetrics functional image arniqa py line module torchvision import transforms file users wagnar projects stable diffusion webui venv lib python site packages torchvision init py line module torchvision import meta registrations datasets io models ops transforms utils file users wagnar projects stable diffusion webui venv lib python site packages torchvision datasets init py line module optical flow import flyingchairs flyingthings hd k kittiflow sintel file users wagnar projects stable diffusion webui venv lib python site packages torchvision datasets optical flow py line module utils import read pfm verify str arg file users wagnar projects stable diffusion webui venv lib python site packages torchvision datasets utils py line module import lzma file users wagnar pyenv versions lib python lzma py line module lzma import modulenotfounderror module named lzma additional information issue occurred clean clone install stable diffusion webui
auto1111_webui,comment,17180,,"I managed to fix the issue by following up on the reinstallation and deleting the `venv` folder and re-installing. Here are the steps I used to resolve this issue:

1. `brew reinstall xz`
2. deleted the `venv/` folder from the project root directory
3. `pyenv uninstall 3.10.10 && pyenv install 3.10.10 && pyenv global 3.10.10`
4. from the project root directory: `./webui.sh`",2025-11-15T02:29:26Z,sotekllc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3535428778,"I managed to fix the issue by following up on the reinstallation and deleting the `venv` folder and re-installing. Here are the steps I used to resolve this issue:

1. `brew reinstall xz`
2. deleted the `venv/` folder from the project root directory
3. `pyenv uninstall 3.10.10 && pyenv install 3.10.10 && pyenv global 3.10.10`
4. from the project root directory: `./webui.sh`",managed fix issue following reinstallation deleting venv folder installing steps used resolve issue brew reinstall xz deleted venv folder project root directory pyenv uninstall pyenv install pyenv global project root directory webui sh
auto1111_webui,comment,17180,,"`pyenv uninstall 3.10.10` and `pyenv global 3.10.10` aren't necessary. Deleting the venv folder and uninstalling the pyenv do the same thing. Setting the global pyenv binary isn't necessary unless you actually want this. If you don't want this, this will actually break your venv for other venvs you use. 

Next time this happens, install the module rather than deleting the venv. It'll not only save you time, but help you understand what is wrong and help you read the error as a useful, constructive helpline. 

Packages are installed using either `pip` or `uv`, with `pip` being the more usual but slower option, albeit still more popular nonetheless. `Pip` is also easier to get started with, as it's more native to Python itself than the external tool `uv`, needing manual installation from an external source.",2025-11-17T11:52:33Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3541414842,"`pyenv uninstall 3.10.10` and `pyenv global 3.10.10` aren't necessary. Deleting the venv folder and uninstalling the pyenv do the same thing. Setting the global pyenv binary isn't necessary unless you actually want this. If you don't want this, this will actually break your venv for other venvs you use. 

Next time this happens, install the module rather than deleting the venv. It'll not only save you time, but help you understand what is wrong and help you read the error as a useful, constructive helpline. 

Packages are installed using either `pip` or `uv`, with `pip` being the more usual but slower option, albeit still more popular nonetheless. `Pip` is also easier to get started with, as it's more native to Python itself than the external tool `uv`, needing manual installation from an external source.",pyenv uninstall pyenv global necessary deleting venv folder uninstalling pyenv thing setting global pyenv binary necessary unless actually want want actually break venv venvs use next time happens install module rather deleting venv save time help understand wrong help read error useful constructive helpline packages installed using either pip uv pip usual slower option albeit still popular nonetheless pip also easier get started native python external tool uv needing manual installation external source
auto1111_webui,comment,17180,,"Humble deer, could you please clarify what are the necessary steps to fix this issue? A detailed step by step instruction would help me resolve this issue.",2025-11-18T20:56:01Z,TeraTyrantShadic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3549513389,"Humble deer, could you please clarify what are the necessary steps to fix this issue? A detailed step by step instruction would help me resolve this issue.",humble deer could please clarify necessary steps fix issue detailed step step instruction would help resolve issue
auto1111_webui,comment,17180,,"I can't provide an exact resolution step by step, because as of right now I have no reason to believe this is a systematic failure that others will experience. 

However, I can elaborate on my suggestions:

- `pyenv uninstall 3.10.10` being unnecessary:
  Deleting the venv folder did that already, short of any specific cache outside of the folder -- they don't impact anything.
  **Suggested resolution** with my comment: use the command or the deleting of the folder; the command is ""the right way"".
- `pyenv global 3.10.10` being unnecessary:
  This sets your global standard for which python version to use. The reason this is unnecessary is twofold:
  - Your venv will have its own local version of python installed inside the `.venv` folder
  - It sets the default for the entire system, which may inadvertently break other improperly installed Python-based programs by breaking their code or dependencies. Furthermore, for the purpose of rebuilding your venv, it doesn't do anything.
  - It does not play a role in your venv creation -- it is and can be kept entirely separated from your global versions, dependencies, and programs. 
- In fact, keeping the venv (virtual environment) separate from the global python version and its installed packages is the entire purpose for why virtual environments are used. That's their primary nigh only reason why they're used. ",2025-11-20T16:49:17Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3559058963,"I can't provide an exact resolution step by step, because as of right now I have no reason to believe this is a systematic failure that others will experience. 

However, I can elaborate on my suggestions:

- `pyenv uninstall 3.10.10` being unnecessary:
  Deleting the venv folder did that already, short of any specific cache outside of the folder -- they don't impact anything.
  **Suggested resolution** with my comment: use the command or the deleting of the folder; the command is ""the right way"".
- `pyenv global 3.10.10` being unnecessary:
  This sets your global standard for which python version to use. The reason this is unnecessary is twofold:
  - Your venv will have its own local version of python installed inside the `.venv` folder
  - It sets the default for the entire system, which may inadvertently break other improperly installed Python-based programs by breaking their code or dependencies. Furthermore, for the purpose of rebuilding your venv, it doesn't do anything.
  - It does not play a role in your venv creation -- it is and can be kept entirely separated from your global versions, dependencies, and programs. 
- In fact, keeping the venv (virtual environment) separate from the global python version and its installed packages is the entire purpose for why virtual environments are used. That's their primary nigh only reason why they're used.",provide exact resolution step step right reason believe systematic failure others experience however elaborate suggestions pyenv uninstall unnecessary deleting venv folder already short specific cache outside folder impact anything suggested resolution comment use command deleting folder command right way pyenv global unnecessary sets global standard python version use reason unnecessary twofold venv local version python installed inside venv folder sets default entire system may inadvertently break improperly installed python based programs breaking code dependencies furthermore purpose rebuilding venv anything play role venv creation kept entirely separated global versions dependencies programs fact keeping venv virtual environment separate global python version installed packages entire purpose virtual environments used primary nigh reason used
auto1111_webui,issue,17173,[Feature Request]: Questions about downloading PyTorch resources,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I have an Nvidia RTX Pro 1000 graphics card. After manually installing CUDA 13 and the corresponding version of PyTorch, running ""webui.sh"" in the project's root directory still installs a version of PyTorch with CUDA 12, and the project reports an error after starting.
In addition, this graphics card belongs to the Blackwell architecture like the RTX 5000 series. I saw some repair issues related to the RTX 5000 series graphics cards, and I can't determine whether it is my operational error or some other issue.

### Proposed workflow

When Pytorch is detected, skip the download step

### Additional information

_No response_",2025-11-08T09:48:06Z,mjzde17,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173,"[Feature Request]: Questions about downloading PyTorch resources ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I have an Nvidia RTX Pro 1000 graphics card. After manually installing CUDA 13 and the corresponding version of PyTorch, running ""webui.sh"" in the project's root directory still installs a version of PyTorch with CUDA 12, and the project reports an error after starting.
In addition, this graphics card belongs to the Blackwell architecture like the RTX 5000 series. I saw some repair issues related to the RTX 5000 series graphics cards, and I can't determine whether it is my operational error or some other issue.

### Proposed workflow

When Pytorch is detected, skip the download step

### Additional information

_No response_",feature request questions downloading pytorch resources existing issue x searched existing issues checked recent builds commits would feature nvidia rtx pro graphics card manually installing cuda corresponding version pytorch running webui sh project root directory still installs version pytorch cuda project reports error starting addition graphics card belongs blackwell architecture like rtx series saw repair issues related rtx series graphics cards determine whether operational error issue proposed workflow pytorch detected skip download step additional information response
auto1111_webui,comment,17173,,"After installing your sd-webui and custom versions of Torch, pass the `--skip-prepare-environment` and `--skip-install` arguments. You can add these in the .bat/.sh file of your choosing — whichever you usually use.

Optionally, `--skip-python-version-check` and `--skip-torch-cuda-test` could be added too. The former stops version checks, the latter stops torch cuda presence test and its subsequent errors if it doesn't detect what it expects. These can clean up the terminal output, but might also hide issues if you end up with a screwed up venv. 

I'd hope it goes without saying, but: if you're installing the new PyTorch version outside of your venv, it's entirely expected for it to not be inside your venv. That's... the entire point of the venv. 

The default checks and installation is there to aid users that might not be trying to tinker and/or just want it to ""just work"". It installs the versions of packages specified in the requirements as those are the ones known to work well for the majority of people as well as being intercompatible with each other. ",2025-11-17T13:10:23Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173#issuecomment-3541757178,"After installing your sd-webui and custom versions of Torch, pass the `--skip-prepare-environment` and `--skip-install` arguments. You can add these in the .bat/.sh file of your choosing — whichever you usually use.

Optionally, `--skip-python-version-check` and `--skip-torch-cuda-test` could be added too. The former stops version checks, the latter stops torch cuda presence test and its subsequent errors if it doesn't detect what it expects. These can clean up the terminal output, but might also hide issues if you end up with a screwed up venv. 

I'd hope it goes without saying, but: if you're installing the new PyTorch version outside of your venv, it's entirely expected for it to not be inside your venv. That's... the entire point of the venv. 

The default checks and installation is there to aid users that might not be trying to tinker and/or just want it to ""just work"". It installs the versions of packages specified in the requirements as those are the ones known to work well for the majority of people as well as being intercompatible with each other.",installing sd webui custom versions torch pass skip prepare environment skip install arguments add bat sh file choosing whichever usually use optionally skip python version check skip torch cuda test could added former stops version checks latter stops torch cuda presence test subsequent errors detect expects clean terminal output might also hide issues end screwed venv hope goes without saying installing new pytorch version outside venv entirely expected inside venv entire point venv default checks installation aid users might trying tinker want work installs versions packages specified requirements ones known work well majority people well intercompatible
auto1111_webui,comment,17173,,"Nvidia RTX Pro 1000 I belibe that this has the same requirements as othre blackwell/50 series GPU
if you are using the `dev` branch pytorch version that works with it
so you shouldn't have to do anything special

---

if you do need something custom

and if pytorch is the only thing you need to change then setting the environment variables `TORCH_COMMAND` and `INDEX_URL` allows you to controls what pytorch webui tries to auto install
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

by default webui use a python venv ([python's virtual environments](https://docs.python.org/3/library/venv.html)), simply put if you system pytorch on your system environment webui it's not going to use it because it is using its own virtual environment, 
webui also installs only if it doesn't ""find"" that pytorch is installed
if for some reason you could always enter the venv and modify (install different version of pytorch)

---

> After manually installing CUDA 13 

if I'm reading this correctly I'm guessing that you are installing CUDA tool kit, 
the official binaries should come with CUDA dependencies package inside
so you shouldn't need to install your own CUDA toolkit in the system environment
",2025-11-21T10:08:24Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173#issuecomment-3562313106,"Nvidia RTX Pro 1000 I belibe that this has the same requirements as othre blackwell/50 series GPU
if you are using the `dev` branch pytorch version that works with it
so you shouldn't have to do anything special

---

if you do need something custom

and if pytorch is the only thing you need to change then setting the environment variables `TORCH_COMMAND` and `INDEX_URL` allows you to controls what pytorch webui tries to auto install
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

by default webui use a python venv ([python's virtual environments](https://docs.python.org/3/library/venv.html)), simply put if you system pytorch on your system environment webui it's not going to use it because it is using its own virtual environment, 
webui also installs only if it doesn't ""find"" that pytorch is installed
if for some reason you could always enter the venv and modify (install different version of pytorch)

---

> After manually installing CUDA 13 

if I'm reading this correctly I'm guessing that you are installing CUDA tool kit, 
the official binaries should come with CUDA dependencies package inside
so you shouldn't need to install your own CUDA toolkit in the system environment",nvidia rtx pro belibe requirements othre blackwell series gpu using dev branch pytorch version works anything special need something custom pytorch thing need change setting environment variables torch command index url allows controls pytorch webui tries auto install default webui use python venv python virtual environments simply put system pytorch system environment webui going use using virtual environment webui also installs find pytorch installed reason could always enter venv modify install different version pytorch manually installing cuda reading correctly guessing installing cuda tool kit official binaries come cuda dependencies package inside need install cuda toolkit system environment
auto1111_webui,issue,17170,[Feature Request]: Vulnerability Disclosure Contact,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello,

We have discovered a vulnerability in Stable Diffusion WebUI and we would like to disclose it responsibly to you. Please provide a private/secure channel where we can submit the report confidentially.

If we are unable to contact you after 15 days, we reserve the right to publish this vulnerability in accordance with our Disclosure Policy, which you can read here: https://www.zerodayinitiative.com/advisories/disclosure_policy/

Thank you and best regards,
Zero Day Initiative
Trend Micro
ZDI-DISCLOSURES@trendmicro.com

### Proposed workflow

a private/secure channel where we can submit the report confidentially.

### Additional information

_No response_",2025-11-06T16:50:16Z,zdi-disclosures,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17170,"[Feature Request]: Vulnerability Disclosure Contact ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello,

We have discovered a vulnerability in Stable Diffusion WebUI and we would like to disclose it responsibly to you. Please provide a private/secure channel where we can submit the report confidentially.

If we are unable to contact you after 15 days, we reserve the right to publish this vulnerability in accordance with our Disclosure Policy, which you can read here: https://www.zerodayinitiative.com/advisories/disclosure_policy/

Thank you and best regards,
Zero Day Initiative
Trend Micro
ZDI-DISCLOSURES@trendmicro.com

### Proposed workflow

a private/secure channel where we can submit the report confidentially.

### Additional information

_No response_",feature request vulnerability disclosure contact existing issue x searched existing issues checked recent builds commits would feature hello discovered vulnerability stable diffusion webui would like disclose responsibly please provide private secure channel submit report confidentially unable contact days reserve right publish vulnerability accordance disclosure policy read thank best regards zero day initiative trend micro zdi disclosures trendmicro com proposed workflow private secure channel submit report confidentially additional information response
auto1111_webui,comment,17170,,"Hi I'm one of the main collaborators of these repo

AUTOMATIC1111 is basically radio silent quite a long time, and he is the only person that has rights to push master branch of this repo
we only only have the rights to push to the dev branch, so honestly I'm not too sure what can be done if there is a vulnerability

---

there's two ways to make contact

there's a Discord server invitation link on the wikihttps://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing
there we can talk privately via direct message

ou can also contact via email
you could contact me at wewgithub@gmail.com

if you want to try and contact AUTOMATIC1111 directly you can potentially try the email address that is listed in the get log
but my guess is like like that he won't answer



",2025-11-21T10:33:49Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17170#issuecomment-3562410098,"Hi I'm one of the main collaborators of these repo

AUTOMATIC1111 is basically radio silent quite a long time, and he is the only person that has rights to push master branch of this repo
we only only have the rights to push to the dev branch, so honestly I'm not too sure what can be done if there is a vulnerability

---

there's two ways to make contact

there's a Discord server invitation link on the wikihttps://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing
there we can talk privately via direct message

ou can also contact via email
you could contact me at wewgithub@gmail.com

if you want to try and contact AUTOMATIC1111 directly you can potentially try the email address that is listed in the get log
but my guess is like like that he won't answer",hi one main collaborators repo automatic basically radio silent quite long time person rights push master branch repo rights push dev branch honestly sure done vulnerability two ways make contact discord server invitation link wiki talk privately via direct message ou also contact via email could contact wewgithub gmail com want try contact automatic directly potentially try email address listed get log guess like like answer
auto1111_webui,issue,17165,"[Bug]:  '(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded","### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when i run ./webui.sh

it goes wrong. how can I put the download files to the right directory.
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Steps to reproduce the problem

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What should have happened?

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Console logs

```Shell
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].
```

### Additional information

_No response_",2025-11-01T08:49:56Z,Xbotgo-Justin1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17165,"[Bug]:  '(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when i run ./webui.sh

it goes wrong. how can I put the download files to the right directory.
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Steps to reproduce the problem

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What should have happened?

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Console logs

```Shell
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].
```

### Additional information

_No response_",bug maxretryerror port max retries exceeded checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened run webui sh goes wrong put download files right directory maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head home justin cache huggingface hub models openai clip vit large patch maxretryerror port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head retrying retry warning huggingface hub utils retry steps reproduce problem maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head home justin cache huggingface hub models openai clip vit large patch maxretryerror port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head retrying retry warning huggingface hub utils retry happened maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head home justin cache huggingface hub models openai clip vit large patch maxretryerror port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head retrying retry warning huggingface hub utils retry browsers use access ui response sysinfo maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head home justin cache huggingface hub models openai clip vit large patch maxretryerror port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head retrying retry warning huggingface hub utils retry console logs shell maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f eff failed establish new connection errno network unreachable request id cbe e b e df b f db thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef c failed establish new connection errno network unreachable request id f c af f fc thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f ef failed establish new connection errno network unreachable request id f beb f f e e thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e f failed establish new connection errno network unreachable request id c eedd b f ac cf f bf thrown requesting head retrying retry warning huggingface hub utils retry maxretryerror port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main vocab json caused newconnectionerror urllib connection object x fc f e failed establish new connection errno network unreachable request id bc e b f fff e thrown requesting head home justin cache huggingface hub models openai clip vit large patch maxretryerror port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head warning huggingface hub utils port max retries exceeded url openai clip vit large patch resolve main merges txt caused newconnectionerror urllib connection object x fc f ea failed establish new connection errno network unreachable request id f e b dcf e db thrown requesting head retrying retry warning huggingface hub utils retry additional information response
auto1111_webui,issue,17162,[Bug]: pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

`run.bat` fails while installing Clip with message `pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'`. Fresh install of webui.

### Steps to reproduce the problem

Download webui, run `update.bat`, then `run.bat`

### What should have happened?

It should run

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2


### Console logs

```Shell
Installing clip
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
    run_pip(f""install {clip_package}"", ""clip"")
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""C:\Users\josep\Downloads\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
  Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",2025-10-27T03:44:09Z,royaldark,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162,"[Bug]: pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta' ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

`run.bat` fails while installing Clip with message `pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'`. Fresh install of webui.

### Steps to reproduce the problem

Download webui, run `update.bat`, then `run.bat`

### What should have happened?

It should run

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2


### Console logs

```Shell
Installing clip
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
    run_pip(f""install {clip_package}"", ""clip"")
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""C:\Users\josep\Downloads\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
  Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",bug pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened run bat fails installing clip message pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta fresh install webui steps reproduce problem download webui run update bat run bat happened run browsers use access ui response sysinfo python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e console logs shell installing clip traceback recent call last file c users josep downloads sd webui webui launch py line module main file c users josep downloads sd webui webui launch py line main prepare environment file c users josep downloads sd webui webui modules launch utils py line prepare environment run pip f install clip package clip file c users josep downloads sd webui webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users josep downloads sd webui webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install clip command c users josep downloads sd webui system python python exe pip install prefer binary error code stdout collecting using cached mb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done stderr error exception traceback recent call last file c users josep downloads sd webui system python lib site packages pip internal cli base command py line run wrapper status inner run file c users josep downloads sd webui system python lib site packages pip internal cli base command py line inner run return self run options args file c users josep downloads sd webui system python lib site packages pip internal cli req command py line wrapper return func self options args file c users josep downloads sd webui system python lib site packages pip internal commands install py line run requirement set resolver resolve file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib resolver py line resolve collected self factory collect root requirements root reqs file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line collect root requirements reqs list file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make requirements install req cand self make base candidate link file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init super init file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file c users josep downloads sd webui system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file c users josep downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file c users josep downloads sd webui system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file c users josep downloads sd webui system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file c users josep downloads sd webui system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs build env installer file c users josep downloads sd webui system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file c users josep downloads sd webui system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file c users josep downloads sd webui system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file c users josep downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file c users josep downloads sd webui system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta additional information response
auto1111_webui,comment,17162,,"EDIT: These steps work fine for me on a clean installation:

1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
2. Run `run.bat` until it throws the error.

3. After that, go to the folder `sd.webui\system\python` and run these commands:
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
4. Finally, run `run.bat` again.",2025-10-28T03:26:39Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3454376026,"EDIT: These steps work fine for me on a clean installation:

1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
2. Run `run.bat` until it throws the error.

3. After that, go to the folder `sd.webui\system\python` and run these commands:
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
4. Finally, run `run.bat` again.",edit steps work fine clean installation run switch branch toole bat also updates automatically choose dev run run bat throws error go folder sd webui system python run commands python exe pip install clip anytorch python exe pip install open clip torch finally run run bat
auto1111_webui,comment,17162,,"> After you get the error message, try going to `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> Then try again.

Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.",2025-10-29T16:17:22Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462533435,"> After you get the error message, try going to `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> Then try again.

Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.",get error message try going sd webui system python run commands python exe pip install clip anytorch python exe pip install open clip torch try thank even though able instal within respective folder fix issue rerun got exact error
auto1111_webui,comment,17162,,I am also facing the same issue,2025-10-29T16:49:08Z,ryker-uptycs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462661691,I am also facing the same issue,also facing issue
auto1111_webui,comment,17162,,"> > After you get the error message, try going to `sd.webui\system\python` and run these commands:
> > ```
> > python.exe -m pip install clip-anytorch
> > python.exe -m pip install open-clip-torch
> > ```
> > 
> > 
> >     
> >   
> > Then try again.
> 
> Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.

Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.",2025-10-29T17:13:27Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462743304,"> > After you get the error message, try going to `sd.webui\system\python` and run these commands:
> > ```
> > python.exe -m pip install clip-anytorch
> > python.exe -m pip install open-clip-torch
> > ```
> > 
> > 
> >     
> >   
> > Then try again.
> 
> Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.

Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.",get error message try going sd webui system python run commands python exe pip install clip anytorch python exe pip install open clip torch try thank even though able instal within respective folder fix issue rerun got exact error well actually installation extra steps gpu used indeed running commands alone work either edit answer include well
auto1111_webui,comment,17162,,"
> Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.

Thanks for the attempted update, but the update didn't work for me either.  From the looks of it, it looks like you're trying to pre-install CLiP.  You, too, are also using xformers.  The pre-installation of the CLiP library didn't help me.  The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.

I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files.  I'm not sure, but I that is an educated guess.

Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update.  That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.",2025-10-30T14:19:42Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3468264596,"> Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.

Thanks for the attempted update, but the update didn't work for me either.  From the looks of it, it looks like you're trying to pre-install CLiP.  You, too, are also using xformers.  The pre-installation of the CLiP library didn't help me.  The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.

I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files.  I'm not sure, but I that is an educated guess.

Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update.  That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.",well actually installation extra steps gpu used indeed running commands alone work either edit answer include well thanks attempted update update work either looks looks like trying pre install clip also using xformers pre installation clip library help installs python folder complete however application still tries install specific zip clip library time dig code dev python dev looking errors seems like issue hard dependency version clip longer exists basic research think clip major updates may removed old dependency files sure educated guess anyway think anything else might changed remove forced dependency version config somewhere appreciate one update said expecting solve problem thanks trying sharing
auto1111_webui,comment,17162,,"> Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> 
> I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> 
> Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.

I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
```
clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
```
to
```
clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
```
But in later tests, I didn’t need to do this anymore.

And that's all I did. I hope it can be of some use to you.",2025-10-30T17:27:43Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3469184718,"> Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> 
> I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> 
> Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.

I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
```
clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
```
to
```
clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
```
But in later tests, I didn’t need to do this anymore.

And that's all I did. I hope it can be of some use to you.",thanks attempted update update work either looks looks like trying pre install clip also using xformers pre installation clip library help installs python folder complete however application still tries install specific zip clip library time dig code dev python dev looking errors seems like issue hard dependency version clip longer exists basic research think clip major updates may removed old dependency files sure educated guess anyway think anything else might changed remove forced dependency version config somewhere appreciate one update said expecting solve problem thanks trying sharing got windows rtx outside webui python python installed manually environment variable added path edited sd webui webui webui user bat set commandline args xformers also first issue fixed editing sd webui webui modules launch utils py lines clip package os environ get clip package openclip package os environ get openclip package clip package os environ get clip package clip anytorch openclip package os environ get openclip package open clip torch later tests didnt need anymore hope use
auto1111_webui,comment,17162,,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Excellent. I'll try to give this a change later and report back with my results.
",2025-10-30T17:53:48Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3469328449,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Excellent. I'll try to give this a change later and report back with my results.",got windows rtx outside webui python python installed manually environment variable added path edited sd webui webui webui user bat set commandline args xformers also first issue fixed editing sd webui webui modules launch utils py lines clip package os environ get clip package openclip package os environ get openclip package clip package os environ get clip package clip anytorch openclip package os environ get openclip package open clip torch later tests didnt need anymore hope use excellent try give change later report back results
auto1111_webui,comment,17162,,"> > Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> > I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> > Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.
> 
> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Unfortunately didn't work.",2025-10-31T10:52:41Z,BerBerOnGithub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472493779,"> > Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> > I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> > Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.
> 
> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Unfortunately didn't work.",thanks attempted update update work either looks looks like trying pre install clip also using xformers pre installation clip library help installs python folder complete however application still tries install specific zip clip library time dig code dev python dev looking errors seems like issue hard dependency version clip longer exists basic research think clip major updates may removed old dependency files sure educated guess anyway think anything else might changed remove forced dependency version config somewhere appreciate one update said expecting solve problem thanks trying sharing got windows rtx outside webui python python installed manually environment variable added path edited sd webui webui webui user bat set commandline args xformers also first issue fixed editing sd webui webui modules launch utils py lines clip package os environ get clip package openclip package os environ get openclip package clip package os environ get clip package clip anytorch openclip package os environ get openclip package open clip torch later tests didnt need anymore hope use unfortunately work
auto1111_webui,comment,17162,,"Try running this command:

**`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**

Worked for me.
",2025-10-31T12:52:40Z,BerBerOnGithub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472973242,"Try running this command:

**`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**

Worked for me.",try running command python exe pip install build isolation r path sd webui webui requirements versions txt worked
auto1111_webui,comment,17162,,"Yeah, the second suggestion didn't work for me either, but I also don't have much time to troubleshoot this. Yes, the application tries to put stuff in the `system\python` folder but I think I might personally have some other dependency issues.

I've been quite busy and I've only been able to mess with this for 5-10 minutes here and there, but if I can get any serious time to look into this, I'll try to diagnose and fix a patch.  Alternatively, someone might have a fork of this and they've updated the related code. It might be worth trying to look into that. I would but, again, that takes time I don't have at the moment.",2025-10-31T12:54:23Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472978302,"Yeah, the second suggestion didn't work for me either, but I also don't have much time to troubleshoot this. Yes, the application tries to put stuff in the `system\python` folder but I think I might personally have some other dependency issues.

I've been quite busy and I've only been able to mess with this for 5-10 minutes here and there, but if I can get any serious time to look into this, I'll try to diagnose and fix a patch.  Alternatively, someone might have a fork of this and they've updated the related code. It might be worth trying to look into that. I would but, again, that takes time I don't have at the moment.",yeah second suggestion work either also much time troubleshoot yes application tries put stuff system python folder think might personally dependency issues quite busy able mess minutes get serious time look try diagnose fix patch alternatively someone might fork updated related code might worth trying look would takes time moment
auto1111_webui,comment,17162,,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Thanks for the help, unfortunately it doesn't change the error, which is (at the end of the trace):

```
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

I also tried some `pip` commands to force upgrade and purge, but to no avail.",2025-10-31T18:18:34Z,rkyoku,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3474299992,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didn’t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Thanks for the help, unfortunately it doesn't change the error, which is (at the end of the trace):

```
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

I also tried some `pip` commands to force upgrade and purge, but to no avail.",got windows rtx outside webui python python installed manually environment variable added path edited sd webui webui webui user bat set commandline args xformers also first issue fixed editing sd webui webui modules launch utils py lines clip package os environ get clip package openclip package os environ get openclip package clip package os environ get clip package clip anytorch openclip package os environ get openclip package open clip torch later tests didnt need anymore hope use thanks help unfortunately change error end trace pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta also tried pip commands force upgrade purge avail
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Yeah, the ""--no-build-isolation"" is the key. THX",2025-11-02T22:10:47Z,I-m-PhD,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478415041,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Yeah, the ""--no-build-isolation"" is the key. THX",try running command python exe pip install build isolation r path sd webui webui requirements versions txt worked yeah build isolation key thx
auto1111_webui,comment,17162,,"Win11, NVIDIA 4060 LAPTOP GPU, the problem was that i had multiple versions of python installed on my pc and SD somehow picks the latest version. 

I fixed it by following this steps.



update.bat switch-branch-toole.bat  option 3, update.bat (just in case)

""**run.bat**"", after it says ""**creating venv**""  press ""**ctrl+c**"" and go to ""**webui\venv**"" and edit ""**pyvenv.cfg**"" file (replace with your installed location)

<img width=""1083"" height=""125"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b9ec391-369c-4751-96ac-ec8b4e6a486e"" />


if it still fails try:

 if you have any vpn services disable it, disable any dns blockers or rewrites, disable any DPI-Bypassers, disable any proxies. After those check if its fixed ",2025-11-02T22:20:53Z,mahmutozerg,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478429562,"Win11, NVIDIA 4060 LAPTOP GPU, the problem was that i had multiple versions of python installed on my pc and SD somehow picks the latest version. 

I fixed it by following this steps.



update.bat switch-branch-toole.bat  option 3, update.bat (just in case)

""**run.bat**"", after it says ""**creating venv**""  press ""**ctrl+c**"" and go to ""**webui\venv**"" and edit ""**pyvenv.cfg**"" file (replace with your installed location)

<img width=""1083"" height=""125"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b9ec391-369c-4751-96ac-ec8b4e6a486e"" />


if it still fails try:

 if you have any vpn services disable it, disable any dns blockers or rewrites, disable any DPI-Bypassers, disable any proxies. After those check if its fixed",win nvidia laptop gpu problem multiple versions python installed pc sd somehow picks latest version fixed following steps update bat switch branch toole bat option update bat case run bat says creating venv press ctrl c go webui venv edit pyvenv cfg file replace installed location img width height alt image src still fails try vpn services disable disable dns blockers rewrites disable dpi bypassers disable proxies check fixed
auto1111_webui,comment,17162,,same issue,2025-11-02T22:49:50Z,kubinka0505,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478451046,same issue,issue
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

```
F:\sd.webui\system\python>""python.exe"" -m pip install --no-build-isolation -r ""F:\sd.webui\webui\requirements_versions.txt""
F:\sd.webui\system\python\python.exe: No module named pip
```",2025-11-02T22:50:57Z,kubinka0505,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478451872,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

```
F:\sd.webui\system\python>""python.exe"" -m pip install --no-build-isolation -r ""F:\sd.webui\webui\requirements_versions.txt""
F:\sd.webui\system\python\python.exe: No module named pip
```",try running command python exe pip install build isolation r path sd webui webui requirements versions txt worked f sd webui system python python exe pip install build isolation r f sd webui webui requirements versions txt f sd webui system python python exe module named pip
auto1111_webui,comment,17162,,"I first tried
```
""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
```
and it didn't work. But I then tried
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
and it got past the issue.",2025-11-06T19:24:26Z,Draaloff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3499040595,"I first tried
```
""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
```
and it didn't work. But I then tried
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
and it got past the issue.",first tried python exe pip install build isolation r path sd webui webui requirements versions txt work tried python exe pip install clip anytorch python exe pip install open clip torch got past issue
auto1111_webui,comment,17162,,"> I first tried
> 
> ```
> ""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
> ```
> 
> and it didn't work. But I then tried
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> and it got past the issue.

I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?",2025-11-06T19:59:17Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3499175736,"> I first tried
> 
> ```
> ""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
> ```
> 
> and it didn't work. But I then tried
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> and it got past the issue.

I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?",first tried python exe pip install build isolation r path sd webui webui requirements versions txt work tried python exe pip install clip anytorch python exe pip install open clip torch got past issue could never get variations work mind asking set type pc version python installed etc
auto1111_webui,comment,17162,,"
> I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?

It also did not solve it for me, despite the commands running and outputting (I guess it used system python, which is not what you need as far as I understand) but then I tried the following, which solved it for me:

 Open an elevated CMD prompt (**not** powershell), cd into: [YOUR_PATH]/webui/system/python,

Then running the following command:
`python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`

After this, the run.bat finally started working. :) ",2025-11-11T20:43:13Z,pushhyeah,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3518666742,"> I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?

It also did not solve it for me, despite the commands running and outputting (I guess it used system python, which is not what you need as far as I understand) but then I tried the following, which solved it for me:

 Open an elevated CMD prompt (**not** powershell), cd into: [YOUR_PATH]/webui/system/python,

Then running the following command:
`python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`

After this, the run.bat finally started working. :)",could never get variations work mind asking set type pc version python installed etc also solve despite commands running outputting guess used system python need far understand tried following solved open elevated cmd prompt powershell cd path webui system python running following command python exe pip install build isolation r path sd webui webui requirements versions txt run bat finally started working
auto1111_webui,comment,17162,,"It seems like the problem also affect CLIP
`RuntimeError: Couldn't install clip.`
So I ran your command @pushhyeah and then ran in ""[YOUR PATH HERE]\sd.webui\system\python>""
`python.exe -m pip install --no-build-isolation https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary`

It allowed the UI to launch but then I faced a failed download from the stable diffusion model.
In addition I got a bit to brave and tried installing the DeOldify extension but had to install manually the missing dependency via your trick.
On a second launch, downloading the stable diffusion model worked just fine. But I am actually stuck in an endless loop of conflicting dependency. 

",2025-11-11T23:40:18Z,TSS-22,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3519192723,"It seems like the problem also affect CLIP
`RuntimeError: Couldn't install clip.`
So I ran your command @pushhyeah and then ran in ""[YOUR PATH HERE]\sd.webui\system\python>""
`python.exe -m pip install --no-build-isolation https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary`

It allowed the UI to launch but then I faced a failed download from the stable diffusion model.
In addition I got a bit to brave and tried installing the DeOldify extension but had to install manually the missing dependency via your trick.
On a second launch, downloading the stable diffusion model worked just fine. But I am actually stuck in an endless loop of conflicting dependency.",seems like problem also affect clip runtimeerror install clip ran command pushhyeah ran path sd webui system python python exe pip install build isolation prefer binary allowed ui launch faced failed download stable diffusion model addition got bit brave tried installing deoldify extension install manually missing dependency via trick second launch downloading stable diffusion model worked fine actually stuck endless loop conflicting dependency
auto1111_webui,comment,17162,,"> pip install open-clip-torch

This full code helped 
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python .exe"" -m pip install clip-anytorch`
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python.exe"" -m pip install open-clip-torch`
Change the disk for yourself.",2025-11-14T22:16:10Z,alukardua1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3534866619,"> pip install open-clip-torch

This full code helped 
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python .exe"" -m pip install clip-anytorch`
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python.exe"" -m pip install open-clip-torch`
Change the disk for yourself.",pip install open clip torch full code helped c stablediffusioninstall stable diffusion system python python exe pip install clip anytorch c stablediffusioninstall stable diffusion system python python exe pip install open clip torch change disk
auto1111_webui,comment,17162,,"after I come to python in the sd.webui files, where do I go then, because there is just more files",2025-11-18T10:25:26Z,Kirsipasta,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3546749433,"after I come to python in the sd.webui files, where do I go then, because there is just more files",come python sd webui files go files
auto1111_webui,comment,17162,,"I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors.  I only found the final fix after reading the stack trace:

Add a `--no-build-isolation` here:

https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142

Result:

```python
    return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
```",2025-11-24T23:39:09Z,YunJD,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3573168981,"I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors.  I only found the final fix after reading the stack trace:

Add a `--no-build-isolation` here:

https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142

Result:

```python
    return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
```",gpu previous comments install clip anytorch open clip torch helpful pass errors found final fix reading stack trace add build isolation result python return run f python pip command build isolation prefer binary index url line desc f installing desc errdesc f install desc live live
auto1111_webui,comment,17162,,"> I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors. I only found the final fix after reading the stack trace:
> 
> Add a `--no-build-isolation` here:
> 
> [stable-diffusion-webui/modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142)
> 
> Line 142 in [6685e53](/AUTOMATIC1111/stable-diffusion-webui/commit/6685e532dfb40deee3287ef62a66bf4465728517)
> 
>  return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live) 
> Result:
> 
>     return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)

Adding `--no-build-isolation` and modding the `launch_utils.py` to use name refs for packages vs commit hash refs at least lets me launch the web UI. I am now getting errors about no CUDA kernel image failing the load of Stable diffusion model. So... progress I guess.",2025-11-29T21:38:36Z,Naphier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3591955624,"> I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors. I only found the final fix after reading the stack trace:
> 
> Add a `--no-build-isolation` here:
> 
> [stable-diffusion-webui/modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142)
> 
> Line 142 in [6685e53](/AUTOMATIC1111/stable-diffusion-webui/commit/6685e532dfb40deee3287ef62a66bf4465728517)
> 
>  return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live) 
> Result:
> 
>     return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)

Adding `--no-build-isolation` and modding the `launch_utils.py` to use name refs for packages vs commit hash refs at least lets me launch the web UI. I am now getting errors about no CUDA kernel image failing the load of Stable diffusion model. So... progress I guess.",gpu previous comments install clip anytorch open clip torch helpful pass errors found final fix reading stack trace add build isolation stable diffusion webui modules launch utils py line e automatic stable diffusion webui commit e dfb deee ef bf return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live result return run f python pip command build isolation prefer binary index url line desc f installing desc errdesc f install desc live live adding build isolation modding launch utils py use name refs packages vs commit hash refs least lets launch web ui getting errors cuda kernel image failing load stable diffusion model progress guess
auto1111_webui,comment,17162,,"Following steps worked for me (I used Git bash as my terminal):
- Uninstall all other versions of Python, keep only 3.10.6
- Open git bash, activate virtual environment inside webui directory: `source /sd.webui/webui/venv/Scripts/activate`
- `pip install -r /sd.webui/webui/requirements_versions.txt`

After this, `run.bat` should work fine.",2025-12-01T21:59:10Z,lakshadeep91,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3599140909,"Following steps worked for me (I used Git bash as my terminal):
- Uninstall all other versions of Python, keep only 3.10.6
- Open git bash, activate virtual environment inside webui directory: `source /sd.webui/webui/venv/Scripts/activate`
- `pip install -r /sd.webui/webui/requirements_versions.txt`

After this, `run.bat` should work fine.",following steps worked used git bash terminal uninstall versions python keep open git bash activate virtual environment inside webui directory source sd webui webui venv scripts activate pip install r sd webui webui requirements versions txt run bat work fine
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Worked for me, too. Thank you!",2025-12-02T13:42:04Z,foreveryoung82,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3602139264,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Worked for me, too. Thank you!",try running command python exe pip install build isolation r path sd webui webui requirements versions txt worked worked thank
auto1111_webui,comment,17162,,"Steps I took to get it running
System: Windows 11, Intel 285k, RTX 5090

- Ensure ONLY Python 3.10.6 is installed (had issues till I removed the others)
- Run switch-branch-toole.bat (it also updates automatically) and choose 3. dev
- (From PowerShell) Run run.bat so it throws errors
- cd to system\python and run
- python.exe -m pip install clip-anytorch
- python.exe -m pip install open-clip-torch
- Edit webui\modules\launch_utils.py
- LINE 142 Add --no-build-isolation before the --prefer-binary
- LINE 377 Change to clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"") 
- LINE 378 Change to openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
- Edit webui\webui-user.bat
- LINE 6 Change to set COMMANDLINE_ARGS=--xformers

At that point it ran and was able to generate a simple test image to be sure it was working 

<img width=""2055"" height=""1147"" alt=""Image"" src=""https://github.com/user-attachments/assets/6ba5a603-7aa2-4693-90dc-b7c62fc04124"" />

Hope this helps anyone else with a 50 series getting this error ",2025-12-30T19:47:39Z,AlyxSharkBite,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3700313904,"Steps I took to get it running
System: Windows 11, Intel 285k, RTX 5090

- Ensure ONLY Python 3.10.6 is installed (had issues till I removed the others)
- Run switch-branch-toole.bat (it also updates automatically) and choose 3. dev
- (From PowerShell) Run run.bat so it throws errors
- cd to system\python and run
- python.exe -m pip install clip-anytorch
- python.exe -m pip install open-clip-torch
- Edit webui\modules\launch_utils.py
- LINE 142 Add --no-build-isolation before the --prefer-binary
- LINE 377 Change to clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"") 
- LINE 378 Change to openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
- Edit webui\webui-user.bat
- LINE 6 Change to set COMMANDLINE_ARGS=--xformers

At that point it ran and was able to generate a simple test image to be sure it was working 

<img width=""2055"" height=""1147"" alt=""Image"" src=""https://github.com/user-attachments/assets/6ba5a603-7aa2-4693-90dc-b7c62fc04124"" />

Hope this helps anyone else with a 50 series getting this error",steps took get running system windows intel k rtx ensure python installed issues till removed others run switch branch toole bat also updates automatically choose dev powershell run run bat throws errors cd system python run python exe pip install clip anytorch python exe pip install open clip torch edit webui modules launch utils py line add build isolation prefer binary line change clip package os environ get clip package clip anytorch line change openclip package os environ get openclip package open clip torch edit webui webui user bat line change set commandline args xformers point ran able generate simple test image sure working img width height alt image src hope helps anyone else series getting error
auto1111_webui,comment,17162,,"@AlyxSharkBite thank you, your steps helped
for me I need to add `.\` begin of bellow commands to make sure that it uses python.exe in  `\sd.webui.zip\system\python\`

like this:

```
.\python.exe -m pip install clip-anytorch
.\python.exe -m pip install open-clip-torch
```",2026-01-04T21:48:15Z,minhhungit,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3708455202,"@AlyxSharkBite thank you, your steps helped
for me I need to add `.\` begin of bellow commands to make sure that it uses python.exe in  `\sd.webui.zip\system\python\`

like this:

```
.\python.exe -m pip install clip-anytorch
.\python.exe -m pip install open-clip-torch
```",alyxsharkbite thank steps helped need add begin bellow commands make sure uses python exe sd webui zip system python like python exe pip install clip anytorch python exe pip install open clip torch
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

OMG THANK YOU SO MUCH",2026-01-16T20:47:43Z,kod0ku,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3761761194,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

OMG THANK YOU SO MUCH",try running command python exe pip install build isolation r path sd webui webui requirements versions txt worked omg thank much
auto1111_webui,comment,17162,,"So you need to correctly install packages for local python installation (that's located in `./system/python` subfolder).
What's worked for me:
1. Run `run.bat`. It fails, you get `setuptools.build_meta` error.
2. Run cmd and go to the aforementioned folder.
3. Run `python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\webui\requirements_versions.txt""`. Double check the path -> `webui` folder is in the root of the `sd.webui.zip` archive; consider it when unarchiving and setting the path in the command.
4. In the same folder run `python.exe -m pip install clip-anytorch`
5. Then `python.exe -m pip install open-clip-torch`
6. Run `run.bat` again.",2026-01-24T13:57:33Z,astepforward,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3794687387,"So you need to correctly install packages for local python installation (that's located in `./system/python` subfolder).
What's worked for me:
1. Run `run.bat`. It fails, you get `setuptools.build_meta` error.
2. Run cmd and go to the aforementioned folder.
3. Run `python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\webui\requirements_versions.txt""`. Double check the path -> `webui` folder is in the root of the `sd.webui.zip` archive; consider it when unarchiving and setting the path in the command.
4. In the same folder run `python.exe -m pip install clip-anytorch`
5. Then `python.exe -m pip install open-clip-torch`
6. Run `run.bat` again.",need correctly install packages local python installation located system python subfolder worked run run bat fails get setuptools build meta error run cmd go aforementioned folder run python exe pip install build isolation r path webui requirements versions txt double check path webui folder root sd webui zip archive consider unarchiving setting path command folder run python exe pip install clip anytorch python exe pip install open clip torch run run bat
auto1111_webui,comment,17162,,"Hey I'm quite new to using Python and I've run into this same issue, but I don't know where to begin troubleshooting. I cant follow the first instruction you give. 

> EDIT: These steps work fine for me on a clean installation:
> 
> 1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
> 2. Run `run.bat` until it throws the error.
> 3. After that, go to the folder `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> 4. Finally, run `run.bat` again.

I go to the folder you state but... where am I running these commands? In the python application in that folder? When I copy the test as-is it throws up a syntax error. I haven't Installed anything else but this application following the steps provided. ",2026-01-28T22:08:54Z,AkioDude,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3814182819,"Hey I'm quite new to using Python and I've run into this same issue, but I don't know where to begin troubleshooting. I cant follow the first instruction you give. 

> EDIT: These steps work fine for me on a clean installation:
> 
> 1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
> 2. Run `run.bat` until it throws the error.
> 3. After that, go to the folder `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> 4. Finally, run `run.bat` again.

I go to the folder you state but... where am I running these commands? In the python application in that folder? When I copy the test as-is it throws up a syntax error. I haven't Installed anything else but this application following the steps provided.",hey quite new using python run issue know begin troubleshooting cant follow first instruction give edit steps work fine clean installation run switch branch toole bat also updates automatically choose dev run run bat throws error go folder sd webui system python run commands python exe pip install clip anytorch python exe pip install open clip torch finally run run bat go folder state running commands python application folder copy test throws syntax error installed anything else application following steps provided
auto1111_webui,issue,17161,[Security Alert]: Not all endpoints require authentication even when explicitly enabled,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Some manually added endpoints such as `/internal/sysinfo` can still be called even when authentication is meant to be enforced by Gradio.



### Steps to reproduce the problem

1. Enable Gradio based authentication
2. Open http://127.0.0.1/internal/sysinfo in an incognito browser window
3. Notice how it still returns system information even when authentication is enabled.

### What should have happened?

It should have required the user to be signed in to return that information.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-00-00-00-00.json](https://github.com/user-attachments/files/23155260/sysinfo-2025-00-00-00-00.json)

### Console logs

```Shell
N/A
```

### Additional information

_No response_",2025-10-27T02:01:37Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17161,"[Security Alert]: Not all endpoints require authentication even when explicitly enabled ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Some manually added endpoints such as `/internal/sysinfo` can still be called even when authentication is meant to be enforced by Gradio.



### Steps to reproduce the problem

1. Enable Gradio based authentication
2. Open http://127.0.0.1/internal/sysinfo in an incognito browser window
3. Notice how it still returns system information even when authentication is enabled.

### What should have happened?

It should have required the user to be signed in to return that information.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-00-00-00-00.json](https://github.com/user-attachments/files/23155260/sysinfo-2025-00-00-00-00.json)

### Console logs

```Shell
N/A
```

### Additional information

_No response_",security alert endpoints require authentication even explicitly enabled checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened manually added endpoints internal sysinfo still called even authentication meant enforced gradio steps reproduce problem enable gradio based authentication open incognito browser window notice still returns system information even authentication enabled happened required user signed return information browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell n additional information response
auto1111_webui,comment,17161,,"for `/internal/sysinfo` I have a PR
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16755

personally I don't like exposed `/internal/sysinfo` that's why I decided to make the pr

but as the authentication password should be stripped from `/internal/sysinfo` response (if you're no using a old version)
I believe AUTOMATIC1111 thinks it ok to be exposed and easier to implement at the time

note that endpoints added by extension they will have to enable authentication when adding the route on the extension side",2025-10-29T19:45:47Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17161#issuecomment-3463565283,"for `/internal/sysinfo` I have a PR
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16755

personally I don't like exposed `/internal/sysinfo` that's why I decided to make the pr

but as the authentication password should be stripped from `/internal/sysinfo` response (if you're no using a old version)
I believe AUTOMATIC1111 thinks it ok to be exposed and easier to implement at the time

note that endpoints added by extension they will have to enable authentication when adding the route on the extension side",internal sysinfo pr personally like exposed internal sysinfo decided make pr authentication password stripped internal sysinfo response using old version believe automatic thinks ok exposed easier implement time note endpoints added extension enable authentication adding route extension side
auto1111_webui,issue,17150,[Feature Request]: Run on Jetson Thor,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

For Jetson orin,there is a jetson-container to help us run this project easily.However, I was trying to run this on Jetson thor and failed.I hope it could provide a convenient way to run on Jetson Thor.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-10-16T06:46:01Z,ckdavid233,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17150,"[Feature Request]: Run on Jetson Thor ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

For Jetson orin,there is a jetson-container to help us run this project easily.However, I was trying to run this on Jetson thor and failed.I hope it could provide a convenient way to run on Jetson Thor.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request run jetson thor existing issue x searched existing issues checked recent builds commits would feature jetson orin jetson container help us run project easily however trying run jetson thor failed hope could provide convenient way run jetson thor proposed workflow go press additional information response
auto1111_webui,issue,17146,[Bug]: Doesn't run in newer python versions (ex. python v3.13.5.),"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

### Steps to reproduce the problem

Try to open program with python version newer than 1.10

### What should have happened?

update if possible, so it work with latest python versions

### What browsers do you use to access the UI ?

Brave

### Sysinfo

[sysinfo.py](https://github.com/user-attachments/files/22881841/sysinfo.py)

### Console logs

```Shell
This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",2025-10-13T09:55:01Z,Rein-42,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146,"[Bug]: Doesn't run in newer python versions (ex. python v3.13.5.) ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

### Steps to reproduce the problem

Try to open program with python version newer than 1.10

### What should have happened?

update if possible, so it work with latest python versions

### What browsers do you use to access the UI ?

Brave

### Sysinfo

[sysinfo.py](https://github.com/user-attachments/files/22881841/sysinfo.py)

### Console logs

```Shell
This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",bug run newer python versions ex python v checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened program tested python error could find version satisfies requirement torch versions none error matching distribution found torch traceback recent call last file download programs stable diffusion webui master launch py line module main file download programs stable diffusion webui master launch py line main prepare environment file download programs stable diffusion webui master modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file download programs stable diffusion webui master modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command download programs stable diffusion webui master venv scripts python exe pip install torch torchvision extra index url error code steps reproduce problem try open program python version newer happened update possible work latest python versions browsers use access ui brave sysinfo sysinfo py console logs shell program tested python error could find version satisfies requirement torch versions none error matching distribution found torch traceback recent call last file download programs stable diffusion webui master launch py line module main file download programs stable diffusion webui master launch py line main prepare environment file download programs stable diffusion webui master modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file download programs stable diffusion webui master modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command download programs stable diffusion webui master venv scripts python exe pip install torch torchvision extra index url error code additional information response
auto1111_webui,comment,17146,,"You can install multiple python versions at once.

Set python 3.10 in [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L3) and delete the venv folder.
```batch
set PYTHON=python3.10.exe
```",2025-10-17T22:12:09Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3417393896,"You can install multiple python versions at once.

Set python 3.10 in [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L3) and delete the venv folder.
```batch
set PYTHON=python3.10.exe
```",install multiple python versions set python webui user bat delete venv folder batch set python python exe
auto1111_webui,comment,17146,,As @missionfloyd said but be sure to set the exe path in quotes as well,2025-11-06T21:28:34Z,ngrosso1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3499457866,As @missionfloyd said but be sure to set the exe path in quotes as well,missionfloyd said sure set exe path quotes well
auto1111_webui,comment,17146,,"I'm having the same issue, and I wrote a [Discussion post yesterday](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues) about this that hasn't gotten any views yet.

In my case, on Linux Mint, README.md says nothing about editing a .bat file, though there is one present. Is the .bat file used on Mint too or just Windows?

Instead, it instructs to edit the `webui.sh` launch script, which as I mention in the post, conflicts with the file's comment instructing **not** to edit it, but to edit `webui-user.sh` instead.

So I edit `webui-user.sh` and it has no effect. And now that I discovered this bug thread, I tried editing the `webui-user.bat` file instead, and it still it does not work. I still get the same error message as the OP, but in a GNU accent.

```
Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0, 2.2.0+cu121, 2.2.1, 2.2.1+cu121, 2.2.2, 2.2.2+cu121, 2.3.0, 2.3.0+cu121, 2.3.1, 2.3.1+cu121, 2.4.0, 2.4.0+cu121, 2.4.1, 2.4.1+cu121, 2.5.0, 2.5.0+cu121, 2.5.1, 2.5.1+cu121, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

```
I should note that the instructions for GNU systems instruct to install Python 3.11—not Python 3.10, and links a ppa repository.  Is this information correct?

The team may want to look into revising the README.md to address all these issues! Documentation is important!",2025-11-23T20:55:53Z,Ratspeed,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3568327656,"I'm having the same issue, and I wrote a [Discussion post yesterday](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues) about this that hasn't gotten any views yet.

In my case, on Linux Mint, README.md says nothing about editing a .bat file, though there is one present. Is the .bat file used on Mint too or just Windows?

Instead, it instructs to edit the `webui.sh` launch script, which as I mention in the post, conflicts with the file's comment instructing **not** to edit it, but to edit `webui-user.sh` instead.

So I edit `webui-user.sh` and it has no effect. And now that I discovered this bug thread, I tried editing the `webui-user.bat` file instead, and it still it does not work. I still get the same error message as the OP, but in a GNU accent.

```
Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0, 2.2.0+cu121, 2.2.1, 2.2.1+cu121, 2.2.2, 2.2.2+cu121, 2.3.0, 2.3.0+cu121, 2.3.1, 2.3.1+cu121, 2.4.0, 2.4.0+cu121, 2.4.1, 2.4.1+cu121, 2.5.0, 2.5.0+cu121, 2.5.1, 2.5.1+cu121, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

```
I should note that the instructions for GNU systems instruct to install Python 3.11—not Python 3.10, and links a ppa repository.  Is this information correct?

The team may want to look into revising the README.md to address all these issues! Documentation is important!",issue wrote discussion post yesterday gotten views yet case linux mint readme md says nothing editing bat file though one present bat file used mint windows instead instructs edit webui sh launch script mention post conflicts file comment instructing edit edit webui user sh instead edit webui user sh effect discovered bug thread tried editing webui user bat file instead still work still get error message op gnu accent python main aug gcc version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes error could find version satisfies requirement torch versions cu cu cu cu cu cu cu cu cu error matching distribution found torch traceback recent call last file home user apps ai stable diffusion webui stable diffusion webui launch py line module main file home user apps ai stable diffusion webui stable diffusion webui launch py line main prepare environment file home user apps ai stable diffusion webui stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file home user apps ai stable diffusion webui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command home user apps ai stable diffusion webui stable diffusion webui venv bin python pip install torch torchvision extra index url error code note instructions gnu systems instruct install python python links ppa repository information correct team may want look revising readme md address issues documentation important
auto1111_webui,comment,17146,,"Currently, with minor dependency changes, there's no problem keeping Automatic1111 updated to Python 3.12 + PyTorch 2.9.1 + CU130 + xformers: 0.0.34+, using a good number of installed extensions, and it works perfectly.

With Python 3.13, I haven't finished resolving some indirect problems specifically caused by ControlNet, since it requires at least pydantic 1.10.20, which breaks several parts of Automatic1111 that I'm currently working on.

Some other extensions also have problems because they don't yet have dependencies compatible with Python 3.13 (obviously, these are the ones I use).",2025-11-26T03:08:59Z,Theliel,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3578769763,"Currently, with minor dependency changes, there's no problem keeping Automatic1111 updated to Python 3.12 + PyTorch 2.9.1 + CU130 + xformers: 0.0.34+, using a good number of installed extensions, and it works perfectly.

With Python 3.13, I haven't finished resolving some indirect problems specifically caused by ControlNet, since it requires at least pydantic 1.10.20, which breaks several parts of Automatic1111 that I'm currently working on.

Some other extensions also have problems because they don't yet have dependencies compatible with Python 3.13 (obviously, these are the ones I use).",currently minor dependency changes problem keeping automatic updated python pytorch cu xformers using good number installed extensions works perfectly python finished resolving indirect problems specifically caused controlnet since requires least pydantic breaks several parts automatic currently working extensions also problems yet dependencies compatible python obviously ones use
auto1111_webui,issue,17126,[Bug]: SDXL Models Fail After WebUI Restart Due to VAE Error Recovery Not Persisting,"### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SDXL models generate properly on fresh WebUI installation but consistently fail after any WebUI restart, producing corrupted output (""color splashes"" or grey boxes). SD 1.5 models remain unaffected. The issue appears to be related to WebUI's automatic VAE error recovery mechanism not initializing properly on restart for SDXL models.

WebUI Version: v1.10.1 (Commit: 82a973c04367123ae98bd9abdf80d9eda9b910e2)
Hardware: NVIDIA GeForce RTX 3050 (6GB VRAM)
CUDA: 12.9
PyTorch: 2.1.2+cu121
Python: 3.10.6
OS: Windows

### Steps to reproduce the problem

Reproduction Steps
Consistent Reproduction:

Fresh WebUI installation
Load any SDXL model
Generate image → Works perfectly
Close WebUI terminal completely
Restart WebUI (one or two times before the failure happens)
Load same SDXL model
Generate image → Produces corrupted output (color splashes/grey boxes)

Key Observations:

SD 1.5 models continue working normally after restart
Some specific SDXL models remain stable across restarts (model-dependent)
Loading certain SD 1.5 models can ""fix"" SDXL generation but contaminates output with SD 1.5 model's characteristics
Issue persists across different SDXL checkpoints

### What should have happened?

SDXL models should generate consistently after WebUI restarts, with the same automatic VAE error recovery that occurs on fresh installation.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-09-14-09-57.json](https://github.com/user-attachments/files/22319280/sysinfo-2025-09-14-09-57.json)

### Console logs

```Shell
C:\webui_fresh>webui-user.bat
venv ""C:\webui_fresh\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
C:\webui_fresh\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [3343bb16c2] from C:\webui_fresh\models\Stable-diffusion\SDXL_madejanss.safetensors
Creating model from config: C:\webui_fresh\configs\v1-inference.yaml
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 12.5s (prepare environment: 3.7s, import torch: 4.3s, import gradio: 1.1s, setup paths: 0.8s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 0.9s, create ui: 0.4s, gradio launch: 0.5s).
Applying attention optimization: xformers... done.
Model loaded in 2.0s (create model: 1.3s, apply weights to model: 0.2s, calculate empty prompt: 0.3s).
100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.46it/s]
Total progress: 100%|██████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.50it/s]
Total progress: 100%|██████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.87it/s]
```

### Additional information

VAE Error Recovery Pattern: The key indicator of working vs failing state is the presence of these console messages:

Working State (Fresh Install):
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.

Failing State (After Restart):
Above VAE error messages do NOT appear
SDXL models fail to generate properly
Corruption occurs during generation process

Hypothesis
WebUI's automatic VAE error recovery mechanism that converts VAE to 32-bit floats is not initializing properly on restart for SDXL models. This protective conversion that prevents VAE corruption works on fresh install but fails to trigger on subsequent sessions.
Attempted Solutions (All Failed)

--no-half-vae flag
--medvram with various memory optimizations
NumPy downgrade to <2.0
Clearing model cache and pycache directories
PyTorch reinstallation with specific CUDA versions
Various precision flags (--no-half, --upcast-sampling, etc.)
Model configuration resets

Additional Context
Model-Specific Behavior:

Some SDXL models maintain stability across restarts
Others fail immediately after any model switching
The corruption appears when WebUI stops automatically handling VAE NaN errors

SD 1.5 Model ""Fixing"" Pattern:

Loading specific SD 1.5 models can restore SDXL functionality
However, SDXL output becomes contaminated with characteristics of the SD 1.5 model
This suggests model state cross-contamination during loading",2025-09-14T10:04:34Z,mlworks90,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17126,"[Bug]: SDXL Models Fail After WebUI Restart Due to VAE Error Recovery Not Persisting ### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SDXL models generate properly on fresh WebUI installation but consistently fail after any WebUI restart, producing corrupted output (""color splashes"" or grey boxes). SD 1.5 models remain unaffected. The issue appears to be related to WebUI's automatic VAE error recovery mechanism not initializing properly on restart for SDXL models.

WebUI Version: v1.10.1 (Commit: 82a973c04367123ae98bd9abdf80d9eda9b910e2)
Hardware: NVIDIA GeForce RTX 3050 (6GB VRAM)
CUDA: 12.9
PyTorch: 2.1.2+cu121
Python: 3.10.6
OS: Windows

### Steps to reproduce the problem

Reproduction Steps
Consistent Reproduction:

Fresh WebUI installation
Load any SDXL model
Generate image → Works perfectly
Close WebUI terminal completely
Restart WebUI (one or two times before the failure happens)
Load same SDXL model
Generate image → Produces corrupted output (color splashes/grey boxes)

Key Observations:

SD 1.5 models continue working normally after restart
Some specific SDXL models remain stable across restarts (model-dependent)
Loading certain SD 1.5 models can ""fix"" SDXL generation but contaminates output with SD 1.5 model's characteristics
Issue persists across different SDXL checkpoints

### What should have happened?

SDXL models should generate consistently after WebUI restarts, with the same automatic VAE error recovery that occurs on fresh installation.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-09-14-09-57.json](https://github.com/user-attachments/files/22319280/sysinfo-2025-09-14-09-57.json)

### Console logs

```Shell
C:\webui_fresh>webui-user.bat
venv ""C:\webui_fresh\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
C:\webui_fresh\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [3343bb16c2] from C:\webui_fresh\models\Stable-diffusion\SDXL_madejanss.safetensors
Creating model from config: C:\webui_fresh\configs\v1-inference.yaml
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 12.5s (prepare environment: 3.7s, import torch: 4.3s, import gradio: 1.1s, setup paths: 0.8s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 0.9s, create ui: 0.4s, gradio launch: 0.5s).
Applying attention optimization: xformers... done.
Model loaded in 2.0s (create model: 1.3s, apply weights to model: 0.2s, calculate empty prompt: 0.3s).
100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.46it/s]
Total progress: 100%|██████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.50it/s]
Total progress: 100%|██████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.87it/s]
```

### Additional information

VAE Error Recovery Pattern: The key indicator of working vs failing state is the presence of these console messages:

Working State (Fresh Install):
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.

Failing State (After Restart):
Above VAE error messages do NOT appear
SDXL models fail to generate properly
Corruption occurs during generation process

Hypothesis
WebUI's automatic VAE error recovery mechanism that converts VAE to 32-bit floats is not initializing properly on restart for SDXL models. This protective conversion that prevents VAE corruption works on fresh install but fails to trigger on subsequent sessions.
Attempted Solutions (All Failed)

--no-half-vae flag
--medvram with various memory optimizations
NumPy downgrade to <2.0
Clearing model cache and pycache directories
PyTorch reinstallation with specific CUDA versions
Various precision flags (--no-half, --upcast-sampling, etc.)
Model configuration resets

Additional Context
Model-Specific Behavior:

Some SDXL models maintain stability across restarts
Others fail immediately after any model switching
The corruption appears when WebUI stops automatically handling VAE NaN errors

SD 1.5 Model ""Fixing"" Pattern:

Loading specific SD 1.5 models can restore SDXL functionality
However, SDXL output becomes contaminated with characteristics of the SD 1.5 model
This suggests model state cross-contamination during loading",bug sdxl models fail webui restart due vae error recovery persisting checklist x issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened sdxl models generate properly fresh webui installation consistently fail webui restart producing corrupted output color splashes grey boxes sd models remain unaffected issue appears related webui automatic vae error recovery mechanism initializing properly restart sdxl models webui version v commit c ae bd abdf eda b e hardware nvidia geforce rtx gb vram cuda pytorch cu python os windows steps reproduce problem reproduction steps consistent reproduction fresh webui installation load sdxl model generate image works perfectly close webui terminal completely restart webui one two times failure happens load sdxl model generate image produces corrupted output color splashes grey boxes key observations sd models continue working normally restart specific sdxl models remain stable across restarts model dependent loading certain sd models fix sdxl generation contaminates output sd model characteristics issue persists across different sdxl checkpoints happened sdxl models generate consistently webui restarts automatic vae error recovery occurs fresh installation browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell c webui fresh webui user bat venv c webui fresh venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments xformers c webui fresh venv lib site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning loading weights bb c c webui fresh models stable diffusion sdxl madejanss safetensors creating model config c webui fresh configs v inference yaml c webui fresh venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn running local url create public link set share true launch c webui fresh venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch applying attention optimization xformers done model loaded create model apply weights model calculate empty prompt total progress total progress additional information vae error recovery pattern key indicator working vs failing state presence console messages working state fresh install tensor nans produced vae web ui convert vae bit float retry disable behavior disable automatically revert vae bit floats setting always start bit vae use half vae commandline flag failing state restart vae error messages appear sdxl models fail generate properly corruption occurs generation process hypothesis webui automatic vae error recovery mechanism converts vae bit floats initializing properly restart sdxl models protective conversion prevents vae corruption works fresh install fails trigger subsequent sessions attempted solutions failed half vae flag medvram various memory optimizations numpy downgrade clearing model cache pycache directories pytorch reinstallation specific cuda versions various precision flags half upcast sampling etc model configuration resets additional context model specific behavior sdxl models maintain stability across restarts others fail immediately model switching corruption appears webui stops automatically handling vae nan errors sd model fixing pattern loading specific sd models restore sdxl functionality however sdxl output becomes contaminated characteristics sd model suggests model state cross contamination loading
auto1111_webui,issue,17122,[Feature Request]: Multi full prompt batch automation in series,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature would allow for automatically processing additional generations from previous prompts from a list of generated image png file paths.

### Proposed workflow

1. Load text file with full png file paths, one file path per line
2. For each file path, load its metadata in the png tab, and automatically parse and transfer metadata to txt2img
3. Override certain generation parameters through fields or sliders to be applied to the entire batch of prompts (e.g. random seed, batch size, number of batches)
4. Run the prompt for the specified batch size, number of batches, and seed
5. Repeat for next png file path in input text file until all are complete


### Additional information

Often times I explore many different prompts in quick succession, and then I want to go back later to generate a larger number of images from past prompts, for greater variety, or to achieve greater quality from the set.  This feature would help with that!  Having to do this manually takes a lot of manual intervention, and switching prompts and pressing 'generate' cannot be done while sleeping or away from the computer.

I already tried developing a Python script to carry out this behavior, but I ran into issues with parsing the metadata tuple from each png file into the fields needed to run txt2img.  Internally the webui clearly has this functionality, as seen by the features of the PNG tab, but I could not find publicly available modules to mimic this behavior.

Ideally, the feature would work within the webui, such that loaded png files and previews of generated images are still displayed, and such that all generated images would be saved as normal according to the webui's user settings.

This feature request differs from the prompt matrix script or using the '|' character because I don't want to do multiple combinations of small changes within the same prompt, I want to load up completely distinct prompts for every run.  And ideally, the input file may have hundreds of different distinct prompts, in which case, I would want to leave the full batch running for days or weeks at a time until everything is complete.",2025-09-07T05:10:02Z,colin-heberling,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17122,"[Feature Request]: Multi full prompt batch automation in series ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature would allow for automatically processing additional generations from previous prompts from a list of generated image png file paths.

### Proposed workflow

1. Load text file with full png file paths, one file path per line
2. For each file path, load its metadata in the png tab, and automatically parse and transfer metadata to txt2img
3. Override certain generation parameters through fields or sliders to be applied to the entire batch of prompts (e.g. random seed, batch size, number of batches)
4. Run the prompt for the specified batch size, number of batches, and seed
5. Repeat for next png file path in input text file until all are complete


### Additional information

Often times I explore many different prompts in quick succession, and then I want to go back later to generate a larger number of images from past prompts, for greater variety, or to achieve greater quality from the set.  This feature would help with that!  Having to do this manually takes a lot of manual intervention, and switching prompts and pressing 'generate' cannot be done while sleeping or away from the computer.

I already tried developing a Python script to carry out this behavior, but I ran into issues with parsing the metadata tuple from each png file into the fields needed to run txt2img.  Internally the webui clearly has this functionality, as seen by the features of the PNG tab, but I could not find publicly available modules to mimic this behavior.

Ideally, the feature would work within the webui, such that loaded png files and previews of generated images are still displayed, and such that all generated images would be saved as normal according to the webui's user settings.

This feature request differs from the prompt matrix script or using the '|' character because I don't want to do multiple combinations of small changes within the same prompt, I want to load up completely distinct prompts for every run.  And ideally, the input file may have hundreds of different distinct prompts, in which case, I would want to leave the full batch running for days or weeks at a time until everything is complete.",feature request multi full prompt batch automation series existing issue x searched existing issues checked recent builds commits would feature feature would allow automatically processing additional generations previous prompts list generated image png file paths proposed workflow load text file full png file paths one file path per line file path load metadata png tab automatically parse transfer metadata txt img override certain generation parameters fields sliders applied entire batch prompts e g random seed batch size number batches run prompt specified batch size number batches seed repeat next png file path input text file complete additional information often times explore many different prompts quick succession want go back later generate larger number images past prompts greater variety achieve greater quality set feature would help manually takes lot manual intervention switching prompts pressing generate cannot done sleeping away computer already tried developing python script carry behavior ran issues parsing metadata tuple png file fields needed run txt img internally webui clearly functionality seen features png tab could find publicly available modules mimic behavior ideally feature would work within webui loaded png files previews generated images still displayed generated images would saved normal according webui user settings feature request differs prompt matrix script using character want multiple combinations small changes within prompt want load completely distinct prompts every run ideally input file may hundreds different distinct prompts case would want leave full batch running days weeks time everything complete
auto1111_webui,comment,17122,,"[sd_batch_from_pngs.py](https://github.com/user-attachments/files/22226496/sd_batch_from_pngs.py)

I figured out a working solution using scripts, but would still be nice to have an inbuilt webui feature for this.  I wrote a custom function for parsing parameters from png metadata.",2025-09-09T05:01:49Z,colin-heberling,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17122#issuecomment-3268877500,"[sd_batch_from_pngs.py](https://github.com/user-attachments/files/22226496/sd_batch_from_pngs.py)

I figured out a working solution using scripts, but would still be nice to have an inbuilt webui feature for this.  I wrote a custom function for parsing parameters from png metadata.",sd batch pngs py figured working solution using scripts would still nice inbuilt webui feature wrote custom function parsing parameters png metadata
auto1111_webui,issue,17119,[Bug]: Runtime error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

every time I start up the run.bat file, it shows this message over and over again. I have a powerful pc and I have no idea whtas going on

<img width=""626"" height=""87"" alt=""Image"" src=""https://github.com/user-attachments/assets/baa327d1-0ef3-4a68-b5d6-1044f765f0a5"" />

### Steps to reproduce the problem

run the run.bat file, thats it

### What should have happened?

it shouldve ran it with no issues like the past times ive run this without an issue on this pc

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

i couldnt find anything that this is asking

### Console logs

```Shell
again, i couldnt figure out how to do this and im short for time
```

### Additional information

_No response_",2025-09-01T19:17:23Z,Marshy111,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17119,"[Bug]: Runtime error ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

every time I start up the run.bat file, it shows this message over and over again. I have a powerful pc and I have no idea whtas going on

<img width=""626"" height=""87"" alt=""Image"" src=""https://github.com/user-attachments/assets/baa327d1-0ef3-4a68-b5d6-1044f765f0a5"" />

### Steps to reproduce the problem

run the run.bat file, thats it

### What should have happened?

it shouldve ran it with no issues like the past times ive run this without an issue on this pc

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

i couldnt find anything that this is asking

### Console logs

```Shell
again, i couldnt figure out how to do this and im short for time
```

### Additional information

_No response_",bug runtime error checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened every time start run bat file shows message powerful pc idea whtas going img width height alt image src steps reproduce problem run run bat file thats happened shouldve ran issues like past times ive run without issue pc browsers use access ui response sysinfo couldnt find anything asking console logs shell couldnt figure im short time additional information response
auto1111_webui,comment,17119,,"## Report to the creator of the project

As your issue is happening on a **fork** of this project, please _report it to them_ instead: https://github.com/lllyasviel/stable-diffusion-webui-forge

---

### Additional tip to ensure you get the support you need

> Sysinfo
> i couldnt find anything that this is asking

Follow the instructions given by the template. They are there for a reason. You can collect the sysinfo without needing the webui to start up completely. 

> again, i couldnt figure out how to do this and im short for time

Copy the entire text output rather than taking a screenshot of a tiny section of it. If you're able to take a screenshot, there's no excuse to not just copy the text instead.

",2025-11-17T13:21:26Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17119#issuecomment-3541811456,"## Report to the creator of the project

As your issue is happening on a **fork** of this project, please _report it to them_ instead: https://github.com/lllyasviel/stable-diffusion-webui-forge

---

### Additional tip to ensure you get the support you need

> Sysinfo
> i couldnt find anything that this is asking

Follow the instructions given by the template. They are there for a reason. You can collect the sysinfo without needing the webui to start up completely. 

> again, i couldnt figure out how to do this and im short for time

Copy the entire text output rather than taking a screenshot of a tiny section of it. If you're able to take a screenshot, there's no excuse to not just copy the text instead.",report creator project issue happening fork project please report instead additional tip ensure get support need sysinfo couldnt find anything asking follow instructions given template reason collect sysinfo without needing webui start completely couldnt figure im short time copy entire text output rather taking screenshot tiny section able take screenshot excuse copy text instead
auto1111_webui,issue,17117,[Bug]: win10安装卡在Installing requirements没反应,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

<img width=""1091"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/b7e00c0c-cde4-46bc-a91b-259180aa4070"" />

### Steps to reproduce the problem

按windows步骤部署

### What should have happened?

希望正常部署

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements


### Console logs

```Shell
venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
```

### Additional information

_No response_",2025-08-28T09:07:26Z,Qiqi-Cici,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117,"[Bug]: win10安装卡在Installing requirements没反应 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

<img width=""1091"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/b7e00c0c-cde4-46bc-a91b-259180aa4070"" />

### Steps to reproduce the problem

按windows步骤部署

### What should have happened?

希望正常部署

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements


### Console logs

```Shell
venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
```

### Additional information

_No response_",bug win installing requirements checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui x issue reported recently issue reported fixed yet happened img width height alt image src steps reproduce problem windows happened browsers use access ui response sysinfo venv f ai stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements console logs shell venv f ai stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements additional information response
auto1111_webui,comment,17117,,"这个问题我之前问chatgpt，按它说的解决了，产生这个问题的原因是还有一些文件需要下载，但是挂梯子都不好使，要在镜像网站下，
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
如果我没记错是这个，另外可以检查一下你的pip是不是最新版",2025-09-13T04:49:03Z,finally12345,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3287555065,"这个问题我之前问chatgpt，按它说的解决了，产生这个问题的原因是还有一些文件需要下载，但是挂梯子都不好使，要在镜像网站下，
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
如果我没记错是这个，另外可以检查一下你的pip是不是最新版",chatgpt pip install r requirements txt pip
auto1111_webui,comment,17117,,"在项目根目录打开终端：
# 激活虚拟环境
D:\stable-diffusion-webui-master\venv\Scripts\activate

# 升级 pip
python -m pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple

# 安装必需依赖
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 安装 xformers（可选，加速）
pip install xformers -i https://pypi.tuna.tsinghua.edu.cn/simple
",2025-09-13T04:51:39Z,finally12345,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3287557305,"在项目根目录打开终端：
# 激活虚拟环境
D:\stable-diffusion-webui-master\venv\Scripts\activate

# 升级 pip
python -m pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple

# 安装必需依赖
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 安装 xformers（可选，加速）
pip install xformers -i https://pypi.tuna.tsinghua.edu.cn/simple",stable diffusion webui master venv scripts activate pip python pip install upgrade pip pip install r requirements txt xformers pip install xformers
auto1111_webui,comment,17117,,"我在运行pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple的时候，出现了这个：
Fatal error in launcher: Unable to create process using ...
请问怎么解决呀？ @finally12345 ",2025-10-26T16:07:52Z,YII266,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3448659819,"我在运行pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple的时候，出现了这个：
Fatal error in launcher: Unable to create process using ...
请问怎么解决呀？ @finally12345",pip install r requirements txt fatal error launcher unable create process using finally
auto1111_webui,issue,17112,# Update 20250501,"# Update 20250501
Official PyTorch 2.7.0 wheels with Blackwell 50 series support and xFormers have been released

Pull Request have been merged into dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16972

## Updated instructions on how to install for 50 series (also work for non 50 series)
### For casual windows users
follow the instructions of [Install-and-Run-on-NVidia-GPUs#windows-method-1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) 
the newly updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) includes a new `switch-branch-toole.bat` that can simplify switching branch
use `switch-branch-toole.bat` to switch to `dev` branch

### Advance users
For new install clone the webui branch `dev`
```sh
git clone --filter=blob:none -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
```
> `-b dev` to clones the desired a branch directly
> `--filter=blob:none` save around 30MB of disk space

or if you prefer you can do it in separate steps
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
```

---

For existing installations you can switch to `dev` branch without re-cloneing
> may have to run `git pull` after `git switch dev`
```
cd stable-diffusion-webui
git switch dev
git pull
```
> if you're already on the `dev` branch then just `git pull` should work

after switching launch webui with `COMMANDLINE_ARGS` `--reinstall-torch` to tell it to reinstall PyTorch
> also launch with `--reinstall-xformers` if you are using `xFormers`
> remember to remove `--reinstall-torch` `--reinstall-xformers` afterwards

---

revelant wiki [How-to-switch-to-different-versions-of-WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

---

<details><summary>Outdated info</summary>
<p>

As PyTorch have not yet released a compatible builds for Blackwell GPUs
we have been allowed to publish Early Access PyTorch wheels by Nvidia 

---

There are several methods to run on Blackwell 50XX GPUs

## Method 1: use the a new standalone release
Recommended for new install or for those not familiar with terminals / commands)

we have prepared a standalone release for Windows which can be downloaded here [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z) (1.8GB)

1. Download [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z)
2. Extract using [7z](https://www.7-zip.org)
> Windows 11 seems to have it added native 7z support

3. Click `run.bat` to launch webui

~~note: do not enable `--xformers`, currently it is not compatible~~ [xformers v0.0.29.post2](https://github.com/facebookresearch/xformers/releases/tag/v0.0.29.post2) is released, see below for instructions

## Method 2: use the latest `dev` branch
Recommended for those who are migrating from existing installation and for those who are familiar with commands and terminals

- As of https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16817 the dev branch have been update with auto detection of blackwell GPUs, when detected it will automatically install the appropriate PyTorch which version

1. Follow the guide on how to switch branches see [wiki How to switch to different versions of WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

> instead of the `release_candidate` in the example substituted with `dev` to switch to dev branch

2. Add `--reinstall-torch` to `COMMANDLINE_ARGS` to tell webui to reinstall PyTorch
3. Launch webui

> remember to remove`--reinstall-torch` from `COMMANDLINE_ARGS` after it's done reinstalling PyTorch

## Method 3: manual upgrade
Meant for developers
The PyTorch wheels are provided at https://huggingface.co/w-e-w/torch-2.6.0-cu128.nv
This should be all the info you need

## xformers (may not work)
to use xformers
you need you need to set the environment variable `XFORMERS_PACKAGE` to `xformers==0.0.29.post2`
on windows this can be done by adding the following line to to `webui-user.bat` before `call webui.bat`
```bat
set XFORMERS_PACKAGE=xformers==0.0.29.post2
```

<details><summary>the <code>webui-user.bat</code> should look like something this (click to expand)

</summary>
<p>

```bat
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=--xformers
set XFORMERS_PACKAGE=xformers==0.0.29.post2

call webui.bat
```

</p>
</details> 

note: if you have previously used `--xformers` then you will need to add `--reinstall-xformers` to tell webui to reinstall xformers
> similer to `--reinstall-torch`, remeber to remove `--reinstall-xformers` after it's done


</p>
</details>

_Originally posted by @w-e-w in https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818_",2025-08-26T18:26:47Z,cjhScotland,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112,"# Update 20250501 # Update 20250501
Official PyTorch 2.7.0 wheels with Blackwell 50 series support and xFormers have been released

Pull Request have been merged into dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16972

## Updated instructions on how to install for 50 series (also work for non 50 series)
### For casual windows users
follow the instructions of [Install-and-Run-on-NVidia-GPUs#windows-method-1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) 
the newly updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) includes a new `switch-branch-toole.bat` that can simplify switching branch
use `switch-branch-toole.bat` to switch to `dev` branch

### Advance users
For new install clone the webui branch `dev`
```sh
git clone --filter=blob:none -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
```
> `-b dev` to clones the desired a branch directly
> `--filter=blob:none` save around 30MB of disk space

or if you prefer you can do it in separate steps
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
```

---

For existing installations you can switch to `dev` branch without re-cloneing
> may have to run `git pull` after `git switch dev`
```
cd stable-diffusion-webui
git switch dev
git pull
```
> if you're already on the `dev` branch then just `git pull` should work

after switching launch webui with `COMMANDLINE_ARGS` `--reinstall-torch` to tell it to reinstall PyTorch
> also launch with `--reinstall-xformers` if you are using `xFormers`
> remember to remove `--reinstall-torch` `--reinstall-xformers` afterwards

---

revelant wiki [How-to-switch-to-different-versions-of-WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

---

<details><summary>Outdated info</summary>
<p>

As PyTorch have not yet released a compatible builds for Blackwell GPUs
we have been allowed to publish Early Access PyTorch wheels by Nvidia 

---

There are several methods to run on Blackwell 50XX GPUs

## Method 1: use the a new standalone release
Recommended for new install or for those not familiar with terminals / commands)

we have prepared a standalone release for Windows which can be downloaded here [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z) (1.8GB)

1. Download [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z)
2. Extract using [7z](https://www.7-zip.org)
> Windows 11 seems to have it added native 7z support

3. Click `run.bat` to launch webui

~~note: do not enable `--xformers`, currently it is not compatible~~ [xformers v0.0.29.post2](https://github.com/facebookresearch/xformers/releases/tag/v0.0.29.post2) is released, see below for instructions

## Method 2: use the latest `dev` branch
Recommended for those who are migrating from existing installation and for those who are familiar with commands and terminals

- As of https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16817 the dev branch have been update with auto detection of blackwell GPUs, when detected it will automatically install the appropriate PyTorch which version

1. Follow the guide on how to switch branches see [wiki How to switch to different versions of WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

> instead of the `release_candidate` in the example substituted with `dev` to switch to dev branch

2. Add `--reinstall-torch` to `COMMANDLINE_ARGS` to tell webui to reinstall PyTorch
3. Launch webui

> remember to remove`--reinstall-torch` from `COMMANDLINE_ARGS` after it's done reinstalling PyTorch

## Method 3: manual upgrade
Meant for developers
The PyTorch wheels are provided at https://huggingface.co/w-e-w/torch-2.6.0-cu128.nv
This should be all the info you need

## xformers (may not work)
to use xformers
you need you need to set the environment variable `XFORMERS_PACKAGE` to `xformers==0.0.29.post2`
on windows this can be done by adding the following line to to `webui-user.bat` before `call webui.bat`
```bat
set XFORMERS_PACKAGE=xformers==0.0.29.post2
```

<details><summary>the <code>webui-user.bat</code> should look like something this (click to expand)

</summary>
<p>

```bat
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=--xformers
set XFORMERS_PACKAGE=xformers==0.0.29.post2

call webui.bat
```

</p>
</details> 

note: if you have previously used `--xformers` then you will need to add `--reinstall-xformers` to tell webui to reinstall xformers
> similer to `--reinstall-torch`, remeber to remove `--reinstall-xformers` after it's done


</p>
</details>

_Originally posted by @w-e-w in https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818_",update update official pytorch wheels blackwell series support xformers released pull request merged dev branch updated instructions install series also work non series casual windows users follow instructions install run nvidia gpus windows method newly updated sd webui zip includes new switch branch toole bat simplify switching branch use switch branch toole bat switch dev branch advance users new install clone webui branch dev sh git clone filter blob none b dev b dev clones desired branch directly filter blob none save around mb disk space prefer separate steps git clone cd stable diffusion webui git switch dev existing installations switch dev branch without cloneing may run git pull git switch dev cd stable diffusion webui git switch dev git pull already dev branch git pull work switching launch webui commandline args reinstall torch tell reinstall pytorch also launch reinstall xformers using xformers remember remove reinstall torch reinstall xformers afterwards revelant wiki switch different versions webui details summary outdated info summary p pytorch yet released compatible builds blackwell gpus allowed publish early access pytorch wheels nvidia several methods run blackwell xx gpus method use new standalone release recommended new install familiar terminals commands prepared standalone release windows downloaded sd webui blackwell z gb download sd webui blackwell z extract using z windows seems added native z support click run bat launch webui note enable xformers currently compatible xformers v post released see instructions method use latest dev branch recommended migrating existing installation familiar commands terminals dev branch update auto detection blackwell gpus detected automatically install appropriate pytorch version follow guide switch branches see wiki switch different versions webui instead release candidate example substituted dev switch dev branch add reinstall torch commandline args tell webui reinstall pytorch launch webui remember remove reinstall torch commandline args done reinstalling pytorch method manual upgrade meant developers pytorch wheels provided info need xformers may work use xformers need need set environment variable xformers package xformers post windows done adding following line webui user bat call webui bat bat set xformers package xformers post details summary code webui user bat code look like something click expand summary p bat echo set python set git set venv dir set commandline args xformers set xformers package xformers post call webui bat p details note previously used xformers need add reinstall xformers tell webui reinstall xformers similer reinstall torch remeber remove reinstall xformers done p details originally posted w e w
auto1111_webui,comment,17112,,"Hi, I have tried to install AutomaticIIII following the instructions in Windows Method 1. I have an Nvidia RTX 5080 and so followed the instructions and ran swich-branch-toole.bat with option 3, dev.

Q. I ran the switch-branch-toole.bat file AFTER update.bat. Is this correct?

run.bat aappeared to run correctly and displayed the UI at the end. However, when I click 'Generate' two grey buttons appear then immediately disappear. No image is created.

can someone please help me. Screendumps of the CMD screens follow (on a subsequent run of run.bat). Windows is up to date and I have downloaded the latest Nvidia drivers.

THanks (hopefully!) in advance

Chris

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/038e0345-2a9e-40f8-b0d8-3f6b57a0f99a"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/69252029-0b9a-442e-99d8-dc9e222fbb20"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/955e59c6-3076-48e4-8853-1f1d2b2f8470"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/8e293c69-3b56-4d3f-9fc5-bc1ae68507f1"" />",2025-08-26T18:38:50Z,cjhScotland,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112#issuecomment-3225297721,"Hi, I have tried to install AutomaticIIII following the instructions in Windows Method 1. I have an Nvidia RTX 5080 and so followed the instructions and ran swich-branch-toole.bat with option 3, dev.

Q. I ran the switch-branch-toole.bat file AFTER update.bat. Is this correct?

run.bat aappeared to run correctly and displayed the UI at the end. However, when I click 'Generate' two grey buttons appear then immediately disappear. No image is created.

can someone please help me. Screendumps of the CMD screens follow (on a subsequent run of run.bat). Windows is up to date and I have downloaded the latest Nvidia drivers.

THanks (hopefully!) in advance

Chris

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/038e0345-2a9e-40f8-b0d8-3f6b57a0f99a"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/69252029-0b9a-442e-99d8-dc9e222fbb20"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/955e59c6-3076-48e4-8853-1f1d2b2f8470"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/8e293c69-3b56-4d3f-9fc5-bc1ae68507f1"" />",hi tried install automaticiiii following instructions windows method nvidia rtx followed instructions ran swich branch toole bat option dev q ran switch branch toole bat file update bat correct run bat aappeared run correctly displayed ui end however click generate two grey buttons appear immediately disappear image created someone please help screendumps cmd screens follow subsequent run run bat windows date downloaded latest nvidia drivers thanks hopefully advance chris img width height alt image src img width height alt image src img width height alt image src img width height alt image src
auto1111_webui,comment,17112,,"I followed this video and it worked for me

https://youtu.be/gVQD2OqX0ZU",2025-09-12T07:46:06Z,pocketpoetry,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112#issuecomment-3284158330,"I followed this video and it worked for me

https://youtu.be/gVQD2OqX0ZU",followed video worked
auto1111_webui,issue,17111,[Bug]:  Any error happening after 'commit hash : XXXX' is not related to the launcher,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Any error happening after 'commit hash : XXXX' is not related to the launcher

### Steps to reproduce the problem

open the luncher 

### What should have happened?

no opened 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no opened

### Console logs

```Shell
no opened
```

### Additional information

no opened",2025-08-25T21:26:13Z,elsepulin,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17111,"[Bug]:  Any error happening after 'commit hash : XXXX' is not related to the launcher ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Any error happening after 'commit hash : XXXX' is not related to the launcher

### Steps to reproduce the problem

open the luncher 

### What should have happened?

no opened 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no opened

### Console logs

```Shell
no opened
```

### Additional information

no opened",bug error happening commit hash xxxx related launcher checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened error happening commit hash xxxx related launcher steps reproduce problem open luncher happened opened browsers use access ui response sysinfo opened console logs shell opened additional information opened
auto1111_webui,comment,17111,,"Without any additional information, there's absolutely no way for anyone to know what you're referring to unless they have themselves gone through the extensive efforts to try and replicate your issue on purpose. 

I can't reproduce any bugs related to ""commit hash: "" and your report is sufficiently unclear enough to confuse me as to what it pertains to.

**Please include the requested diagnostic information.** 

Given you're talking about a console output, ""no opened"" is not only not a valid response to any question, but also simply false in its implied meaning. You cannot have a reported issue or bug regarding console output, only to then claim your console never opened. Those are mutually exclusive, friend.",2025-11-17T13:18:12Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17111#issuecomment-3541794634,"Without any additional information, there's absolutely no way for anyone to know what you're referring to unless they have themselves gone through the extensive efforts to try and replicate your issue on purpose. 

I can't reproduce any bugs related to ""commit hash: "" and your report is sufficiently unclear enough to confuse me as to what it pertains to.

**Please include the requested diagnostic information.** 

Given you're talking about a console output, ""no opened"" is not only not a valid response to any question, but also simply false in its implied meaning. You cannot have a reported issue or bug regarding console output, only to then claim your console never opened. Those are mutually exclusive, friend.",without additional information absolutely way anyone know referring unless gone extensive efforts try replicate issue purpose reproduce bugs related commit hash report sufficiently unclear enough confuse pertains please include requested diagnostic information given talking console output opened valid response question also simply false implied meaning cannot reported issue bug regarding console output claim console never opened mutually exclusive friend
auto1111_webui,issue,17102,[Bug]: Missing xformers (on linux at least),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Both dev branch and master branch (1.10.1)

xformers does not show up as an available option under ""Cross attention optimization"" even though launch option has been set
`Launching Web UI with arguments: --xformers`

<img width=""473"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/929af83c-d0c7-4d7c-860c-1f7b469d9b8f"" />

### Steps to reproduce the problem

1. fresh install on linux
2. add argument for xformers
3. run
4. check settings
--> missing option for xformers

### What should have happened?

xformers should show up as an available option

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-08-19-19-26.json](https://github.com/user-attachments/files/21865900/sysinfo-2025-08-19-19-26.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.9 (main, Jun  2 2025, 19:48:19) [GCC 13.3.0]
Version: v1.10.1-89-g2174ce5a
Commit hash: 2174ce5afea90ca489d222f539988dcef59f1027
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --xformers
[-] ADetailer initialized. version: 25.3.0, num models: 10
ControlNet preprocessor location: /home/user/venvs/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-08-19 21:29:18,516 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [9687bd2559] from /home/user/venvs/stable-diffusion-webui/models/Stable-diffusion/ricecakeRemix.safetensors
2025-08-19 21:29:19,121 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/venvs/stable-diffusion-webui/configs/v1-inference.yaml
/home/user/venvs/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 9.0s (prepare environment: 1.7s, import torch: 2.8s, import gradio: 0.5s, setup paths: 1.0s, initialize shared: 0.2s, other imports: 0.2s, load scripts: 1.5s, create ui: 0.7s, gradio launch: 0.4s).
Loading VAE weights specified in settings: /home/user/venvs/stable-diffusion-webui/models/VAE/SD1.5.safetensors
Disabling attention optimization
Model loaded in 3.6s (load weights from disk: 1.0s, create model: 0.4s, apply weights to model: 1.7s, load VAE: 0.2s, calculate empty prompt: 0.2s).
Disabling attention optimization
```

### Additional information

_No response_",2025-08-19T20:17:38Z,TeKett,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102,"[Bug]: Missing xformers (on linux at least) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Both dev branch and master branch (1.10.1)

xformers does not show up as an available option under ""Cross attention optimization"" even though launch option has been set
`Launching Web UI with arguments: --xformers`

<img width=""473"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/929af83c-d0c7-4d7c-860c-1f7b469d9b8f"" />

### Steps to reproduce the problem

1. fresh install on linux
2. add argument for xformers
3. run
4. check settings
--> missing option for xformers

### What should have happened?

xformers should show up as an available option

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-08-19-19-26.json](https://github.com/user-attachments/files/21865900/sysinfo-2025-08-19-19-26.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.9 (main, Jun  2 2025, 19:48:19) [GCC 13.3.0]
Version: v1.10.1-89-g2174ce5a
Commit hash: 2174ce5afea90ca489d222f539988dcef59f1027
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --xformers
[-] ADetailer initialized. version: 25.3.0, num models: 10
ControlNet preprocessor location: /home/user/venvs/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-08-19 21:29:18,516 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [9687bd2559] from /home/user/venvs/stable-diffusion-webui/models/Stable-diffusion/ricecakeRemix.safetensors
2025-08-19 21:29:19,121 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/venvs/stable-diffusion-webui/configs/v1-inference.yaml
/home/user/venvs/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 9.0s (prepare environment: 1.7s, import torch: 2.8s, import gradio: 0.5s, setup paths: 1.0s, initialize shared: 0.2s, other imports: 0.2s, load scripts: 1.5s, create ui: 0.7s, gradio launch: 0.4s).
Loading VAE weights specified in settings: /home/user/venvs/stable-diffusion-webui/models/VAE/SD1.5.safetensors
Disabling attention optimization
Model loaded in 3.6s (load weights from disk: 1.0s, create model: 0.4s, apply weights to model: 1.7s, load VAE: 0.2s, calculate empty prompt: 0.2s).
Disabling attention optimization
```

### Additional information

_No response_",bug missing xformers linux least checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened dev branch master branch xformers show available option cross attention optimization even though launch option set launching web ui arguments xformers img width height alt image src steps reproduce problem fresh install linux add argument xformers run check settings missing option xformers happened xformers show available option browsers use access ui google chrome sysinfo sysinfo json console logs shell install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running user user repo already cloned using install directory create activate python venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload lib x linux gnu libtcmalloc minimal python main jun gcc version v g ce commit hash ce afea ca f dcef f controlnet init warning unable install insightface automatically please try run pip install insightface manually launching web ui arguments xformers adetailer initialized version num models controlnet preprocessor location home user venvs stable diffusion webui extensions sd webui controlnet annotator downloads controlnet info controlnet v loading weights bd home user venvs stable diffusion webui models stable diffusion ricecakeremix safetensors controlnet info controlnet ui callback registered running local url create public link set share true launch creating model config home user venvs stable diffusion webui configs v inference yaml home user venvs stable diffusion webui venv lib python site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch loading vae weights specified settings home user venvs stable diffusion webui models vae sd safetensors disabling attention optimization model loaded load weights disk create model apply weights model load vae calculate empty prompt disabling attention optimization additional information response
auto1111_webui,comment,17102,,"Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**

Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.

",2025-09-02T13:50:39Z,Nate82,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102#issuecomment-3245440383,"Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**

Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.",try adding xformers force enable xformers webui user bat file read set commandline args xformers force enable xformers previously mine xformers using doggettx xformers showing optimization tab
auto1111_webui,comment,17102,,"> Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**
> 
> Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.

hes on linux so its web-user.sh which then it should look like (export COMMANDLINE_ARGS="" --xformers --force-enable-xformers"") its a bit different but mostly the same cant really confirm since im on archlinux and i don't use xformers despite having an nvidia card 
",2025-12-18T00:52:04Z,FemBoyGamerTechGuy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102#issuecomment-3667761449,"> Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**
> 
> Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.

hes on linux so its web-user.sh which then it should look like (export COMMANDLINE_ARGS="" --xformers --force-enable-xformers"") its a bit different but mostly the same cant really confirm since im on archlinux and i don't use xformers despite having an nvidia card",try adding xformers force enable xformers webui user bat file read set commandline args xformers force enable xformers previously mine xformers using doggettx xformers showing optimization tab hes linux web user sh look like export commandline args xformers force enable xformers bit different mostly cant really confirm since im archlinux use xformers despite nvidia card
auto1111_webui,issue,17081,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControleNet via the interface, the program terminated without further possibility to open it

### Steps to reproduce the problem

1. Install ControlNet
2. Update interface

### What should have happened?

Adding a ControlNet Option

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

It is not possible due to the inability to open the interface

### Console logs

```Shell
C:\HUI\stable-diffusion-webui>git pull
Already up to date.
venv ""C:\HUI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --autolaunch
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-cn-in-extras-tab"" requires ""sd-webui-controlnet"" which is not installed.
Loading weights [b8616b3a8f] from C:\HUI\stable-diffusion-webui\models\Stable-diffusion\pasanctuarySDXL_v50.safetensors
Creating model from config: C:\HUI\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 5.1s (load weights from disk: 0.2s, create model: 0.4s, apply weights to model: 4.1s, move model to device: 0.1s, calculate empty prompt: 0.2s).
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
calling C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py/ui: ImportError
Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 103, in wrap_call
    res = func(*args, **kwargs)
  File ""C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py"", line 108, in ui
    from scripts import global_state
ImportError: cannot import name 'global_state' from 'scripts' (unknown location)

Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 44, in main
    start()
  File ""C:\HUI\stable-diffusion-webui\modules\launch_utils.py"", line 469, in start
    webui.webui()
  File ""C:\HUI\stable-diffusion-webui\webui.py"", line 64, in webui
    shared.demo = ui.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui.py"", line 872, in create_ui
    ui_postprocessing.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui_postprocessing.py"", line 25, in create_ui
    script_inputs = scripts.scripts_postproc.setup_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 165, in setup_ui
    self.create_script_ui(script, inputs)
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 134, in create_script_ui
    for control in script.controls.values():
AttributeError: 'NoneType' object has no attribute 'values'
```

### Additional information

_No response_",2025-08-03T13:19:57Z,superdonz-crypto,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17081,"[Bug]: ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControleNet via the interface, the program terminated without further possibility to open it

### Steps to reproduce the problem

1. Install ControlNet
2. Update interface

### What should have happened?

Adding a ControlNet Option

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

It is not possible due to the inability to open the interface

### Console logs

```Shell
C:\HUI\stable-diffusion-webui>git pull
Already up to date.
venv ""C:\HUI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --autolaunch
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-cn-in-extras-tab"" requires ""sd-webui-controlnet"" which is not installed.
Loading weights [b8616b3a8f] from C:\HUI\stable-diffusion-webui\models\Stable-diffusion\pasanctuarySDXL_v50.safetensors
Creating model from config: C:\HUI\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 5.1s (load weights from disk: 0.2s, create model: 0.4s, apply weights to model: 4.1s, move model to device: 0.1s, calculate empty prompt: 0.2s).
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
calling C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py/ui: ImportError
Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 103, in wrap_call
    res = func(*args, **kwargs)
  File ""C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py"", line 108, in ui
    from scripts import global_state
ImportError: cannot import name 'global_state' from 'scripts' (unknown location)

Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 44, in main
    start()
  File ""C:\HUI\stable-diffusion-webui\modules\launch_utils.py"", line 469, in start
    webui.webui()
  File ""C:\HUI\stable-diffusion-webui\webui.py"", line 64, in webui
    shared.demo = ui.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui.py"", line 872, in create_ui
    ui_postprocessing.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui_postprocessing.py"", line 25, in create_ui
    script_inputs = scripts.scripts_postproc.setup_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 165, in setup_ui
    self.create_script_ui(script, inputs)
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 134, in create_script_ui
    for control in script.controls.values():
AttributeError: 'NoneType' object has no attribute 'values'
```

### Additional information

_No response_",bug checklist issue exists disabling extensions issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened installing controlenet via interface program terminated without possibility open steps reproduce problem install controlnet update interface happened adding controlnet option browsers use access ui microsoft edge sysinfo possible due inability open interface console logs shell c hui stable diffusion webui git pull already date venv c hui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments autolaunch c hui stable diffusion webui venv lib site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers proceeding without extension sd webui cn extras tab requires sd webui controlnet installed loading weights b b f c hui stable diffusion webui models stable diffusion pasanctuarysdxl v safetensors creating model config c hui stable diffusion webui repositories generative models configs inference sd xl base yaml c hui stable diffusion webui venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn applying attention optimization doggettx done model loaded load weights disk create model apply weights model move model device calculate empty prompt c hui stable diffusion webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead model style container false c hui stable diffusion webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false c hui stable diffusion webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false c hui stable diffusion webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false calling c hui stable diffusion webui extensions sd webui cn extras tab scripts cn extras tab py ui importerror traceback recent call last file c hui stable diffusion webui modules scripts postprocessing py line wrap call res func args kwargs file c hui stable diffusion webui extensions sd webui cn extras tab scripts cn extras tab py line ui scripts import global state importerror cannot import name global state scripts unknown location traceback recent call last file c hui stable diffusion webui launch py line module main file c hui stable diffusion webui launch py line main start file c hui stable diffusion webui modules launch utils py line start webui webui file c hui stable diffusion webui webui py line webui shared demo ui create ui file c hui stable diffusion webui modules ui py line create ui ui postprocessing create ui file c hui stable diffusion webui modules ui postprocessing py line create ui script inputs scripts scripts postproc setup ui file c hui stable diffusion webui modules scripts postprocessing py line setup ui self create script ui script inputs file c hui stable diffusion webui modules scripts postprocessing py line create script ui control script controls values attributeerror nonetype object attribute values additional information response
auto1111_webui,comment,17081,,"it is highly likely that this is caused by `sd-webui-cn-in-extras-tab`
I was able to produce similar errors usnign an old version of `sd-webui-cn-in-extras-tab`

I suggest you first try removeing `sd-webui-cn-in-extras-tab` by deleting `extensions\sd-webui-cn-in-extras-tab` dir
then launching webui
it is likely that this will get you back and running

if you still want to use `sd-webui-cn-in-extras-tab` install it again from the extensions tab, this will install the latest version

---

Sysinfo
> It is not possible due to the inability to open the interface

as written in the issue template
it is likely that you will be able to dump the sysinfo by adding `--dump-sysinfo` to command line args
<img width=""602"" height=""243"" alt=""Image"" src=""https://github.com/user-attachments/assets/98ea0021-b474-4a19-b414-f3b5b5f579e8"" />


",2025-08-07T19:05:35Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17081#issuecomment-3165398516,"it is highly likely that this is caused by `sd-webui-cn-in-extras-tab`
I was able to produce similar errors usnign an old version of `sd-webui-cn-in-extras-tab`

I suggest you first try removeing `sd-webui-cn-in-extras-tab` by deleting `extensions\sd-webui-cn-in-extras-tab` dir
then launching webui
it is likely that this will get you back and running

if you still want to use `sd-webui-cn-in-extras-tab` install it again from the extensions tab, this will install the latest version

---

Sysinfo
> It is not possible due to the inability to open the interface

as written in the issue template
it is likely that you will be able to dump the sysinfo by adding `--dump-sysinfo` to command line args
<img width=""602"" height=""243"" alt=""Image"" src=""https://github.com/user-attachments/assets/98ea0021-b474-4a19-b414-f3b5b5f579e8"" />",highly likely caused sd webui cn extras tab able produce similar errors usnign old version sd webui cn extras tab suggest first try removeing sd webui cn extras tab deleting extensions sd webui cn extras tab dir launching webui likely get back running still want use sd webui cn extras tab install extensions tab install latest version sysinfo possible due inability open interface written issue template likely able dump sysinfo adding dump sysinfo command line args img width height alt image src
auto1111_webui,issue,17067,[Bug]: Issue Running V-Pred Model on A1111 Dev Branch: Black Output After Fixing NaNs Error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

I'm trying to run a V-pred model:
https://files.catbox.moe/vciz3c.pdf

I followed the instructions to use the dev branch of Automatic1111 to make it work. However, after a clean install, I encountered this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion, or use the --no-half command line argument to fix this. Use --disable-nan-check to disable this check.

After I added the --no-half and --disable-nan-check arguments, the error disappeared — but the model only generates black images.

Is there any additional step required to get this model working correctly?

My Specs : 
NVIDIA GeForce RTX 3090 (24GB VRAM), 64GB RAM, Intel Core i5-9600K

I’ve also uploaded my full system information file generated by the WebUI below.



### Steps to reproduce the problem

I performed a clean install of the WebUI using the dev branch of Automatic1111, following the instructions provided in this document:
https://files.catbox.moe/vciz3c.pdf

Then, I tried generating an image using the V-Pred model mentioned in the guide.



### What should have happened?

its generate an image of Model Sdxl V-Pred

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-24-19-57.json](https://github.com/user-attachments/files/21418368/sysinfo-2025-07-24-19-57.json)

### Console logs

```Shell
Here is the full Console : 

Running on local URL:  http://127.0.0.1:7861

To create a public link, set `share=True` in `launch()`.
Creating model from config: D:\stable-diffusion-webui-dev\configs\sd_xl_v.yaml
D:\stable-diffusion-webui-dev\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 14.9s (prepare environment: 3.0s, import torch: 6.0s, import gradio: 1.3s, setup paths: 1.7s, initialize shared: 0.3s, other imports: 0.4s, load scripts: 0.8s, create ui: 0.7s, gradio launch: 0.6s).
Applying attention optimization: xformers... done.
Model loaded in 12.1s (load weights from disk: 1.0s, create model: 0.5s, apply weights to model: 9.8s, apply half(): 0.1s, apply dtype to VAE: 0.2s, move model to device: 0.1s, calculate empty prompt: 0.2s).
 40%|████████████████████████████████▊                                                 | 12/30 [00:03<00:05,  3.48it/s]D:\stable-diffusion-webui-dev\modules\sd_samplers_common.py:68: RuntimeWarning: invalid value encountered in cast54it/s]
  x_sample = x_sample.astype(np.uint8)
100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.44it/s]
*** Error completing request███████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.46it/s]
*** Arguments: ('task(0zf4yw7wrdpmybr)', <gradio.routes.Request object at 0x000001805EA70FA0>, 'masterpiece, best quality, newest, absurdres, highres, nsfw, anime screencap, ayase seiko, dandadan, 1girl, mature female, red eyes,  glasses, beehive hairdo, long hair, white hair, grey hair, ponytail, large breasts, cleavage, thighs, hoop earrings, baseball bat, cigarette, mature female,', 'sfw, worst quality, old, early, low quality, lowres, signature, username, logo, bad hands, mutated hands, mammal, anthro, furry, ambiguous form, feral, semi-anthro, 3d, realistic,', [], 1, 1, 7, 1216, 864, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['Downcast alphas_cumprod: True', 'Clip skip: 2'], 0, 30, 'Euler a', 'Automatic', False, '', 0.8, 696349519, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""D:\stable-diffusion-webui-dev\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.
```

### Additional information

_No response_",2025-07-24T20:03:32Z,xura-xa,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067,"[Bug]: Issue Running V-Pred Model on A1111 Dev Branch: Black Output After Fixing NaNs Error ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

I'm trying to run a V-pred model:
https://files.catbox.moe/vciz3c.pdf

I followed the instructions to use the dev branch of Automatic1111 to make it work. However, after a clean install, I encountered this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion, or use the --no-half command line argument to fix this. Use --disable-nan-check to disable this check.

After I added the --no-half and --disable-nan-check arguments, the error disappeared — but the model only generates black images.

Is there any additional step required to get this model working correctly?

My Specs : 
NVIDIA GeForce RTX 3090 (24GB VRAM), 64GB RAM, Intel Core i5-9600K

I’ve also uploaded my full system information file generated by the WebUI below.



### Steps to reproduce the problem

I performed a clean install of the WebUI using the dev branch of Automatic1111, following the instructions provided in this document:
https://files.catbox.moe/vciz3c.pdf

Then, I tried generating an image using the V-Pred model mentioned in the guide.



### What should have happened?

its generate an image of Model Sdxl V-Pred

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-24-19-57.json](https://github.com/user-attachments/files/21418368/sysinfo-2025-07-24-19-57.json)

### Console logs

```Shell
Here is the full Console : 

Running on local URL:  http://127.0.0.1:7861

To create a public link, set `share=True` in `launch()`.
Creating model from config: D:\stable-diffusion-webui-dev\configs\sd_xl_v.yaml
D:\stable-diffusion-webui-dev\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 14.9s (prepare environment: 3.0s, import torch: 6.0s, import gradio: 1.3s, setup paths: 1.7s, initialize shared: 0.3s, other imports: 0.4s, load scripts: 0.8s, create ui: 0.7s, gradio launch: 0.6s).
Applying attention optimization: xformers... done.
Model loaded in 12.1s (load weights from disk: 1.0s, create model: 0.5s, apply weights to model: 9.8s, apply half(): 0.1s, apply dtype to VAE: 0.2s, move model to device: 0.1s, calculate empty prompt: 0.2s).
 40%|████████████████████████████████▊                                                 | 12/30 [00:03<00:05,  3.48it/s]D:\stable-diffusion-webui-dev\modules\sd_samplers_common.py:68: RuntimeWarning: invalid value encountered in cast54it/s]
  x_sample = x_sample.astype(np.uint8)
100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.44it/s]
*** Error completing request███████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.46it/s]
*** Arguments: ('task(0zf4yw7wrdpmybr)', <gradio.routes.Request object at 0x000001805EA70FA0>, 'masterpiece, best quality, newest, absurdres, highres, nsfw, anime screencap, ayase seiko, dandadan, 1girl, mature female, red eyes,  glasses, beehive hairdo, long hair, white hair, grey hair, ponytail, large breasts, cleavage, thighs, hoop earrings, baseball bat, cigarette, mature female,', 'sfw, worst quality, old, early, low quality, lowres, signature, username, logo, bad hands, mutated hands, mammal, anthro, furry, ambiguous form, feral, semi-anthro, 3d, realistic,', [], 1, 1, 7, 1216, 864, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['Downcast alphas_cumprod: True', 'Clip skip: 2'], 0, 30, 'Euler a', 'Automatic', False, '', 0.8, 696349519, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""D:\stable-diffusion-webui-dev\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.
```

### Additional information

_No response_",bug issue running v pred model dev branch black output fixing nans error checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened trying run v pred model followed instructions use dev branch automatic make work however clean install encountered error nansexception tensor nans produced unet could either enough precision represent picture video card support half type try setting upcast cross attention layer float option settings stable diffusion use half command line argument fix use disable nan check disable check added half disable nan check arguments error disappeared model generates black images additional step required get model working correctly specs nvidia geforce rtx gb vram gb ram intel core k ive also uploaded full system information file generated webui steps reproduce problem performed clean install webui using dev branch automatic following instructions provided document tried generating image using v pred model mentioned guide happened generate image model sdxl v pred browsers use access ui google chrome sysinfo sysinfo json console logs shell full console running local url create public link set share true launch creating model config stable diffusion webui dev configs sd xl v yaml stable diffusion webui dev venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch applying attention optimization xformers done model loaded load weights disk create model apply weights model apply half apply dtype vae move model device calculate empty prompt stable diffusion webui dev modules sd samplers common py runtimewarning invalid value encountered cast x sample x sample astype np uint error completing request arguments task zf yw wrdpmybr gradio routes request object x ea fa masterpiece best quality newest absurdres highres nsfw anime screencap ayase seiko dandadan girl mature female red eyes glasses beehive hairdo long hair white hair grey hair ponytail large breasts cleavage thighs hoop earrings baseball bat cigarette mature female sfw worst quality old early low quality lowres signature username logo bad hands mutated hands mammal anthro furry ambiguous form feral semi anthro realistic false latent use checkpoint use sampler use scheduler downcast alphas cumprod true clip skip euler automatic false false false false positive comma false false start true false false false false false false false true traceback recent call last file stable diffusion webui dev modules call queue py line f res list func args kwargs file stable diffusion webui dev modules call queue py line f res func args kwargs file stable diffusion webui dev modules call queue py line f res func args kwargs file stable diffusion webui dev modules txt img py line txt img processed processing process images p file stable diffusion webui dev modules processing py line process images res process images inner p file stable diffusion webui dev modules processing py line process images inner devices test nans samples ddim unet file stable diffusion webui dev modules devices py line test nans raise nansexception message modules devices nansexception tensor nans produced unet could either enough precision represent picture video card support half type try setting upcast cross attention layer float option settings stable diffusion using half commandline argument fix use disable nan check commandline argument disable check additional information response
auto1111_webui,comment,17067,,"Same problem, sdxl model",2025-07-28T01:59:53Z,Roywhite,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067#issuecomment-3124989192,"Same problem, sdxl model",problem sdxl model
auto1111_webui,comment,17067,,"I get this error if I have `Clip Skip SDXL` Enabled and `Clip Skip` set to `1`
I don't have `--no-half` or `--disable-nan-check` arguments enabled
I don't get this error if I set `Clip Skip` to `2` while `Clip Skip SDXL` is enabled, or I disable `Clip Skip SDXL`
Be sure to restart the UI after turning on/off `Clip Skip SDXL`",2025-08-01T06:09:40Z,FriedGenera,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067#issuecomment-3142608655,"I get this error if I have `Clip Skip SDXL` Enabled and `Clip Skip` set to `1`
I don't have `--no-half` or `--disable-nan-check` arguments enabled
I don't get this error if I set `Clip Skip` to `2` while `Clip Skip SDXL` is enabled, or I disable `Clip Skip SDXL`
Be sure to restart the UI after turning on/off `Clip Skip SDXL`",get error clip skip sdxl enabled clip skip set half disable nan check arguments enabled get error set clip skip clip skip sdxl enabled disable clip skip sdxl sure restart ui turning clip skip sdxl
auto1111_webui,issue,17064,[Bug]: AttributeError: 'NoneType' object has no attribute 'get',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

the issue happened when i train hypernetwork

<img width=""1764"" height=""1028"" alt=""Image"" src=""https://github.com/user-attachments/assets/70b7641f-5ae6-4492-b457-d586465a6254"" />

### Steps to reproduce the problem

preprocess the image
train the hypernetwork model
then the issue happend

### What should have happened?

start training the issue

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-23-08-32.txt](https://github.com/user-attachments/files/21383763/sysinfo-2025-07-23-08-32.txt)

### Console logs

```Shell
*** Error verifying pickled file from D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt
*** The file may be malicious, so the program is not going to read it.
*** You can skip this check with --disable-safe-unpickle commandline argument.
***
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 137, in load_with_extra
        check_pt(filename, extra_handler)
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 84, in check_pt
        check_zip_filenames(filename, z.namelist())
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 76, in check_zip_filenames
        raise Exception(f""bad file inside {filename}: {name}"")
    Exception: bad file inside D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt: archive/.format_version

---
Applying attention optimization: sdp... done.
*** Error completing request
*** Arguments: ('task(2gmsdezwnvylszq)', 'mural-restore', '0.00001', 1, 1, 'D:\\code\\sdfile\\sd_processed', 'textual_inversion', 512, 512, False, 100000, 'disabled', '0.1', False, 0, 'once', False, 500, 500, 'style_filewords.txt', False, '', '', 20, 'DPM++ 2M Karras', 7, -1, 512, 512) {}
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 57, in f
        res = list(func(*args, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 36, in f
        res = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\ui.py"", line 25, in train_hypernetwork
        hypernetwork, filename = modules.hypernetworks.hypernetwork.train_hypernetwork(*args)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 482, in train_hypernetwork
        hypernetwork.load(path)
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 249, in load
        self.layer_structure = state_dict.get('layer_structure', [1, 2, 1])
                               ^^^^^^^^^^^^^^
    AttributeError: 'NoneType' object has no attribute 'get'
```

### Additional information

_No response_",2025-07-23T08:32:52Z,war-nightmare,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17064,"[Bug]: AttributeError: 'NoneType' object has no attribute 'get' ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

the issue happened when i train hypernetwork

<img width=""1764"" height=""1028"" alt=""Image"" src=""https://github.com/user-attachments/assets/70b7641f-5ae6-4492-b457-d586465a6254"" />

### Steps to reproduce the problem

preprocess the image
train the hypernetwork model
then the issue happend

### What should have happened?

start training the issue

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-23-08-32.txt](https://github.com/user-attachments/files/21383763/sysinfo-2025-07-23-08-32.txt)

### Console logs

```Shell
*** Error verifying pickled file from D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt
*** The file may be malicious, so the program is not going to read it.
*** You can skip this check with --disable-safe-unpickle commandline argument.
***
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 137, in load_with_extra
        check_pt(filename, extra_handler)
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 84, in check_pt
        check_zip_filenames(filename, z.namelist())
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 76, in check_zip_filenames
        raise Exception(f""bad file inside {filename}: {name}"")
    Exception: bad file inside D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt: archive/.format_version

---
Applying attention optimization: sdp... done.
*** Error completing request
*** Arguments: ('task(2gmsdezwnvylszq)', 'mural-restore', '0.00001', 1, 1, 'D:\\code\\sdfile\\sd_processed', 'textual_inversion', 512, 512, False, 100000, 'disabled', '0.1', False, 0, 'once', False, 500, 500, 'style_filewords.txt', False, '', '', 20, 'DPM++ 2M Karras', 7, -1, 512, 512) {}
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 57, in f
        res = list(func(*args, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 36, in f
        res = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\ui.py"", line 25, in train_hypernetwork
        hypernetwork, filename = modules.hypernetworks.hypernetwork.train_hypernetwork(*args)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 482, in train_hypernetwork
        hypernetwork.load(path)
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 249, in load
        self.layer_structure = state_dict.get('layer_structure', [1, 2, 1])
                               ^^^^^^^^^^^^^^
    AttributeError: 'NoneType' object has no attribute 'get'
```

### Additional information

_No response_",bug attributeerror nonetype object attribute get checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened issue happened train hypernetwork img width height alt image src steps reproduce problem preprocess image train hypernetwork model issue happend happened start training issue browsers use access ui google chrome sysinfo sysinfo txt console logs shell error verifying pickled file code sd webui aki v models hypernetworks mural restore pt file may malicious program going read skip check disable safe unpickle commandline argument traceback recent call last file code sd webui aki v modules safe py line load extra check pt filename extra handler file code sd webui aki v modules safe py line check pt check zip filenames filename z namelist file code sd webui aki v modules safe py line check zip filenames raise exception f bad file inside filename name exception bad file inside code sd webui aki v models hypernetworks mural restore pt archive format version applying attention optimization sdp done error completing request arguments task gmsdezwnvylszq mural restore code sdfile sd processed textual inversion false disabled false false style filewords txt false dpm karras traceback recent call last file code sd webui aki v modules call queue py line f res list func args kwargs file code sd webui aki v modules call queue py line f res func args kwargs file code sd webui aki v modules hypernetworks ui py line train hypernetwork hypernetwork filename modules hypernetworks hypernetwork train hypernetwork args file code sd webui aki v modules hypernetworks hypernetwork py line train hypernetwork hypernetwork load path file code sd webui aki v modules hypernetworks hypernetwork py line load self layer structure state dict get layer structure attributeerror nonetype object attribute get additional information response
auto1111_webui,issue,17063,[Bug]: ModuleNotFoundError: No module named 'numpy.exceptions',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Automatic1111 Google Collab, yesterday it launched fine, 

https://github.com/TheLastBen/fast-stable-diffusion

today I got error : 



### Steps to reproduce the problem

Launch Automatic1111 https://github.com/TheLastBen/fast-stable-diffusion

### What should have happened?

It should launch 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no access to UI due to error

### Console logs

```Shell
Traceback (most recent call last):
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/__init__.py"", line 34, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/types.py"", line 28, in <module>
    from torchmetrics import Metric
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/__init__.py"", line 52, in <module>
    from torchmetrics.image import (  # noqa: E402
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/__init__.py"", line 26, in <module>
    from torchmetrics.image.fid import FrechetInceptionDistance  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/fid.py"", line 28, in <module>
    from torch_fidelity.feature_extractor_inceptionv3 import FeatureExtractorInceptionV3
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/__init__.py"", line 6, in <module>
    from torch_fidelity.metric_fid import KEY_METRIC_FID
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/metric_fid.py"", line 6, in <module>
    import scipy.linalg
  File ""/usr/local/lib/python3.11/dist-packages/scipy/linalg/__init__.py"", line 204, in <module>
    from ._cythonized_array_utils import *
  File ""scipy/linalg/_cythonized_array_utils.pyx"", line 11, in init scipy.linalg._cythonized_array_utils
  File ""/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py"", line 20, in <module>
    from numpy.exceptions import AxisError
ModuleNotFoundError: No module named 'numpy.exceptions'
```

### Additional information

_No response_",2025-07-23T00:09:12Z,Limmweb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063,"[Bug]: ModuleNotFoundError: No module named 'numpy.exceptions' ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Automatic1111 Google Collab, yesterday it launched fine, 

https://github.com/TheLastBen/fast-stable-diffusion

today I got error : 



### Steps to reproduce the problem

Launch Automatic1111 https://github.com/TheLastBen/fast-stable-diffusion

### What should have happened?

It should launch 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no access to UI due to error

### Console logs

```Shell
Traceback (most recent call last):
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/__init__.py"", line 34, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/types.py"", line 28, in <module>
    from torchmetrics import Metric
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/__init__.py"", line 52, in <module>
    from torchmetrics.image import (  # noqa: E402
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/__init__.py"", line 26, in <module>
    from torchmetrics.image.fid import FrechetInceptionDistance  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/fid.py"", line 28, in <module>
    from torch_fidelity.feature_extractor_inceptionv3 import FeatureExtractorInceptionV3
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/__init__.py"", line 6, in <module>
    from torch_fidelity.metric_fid import KEY_METRIC_FID
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/metric_fid.py"", line 6, in <module>
    import scipy.linalg
  File ""/usr/local/lib/python3.11/dist-packages/scipy/linalg/__init__.py"", line 204, in <module>
    from ._cythonized_array_utils import *
  File ""scipy/linalg/_cythonized_array_utils.pyx"", line 11, in init scipy.linalg._cythonized_array_utils
  File ""/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py"", line 20, in <module>
    from numpy.exceptions import AxisError
ModuleNotFoundError: No module named 'numpy.exceptions'
```

### Additional information

_No response_",bug modulenotfounderror module named numpy exceptions checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened automatic google collab yesterday launched fine today got error steps reproduce problem launch automatic happened launch browsers use access ui response sysinfo access ui due error console logs shell traceback recent call last file content gdrive mydrive sd stable diffusion webui webui py line module initialize imports file content gdrive mydrive sd stable diffusion webui modules initialize py line imports import pytorch lightning noqa f file usr local lib python dist packages pytorch lightning init py line module pytorch lightning callbacks import callback noqa e file usr local lib python dist packages pytorch lightning callbacks init py line module pytorch lightning callbacks callback import callback file usr local lib python dist packages pytorch lightning callbacks callback py line module pytorch lightning utilities types import step output file usr local lib python dist packages pytorch lightning utilities types py line module torchmetrics import metric file usr local lib python dist packages torchmetrics init py line module torchmetrics image import noqa e file usr local lib python dist packages torchmetrics image init py line module torchmetrics image fid import frechetinceptiondistance noqa f file usr local lib python dist packages torchmetrics image fid py line module torch fidelity feature extractor inceptionv import featureextractorinceptionv file usr local lib python dist packages torch fidelity init py line module torch fidelity metric fid import key metric fid file usr local lib python dist packages torch fidelity metric fid py line module import scipy linalg file usr local lib python dist packages scipy linalg init py line module cythonized array utils import file scipy linalg cythonized array utils pyx line init scipy linalg cythonized array utils file usr local lib python dist packages scipy lib util py line module numpy exceptions import axiserror modulenotfounderror module named numpy exceptions additional information response
auto1111_webui,comment,17063,,"Update: solved issue by adding this command 

`!pip install numpy==1.26.4 scipy==1.11.4 --force-reinstall
`

after **Connect Google Drive** and before **Install/Update AUTOMATIC1111 repo** modules in Google Collab",2025-07-23T00:32:41Z,Limmweb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3105241421,"Update: solved issue by adding this command 

`!pip install numpy==1.26.4 scipy==1.11.4 --force-reinstall
`

after **Connect Google Drive** and before **Install/Update AUTOMATIC1111 repo** modules in Google Collab",update solved issue adding command pip install numpy scipy force reinstall connect google drive install update automatic repo modules google collab
auto1111_webui,comment,17063,,"Thank you so much for sharing this! 
I tried running the script after mounting Google Drive, but ran into the following issue:

```Collecting numpy==1.26.4
  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 4.7 MB/s eta 0:00:00
Collecting scipy==1.11.4
  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 5.9 MB/s eta 0:00:00
Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 92.1 MB/s eta 0:00:00
Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 24.6 MB/s eta 0:00:00
Installing collected packages: numpy, scipy
  Attempting uninstall: numpy
    Found existing installation: numpy 2.0.2
    Uninstalling numpy-2.0.2:
      Successfully uninstalled numpy-2.0.2
  Attempting uninstall: scipy
    Found existing installation: scipy 1.16.0
    Uninstalling scipy-1.16.0:
      Successfully uninstalled scipy-1.16.0
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
Successfully installed numpy-1.26.4 scipy-1.11.4
WARNING: The following packages were previously imported in this runtime:
  [numpy]
You must restart the runtime in order to use newly installed versions.
```

However, even after restarting the session, the same warning keeps appearing.
I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?


",2025-07-26T03:35:55Z,rororoSSS,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3121126859,"Thank you so much for sharing this! 
I tried running the script after mounting Google Drive, but ran into the following issue:

```Collecting numpy==1.26.4
  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 4.7 MB/s eta 0:00:00
Collecting scipy==1.11.4
  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 5.9 MB/s eta 0:00:00
Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 92.1 MB/s eta 0:00:00
Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 24.6 MB/s eta 0:00:00
Installing collected packages: numpy, scipy
  Attempting uninstall: numpy
    Found existing installation: numpy 2.0.2
    Uninstalling numpy-2.0.2:
      Successfully uninstalled numpy-2.0.2
  Attempting uninstall: scipy
    Found existing installation: scipy 1.16.0
    Uninstalling scipy-1.16.0:
      Successfully uninstalled scipy-1.16.0
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
Successfully installed numpy-1.26.4 scipy-1.11.4
WARNING: The following packages were previously imported in this runtime:
  [numpy]
You must restart the runtime in order to use newly installed versions.
```

However, even after restarting the session, the same warning keeps appearing.
I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?",thank much sharing tried running script mounting google drive ran following issue collecting numpy downloading numpy cp cp manylinux x manylinux x whl metadata kb kb mb eta collecting scipy downloading scipy cp cp manylinux x manylinux x whl metadata kb kb mb eta downloading numpy cp cp manylinux x manylinux x whl mb mb mb eta downloading scipy cp cp manylinux x manylinux x whl mb mb mb eta installing collected packages numpy scipy attempting uninstall numpy found existing installation numpy uninstalling numpy successfully uninstalled numpy attempting uninstall scipy found existing installation scipy uninstalling scipy successfully uninstalled scipy error pip dependency resolver currently take account packages installed behaviour source following dependency conflicts opencv contrib python requires numpy python version numpy incompatible tsfresh requires scipy python version scipy incompatible opencv python headless requires numpy python version numpy incompatible thinc requires numpy numpy incompatible opencv python requires numpy python version numpy incompatible successfully installed numpy scipy warning following packages previously imported runtime numpy must restart runtime order use newly installed versions however even restarting session warning keeps appearing wondering encountered issue well something might missing setup
auto1111_webui,comment,17063,,"> Thank you so much for sharing this! I tried running the script after mounting Google Drive, but ran into the following issue:
> 
> ```
>   Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
>      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 4.7 MB/s eta 0:00:00
> Collecting scipy==1.11.4
>   Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
>      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 5.9 MB/s eta 0:00:00
> Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
>    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 92.1 MB/s eta 0:00:00
> Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
>    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 24.6 MB/s eta 0:00:00
> Installing collected packages: numpy, scipy
>   Attempting uninstall: numpy
>     Found existing installation: numpy 2.0.2
>     Uninstalling numpy-2.0.2:
>       Successfully uninstalled numpy-2.0.2
>   Attempting uninstall: scipy
>     Found existing installation: scipy 1.16.0
>     Uninstalling scipy-1.16.0:
>       Successfully uninstalled scipy-1.16.0
> ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
> opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
> opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
> opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> Successfully installed numpy-1.26.4 scipy-1.11.4
> WARNING: The following packages were previously imported in this runtime:
>   [numpy]
> You must restart the runtime in order to use newly installed versions.
> ```
> 
> However, even after restarting the session, the same warning keeps appearing. I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?

After restarting the runtime, you skip this module and run everything as usual. I have the same error, but it doesn't cause any problems with startup.",2025-07-26T10:50:29Z,lRyzzl,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3121611474,"> Thank you so much for sharing this! I tried running the script after mounting Google Drive, but ran into the following issue:
> 
> ```
>   Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
>      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 4.7 MB/s eta 0:00:00
> Collecting scipy==1.11.4
>   Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
>      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 5.9 MB/s eta 0:00:00
> Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
>    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 92.1 MB/s eta 0:00:00
> Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
>    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 24.6 MB/s eta 0:00:00
> Installing collected packages: numpy, scipy
>   Attempting uninstall: numpy
>     Found existing installation: numpy 2.0.2
>     Uninstalling numpy-2.0.2:
>       Successfully uninstalled numpy-2.0.2
>   Attempting uninstall: scipy
>     Found existing installation: scipy 1.16.0
>     Uninstalling scipy-1.16.0:
>       Successfully uninstalled scipy-1.16.0
> ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
> opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
> opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
> opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> Successfully installed numpy-1.26.4 scipy-1.11.4
> WARNING: The following packages were previously imported in this runtime:
>   [numpy]
> You must restart the runtime in order to use newly installed versions.
> ```
> 
> However, even after restarting the session, the same warning keeps appearing. I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?

After restarting the runtime, you skip this module and run everything as usual. I have the same error, but it doesn't cause any problems with startup.",thank much sharing tried running script mounting google drive ran following issue downloading numpy cp cp manylinux x manylinux x whl metadata kb kb mb eta collecting scipy downloading scipy cp cp manylinux x manylinux x whl metadata kb kb mb eta downloading numpy cp cp manylinux x manylinux x whl mb mb mb eta downloading scipy cp cp manylinux x manylinux x whl mb mb mb eta installing collected packages numpy scipy attempting uninstall numpy found existing installation numpy uninstalling numpy successfully uninstalled numpy attempting uninstall scipy found existing installation scipy uninstalling scipy successfully uninstalled scipy error pip dependency resolver currently take account packages installed behaviour source following dependency conflicts opencv contrib python requires numpy python version numpy incompatible tsfresh requires scipy python version scipy incompatible opencv python headless requires numpy python version numpy incompatible thinc requires numpy numpy incompatible opencv python requires numpy python version numpy incompatible successfully installed numpy scipy warning following packages previously imported runtime numpy must restart runtime order use newly installed versions however even restarting session warning keeps appearing wondering encountered issue well something might missing setup restarting runtime skip module run everything usual error cause problems startup
auto1111_webui,comment,17063,,"It's working, thank you so much for the help!",2025-07-27T02:19:26Z,rororoSSS,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3123780214,"It's working, thank you so much for the help!",working thank much help
auto1111_webui,issue,17062,[Feature Request]: AVIF Lossless Support,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Stable Diffusion Webui already supports avif, but there is no setting to make it lossless like webp.

Also of note, if I pass an avif image through an upscaler in extras, the resulting avif's colorspace, color primaries and color transfer settings will be changed (to bt601,bt709 and srgb)

The whole idea here is to use AVIF to extract frames losslessly (or near losslessly I guess) from a video, upscale those frames in sdwebui's extras tab and saving them as an AVIF with the same paramaters as the AVIF that was loaded in.

### Proposed workflow

1. A lossless setting for avif next to the 'Use lossless compression for webp images' setting. 
2. The setting should ideally try to account for colorspace, color primaries, and color transfer of the original image. (Otherwise it cannot be called lossless as the colors will change from the conversion of those attributes to different ones)

### Additional information

You can extract a frame from any video as avif with ffmpeg as avif using this command:

    ffmpeg -i <input_video> -ss <timestamp> -cpu-used 4 -c:v libaom-av1 -aom-params lossless=1 -frames:v 1 <output_image>.avif


Alternatively below is an example avif image.

I had to rename the extension to png because github said so. 

Simply download it and rename it's extension to .avif.

![Image](https://github.com/user-attachments/assets/6fbf77c3-8ccf-4b5d-8543-01e8e91a4957)

",2025-07-15T05:03:40Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062,"[Feature Request]: AVIF Lossless Support ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Stable Diffusion Webui already supports avif, but there is no setting to make it lossless like webp.

Also of note, if I pass an avif image through an upscaler in extras, the resulting avif's colorspace, color primaries and color transfer settings will be changed (to bt601,bt709 and srgb)

The whole idea here is to use AVIF to extract frames losslessly (or near losslessly I guess) from a video, upscale those frames in sdwebui's extras tab and saving them as an AVIF with the same paramaters as the AVIF that was loaded in.

### Proposed workflow

1. A lossless setting for avif next to the 'Use lossless compression for webp images' setting. 
2. The setting should ideally try to account for colorspace, color primaries, and color transfer of the original image. (Otherwise it cannot be called lossless as the colors will change from the conversion of those attributes to different ones)

### Additional information

You can extract a frame from any video as avif with ffmpeg as avif using this command:

    ffmpeg -i <input_video> -ss <timestamp> -cpu-used 4 -c:v libaom-av1 -aom-params lossless=1 -frames:v 1 <output_image>.avif


Alternatively below is an example avif image.

I had to rename the extension to png because github said so. 

Simply download it and rename it's extension to .avif.

![Image](https://github.com/user-attachments/assets/6fbf77c3-8ccf-4b5d-8543-01e8e91a4957)",feature request avif lossless support existing issue x searched existing issues checked recent builds commits would feature stable diffusion webui already supports avif setting make lossless like webp also note pass avif image upscaler extras resulting avif colorspace color primaries color transfer settings changed bt bt srgb whole idea use avif extract frames losslessly near losslessly guess video upscale frames sdwebui extras tab saving avif paramaters avif loaded proposed workflow lossless setting avif next use lossless compression webp images setting setting ideally try account colorspace color primaries color transfer original image otherwise cannot called lossless colors change conversion attributes different ones additional information extract frame video avif ffmpeg avif using command ffmpeg input video ss timestamp cpu used c v libaom av aom params lossless frames v output image avif alternatively example avif image rename extension png github said simply download rename extension avif image
auto1111_webui,comment,17062,,"you sure we don't support losses AVIF?
 
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/15610

<img width=""341"" height=""94"" alt=""Image"" src=""https://github.com/user-attachments/assets/8a6584e6-bce7-439b-ab5a-7f8edd65774f"" />

",2025-07-19T02:38:53Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062#issuecomment-3091427111,"you sure we don't support losses AVIF?
 
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/15610

<img width=""341"" height=""94"" alt=""Image"" src=""https://github.com/user-attachments/assets/8a6584e6-bce7-439b-ab5a-7f8edd65774f"" />",sure support losses avif img width height alt image src
auto1111_webui,comment,17062,,"> you sure we don't support losses AVIF?

Setting avif quality to 100%, like with jpeg, does not make it lossless, it would need to be a separate tickable setting like with the webp. And the lossless compression for webp setting does not make avif lossless, I've checked that.

A lossless parameter needs to be set, this remains true for all av1 libraries I tested except for rav1e which doesn't support lossless av1 at all.
 
For example with ffmpeg to create lossless avif one of the below combinations of settings is required, there's also a quality setting but as I said, setting it to 100 is not the same as lossless.
```
#svtav1
 -c:v libsvtav1 -svtav1-params lossless=1
#libaom-av1
 -c:v libaom-av1 -aom-params lossless=1
```

The pixel format and colorspace conversions would also still be a rather big issue.",2025-07-21T11:12:14Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062#issuecomment-3096245082,"> you sure we don't support losses AVIF?

Setting avif quality to 100%, like with jpeg, does not make it lossless, it would need to be a separate tickable setting like with the webp. And the lossless compression for webp setting does not make avif lossless, I've checked that.

A lossless parameter needs to be set, this remains true for all av1 libraries I tested except for rav1e which doesn't support lossless av1 at all.
 
For example with ffmpeg to create lossless avif one of the below combinations of settings is required, there's also a quality setting but as I said, setting it to 100 is not the same as lossless.
```
#svtav1
 -c:v libsvtav1 -svtav1-params lossless=1
#libaom-av1
 -c:v libaom-av1 -aom-params lossless=1
```

The pixel format and colorspace conversions would also still be a rather big issue.",sure support losses avif setting avif quality like jpeg make lossless would need separate tickable setting like webp lossless compression webp setting make avif lossless checked lossless parameter needs set remains true av libraries tested except rav e support lossless av example ffmpeg create lossless avif one combinations settings required also quality setting said setting lossless svtav c v libsvtav svtav params lossless libaom av c v libaom av aom params lossless pixel format colorspace conversions would also still rather big issue
auto1111_webui,issue,17061,[Bug]: AttributeError: 'BertLMHeadModel' object has no attribute 'generate',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I tried to run BLIP image caption for data preprocess
but I cannot run it successfully.

### Steps to reproduce the problem

1. Select the tab `Extras` > `Batch from directory`.
2. fill in input dir & output dir.
3. Select Caption > BLIP.

### What should have happened?

In `repositories/BLIP/models/blip.py` there's no function called `generate` in `Class BertLMHeadModel` indeed, but this method called by `modules/interrogate.py` at line 181.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

{
    ""Platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
    ""Python"": ""3.10.18"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""位於分支 master\n您的分支與上游分支 'origin/master' 一致。\n\n尚未暫存以備提交的變更：\n  （使用 \""git add <檔案>...\"" 更新要提交的內容）\n  （使用 \""git restore <檔案>...\"" 捨棄工作區的改動）\n\t修改：     modules/launch_utils.py\n\t修改：     webui-user.sh\n\t修改：     webui.sh\n\n未追蹤的檔案:\n  （使用 \""git add <檔案>...\"" 以包含要提交的內容）\n\tdata/\n\n修改尚未加入提交（使用 \""git add\"" 和/或 \""git commit -a\""）"",
    ""Script path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Data path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Extensions dir"": ""/home/matt/Documents/stable-diffusion-webui/extensions"",
    ""Checksum"": ""4e7bff3f3cfe0f27f5e47b1af1d0d720b5211dbd577cace58e87aa151cb03fd9"",
    ""Commandline"": [
        ""launch.py"",
        ""--disable-safe-unpickle""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.9.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.9"",
        ""gcc_version"": ""(Ubuntu 14.2.0-4ubuntu2~24.04) 14.2.0"",
        ""clang_version"": null,
        ""cmake_version"": ""version 3.28.3"",
        ""os"": ""Ubuntu 24.04.2 LTS (x86_64)"",
        ""libc_version"": ""glibc-2.39"",
        ""python_version"": ""3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0] (64-bit runtime)"",
        ""python_platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""575.57.08"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5090"",
        ""cudnn_version"": [
            ""Probably one of the following:"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_train.so.8""
        ],
        ""is_xpu_available"": ""False"",
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""nvidia-cublas-cu12==12.9.1.4"",
            ""nvidia-cuda-cupti-cu12==12.9.79"",
            ""nvidia-cuda-nvrtc-cu12==12.9.86"",
            ""nvidia-cuda-runtime-cu12==12.9.79"",
            ""nvidia-cudnn-cu12==9.10.2.21"",
            ""nvidia-cufft-cu12==11.4.1.4"",
            ""nvidia-curand-cu12==10.3.10.19"",
            ""nvidia-cusolver-cu12==11.7.5.82"",
            ""nvidia-cusparse-cu12==12.5.10.65"",
            ""nvidia-cusparselt-cu12==0.7.1"",
            ""nvidia-nccl-cu12==2.27.5"",
            ""nvidia-nvjitlink-cu12==12.9.86"",
            ""nvidia-nvtx-cu12==12.9.79"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""pytorch_optimizer==3.4.0"",
            ""pytorch-triton==3.4.0+gitae848267"",
            ""torch==2.9.0.dev20250712+cu129"",
            ""torchaudio==2.8.0.dev20250713+cu129"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.24.0.dev20250713+cu129"",
            ""triton==3.3.1""
        ],
        ""conda_packages"": [
            ""numpy                        1.26.2                    pypi_0           pypi"",
            ""nvidia-cublas-cu12           12.9.1.4                  pypi_0           pypi"",
            ""nvidia-cuda-cupti-cu12       12.9.79                   pypi_0           pypi"",
            ""nvidia-cuda-nvrtc-cu12       12.9.86                   pypi_0           pypi"",
            ""nvidia-cuda-runtime-cu12     12.9.79                   pypi_0           pypi"",
            ""nvidia-cudnn-cu12            9.10.2.21                 pypi_0           pypi"",
            ""nvidia-cufft-cu12            11.4.1.4                  pypi_0           pypi"",
            ""nvidia-curand-cu12           10.3.10.19                pypi_0           pypi"",
            ""nvidia-cusolver-cu12         11.7.5.82                 pypi_0           pypi"",
            ""nvidia-cusparse-cu12         12.5.10.65                pypi_0           pypi"",
            ""nvidia-cusparselt-cu12       0.7.1                     pypi_0           pypi"",
            ""nvidia-nccl-cu12             2.27.5                    pypi_0           pypi"",
            ""nvidia-nvjitlink-cu12        12.9.86                   pypi_0           pypi"",
            ""nvidia-nvtx-cu12             12.9.79                   pypi_0           pypi"",
            ""open-clip-torch              2.20.0                    pypi_0           pypi"",
            ""pytorch-lightning            1.9.4                     pypi_0           pypi"",
            ""pytorch-optimizer            3.4.0                     pypi_0           pypi"",
            ""pytorch-triton               3.4.0+gitae848267         pypi_0           pypi"",
            ""torch                        2.9.0.dev20250712+cu129   pypi_0           pypi"",
            ""torchaudio                   2.8.0.dev20250713+cu129   pypi_0           pypi"",
            ""torchdiffeq                  0.2.3                     pypi_0           pypi"",
            ""torchmetrics                 1.7.4                     pypi_0           pypi"",
            ""torchsde                     0.2.6                     pypi_0           pypi"",
            ""torchvision                  0.24.0.dev20250713+cu129  pypi_0           pypi"",
            ""triton                       3.3.1                     pypi_0           pypi""
        ],
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""架構：                                   x86_64"",
            ""CPU 作業模式：                           32-bit, 64-bit"",
            ""Address sizes:                           46 bits physical, 48 bits virtual"",
            ""Byte Order:                              Little Endian"",
            ""CPU(s):                                  24"",
            ""On-line CPU(s) list:                     0-23"",
            ""供應商識別號：                           GenuineIntel"",
            ""Model name:                              Intel(R) Core(TM) Ultra 9 285K"",
            ""CPU 家族：                               6"",
            ""型號：                                   198"",
            ""每核心執行緒數：                         1"",
            ""每通訊端核心數：                         24"",
            ""Socket(s):                               1"",
            ""製程：                                   2"",
            ""CPU(s) scaling MHz:                      70%"",
            ""CPU max MHz:                             6500.0000"",
            ""CPU min MHz:                             800.0000"",
            ""BogoMIPS:                                7372.80"",
            ""Flags:                                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect user_shstk avx_vnni lam wbnoinvd dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid bus_lock_detect movdiri movdir64b fsrm md_clear serialize arch_lbr ibt flush_l1d arch_capabilities"",
            ""虛擬：                                   VT-x"",
            ""L1d 快取：                               768 KiB (20 instances)"",
            ""L1i 快取：                               1.3 MiB (20 instances)"",
            ""L2 快取：                                40 MiB (12 instances)"",
            ""L3 快取：                                36 MiB (1 instance)"",
            ""NUMA 節點：                              1"",
            ""NUMA node0 CPU(s)：                      0-23"",
            ""Vulnerability Gather data sampling:      Not affected"",
            ""Vulnerability Ghostwrite:                Not affected"",
            ""Vulnerability Indirect target selection: Not affected"",
            ""Vulnerability Itlb multihit:             Not affected"",
            ""Vulnerability L1tf:                      Not affected"",
            ""Vulnerability Mds:                       Not affected"",
            ""Vulnerability Meltdown:                  Not affected"",
            ""Vulnerability Mmio stale data:           Not affected"",
            ""Vulnerability Reg file data sampling:    Not affected"",
            ""Vulnerability Retbleed:                  Not affected"",
            ""Vulnerability Spec rstack overflow:      Not affected"",
            ""Vulnerability Spec store bypass:         Mitigation; Speculative Store Bypass disabled via prctl"",
            ""Vulnerability Spectre v1:                Mitigation; usercopy/swapgs barriers and __user pointer sanitization"",
            ""Vulnerability Spectre v2:                Mitigation; Enhanced / Automatic IBRS; IBPB conditional; PBRSB-eIBRS Not affected; BHI BHI_DIS_S"",
            ""Vulnerability Srbds:                     Not affected"",
            ""Vulnerability Tsx async abort:           Not affected""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""x86_64"",
        ""count logical"": 24,
        ""count physical"": 24
    },
    ""RAM"": {
        ""total"": ""62GB"",
        ""used"": ""13GB"",
        ""free"": ""4GB"",
        ""active"": ""11GB"",
        ""inactive"": ""43GB"",
        ""buffers"": ""736MB"",
        ""cached"": ""44GB"",
        ""shared"": ""1GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd_dreambooth_extension"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd_dreambooth_extension"",
            ""commit"": ""bae1e87c9b0fe3bb0d261d6851ceffab6f99dfb6"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/d8ahazard/sd_dreambooth_extension.git""
        }
    ],
    ""Inactive extensions"": [
        {
            ""name"": ""sd-webui-blip2"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd-webui-blip2"",
            ""commit"": ""6ca77c3ac9f522fc288f302d73e6e1e3edd1c0f4"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Tps-F/sd-webui-blip2.git""
        }
    ],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--disable-safe-unpickle"",
        ""GIT"": ""git"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v1-5-pruned-emaonly.safetensors [6ce0161689]"",
        ""sd_checkpoint_hash"": ""6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa"",
        ""disabled_extensions"": [
            ""sd-webui-blip2""
        ],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 54.858973026275635,
        ""records"": {
            ""initial startup"": 0.006804466247558594,
            ""prepare environment/checks"": 4.76837158203125e-05,
            ""prepare environment/git version info"": 0.0056149959564208984,
            ""prepare environment/install torch"": 38.455273389816284,
            ""prepare environment/torch GPU test"": 1.2488372325897217,
            ""prepare environment/clone repositores"": 0.021414518356323242,
            ""prepare environment/install requirements"": 3.1076724529266357,
            ""prepare environment/run extensions installers/sd_dreambooth_extension"": 7.6595964431762695,
            ""prepare environment/run extensions installers"": 7.659667015075684,
            ""prepare environment"": 50.49855923652649,
            ""launcher"": 0.0026547908782958984,
            ""import torch"": 1.9291045665740967,
            ""import gradio"": 0.3491065502166748,
            ""setup paths"": 0.6249384880065918,
            ""import ldm"": 0.0012063980102539062,
            ""import sgm"": 1.9073486328125e-06,
            ""initialize shared"": 0.11213350296020508,
            ""other imports"": 0.21344661712646484,
            ""opts onchange"": 0.00021076202392578125,
            ""setup SD model"": 2.5987625122070312e-05,
            ""setup codeformer"": 0.0003218650817871094,
            ""setup gfpgan"": 0.01207423210144043,
            ""set samplers"": 1.6927719116210938e-05,
            ""list extensions"": 0.0004096031188964844,
            ""restore config state file"": 4.5299530029296875e-06,
            ""list SD models"": 0.01157999038696289,
            ""list localizations"": 8.106231689453125e-05,
            ""load scripts/custom_code.py"": 0.0005917549133300781,
            ""load scripts/img2imgalt.py"": 0.00019502639770507812,
            ""load scripts/loopback.py"": 0.00010895729064941406,
            ""load scripts/outpainting_mk_2.py"": 0.00012350082397460938,
            ""load scripts/poor_mans_outpainting.py"": 8.249282836914062e-05,
            ""load scripts/postprocessing_codeformer.py"": 7.224082946777344e-05,
            ""load scripts/postprocessing_gfpgan.py"": 6.318092346191406e-05,
            ""load scripts/postprocessing_upscale.py"": 0.00011491775512695312,
            ""load scripts/prompt_matrix.py"": 8.20159912109375e-05,
            ""load scripts/prompts_from_file.py"": 0.0001304149627685547,
            ""load scripts/sd_upscale.py"": 7.557868957519531e-05,
            ""load scripts/xyz_grid.py"": 0.0006914138793945312,
            ""load scripts/ldsr_model.py"": 0.021519184112548828,
            ""load scripts/lora_script.py"": 0.05590462684631348,
            ""load scripts/scunet_model.py"": 0.00992441177368164,
            ""load scripts/swinir_model.py"": 0.008924245834350586,
            ""load scripts/hotkey_config.py"": 0.0006728172302246094,
            ""load scripts/extra_options_section.py"": 0.0006744861602783203,
            ""load scripts/hypertile_script.py"": 0.017293930053710938,
            ""load scripts/postprocessing_autosized_crop.py"": 0.00045418739318847656,
            ""load scripts/postprocessing_caption.py"": 0.00043702125549316406,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.00041174888610839844,
            ""load scripts/postprocessing_focal_crop.py"": 0.0007452964782714844,
            ""load scripts/postprocessing_split_oversized.py"": 0.0003840923309326172,
            ""load scripts/soft_inpainting.py"": 0.00027942657470703125,
            ""load scripts/__init__.py"": 0.00014495849609375,
            ""load scripts/api.py"": 0.2062222957611084,
            ""load scripts/main.py"": 0.02004265785217285,
            ""load scripts/comments.py"": 0.008637189865112305,
            ""load scripts/refiner.py"": 0.00034928321838378906,
            ""load scripts/sampler.py"": 0.0004024505615234375,
            ""load scripts/seed.py"": 0.00018310546875,
            ""load scripts"": 0.3559587001800537,
            ""load upscalers"": 0.0018105506896972656,
            ""refresh VAE"": 0.00035762786865234375,
            ""refresh textual inversion templates"": 2.1696090698242188e-05,
            ""scripts list_optimizers"": 0.00014162063598632812,
            ""scripts list_unets"": 7.867813110351562e-06,
            ""reload hypernetworks"": 0.0006139278411865234,
            ""initialize extra networks"": 0.011160135269165039,
            ""scripts before_ui_callback"": 0.0008454322814941406,
            ""create ui"": 0.35759758949279785,
            ""gradio launch"": 0.3304779529571533,
            ""add APIs"": 0.037171363830566406,
            ""app_started_callback/lora_script.py"": 0.0001723766326904297,
            ""app_started_callback"": 0.0001742839813232422
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""altair==5.5.0"",
        ""annotated-types==0.7.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""bitsandbytes==0.46.1"",
        ""blendmodes==2022"",
        ""certifi==2025.7.14"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""dadaptation==3.2"",
        ""deprecation==2.1.0"",
        ""diffusers==0.34.0"",
        ""discord-webhook==1.3.1"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""hf-xet==1.1.5"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""kornia_rs==0.1.9"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""nvidia-cublas-cu12==12.9.1.4"",
        ""nvidia-cuda-cupti-cu12==12.9.79"",
        ""nvidia-cuda-nvrtc-cu12==12.9.86"",
        ""nvidia-cuda-runtime-cu12==12.9.79"",
        ""nvidia-cudnn-cu12==9.10.2.21"",
        ""nvidia-cufft-cu12==11.4.1.4"",
        ""nvidia-cufile-cu12==1.14.1.1"",
        ""nvidia-curand-cu12==10.3.10.19"",
        ""nvidia-cusolver-cu12==11.7.5.82"",
        ""nvidia-cusparse-cu12==12.5.10.65"",
        ""nvidia-cusparselt-cu12==0.7.1"",
        ""nvidia-nccl-cu12==2.27.5"",
        ""nvidia-nvjitlink-cu12==12.9.86"",
        ""nvidia-nvshmem-cu12==3.3.9"",
        ""nvidia-nvtx-cu12==12.9.79"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip @ file:///croot/pip_1746204010231/work"",
        ""propcache==0.3.2"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydantic_core==2.33.2"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytorch-triton==3.4.0+gitae848267"",
        ""pytorch_optimizer==3.4.0"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.26.0"",
        ""safetensors==0.5.3"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.17"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""torch==2.9.0.dev20250712+cu129"",
        ""torchaudio==2.8.0.dev20250713+cu129"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.24.0.dev20250713+cu129"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.53.2"",
        ""triton==3.3.1"",
        ""typing-inspection==0.4.1"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""xformers==0.0.31.post1"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
Here's the full log about this issue


*** Error interrogating
    Traceback (most recent call last):
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 194, in interrogate
        caption = self.generate_caption(pil_image)
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 181, in generate_caption
        caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)
      File ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py"", line 156, in generate
        outputs = self.text_decoder.generate(input_ids=input_ids,
      File ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1962, in __getattr__
        raise AttributeError(
    AttributeError: 'BertLMHeadModel' object has no attribute 'generate'
```

### Additional information

_No response_",2025-07-14T08:18:13Z,hanasay,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17061,"[Bug]: AttributeError: 'BertLMHeadModel' object has no attribute 'generate' ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I tried to run BLIP image caption for data preprocess
but I cannot run it successfully.

### Steps to reproduce the problem

1. Select the tab `Extras` > `Batch from directory`.
2. fill in input dir & output dir.
3. Select Caption > BLIP.

### What should have happened?

In `repositories/BLIP/models/blip.py` there's no function called `generate` in `Class BertLMHeadModel` indeed, but this method called by `modules/interrogate.py` at line 181.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

{
    ""Platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
    ""Python"": ""3.10.18"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""位於分支 master\n您的分支與上游分支 'origin/master' 一致。\n\n尚未暫存以備提交的變更：\n  （使用 \""git add <檔案>...\"" 更新要提交的內容）\n  （使用 \""git restore <檔案>...\"" 捨棄工作區的改動）\n\t修改：     modules/launch_utils.py\n\t修改：     webui-user.sh\n\t修改：     webui.sh\n\n未追蹤的檔案:\n  （使用 \""git add <檔案>...\"" 以包含要提交的內容）\n\tdata/\n\n修改尚未加入提交（使用 \""git add\"" 和/或 \""git commit -a\""）"",
    ""Script path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Data path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Extensions dir"": ""/home/matt/Documents/stable-diffusion-webui/extensions"",
    ""Checksum"": ""4e7bff3f3cfe0f27f5e47b1af1d0d720b5211dbd577cace58e87aa151cb03fd9"",
    ""Commandline"": [
        ""launch.py"",
        ""--disable-safe-unpickle""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.9.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.9"",
        ""gcc_version"": ""(Ubuntu 14.2.0-4ubuntu2~24.04) 14.2.0"",
        ""clang_version"": null,
        ""cmake_version"": ""version 3.28.3"",
        ""os"": ""Ubuntu 24.04.2 LTS (x86_64)"",
        ""libc_version"": ""glibc-2.39"",
        ""python_version"": ""3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0] (64-bit runtime)"",
        ""python_platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""575.57.08"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5090"",
        ""cudnn_version"": [
            ""Probably one of the following:"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_train.so.8""
        ],
        ""is_xpu_available"": ""False"",
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""nvidia-cublas-cu12==12.9.1.4"",
            ""nvidia-cuda-cupti-cu12==12.9.79"",
            ""nvidia-cuda-nvrtc-cu12==12.9.86"",
            ""nvidia-cuda-runtime-cu12==12.9.79"",
            ""nvidia-cudnn-cu12==9.10.2.21"",
            ""nvidia-cufft-cu12==11.4.1.4"",
            ""nvidia-curand-cu12==10.3.10.19"",
            ""nvidia-cusolver-cu12==11.7.5.82"",
            ""nvidia-cusparse-cu12==12.5.10.65"",
            ""nvidia-cusparselt-cu12==0.7.1"",
            ""nvidia-nccl-cu12==2.27.5"",
            ""nvidia-nvjitlink-cu12==12.9.86"",
            ""nvidia-nvtx-cu12==12.9.79"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""pytorch_optimizer==3.4.0"",
            ""pytorch-triton==3.4.0+gitae848267"",
            ""torch==2.9.0.dev20250712+cu129"",
            ""torchaudio==2.8.0.dev20250713+cu129"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.24.0.dev20250713+cu129"",
            ""triton==3.3.1""
        ],
        ""conda_packages"": [
            ""numpy                        1.26.2                    pypi_0           pypi"",
            ""nvidia-cublas-cu12           12.9.1.4                  pypi_0           pypi"",
            ""nvidia-cuda-cupti-cu12       12.9.79                   pypi_0           pypi"",
            ""nvidia-cuda-nvrtc-cu12       12.9.86                   pypi_0           pypi"",
            ""nvidia-cuda-runtime-cu12     12.9.79                   pypi_0           pypi"",
            ""nvidia-cudnn-cu12            9.10.2.21                 pypi_0           pypi"",
            ""nvidia-cufft-cu12            11.4.1.4                  pypi_0           pypi"",
            ""nvidia-curand-cu12           10.3.10.19                pypi_0           pypi"",
            ""nvidia-cusolver-cu12         11.7.5.82                 pypi_0           pypi"",
            ""nvidia-cusparse-cu12         12.5.10.65                pypi_0           pypi"",
            ""nvidia-cusparselt-cu12       0.7.1                     pypi_0           pypi"",
            ""nvidia-nccl-cu12             2.27.5                    pypi_0           pypi"",
            ""nvidia-nvjitlink-cu12        12.9.86                   pypi_0           pypi"",
            ""nvidia-nvtx-cu12             12.9.79                   pypi_0           pypi"",
            ""open-clip-torch              2.20.0                    pypi_0           pypi"",
            ""pytorch-lightning            1.9.4                     pypi_0           pypi"",
            ""pytorch-optimizer            3.4.0                     pypi_0           pypi"",
            ""pytorch-triton               3.4.0+gitae848267         pypi_0           pypi"",
            ""torch                        2.9.0.dev20250712+cu129   pypi_0           pypi"",
            ""torchaudio                   2.8.0.dev20250713+cu129   pypi_0           pypi"",
            ""torchdiffeq                  0.2.3                     pypi_0           pypi"",
            ""torchmetrics                 1.7.4                     pypi_0           pypi"",
            ""torchsde                     0.2.6                     pypi_0           pypi"",
            ""torchvision                  0.24.0.dev20250713+cu129  pypi_0           pypi"",
            ""triton                       3.3.1                     pypi_0           pypi""
        ],
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""架構：                                   x86_64"",
            ""CPU 作業模式：                           32-bit, 64-bit"",
            ""Address sizes:                           46 bits physical, 48 bits virtual"",
            ""Byte Order:                              Little Endian"",
            ""CPU(s):                                  24"",
            ""On-line CPU(s) list:                     0-23"",
            ""供應商識別號：                           GenuineIntel"",
            ""Model name:                              Intel(R) Core(TM) Ultra 9 285K"",
            ""CPU 家族：                               6"",
            ""型號：                                   198"",
            ""每核心執行緒數：                         1"",
            ""每通訊端核心數：                         24"",
            ""Socket(s):                               1"",
            ""製程：                                   2"",
            ""CPU(s) scaling MHz:                      70%"",
            ""CPU max MHz:                             6500.0000"",
            ""CPU min MHz:                             800.0000"",
            ""BogoMIPS:                                7372.80"",
            ""Flags:                                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect user_shstk avx_vnni lam wbnoinvd dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid bus_lock_detect movdiri movdir64b fsrm md_clear serialize arch_lbr ibt flush_l1d arch_capabilities"",
            ""虛擬：                                   VT-x"",
            ""L1d 快取：                               768 KiB (20 instances)"",
            ""L1i 快取：                               1.3 MiB (20 instances)"",
            ""L2 快取：                                40 MiB (12 instances)"",
            ""L3 快取：                                36 MiB (1 instance)"",
            ""NUMA 節點：                              1"",
            ""NUMA node0 CPU(s)：                      0-23"",
            ""Vulnerability Gather data sampling:      Not affected"",
            ""Vulnerability Ghostwrite:                Not affected"",
            ""Vulnerability Indirect target selection: Not affected"",
            ""Vulnerability Itlb multihit:             Not affected"",
            ""Vulnerability L1tf:                      Not affected"",
            ""Vulnerability Mds:                       Not affected"",
            ""Vulnerability Meltdown:                  Not affected"",
            ""Vulnerability Mmio stale data:           Not affected"",
            ""Vulnerability Reg file data sampling:    Not affected"",
            ""Vulnerability Retbleed:                  Not affected"",
            ""Vulnerability Spec rstack overflow:      Not affected"",
            ""Vulnerability Spec store bypass:         Mitigation; Speculative Store Bypass disabled via prctl"",
            ""Vulnerability Spectre v1:                Mitigation; usercopy/swapgs barriers and __user pointer sanitization"",
            ""Vulnerability Spectre v2:                Mitigation; Enhanced / Automatic IBRS; IBPB conditional; PBRSB-eIBRS Not affected; BHI BHI_DIS_S"",
            ""Vulnerability Srbds:                     Not affected"",
            ""Vulnerability Tsx async abort:           Not affected""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""x86_64"",
        ""count logical"": 24,
        ""count physical"": 24
    },
    ""RAM"": {
        ""total"": ""62GB"",
        ""used"": ""13GB"",
        ""free"": ""4GB"",
        ""active"": ""11GB"",
        ""inactive"": ""43GB"",
        ""buffers"": ""736MB"",
        ""cached"": ""44GB"",
        ""shared"": ""1GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd_dreambooth_extension"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd_dreambooth_extension"",
            ""commit"": ""bae1e87c9b0fe3bb0d261d6851ceffab6f99dfb6"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/d8ahazard/sd_dreambooth_extension.git""
        }
    ],
    ""Inactive extensions"": [
        {
            ""name"": ""sd-webui-blip2"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd-webui-blip2"",
            ""commit"": ""6ca77c3ac9f522fc288f302d73e6e1e3edd1c0f4"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Tps-F/sd-webui-blip2.git""
        }
    ],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--disable-safe-unpickle"",
        ""GIT"": ""git"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v1-5-pruned-emaonly.safetensors [6ce0161689]"",
        ""sd_checkpoint_hash"": ""6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa"",
        ""disabled_extensions"": [
            ""sd-webui-blip2""
        ],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 54.858973026275635,
        ""records"": {
            ""initial startup"": 0.006804466247558594,
            ""prepare environment/checks"": 4.76837158203125e-05,
            ""prepare environment/git version info"": 0.0056149959564208984,
            ""prepare environment/install torch"": 38.455273389816284,
            ""prepare environment/torch GPU test"": 1.2488372325897217,
            ""prepare environment/clone repositores"": 0.021414518356323242,
            ""prepare environment/install requirements"": 3.1076724529266357,
            ""prepare environment/run extensions installers/sd_dreambooth_extension"": 7.6595964431762695,
            ""prepare environment/run extensions installers"": 7.659667015075684,
            ""prepare environment"": 50.49855923652649,
            ""launcher"": 0.0026547908782958984,
            ""import torch"": 1.9291045665740967,
            ""import gradio"": 0.3491065502166748,
            ""setup paths"": 0.6249384880065918,
            ""import ldm"": 0.0012063980102539062,
            ""import sgm"": 1.9073486328125e-06,
            ""initialize shared"": 0.11213350296020508,
            ""other imports"": 0.21344661712646484,
            ""opts onchange"": 0.00021076202392578125,
            ""setup SD model"": 2.5987625122070312e-05,
            ""setup codeformer"": 0.0003218650817871094,
            ""setup gfpgan"": 0.01207423210144043,
            ""set samplers"": 1.6927719116210938e-05,
            ""list extensions"": 0.0004096031188964844,
            ""restore config state file"": 4.5299530029296875e-06,
            ""list SD models"": 0.01157999038696289,
            ""list localizations"": 8.106231689453125e-05,
            ""load scripts/custom_code.py"": 0.0005917549133300781,
            ""load scripts/img2imgalt.py"": 0.00019502639770507812,
            ""load scripts/loopback.py"": 0.00010895729064941406,
            ""load scripts/outpainting_mk_2.py"": 0.00012350082397460938,
            ""load scripts/poor_mans_outpainting.py"": 8.249282836914062e-05,
            ""load scripts/postprocessing_codeformer.py"": 7.224082946777344e-05,
            ""load scripts/postprocessing_gfpgan.py"": 6.318092346191406e-05,
            ""load scripts/postprocessing_upscale.py"": 0.00011491775512695312,
            ""load scripts/prompt_matrix.py"": 8.20159912109375e-05,
            ""load scripts/prompts_from_file.py"": 0.0001304149627685547,
            ""load scripts/sd_upscale.py"": 7.557868957519531e-05,
            ""load scripts/xyz_grid.py"": 0.0006914138793945312,
            ""load scripts/ldsr_model.py"": 0.021519184112548828,
            ""load scripts/lora_script.py"": 0.05590462684631348,
            ""load scripts/scunet_model.py"": 0.00992441177368164,
            ""load scripts/swinir_model.py"": 0.008924245834350586,
            ""load scripts/hotkey_config.py"": 0.0006728172302246094,
            ""load scripts/extra_options_section.py"": 0.0006744861602783203,
            ""load scripts/hypertile_script.py"": 0.017293930053710938,
            ""load scripts/postprocessing_autosized_crop.py"": 0.00045418739318847656,
            ""load scripts/postprocessing_caption.py"": 0.00043702125549316406,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.00041174888610839844,
            ""load scripts/postprocessing_focal_crop.py"": 0.0007452964782714844,
            ""load scripts/postprocessing_split_oversized.py"": 0.0003840923309326172,
            ""load scripts/soft_inpainting.py"": 0.00027942657470703125,
            ""load scripts/__init__.py"": 0.00014495849609375,
            ""load scripts/api.py"": 0.2062222957611084,
            ""load scripts/main.py"": 0.02004265785217285,
            ""load scripts/comments.py"": 0.008637189865112305,
            ""load scripts/refiner.py"": 0.00034928321838378906,
            ""load scripts/sampler.py"": 0.0004024505615234375,
            ""load scripts/seed.py"": 0.00018310546875,
            ""load scripts"": 0.3559587001800537,
            ""load upscalers"": 0.0018105506896972656,
            ""refresh VAE"": 0.00035762786865234375,
            ""refresh textual inversion templates"": 2.1696090698242188e-05,
            ""scripts list_optimizers"": 0.00014162063598632812,
            ""scripts list_unets"": 7.867813110351562e-06,
            ""reload hypernetworks"": 0.0006139278411865234,
            ""initialize extra networks"": 0.011160135269165039,
            ""scripts before_ui_callback"": 0.0008454322814941406,
            ""create ui"": 0.35759758949279785,
            ""gradio launch"": 0.3304779529571533,
            ""add APIs"": 0.037171363830566406,
            ""app_started_callback/lora_script.py"": 0.0001723766326904297,
            ""app_started_callback"": 0.0001742839813232422
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""altair==5.5.0"",
        ""annotated-types==0.7.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""bitsandbytes==0.46.1"",
        ""blendmodes==2022"",
        ""certifi==2025.7.14"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""dadaptation==3.2"",
        ""deprecation==2.1.0"",
        ""diffusers==0.34.0"",
        ""discord-webhook==1.3.1"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""hf-xet==1.1.5"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""kornia_rs==0.1.9"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""nvidia-cublas-cu12==12.9.1.4"",
        ""nvidia-cuda-cupti-cu12==12.9.79"",
        ""nvidia-cuda-nvrtc-cu12==12.9.86"",
        ""nvidia-cuda-runtime-cu12==12.9.79"",
        ""nvidia-cudnn-cu12==9.10.2.21"",
        ""nvidia-cufft-cu12==11.4.1.4"",
        ""nvidia-cufile-cu12==1.14.1.1"",
        ""nvidia-curand-cu12==10.3.10.19"",
        ""nvidia-cusolver-cu12==11.7.5.82"",
        ""nvidia-cusparse-cu12==12.5.10.65"",
        ""nvidia-cusparselt-cu12==0.7.1"",
        ""nvidia-nccl-cu12==2.27.5"",
        ""nvidia-nvjitlink-cu12==12.9.86"",
        ""nvidia-nvshmem-cu12==3.3.9"",
        ""nvidia-nvtx-cu12==12.9.79"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip @ file:///croot/pip_1746204010231/work"",
        ""propcache==0.3.2"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydantic_core==2.33.2"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytorch-triton==3.4.0+gitae848267"",
        ""pytorch_optimizer==3.4.0"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.26.0"",
        ""safetensors==0.5.3"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.17"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""torch==2.9.0.dev20250712+cu129"",
        ""torchaudio==2.8.0.dev20250713+cu129"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.24.0.dev20250713+cu129"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.53.2"",
        ""triton==3.3.1"",
        ""typing-inspection==0.4.1"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""xformers==0.0.31.post1"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
Here's the full log about this issue


*** Error interrogating
    Traceback (most recent call last):
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 194, in interrogate
        caption = self.generate_caption(pil_image)
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 181, in generate_caption
        caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)
      File ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py"", line 156, in generate
        outputs = self.text_decoder.generate(input_ids=input_ids,
      File ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1962, in __getattr__
        raise AttributeError(
    AttributeError: 'BertLMHeadModel' object has no attribute 'generate'
```

### Additional information

_No response_",bug attributeerror bertlmheadmodel object attribute generate checklist issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened tried run blip image caption data preprocess cannot run successfully steps reproduce problem select tab extras batch directory fill input dir output dir select caption blip happened repositories blip models blip py function called generate class bertlmheadmodel indeed method called modules interrogate py line browsers use access ui response sysinfo platform linux generic x glibc python version v commit c ae bd abdf eda b e git status master n origin master n n n git add n git restore n modules launch utils py n webui user sh n webui sh n n n git add n tdata n n git add git commit script path home matt documents stable diffusion webui data path home matt documents stable diffusion webui extensions dir home matt documents stable diffusion webui extensions checksum e bff f cfe f f e b af b dbd cace e aa cb fd commandline launch py disable safe unpickle torch env info torch version debug build false cuda compiled version gcc version ubuntu ubuntu clang version null cmake version version os ubuntu lts x libc version glibc python version main jun gcc bit runtime python platform linux generic x glibc cuda available true cuda runtime version cuda module loading lazy nvidia driver version nvidia gpu models gpu nvidia geforce rtx cudnn version probably one following usr local cuda targets x linux lib libcudnn usr local cuda targets x linux lib libcudnn adv infer usr local cuda targets x linux lib libcudnn adv train usr local cuda targets x linux lib libcudnn cnn infer usr local cuda targets x linux lib libcudnn cnn train usr local cuda targets x linux lib libcudnn ops infer usr local cuda targets x linux lib libcudnn ops train usr local cuda targets x linux lib libcudnn usr local cuda targets x linux lib libcudnn adv infer usr local cuda targets x linux lib libcudnn adv train usr local cuda targets x linux lib libcudnn cnn infer usr local cuda targets x linux lib libcudnn cnn train usr local cuda targets x linux lib libcudnn ops infer usr local cuda targets x linux lib libcudnn ops train xpu available false pip version pip pip packages numpy nvidia cublas cu nvidia cuda cupti cu nvidia cuda nvrtc cu nvidia cuda runtime cu nvidia cudnn cu nvidia cufft cu nvidia curand cu nvidia cusolver cu nvidia cusparse cu nvidia cusparselt cu nvidia nccl cu nvidia nvjitlink cu nvidia nvtx cu open clip torch pytorch lightning pytorch optimizer pytorch triton gitae torch dev cu torchaudio dev cu torchdiffeq torchmetrics torchsde torchvision dev cu triton conda packages numpy pypi pypi nvidia cublas cu pypi pypi nvidia cuda cupti cu pypi pypi nvidia cuda nvrtc cu pypi pypi nvidia cuda runtime cu pypi pypi nvidia cudnn cu pypi pypi nvidia cufft cu pypi pypi nvidia curand cu pypi pypi nvidia cusolver cu pypi pypi nvidia cusparse cu pypi pypi nvidia cusparselt cu pypi pypi nvidia nccl cu pypi pypi nvidia nvjitlink cu pypi pypi nvidia nvtx cu pypi pypi open clip torch pypi pypi pytorch lightning pypi pypi pytorch optimizer pypi pypi pytorch triton gitae pypi pypi torch dev cu pypi pypi torchaudio dev cu pypi pypi torchdiffeq pypi pypi torchmetrics pypi pypi torchsde pypi pypi torchvision dev cu pypi pypi triton pypi pypi hip compiled version n hip runtime version n miopen runtime version n caching allocator config xnnpack available true cpu info x cpu bit bit address sizes bits physical bits virtual byte order little endian cpu line cpu list genuineintel model name intel r core tm ultra k cpu socket cpu scaling mhz cpu max mhz cpu min mhz bogomips flags fpu vme de pse tsc msr pae mce cx apic sep mtrr pge mca cmov pat pse clflush dts acpi mmx fxsr sse sse ss ht tm pbe syscall nx pdpe gb rdtscp lm constant tsc art arch perfmon pebs bts rep good nopl xtopology nonstop tsc cpuid aperfmperf tsc known freq pni pclmulqdq dtes monitor ds cpl vmx smx est tm ssse sdbg fma cx xtpr pdcm pcid sse sse x apic movbe popcnt tsc deadline timer aes xsave avx f c rdrand lahf lm abm dnowprefetch cpuid fault ssbd ibrs ibpb stibp ibrs enhanced tpr shadow flexpriority ept vpid ept ad fsgsbase tsc adjust bmi avx smep bmi erms invpcid rdt rdseed adx smap clflushopt clwb intel pt sha ni xsaveopt xsavec xgetbv xsaves split lock detect user shstk avx vnni lam wbnoinvd dtherm ida arat pln pts hwp hwp notify hwp act window hwp epp hwp pkg req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid bus lock detect movdiri movdir b fsrm md clear serialize arch lbr ibt flush l arch capabilities vt x l kib instances l mib instances l mib instances l mib instance numa numa node cpu vulnerability gather data sampling affected vulnerability ghostwrite affected vulnerability indirect target selection affected vulnerability itlb multihit affected vulnerability l tf affected vulnerability mds affected vulnerability meltdown affected vulnerability mmio stale data affected vulnerability reg file data sampling affected vulnerability retbleed affected vulnerability spec rstack overflow affected vulnerability spec store bypass mitigation speculative store bypass disabled via prctl vulnerability spectre v mitigation usercopy swapgs barriers user pointer sanitization vulnerability spectre v mitigation enhanced automatic ibrs ibpb conditional pbrsb eibrs affected bhi bhi dis vulnerability srbds affected vulnerability tsx async abort affected exceptions exception bertlmheadmodel object attribute generate traceback home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror exception bertlmheadmodel object attribute generate traceback home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror exception bertlmheadmodel object attribute generate traceback home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror exception bertlmheadmodel object attribute generate traceback home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror exception bertlmheadmodel object attribute generate traceback home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror cpu model x count logical count physical ram total gb used gb free gb active gb inactive gb buffers mb cached gb shared gb extensions name sd dreambooth extension path home matt documents stable diffusion webui extensions sd dreambooth extension commit bae e c b fe bb ceffab f dfb branch main remote inactive extensions name sd webui blip path home matt documents stable diffusion webui extensions sd webui blip commit ca c ac f fc f e e e edd c f branch main remote environment commandline args disable safe unpickle git git gradio analytics enabled false config ldsr steps ldsr cached false scunet tile scunet tile overlap swin tile swin tile overlap swin torch compile false hypertile enable unet false hypertile enable unet secondpass false hypertile max depth unet hypertile max tile unet hypertile swap size unet hypertile enable vae false hypertile max depth vae hypertile max tile vae hypertile swap size vae sd model checkpoint v pruned emaonly safetensors ce sd checkpoint hash ce b acaa ec eafe f ced bee f fa fa disabled extensions sd webui blip disable extensions none startup total records initial startup prepare environment checks e prepare environment git version info prepare environment install torch prepare environment torch gpu test prepare environment clone repositores prepare environment install requirements prepare environment run extensions installers sd dreambooth extension prepare environment run extensions installers prepare environment launcher import torch import gradio setup paths import ldm import sgm e initialize shared imports opts onchange setup sd model e setup codeformer setup gfpgan set samplers e list extensions restore config state file e list sd models list localizations e load scripts custom code py load scripts img imgalt py load scripts loopback py load scripts outpainting mk py load scripts poor mans outpainting py e load scripts postprocessing codeformer py e load scripts postprocessing gfpgan py e load scripts postprocessing upscale py load scripts prompt matrix py e load scripts prompts file py load scripts sd upscale py e load scripts xyz grid py load scripts ldsr model py load scripts lora script py load scripts scunet model py load scripts swinir model py load scripts hotkey config py load scripts extra options section py load scripts hypertile script py load scripts postprocessing autosized crop py load scripts postprocessing caption py load scripts postprocessing create flipped copies py load scripts postprocessing focal crop py load scripts postprocessing split oversized py load scripts soft inpainting py load scripts init py load scripts api py load scripts main py load scripts comments py load scripts refiner py load scripts sampler py load scripts seed py load scripts load upscalers refresh vae refresh textual inversion templates e scripts list optimizers scripts list unets e reload hypernetworks initialize extra networks scripts ui callback create ui gradio launch add apis app started callback lora script py app started callback packages absl py accelerate aenum aiofiles aiohappyeyeballs aio aiosignal altair annotated types antlr python runtime anyio async timeout attrs bitsandbytes blendmodes certifi charset normalizer clean fid click clip contourpy cycler dadaptation deprecation diffusers discord webhook diskcache einops exceptiongroup facexlib fastapi ffmpy filelock filterpy fonttools frozenlist fsspec ftfy gitdb gitpython gradio gradio client grpcio h hf xet huggingface hub idna imageio importlib metadata importlib resources inflection jinja jsonmerge jsonschema jsonschema specifications kiwisolver kornia kornia rs lark lazy loader lightning utilities llvmlite markdown markupsafe matplotlib mpmath multidict narwhals networkx numba numpy nvidia cublas cu nvidia cuda cupti cu nvidia cuda nvrtc cu nvidia cuda runtime cu nvidia cudnn cu nvidia cufft cu nvidia cufile cu nvidia curand cu nvidia cusolver cu nvidia cusparse cu nvidia cusparselt cu nvidia nccl cu nvidia nvjitlink cu nvidia nvshmem cu nvidia nvtx cu omegaconf open clip torch opencv python orjson packaging pandas piexif pillow pillow avif plugin pip file croot pip work propcache protobuf psutil pydantic pydantic core pydub pyparsing python dateutil post python multipart pytorch lightning pytorch triton gitae pytorch optimizer pytz pywavelets pyyaml referencing regex requests resize right rpds py safetensors scikit image scipy semantic version sentencepiece setuptools six smmap sniffio spandrel spandrel extra arches starlette sympy tensorboard tensorboard data server tifffile timm tokenizers tomesd torch dev cu torchaudio dev cu torchdiffeq torchmetrics torchsde torchvision dev cu tqdm trampoline transformers triton typing inspection typing extensions tzdata urllib uvicorn wcwidth websockets werkzeug wheel xformers post yarl zipp console logs shell full log issue error interrogating traceback recent call last file home matt documents stable diffusion webui modules interrogate py line interrogate caption self generate caption pil image file home matt documents stable diffusion webui modules interrogate py line generate caption caption self blip model generate gpu image sample false num beams shared opts interrogate clip num beams min length shared opts interrogate clip min length max length shared opts interrogate clip max length file home matt documents stable diffusion webui repositories blip models blip py line generate outputs self text decoder generate input ids input ids file home matt miniconda envs webui lib python site packages torch nn modules module py line getattr raise attributeerror attributeerror bertlmheadmodel object attribute generate additional information response
auto1111_webui,comment,17061,,"same here 
```
from caption import caption
caption(imgpth,batch_size=50)
```

It nags you about this first before proceeding to crap the bed with the error posted by OP:
```
BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
```",2025-09-05T01:01:05Z,openSourcerer9000,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17061#issuecomment-3256640049,"same here 
```
from caption import caption
caption(imgpth,batch_size=50)
```

It nags you about this first before proceeding to crap the bed with the error posted by OP:
```
BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
```",caption import caption caption imgpth batch size nags first proceeding crap bed error posted op bertlmheadmodel generative capabilities prepare inputs generation explicitly defined however directly inherit generationmixin v onwards pretrainedmodel inherit generationmixin model lose ability call generate related functions using trust remote code true get rid warning loading model auto class see owner model architecture code please modify model class inherits generationmixin pretrainedmodel otherwise get exception owner model architecture class please contact model code owner update
auto1111_webui,issue,17060,[Bug]: SDXL Hires. fix Fails with OOM (Out Of Memory) on Intel Arc (DirectML),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When generating SDXL images with Hires. fix on an Intel Arc A770 (DirectML) GPU, the generation frequently stops mid-process, usually at the Hires. fix stage (around 50-70% progress). This happens even with `--lowvram` and `--no-half-vae` enabled, and at relatively low base resolutions like 512x512. The VRAM usage shown by Task Manager often indicates around 3GB used when it stops, while the console shows Out Of Memory (OOM) errors (e.g., ""Could not allocate tensor..."") or sometimes a NaN error with automatic 32-bit VAE retry. The issue is inconsistent; sometimes a generation succeeds, but subsequent attempts often fail.

### Steps to reproduce the problem

1.  **Hardware:** Intel Arc A770 16GB VRAM, Windows 11.
2.  **Web UI Setup:**
    * Using Automatic1111 stable-diffusion-webui (latest `git pull`).
    * `webui-user.bat` includes: `--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae`
    * Python 3.10.9, Torch 2.0.0+cpu (as shown in startup log, despite `--reinstall-torch` attempts).
3.  **Model:** Use an SDXL 1.0 base model (e.g., `novaOrangeXL_reV10.safetensors` or `waiNSFWIllustrious_v140.safetensors`).
4.  **Steps:**
    a.  Launch Web UI using `webui-user.bat`.
    b.  Go to the `txt2img` tab.
    c.  Enter a simple prompt (e.g., ""masterpiece, best quality, beautiful girl, clear eyes"").
    d.  Set image dimensions to **Width: 512, Height: 512**.
    e.  Enable **Hires. fix**.
    f.  Set **Upscale by: 2**.
    g.  Set **Hires steps: 24** (or similar, default often used).
    h.  Set **Denoising strength: 0.7** (or similar).
    i.  Set **Sampler: Euler a** (or any other, issue persists).
    j.  Click **""Generate""**.
5.  **Observe:** The generation often stops at around 50-70% progress (Hires. fix stage). The console shows `RuntimeError: Could not allocate tensor...` or sometimes prints ""A tensor with all NaNs was produced in VAE."" before converting to float32 and then potentially still failing with OOM.
6.  **Inconsistency:** If the first generation succeeds, attempting a second generation immediately after often results in a failure with the same errors. Restarting the Web UI process (closing and relaunching `webui-user.bat`) usually allows for one successful generation again.

### What should have happened?

The image generation, including the Hires. fix stage, should complete successfully without encountering Out Of Memory errors or NaN issues. The process should be stable, allowing for continuous image generation without requiring a Web UI restart after each successful image. Given the 16GB VRAM on the Intel Arc A770, it should be capable of consistently handling SDXL Hires. fix up to 1024x1024 (or at least 896x896) without crashing or inconsistent behavior, especially with `--lowvram` and `--no-half-vae` enabled.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.26100-SP0"",
    ""Python"": ""3.10.9"",
    ""Version"": ""v1.10.1-amd-39-g6d85a7df"",
    ""Commit"": ""6d85a7dfa4977ae4eece9cbbab4725123833be14"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   launch.py\n\tmodified:   webui-user.bat\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""D:\\sd_directml"",
    ""Data path"": ""D:\\sd_directml"",
    ""Extensions dir"": ""D:\\sd_directml\\extensions"",
    ""Checksum"": ""ba7a852b3fbd4f24b5aad10e0a0c032445127e2e79154b9925ee223e4c5c4b70"",
    ""Commandline"": [
        ""launch.py"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.0.0+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": null,
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Home"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.26100-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.0.0"",
            ""torch-directml==0.2.0.dev230426"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.15.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=2592"",
            ""DeviceID=CPU0"",
            ""Family=205"",
            ""L2CacheSize=3072"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=2592"",
            ""Name=11th Gen Intel(R) Core(TM) i5-11400 @ 2.60GHz"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": """",
            ""traceback"": [
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 849, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""D:\\sd_directml\\extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py, line 59, processing_process_images_hijack"",
                    ""return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1083, process_images_inner"",
                    ""samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1457, sample"",
                    ""return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1549, sample_hr_pass"",
                    ""samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, sample_img2img"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_common.py, line 272, launch_sampling"",
                    ""return func()""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, <lambda>"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py, line 115, decorate_context"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\sampling.py, line 145, sample_euler_ancestral"",
                    ""denoised = model(x, sigmas[i] * s_in, **extra_args)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_cfg_denoiser.py, line 268, forward"",
                    ""x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 112, forward"",
                    ""eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 138, get_eps"",
                    ""return self.inner_model.apply_model(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_models_xl.py, line 43, apply_model"",
                    ""return self.model(x, t, cond)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 22, <lambda>"",
                    ""setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 34, __call__"",
                    ""return self.__sub_func(self.__orig_func, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_unet.py, line 50, apply_model"",
                    ""result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\wrappers.py, line 28, forward"",
                    ""return self.diffusion_model(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_unet.py, line 91, UNetModel_forward"",
                    ""return original_forward(self, x, timesteps, context, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 993, forward"",
                    ""h = module(h, emb, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1538, _call_impl"",
                    ""result = forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 100, forward"",
                    ""x = layer(x, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 627, forward"",
                    ""x = block(x, context=context[i])""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 459, forward"",
                    ""return checkpoint(""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\util.py, line 167, checkpoint"",
                    ""return func(*inputs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 467, _forward"",
                    ""self.attn1(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_optimizations.py, line 547, scaled_dot_product_attention_forward"",
                    ""hidden_states = torch.nn.functional.scaled_dot_product_attention(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 167 Stepping 1, GenuineIntel"",
        ""count logical"": 12,
        ""count physical"": 6
    },
    ""RAM"": {
        ""total"": ""16GB"",
        ""used"": ""10GB"",
        ""free"": ""6GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd-webui-animatediff"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-animatediff"",
            ""commit"": ""a88e88912bcbae0531caccfc50fd639f6ea83fd0"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/continue-revolution/sd-webui-animatediff""
        },
        {
            ""name"": ""sd-webui-controlnet"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-controlnet"",
            ""commit"": ""56cec5b2958edf3b1807b7e7b2b1b5186dbd2f81"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Mikubill/sd-webui-controlnet""
        },
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""D:\\sd_directml\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""http://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""novaOrangeXL_reV10.safetensors [2e13269995]"",
        ""sd_checkpoint_hash"": ""2e13269995e4c3e1e1edb7d45e815dc311f770558ee5a31f248807f5d598e964"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""onnx_cached_models_path"": ""D:\\sd_directml\\models\\ONNX\\cache"",
        ""onnx_temp_dir"": ""D:\\sd_directml\\models\\ONNX\\temp"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""onnx_enable"": false,
        ""diffusers_pipeline"": ""ONNX Stable Diffusion"",
        ""diffusers_vae_upcast"": ""default"",
        ""onnx_execution_provider"": ""CUDAExecutionProvider"",
        ""onnx_cache_converted"": true,
        ""olive_enable"": false,
        ""olive_submodels"": [],
        ""olive_float16"": true,
        ""olive_vae_encoder_float32"": false,
        ""olive_static_dims"": true,
        ""olive_cache_optimized"": true,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""directml_memory_provider"": ""Performance Counter"",
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""sdxlVAE_sdxlVAE.safetensors"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""animatediff_model_path"": """",
        ""animatediff_default_save_formats"": [
            ""GIF"",
            ""PNG""
        ],
        ""animatediff_save_to_custom"": true,
        ""animatediff_frame_extract_path"": """",
        ""animatediff_frame_extract_remove"": false,
        ""animatediff_default_frame_extract_method"": ""ffmpeg"",
        ""animatediff_optimize_gif_palette"": false,
        ""animatediff_optimize_gif_gifsicle"": false,
        ""animatediff_mp4_crf"": 23,
        ""animatediff_mp4_preset"": """",
        ""animatediff_mp4_tune"": """",
        ""animatediff_webp_quality"": 80,
        ""animatediff_webp_lossless"": false,
        ""animatediff_s3_enable"": false,
        ""animatediff_s3_host"": """",
        ""animatediff_s3_port"": """",
        ""animatediff_s3_access_key"": """",
        ""animatediff_s3_secret_key"": """",
        ""animatediff_s3_storge_bucket"": """",
        ""control_net_detectedmap_dir"": ""detected_maps"",
        ""control_net_models_path"": """",
        ""control_net_modules_path"": """",
        ""control_net_unit_count"": 3,
        ""control_net_model_cache_size"": 2,
        ""control_net_inpaint_blur_sigma"": 7,
        ""control_net_no_detectmap"": false,
        ""control_net_detectmap_autosaving"": false,
        ""control_net_allow_script_control"": false,
        ""control_net_sync_field_args"": true,
        ""controlnet_show_batch_images_in_ui"": false,
        ""controlnet_increment_seed_during_batch"": false,
        ""controlnet_disable_openpose_edit"": false,
        ""controlnet_disable_photopea_edit"": false,
        ""controlnet_photopea_warning"": true,
        ""controlnet_ignore_noninpaint_mask"": false,
        ""controlnet_clip_detector_on_cpu"": false,
        ""controlnet_control_type_dropdown"": false,
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""D:\\sd_directml\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": [],
        ""prioritized_callbacks_cfg_denoiser"": [],
        ""prioritized_callbacks_after_component"": [],
        ""prioritized_callbacks_on_reload"": [],
        ""prioritized_callbacks_script_before_process_batch"": [],
        ""prioritized_callbacks_script_postprocess"": [],
        ""prioritized_callbacks_script_postprocess_batch"": [],
        ""prioritized_callbacks_script_postprocess_batch_list"": [],
        ""prioritized_callbacks_script_postprocess_image"": []
    },
    ""Startup"": {
        ""total"": 117.79217195510864,
        ""records"": {
            ""launcher"": 35.03606104850769,
            ""import torch"": 21.190768241882324,
            ""import gradio"": 1.6846561431884766,
            ""setup paths"": 12.206217765808105,
            ""import ldm"": 0.007937192916870117,
            ""import sgm"": 0.0,
            ""initialize shared"": 2.566276788711548,
            ""other imports"": 0.046120643615722656,
            ""opts onchange"": 0.0010085105895996094,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.002558469772338867,
            ""setup gfpgan"": 0.0189664363861084,
            ""set samplers"": 0.00102996826171875,
            ""list extensions"": 0.0015044212341308594,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.07561135292053223,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.013432025909423828,
            ""load scripts/img2imgalt.py"": 0.0015058517456054688,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0010120868682861328,
            ""load scripts/poor_mans_outpainting.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0010037422180175781,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0017118453979492188,
            ""load scripts/prompts_from_file.py"": 0.0011334419250488281,
            ""load scripts/sd_upscale.py"": 0.0010564327239990234,
            ""load scripts/xyz_grid.py"": 0.001165151596069336,
            ""load scripts/ldsr_model.py"": 1.1645009517669678,
            ""load scripts/lora_script.py"": 0.2477409839630127,
            ""load scripts/scunet_model.py"": 0.041359901428222656,
            ""load scripts/swinir_model.py"": 0.040180206298828125,
            ""load scripts/hotkey_config.py"": 0.0017354488372802734,
            ""load scripts/extra_options_section.py"": 0.0014653205871582031,
            ""load scripts/hypertile_script.py"": 0.08105015754699707,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0012936592102050781,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0015063285827636719,
            ""load scripts/postprocessing_focal_crop.py"": 0.002042531967163086,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009915828704833984,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/animatediff.py"": 0.19388294219970703,
            ""load scripts/animatediff_freeinit.py"": 0.0010075569152832031,
            ""load scripts/animatediff_i2ibatch.py"": 0.0010106563568115234,
            ""load scripts/animatediff_infotext.py"": 0.0,
            ""load scripts/animatediff_infv2v.py"": 0.0011479854583740234,
            ""load scripts/animatediff_latent.py"": 0.0,
            ""load scripts/animatediff_logger.py"": 0.0012199878692626953,
            ""load scripts/animatediff_mm.py"": 0.0,
            ""load scripts/animatediff_output.py"": 0.0,
            ""load scripts/animatediff_prompt.py"": 0.0015058517456054688,
            ""load scripts/animatediff_settings.py"": 0.0,
            ""load scripts/animatediff_ui.py"": 0.0,
            ""load scripts/animatediff_utils.py"": 0.0015609264373779297,
            ""load scripts/animatediff_xyz.py"": 0.0,
            ""load scripts/adapter.py"": 0.002076864242553711,
            ""load scripts/api.py"": 0.3266606330871582,
            ""load scripts/batch_hijack.py"": 0.0015680789947509766,
            ""load scripts/cldm.py"": 0.0026121139526367188,
            ""load scripts/controlnet.py"": 1.2729477882385254,
            ""load scripts/controlnet_diffusers.py"": 0.0010955333709716797,
            ""load scripts/controlnet_lllite.py"": 0.0,
            ""load scripts/controlnet_lora.py"": 0.0,
            ""load scripts/controlnet_model_guess.py"": 0.0015072822570800781,
            ""load scripts/controlnet_sparsectrl.py"": 0.0,
            ""load scripts/controlnet_version.py"": 0.0,
            ""load scripts/enums.py"": 0.0015232563018798828,
            ""load scripts/external_code.py"": 0.0010516643524169922,
            ""load scripts/global_state.py"": 0.0,
            ""load scripts/hook.py"": 0.0010027885437011719,
            ""load scripts/infotext.py"": 0.0,
            ""load scripts/logging.py"": 0.0010135173797607422,
            ""load scripts/lvminthin.py"": 0.0,
            ""load scripts/movie2movie.py"": 0.0,
            ""load scripts/supported_preprocessor.py"": 0.001506805419921875,
            ""load scripts/utils.py"": 0.0011930465698242188,
            ""load scripts/xyz_grid_support.py"": 0.0,
            ""load scripts/tagger.py"": 0.14598941802978516,
            ""load scripts/comments.py"": 0.044586181640625,
            ""load scripts/refiner.py"": 0.0010988712310791016,
            ""load scripts/sampler.py"": 0.0009937286376953125,
            ""load scripts/seed.py"": 0.0015211105346679688,
            ""load scripts"": 3.618171453475952,
            ""load upscalers"": 0.004336118698120117,
            ""refresh VAE"": 0.0010046958923339844,
            ""refresh textual inversion templates"": 0.0010097026824951172,
            ""scripts list_optimizers"": 0.0010306835174560547,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009660720825195312,
            ""initialize extra networks"": 0.0998542308807373,
            ""scripts before_ui_callback"": 0.01022028923034668,
            ""create ui"": 40.41819214820862,
            ""gradio launch"": 0.772036075592041,
            ""add APIs"": 0.019764184951782227,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/api.py"": 0.003812551498413086,
            ""app_started_callback/tagger.py"": 0.003056764602661133,
            ""app_started_callback"": 0.006869316101074219
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""addict==2.4.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""albumentations==1.4.3"",
        ""alembic==1.16.4"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""basicsr==1.4.2"",
        ""beautifulsoup4==4.13.4"",
        ""blendmodes==2022"",
        ""certifi==2025.7.9"",
        ""cffi==1.17.1"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""controlnet_aux==0.0.10"",
        ""cssselect2==0.8.0"",
        ""cycler==0.12.1"",
        ""Cython==3.1.2"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""depth_anything @ https://github.com/huchenlei/Depth-Anything/releases/download/v1.0.0/depth_anything-2024.1.22.0-py2.py3-none-any.whl#sha256=26c1d38b8c3c306b4a2197d725a4b989ff65f7ebcf4fb5a96a1b6db7fbd56780"",
        ""depth_anything_v2 @ https://github.com/MackinationsAi/UDAV2-ControlNet/releases/download/v1.0.0/depth_anything_v2-2024.7.1.0-py2.py3-none-any.whl#sha256=6848128867d1f7c7519d88df0f88bfab89100dc5225259c4d7cb90325c308c9f"",
        ""diffusers==0.30.2"",
        ""diskcache==5.6.3"",
        ""dsine @ https://github.com/sdbds/DSINE/releases/download/1.0.2/dsine-2024.3.23-py3-none-any.whl#sha256=b9ea3bacce09f9b3f7fb4fa12471da7e465b2f9a60412711105a9238db280442"",
        ""easydict==1.13"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""future==1.0.0"",
        ""fvcore==0.1.5.post20221221"",
        ""gast==0.6.0"",
        ""gdown==5.2.0"",
        ""geffnet==1.0.2"",
        ""gfpgan @ git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""glob2==0.5"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.3"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""handrefinerportable @ https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl#sha256=1e6c702905919f4c49bcb2db7b20d334e8458a7555cd57630600584ec38ca6a9"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""insightface @ https://github.com/Gourieff/Assets/raw/main/Insightface/insightface-0.7.3-cp310-cp310-win_amd64.whl#sha256=47aa0571b2aadd8545d4bc7615dfbc374c10180c283b7ac65058fcb41ed4df86"",
        ""iopath==0.1.9"",
        ""jax==0.6.2"",
        ""jaxlib==0.6.2"",
        ""Jinja2==3.1.6"",
        ""joblib==1.5.1"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""lmdb==1.7.2"",
        ""lpips==0.1.4"",
        ""lxml==6.0.0"",
        ""Mako==1.3.10"",
        ""manifold3d==3.1.1"",
        ""mapbox_earcut==1.0.3"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""mediapipe==0.10.21"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""namex==0.1.0"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""olive-ai==0.9.1"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnx-ir==0.1.4"",
        ""onnxruntime==1.22.1"",
        ""onnxscript==0.3.2"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optimum==1.26.1"",
        ""optree==0.16.0"",
        ""optuna==4.4.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""platformdirs==4.3.8"",
        ""portalocker==3.2.0"",
        ""prettytable==3.16.0"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pycollada==0.9.2"",
        ""pycparser==2.22"",
        ""pydantic==1.10.17"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""PySocks==1.7.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""pywin32==310"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""reportlab==4.4.2"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.26.0"",
        ""rtree==1.4.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.25.2"",
        ""scikit-learn==1.7.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""shapely==2.1.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""sounddevice==0.5.2"",
        ""soupsieve==2.7"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.41"",
        ""starlette==0.26.1"",
        ""svg.path==7.0"",
        ""svglib==1.5.1"",
        ""sympy==1.14.0"",
        ""tabulate==0.9.0"",
        ""tb-nightly==2.20.0a20250711"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.5.10"",
        ""timm==0.9.5"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.0.0"",
        ""torch-directml==0.2.0.dev230426"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.15.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.7.0"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
venv ""D:\sd_directml\venv\Scripts\Python.exe""
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Commit hash: 6d85a7dfa4977ae4eece9cbbab4725123833be14
Installing requirements

loading WD14-tagger reqs from D:\sd_directml\extensions\stable-diffusion-webui-wd14-tagger\requirements.txt
Checking WD14-tagger requirements.

Launching Web UI with arguments: --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae
2025-07-13 11:08:42.939440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-13 11:08:45.640065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ONNX failed to initialize: Failed to import optimum.onnxruntime.modeling_diffusion because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
==============================================================================
You are running torch 2.0.0+cpu.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
ControlNet preprocessor location: D:\sd_directml\extensions\sd-webui-controlnet\annotator\downloads
2025-07-13 11:08:56,379 - ControlNet - INFO - ControlNet v1.1.455
== WD14 tagger /gpu:0, uname_result(system='Windows', node='DESKTOP-GBPLTQV', release='10', version='10.0.26100', machine='AMD64') ==
Loading weights [2e13269995] from D:\sd_directml\models\Stable-diffusion\novaOrangeXL_reV10.safetensors
Creating model from config: D:\sd_directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
Model loaded in 36.5s (load weights from disk: 0.6s, create model: 0.9s, apply weights to model: 25.6s, apply half(): 0.3s, apply dtype to VAE: 0.1s, load VAE: 3.2s, load weights from state dict: 0.2s, move model to device: 0.3s, hijack: 1.0s, load textual inversion embeddings: 1.9s, calculate empty prompt: 2.3s).
2025-07-13 11:09:36,520 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 117.8s (launcher: 35.0s, import torch: 21.2s, import gradio: 1.7s, setup paths: 12.2s, initialize shared: 2.6s, load scripts: 3.6s, create ui: 40.4s, gradio launch: 0.8s).
Couldn't find VAE named sdxl_vae.safetensors; using None instead
Restoring base VAE
Applying attention optimization: sdp... done.
VAE weights loaded.
100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [07:00<00:00, 15.56s/it]
  0%|                                                                                           | 0/27 [00:00<?, ?it/s]
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
VAE weights loaded.
*** Error completing request
*** Arguments: ('task(tblrxw7xt728m2a)', <gradio.routes.Request object at 0x00000142C4CDE1D0>, 'beautiful girl, masterpiece, best quality, ultra-detailed face,beautiful eyes,Well-arranged eyes,\nshort layered bob haircut,purple eyes, slightly upturned nose,(smile:0.5),small nose,\ndeep violet hair with mint green gradient tips, smooth shiny hair, slightly tousled, detailed hair strands, natural skin texture,\nslim yet curvy body, slender waist, wide hips, hourglass figure, youthful proportions,\nnatural-looking large breasts, C-cup, smooth cleavage,\nlong legs, plump thighs, soft skin, firm hips, well-defined back curve, shapely arms, elegant neck,\nrealistic yet anime-inspired body proportions,height around 165cm,\nwhite dress shirt, glossy slightly,sleeves casually rolled up to elbows,\ntop buttons undone, teal necktie, loosely tied, natural drape,\nshort pleated skirt, (beige and brown plaid pattern), uniform style, folded waistband,\nthick fabric with sharp pleats, natural shadows, realistic light reflection,\nschool uniform inspired but casually worn,\n,on the train, train interior, front view of front seat,(looking away:1.4) ,\n(sitting:1.3),(skirt:1.3), show off panties, light blue panties,\nasakura toru, <lora:Asakura_Toru:1.2>', 'bad anatomy, poorly drawn face, asymmetrical eyes, extra hair strands, blurry face, lowres, jpeg artifacts,\nwrong hair color, wrong hairstyle, deformed, monochrome, sketch, photo\n', [], 1, 1, 5, 1056, 904, True, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['VAE: sdxl_vae.safetensors'], 0, 27, 'Euler a', 'Karras', False, '', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x00000142C4DFBC40>, ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, None, None, False, None, None, False, None, None, False, 50) {}
    Traceback (most recent call last):
      File ""D:\sd_directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\sd_directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\sd_directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""D:\sd_directml\extensions\sd-webui-controlnet\scripts\batch_hijack.py"", line 59, in processing_process_images_hijack
        return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)
      File ""D:\sd_directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1457, in sample
        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1549, in sample_hr_pass
        samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 145, in sample_euler_ancestral
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_samplers_cfg_denoiser.py"", line 268, in forward
        x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1538, in _call_impl
        result = forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 100, in forward
        x = layer(x, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 627, in forward
        x = block(x, context=context[i])
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 459, in forward
        return checkpoint(
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 467, in _forward
        self.attn1(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_optimizations.py"", line 547, in scaled_dot_product_attention_forward
        hidden_states = torch.nn.functional.scaled_dot_product_attention(
    RuntimeError

---
```

### Additional information

Operating System: Windows 11 Insider Preview (Build 26100). I am aware this is a pre-release build and might be a contributing factor to the instability.

GPU Driver: Intel Graphics Driver version 32.0.101.6913. I regularly update my drivers to the latest available.

Problem Summary: The issue consistently occurs during the Highres. fix step of image generation (specifically with SDXL models), leading to a RuntimeError. This happens when upscaling with a Denoising strength of 0.7 or higher, even at relatively low base resolutions 

VRAM Management: I have confirmed that the ""VRAM usage polls per second"" setting was at 8 and will change it to 0 as suggested.

Commandline Args: I've identified that my webui-user.bat file contains duplicate COMMANDLINE_ARGS entries and will correct this.

PyTorch-DirectML Version: My torch-directml version is 0.2.0.dev230426, which seems to be an older development version. I plan to attempt to update it.

Extensions: While the provided log was generated with extensions active, the issue has also persisted when --disable-all-extensions was enabled (I will re-test if needed).

System RAM: My system has 16GB of RAM, with approximately 12GB typically in use before starting the WebUI. I make an effort to close other applications to free up RAM during image generation.",2025-07-13T02:48:38Z,RUTO1920,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17060,"[Bug]: SDXL Hires. fix Fails with OOM (Out Of Memory) on Intel Arc (DirectML) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When generating SDXL images with Hires. fix on an Intel Arc A770 (DirectML) GPU, the generation frequently stops mid-process, usually at the Hires. fix stage (around 50-70% progress). This happens even with `--lowvram` and `--no-half-vae` enabled, and at relatively low base resolutions like 512x512. The VRAM usage shown by Task Manager often indicates around 3GB used when it stops, while the console shows Out Of Memory (OOM) errors (e.g., ""Could not allocate tensor..."") or sometimes a NaN error with automatic 32-bit VAE retry. The issue is inconsistent; sometimes a generation succeeds, but subsequent attempts often fail.

### Steps to reproduce the problem

1.  **Hardware:** Intel Arc A770 16GB VRAM, Windows 11.
2.  **Web UI Setup:**
    * Using Automatic1111 stable-diffusion-webui (latest `git pull`).
    * `webui-user.bat` includes: `--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae`
    * Python 3.10.9, Torch 2.0.0+cpu (as shown in startup log, despite `--reinstall-torch` attempts).
3.  **Model:** Use an SDXL 1.0 base model (e.g., `novaOrangeXL_reV10.safetensors` or `waiNSFWIllustrious_v140.safetensors`).
4.  **Steps:**
    a.  Launch Web UI using `webui-user.bat`.
    b.  Go to the `txt2img` tab.
    c.  Enter a simple prompt (e.g., ""masterpiece, best quality, beautiful girl, clear eyes"").
    d.  Set image dimensions to **Width: 512, Height: 512**.
    e.  Enable **Hires. fix**.
    f.  Set **Upscale by: 2**.
    g.  Set **Hires steps: 24** (or similar, default often used).
    h.  Set **Denoising strength: 0.7** (or similar).
    i.  Set **Sampler: Euler a** (or any other, issue persists).
    j.  Click **""Generate""**.
5.  **Observe:** The generation often stops at around 50-70% progress (Hires. fix stage). The console shows `RuntimeError: Could not allocate tensor...` or sometimes prints ""A tensor with all NaNs was produced in VAE."" before converting to float32 and then potentially still failing with OOM.
6.  **Inconsistency:** If the first generation succeeds, attempting a second generation immediately after often results in a failure with the same errors. Restarting the Web UI process (closing and relaunching `webui-user.bat`) usually allows for one successful generation again.

### What should have happened?

The image generation, including the Hires. fix stage, should complete successfully without encountering Out Of Memory errors or NaN issues. The process should be stable, allowing for continuous image generation without requiring a Web UI restart after each successful image. Given the 16GB VRAM on the Intel Arc A770, it should be capable of consistently handling SDXL Hires. fix up to 1024x1024 (or at least 896x896) without crashing or inconsistent behavior, especially with `--lowvram` and `--no-half-vae` enabled.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.26100-SP0"",
    ""Python"": ""3.10.9"",
    ""Version"": ""v1.10.1-amd-39-g6d85a7df"",
    ""Commit"": ""6d85a7dfa4977ae4eece9cbbab4725123833be14"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   launch.py\n\tmodified:   webui-user.bat\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""D:\\sd_directml"",
    ""Data path"": ""D:\\sd_directml"",
    ""Extensions dir"": ""D:\\sd_directml\\extensions"",
    ""Checksum"": ""ba7a852b3fbd4f24b5aad10e0a0c032445127e2e79154b9925ee223e4c5c4b70"",
    ""Commandline"": [
        ""launch.py"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.0.0+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": null,
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Home"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.26100-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.0.0"",
            ""torch-directml==0.2.0.dev230426"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.15.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=2592"",
            ""DeviceID=CPU0"",
            ""Family=205"",
            ""L2CacheSize=3072"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=2592"",
            ""Name=11th Gen Intel(R) Core(TM) i5-11400 @ 2.60GHz"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": """",
            ""traceback"": [
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 849, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""D:\\sd_directml\\extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py, line 59, processing_process_images_hijack"",
                    ""return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1083, process_images_inner"",
                    ""samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1457, sample"",
                    ""return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1549, sample_hr_pass"",
                    ""samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, sample_img2img"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_common.py, line 272, launch_sampling"",
                    ""return func()""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, <lambda>"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py, line 115, decorate_context"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\sampling.py, line 145, sample_euler_ancestral"",
                    ""denoised = model(x, sigmas[i] * s_in, **extra_args)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_cfg_denoiser.py, line 268, forward"",
                    ""x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 112, forward"",
                    ""eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 138, get_eps"",
                    ""return self.inner_model.apply_model(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_models_xl.py, line 43, apply_model"",
                    ""return self.model(x, t, cond)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 22, <lambda>"",
                    ""setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 34, __call__"",
                    ""return self.__sub_func(self.__orig_func, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_unet.py, line 50, apply_model"",
                    ""result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\wrappers.py, line 28, forward"",
                    ""return self.diffusion_model(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_unet.py, line 91, UNetModel_forward"",
                    ""return original_forward(self, x, timesteps, context, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 993, forward"",
                    ""h = module(h, emb, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1538, _call_impl"",
                    ""result = forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 100, forward"",
                    ""x = layer(x, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 627, forward"",
                    ""x = block(x, context=context[i])""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 459, forward"",
                    ""return checkpoint(""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\util.py, line 167, checkpoint"",
                    ""return func(*inputs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 467, _forward"",
                    ""self.attn1(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_optimizations.py, line 547, scaled_dot_product_attention_forward"",
                    ""hidden_states = torch.nn.functional.scaled_dot_product_attention(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 167 Stepping 1, GenuineIntel"",
        ""count logical"": 12,
        ""count physical"": 6
    },
    ""RAM"": {
        ""total"": ""16GB"",
        ""used"": ""10GB"",
        ""free"": ""6GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd-webui-animatediff"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-animatediff"",
            ""commit"": ""a88e88912bcbae0531caccfc50fd639f6ea83fd0"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/continue-revolution/sd-webui-animatediff""
        },
        {
            ""name"": ""sd-webui-controlnet"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-controlnet"",
            ""commit"": ""56cec5b2958edf3b1807b7e7b2b1b5186dbd2f81"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Mikubill/sd-webui-controlnet""
        },
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""D:\\sd_directml\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""http://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""novaOrangeXL_reV10.safetensors [2e13269995]"",
        ""sd_checkpoint_hash"": ""2e13269995e4c3e1e1edb7d45e815dc311f770558ee5a31f248807f5d598e964"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""onnx_cached_models_path"": ""D:\\sd_directml\\models\\ONNX\\cache"",
        ""onnx_temp_dir"": ""D:\\sd_directml\\models\\ONNX\\temp"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""onnx_enable"": false,
        ""diffusers_pipeline"": ""ONNX Stable Diffusion"",
        ""diffusers_vae_upcast"": ""default"",
        ""onnx_execution_provider"": ""CUDAExecutionProvider"",
        ""onnx_cache_converted"": true,
        ""olive_enable"": false,
        ""olive_submodels"": [],
        ""olive_float16"": true,
        ""olive_vae_encoder_float32"": false,
        ""olive_static_dims"": true,
        ""olive_cache_optimized"": true,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""directml_memory_provider"": ""Performance Counter"",
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""sdxlVAE_sdxlVAE.safetensors"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""animatediff_model_path"": """",
        ""animatediff_default_save_formats"": [
            ""GIF"",
            ""PNG""
        ],
        ""animatediff_save_to_custom"": true,
        ""animatediff_frame_extract_path"": """",
        ""animatediff_frame_extract_remove"": false,
        ""animatediff_default_frame_extract_method"": ""ffmpeg"",
        ""animatediff_optimize_gif_palette"": false,
        ""animatediff_optimize_gif_gifsicle"": false,
        ""animatediff_mp4_crf"": 23,
        ""animatediff_mp4_preset"": """",
        ""animatediff_mp4_tune"": """",
        ""animatediff_webp_quality"": 80,
        ""animatediff_webp_lossless"": false,
        ""animatediff_s3_enable"": false,
        ""animatediff_s3_host"": """",
        ""animatediff_s3_port"": """",
        ""animatediff_s3_access_key"": """",
        ""animatediff_s3_secret_key"": """",
        ""animatediff_s3_storge_bucket"": """",
        ""control_net_detectedmap_dir"": ""detected_maps"",
        ""control_net_models_path"": """",
        ""control_net_modules_path"": """",
        ""control_net_unit_count"": 3,
        ""control_net_model_cache_size"": 2,
        ""control_net_inpaint_blur_sigma"": 7,
        ""control_net_no_detectmap"": false,
        ""control_net_detectmap_autosaving"": false,
        ""control_net_allow_script_control"": false,
        ""control_net_sync_field_args"": true,
        ""controlnet_show_batch_images_in_ui"": false,
        ""controlnet_increment_seed_during_batch"": false,
        ""controlnet_disable_openpose_edit"": false,
        ""controlnet_disable_photopea_edit"": false,
        ""controlnet_photopea_warning"": true,
        ""controlnet_ignore_noninpaint_mask"": false,
        ""controlnet_clip_detector_on_cpu"": false,
        ""controlnet_control_type_dropdown"": false,
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""D:\\sd_directml\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": [],
        ""prioritized_callbacks_cfg_denoiser"": [],
        ""prioritized_callbacks_after_component"": [],
        ""prioritized_callbacks_on_reload"": [],
        ""prioritized_callbacks_script_before_process_batch"": [],
        ""prioritized_callbacks_script_postprocess"": [],
        ""prioritized_callbacks_script_postprocess_batch"": [],
        ""prioritized_callbacks_script_postprocess_batch_list"": [],
        ""prioritized_callbacks_script_postprocess_image"": []
    },
    ""Startup"": {
        ""total"": 117.79217195510864,
        ""records"": {
            ""launcher"": 35.03606104850769,
            ""import torch"": 21.190768241882324,
            ""import gradio"": 1.6846561431884766,
            ""setup paths"": 12.206217765808105,
            ""import ldm"": 0.007937192916870117,
            ""import sgm"": 0.0,
            ""initialize shared"": 2.566276788711548,
            ""other imports"": 0.046120643615722656,
            ""opts onchange"": 0.0010085105895996094,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.002558469772338867,
            ""setup gfpgan"": 0.0189664363861084,
            ""set samplers"": 0.00102996826171875,
            ""list extensions"": 0.0015044212341308594,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.07561135292053223,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.013432025909423828,
            ""load scripts/img2imgalt.py"": 0.0015058517456054688,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0010120868682861328,
            ""load scripts/poor_mans_outpainting.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0010037422180175781,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0017118453979492188,
            ""load scripts/prompts_from_file.py"": 0.0011334419250488281,
            ""load scripts/sd_upscale.py"": 0.0010564327239990234,
            ""load scripts/xyz_grid.py"": 0.001165151596069336,
            ""load scripts/ldsr_model.py"": 1.1645009517669678,
            ""load scripts/lora_script.py"": 0.2477409839630127,
            ""load scripts/scunet_model.py"": 0.041359901428222656,
            ""load scripts/swinir_model.py"": 0.040180206298828125,
            ""load scripts/hotkey_config.py"": 0.0017354488372802734,
            ""load scripts/extra_options_section.py"": 0.0014653205871582031,
            ""load scripts/hypertile_script.py"": 0.08105015754699707,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0012936592102050781,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0015063285827636719,
            ""load scripts/postprocessing_focal_crop.py"": 0.002042531967163086,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009915828704833984,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/animatediff.py"": 0.19388294219970703,
            ""load scripts/animatediff_freeinit.py"": 0.0010075569152832031,
            ""load scripts/animatediff_i2ibatch.py"": 0.0010106563568115234,
            ""load scripts/animatediff_infotext.py"": 0.0,
            ""load scripts/animatediff_infv2v.py"": 0.0011479854583740234,
            ""load scripts/animatediff_latent.py"": 0.0,
            ""load scripts/animatediff_logger.py"": 0.0012199878692626953,
            ""load scripts/animatediff_mm.py"": 0.0,
            ""load scripts/animatediff_output.py"": 0.0,
            ""load scripts/animatediff_prompt.py"": 0.0015058517456054688,
            ""load scripts/animatediff_settings.py"": 0.0,
            ""load scripts/animatediff_ui.py"": 0.0,
            ""load scripts/animatediff_utils.py"": 0.0015609264373779297,
            ""load scripts/animatediff_xyz.py"": 0.0,
            ""load scripts/adapter.py"": 0.002076864242553711,
            ""load scripts/api.py"": 0.3266606330871582,
            ""load scripts/batch_hijack.py"": 0.0015680789947509766,
            ""load scripts/cldm.py"": 0.0026121139526367188,
            ""load scripts/controlnet.py"": 1.2729477882385254,
            ""load scripts/controlnet_diffusers.py"": 0.0010955333709716797,
            ""load scripts/controlnet_lllite.py"": 0.0,
            ""load scripts/controlnet_lora.py"": 0.0,
            ""load scripts/controlnet_model_guess.py"": 0.0015072822570800781,
            ""load scripts/controlnet_sparsectrl.py"": 0.0,
            ""load scripts/controlnet_version.py"": 0.0,
            ""load scripts/enums.py"": 0.0015232563018798828,
            ""load scripts/external_code.py"": 0.0010516643524169922,
            ""load scripts/global_state.py"": 0.0,
            ""load scripts/hook.py"": 0.0010027885437011719,
            ""load scripts/infotext.py"": 0.0,
            ""load scripts/logging.py"": 0.0010135173797607422,
            ""load scripts/lvminthin.py"": 0.0,
            ""load scripts/movie2movie.py"": 0.0,
            ""load scripts/supported_preprocessor.py"": 0.001506805419921875,
            ""load scripts/utils.py"": 0.0011930465698242188,
            ""load scripts/xyz_grid_support.py"": 0.0,
            ""load scripts/tagger.py"": 0.14598941802978516,
            ""load scripts/comments.py"": 0.044586181640625,
            ""load scripts/refiner.py"": 0.0010988712310791016,
            ""load scripts/sampler.py"": 0.0009937286376953125,
            ""load scripts/seed.py"": 0.0015211105346679688,
            ""load scripts"": 3.618171453475952,
            ""load upscalers"": 0.004336118698120117,
            ""refresh VAE"": 0.0010046958923339844,
            ""refresh textual inversion templates"": 0.0010097026824951172,
            ""scripts list_optimizers"": 0.0010306835174560547,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009660720825195312,
            ""initialize extra networks"": 0.0998542308807373,
            ""scripts before_ui_callback"": 0.01022028923034668,
            ""create ui"": 40.41819214820862,
            ""gradio launch"": 0.772036075592041,
            ""add APIs"": 0.019764184951782227,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/api.py"": 0.003812551498413086,
            ""app_started_callback/tagger.py"": 0.003056764602661133,
            ""app_started_callback"": 0.006869316101074219
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""addict==2.4.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""albumentations==1.4.3"",
        ""alembic==1.16.4"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""basicsr==1.4.2"",
        ""beautifulsoup4==4.13.4"",
        ""blendmodes==2022"",
        ""certifi==2025.7.9"",
        ""cffi==1.17.1"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""controlnet_aux==0.0.10"",
        ""cssselect2==0.8.0"",
        ""cycler==0.12.1"",
        ""Cython==3.1.2"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""depth_anything @ https://github.com/huchenlei/Depth-Anything/releases/download/v1.0.0/depth_anything-2024.1.22.0-py2.py3-none-any.whl#sha256=26c1d38b8c3c306b4a2197d725a4b989ff65f7ebcf4fb5a96a1b6db7fbd56780"",
        ""depth_anything_v2 @ https://github.com/MackinationsAi/UDAV2-ControlNet/releases/download/v1.0.0/depth_anything_v2-2024.7.1.0-py2.py3-none-any.whl#sha256=6848128867d1f7c7519d88df0f88bfab89100dc5225259c4d7cb90325c308c9f"",
        ""diffusers==0.30.2"",
        ""diskcache==5.6.3"",
        ""dsine @ https://github.com/sdbds/DSINE/releases/download/1.0.2/dsine-2024.3.23-py3-none-any.whl#sha256=b9ea3bacce09f9b3f7fb4fa12471da7e465b2f9a60412711105a9238db280442"",
        ""easydict==1.13"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""future==1.0.0"",
        ""fvcore==0.1.5.post20221221"",
        ""gast==0.6.0"",
        ""gdown==5.2.0"",
        ""geffnet==1.0.2"",
        ""gfpgan @ git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""glob2==0.5"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.3"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""handrefinerportable @ https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl#sha256=1e6c702905919f4c49bcb2db7b20d334e8458a7555cd57630600584ec38ca6a9"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""insightface @ https://github.com/Gourieff/Assets/raw/main/Insightface/insightface-0.7.3-cp310-cp310-win_amd64.whl#sha256=47aa0571b2aadd8545d4bc7615dfbc374c10180c283b7ac65058fcb41ed4df86"",
        ""iopath==0.1.9"",
        ""jax==0.6.2"",
        ""jaxlib==0.6.2"",
        ""Jinja2==3.1.6"",
        ""joblib==1.5.1"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""lmdb==1.7.2"",
        ""lpips==0.1.4"",
        ""lxml==6.0.0"",
        ""Mako==1.3.10"",
        ""manifold3d==3.1.1"",
        ""mapbox_earcut==1.0.3"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""mediapipe==0.10.21"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""namex==0.1.0"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""olive-ai==0.9.1"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnx-ir==0.1.4"",
        ""onnxruntime==1.22.1"",
        ""onnxscript==0.3.2"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optimum==1.26.1"",
        ""optree==0.16.0"",
        ""optuna==4.4.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""platformdirs==4.3.8"",
        ""portalocker==3.2.0"",
        ""prettytable==3.16.0"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pycollada==0.9.2"",
        ""pycparser==2.22"",
        ""pydantic==1.10.17"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""PySocks==1.7.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""pywin32==310"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""reportlab==4.4.2"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.26.0"",
        ""rtree==1.4.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.25.2"",
        ""scikit-learn==1.7.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""shapely==2.1.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""sounddevice==0.5.2"",
        ""soupsieve==2.7"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.41"",
        ""starlette==0.26.1"",
        ""svg.path==7.0"",
        ""svglib==1.5.1"",
        ""sympy==1.14.0"",
        ""tabulate==0.9.0"",
        ""tb-nightly==2.20.0a20250711"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.5.10"",
        ""timm==0.9.5"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.0.0"",
        ""torch-directml==0.2.0.dev230426"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.15.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.7.0"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
venv ""D:\sd_directml\venv\Scripts\Python.exe""
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Commit hash: 6d85a7dfa4977ae4eece9cbbab4725123833be14
Installing requirements

loading WD14-tagger reqs from D:\sd_directml\extensions\stable-diffusion-webui-wd14-tagger\requirements.txt
Checking WD14-tagger requirements.

Launching Web UI with arguments: --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae
2025-07-13 11:08:42.939440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-13 11:08:45.640065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ONNX failed to initialize: Failed to import optimum.onnxruntime.modeling_diffusion because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
==============================================================================
You are running torch 2.0.0+cpu.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
ControlNet preprocessor location: D:\sd_directml\extensions\sd-webui-controlnet\annotator\downloads
2025-07-13 11:08:56,379 - ControlNet - INFO - ControlNet v1.1.455
== WD14 tagger /gpu:0, uname_result(system='Windows', node='DESKTOP-GBPLTQV', release='10', version='10.0.26100', machine='AMD64') ==
Loading weights [2e13269995] from D:\sd_directml\models\Stable-diffusion\novaOrangeXL_reV10.safetensors
Creating model from config: D:\sd_directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
Model loaded in 36.5s (load weights from disk: 0.6s, create model: 0.9s, apply weights to model: 25.6s, apply half(): 0.3s, apply dtype to VAE: 0.1s, load VAE: 3.2s, load weights from state dict: 0.2s, move model to device: 0.3s, hijack: 1.0s, load textual inversion embeddings: 1.9s, calculate empty prompt: 2.3s).
2025-07-13 11:09:36,520 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 117.8s (launcher: 35.0s, import torch: 21.2s, import gradio: 1.7s, setup paths: 12.2s, initialize shared: 2.6s, load scripts: 3.6s, create ui: 40.4s, gradio launch: 0.8s).
Couldn't find VAE named sdxl_vae.safetensors; using None instead
Restoring base VAE
Applying attention optimization: sdp... done.
VAE weights loaded.
100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [07:00<00:00, 15.56s/it]
  0%|                                                                                           | 0/27 [00:00<?, ?it/s]
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
VAE weights loaded.
*** Error completing request
*** Arguments: ('task(tblrxw7xt728m2a)', <gradio.routes.Request object at 0x00000142C4CDE1D0>, 'beautiful girl, masterpiece, best quality, ultra-detailed face,beautiful eyes,Well-arranged eyes,\nshort layered bob haircut,purple eyes, slightly upturned nose,(smile:0.5),small nose,\ndeep violet hair with mint green gradient tips, smooth shiny hair, slightly tousled, detailed hair strands, natural skin texture,\nslim yet curvy body, slender waist, wide hips, hourglass figure, youthful proportions,\nnatural-looking large breasts, C-cup, smooth cleavage,\nlong legs, plump thighs, soft skin, firm hips, well-defined back curve, shapely arms, elegant neck,\nrealistic yet anime-inspired body proportions,height around 165cm,\nwhite dress shirt, glossy slightly,sleeves casually rolled up to elbows,\ntop buttons undone, teal necktie, loosely tied, natural drape,\nshort pleated skirt, (beige and brown plaid pattern), uniform style, folded waistband,\nthick fabric with sharp pleats, natural shadows, realistic light reflection,\nschool uniform inspired but casually worn,\n,on the train, train interior, front view of front seat,(looking away:1.4) ,\n(sitting:1.3),(skirt:1.3), show off panties, light blue panties,\nasakura toru, <lora:Asakura_Toru:1.2>', 'bad anatomy, poorly drawn face, asymmetrical eyes, extra hair strands, blurry face, lowres, jpeg artifacts,\nwrong hair color, wrong hairstyle, deformed, monochrome, sketch, photo\n', [], 1, 1, 5, 1056, 904, True, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['VAE: sdxl_vae.safetensors'], 0, 27, 'Euler a', 'Karras', False, '', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x00000142C4DFBC40>, ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, None, None, False, None, None, False, None, None, False, 50) {}
    Traceback (most recent call last):
      File ""D:\sd_directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\sd_directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\sd_directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""D:\sd_directml\extensions\sd-webui-controlnet\scripts\batch_hijack.py"", line 59, in processing_process_images_hijack
        return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)
      File ""D:\sd_directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1457, in sample
        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1549, in sample_hr_pass
        samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 145, in sample_euler_ancestral
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_samplers_cfg_denoiser.py"", line 268, in forward
        x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1538, in _call_impl
        result = forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 100, in forward
        x = layer(x, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 627, in forward
        x = block(x, context=context[i])
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 459, in forward
        return checkpoint(
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 467, in _forward
        self.attn1(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_optimizations.py"", line 547, in scaled_dot_product_attention_forward
        hidden_states = torch.nn.functional.scaled_dot_product_attention(
    RuntimeError

---
```

### Additional information

Operating System: Windows 11 Insider Preview (Build 26100). I am aware this is a pre-release build and might be a contributing factor to the instability.

GPU Driver: Intel Graphics Driver version 32.0.101.6913. I regularly update my drivers to the latest available.

Problem Summary: The issue consistently occurs during the Highres. fix step of image generation (specifically with SDXL models), leading to a RuntimeError. This happens when upscaling with a Denoising strength of 0.7 or higher, even at relatively low base resolutions 

VRAM Management: I have confirmed that the ""VRAM usage polls per second"" setting was at 8 and will change it to 0 as suggested.

Commandline Args: I've identified that my webui-user.bat file contains duplicate COMMANDLINE_ARGS entries and will correct this.

PyTorch-DirectML Version: My torch-directml version is 0.2.0.dev230426, which seems to be an older development version. I plan to attempt to update it.

Extensions: While the provided log was generated with extensions active, the issue has also persisted when --disable-all-extensions was enabled (I will re-test if needed).

System RAM: My system has 16GB of RAM, with approximately 12GB typically in use before starting the WebUI. I make an effort to close other applications to free up RAM during image generation.",bug sdxl hires fix fails oom memory intel arc directml checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened generating sdxl images hires fix intel arc directml gpu generation frequently stops mid process usually hires fix stage around progress happens even lowvram half vae enabled relatively low base resolutions like x vram usage shown task manager often indicates around gb used stops console shows memory oom errors e g could allocate tensor sometimes nan error automatic bit vae retry issue inconsistent sometimes generation succeeds subsequent attempts often fail steps reproduce problem hardware intel arc gb vram windows web ui setup using automatic stable diffusion webui latest git pull webui user bat includes autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae python torch cpu shown startup log despite reinstall torch attempts model use sdxl base model e g novaorangexl rev safetensors wainsfwillustrious v safetensors steps launch web ui using webui user bat b go txt img tab c enter simple prompt e g masterpiece best quality beautiful girl clear eyes set image dimensions width height e enable hires fix f set upscale g set hires steps similar default often used h set denoising strength similar set sampler euler issue persists j click generate observe generation often stops around progress hires fix stage console shows runtimeerror could allocate tensor sometimes prints tensor nans produced vae converting float potentially still failing oom inconsistency first generation succeeds attempting second generation immediately often results failure errors restarting web ui process closing relaunching webui user bat usually allows one successful generation happened image generation including hires fix stage complete successfully without encountering memory errors nan issues process stable allowing continuous image generation without requiring web ui restart successful image given gb vram intel arc capable consistently handling sdxl hires fix x least x without crashing inconsistent behavior especially lowvram half vae enabled browsers use access ui microsoft edge sysinfo platform windows sp python version v amd g df commit dfa ae eece cbbab git status branch master nyour branch date origin master n nchanges staged commit n use git add file update committed n use git restore file discard changes working directory n tmodified launch py n tmodified webui user bat n nno changes added commit use git add git commit script path sd directml data path sd directml extensions dir sd directml extensions checksum ba b fbd f b aad e c e e b ee e c c b commandline launch py autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae torch env info torch version cpu debug build false cuda compiled version null gcc version null clang version null cmake version null os microsoft windows home libc version n python version tags v dd dec msc v bit amd bit runtime python platform windows sp cuda available false cuda runtime version null cuda module loading n nvidia driver version null nvidia gpu models null cudnn version null pip version pip pip packages numpy open clip torch pytorch lightning torch torch directml dev torchdiffeq torchmetrics torchsde torchvision conda packages null hip compiled version n hip runtime version n miopen runtime version n caching allocator config xnnpack available true cpu info architecture currentclockspeed deviceid cpu family l cachesize l cachespeed manufacturer genuineintel maxclockspeed name th gen intel r core tm ghz processortype revision exceptions exception traceback sd directml modules call queue py line f res list func args kwargs sd directml modules call queue py line f res func args kwargs sd directml modules call queue py line f res func args kwargs sd directml modules txt img py line txt img processed processing process images p sd directml modules processing py line process images res process images inner p sd directml extensions sd webui controlnet scripts batch hijack py line processing process images hijack return getattr processing controlnet original process images inner p args kwargs sd directml modules processing py line process images inner samples ddim p sample conditioning p c unconditional conditioning p uc seeds p seeds subseeds p subseeds subseed strength p subseed strength prompts p prompts sd directml modules processing py line sample return self sample hr pass samples decoded samples seeds subseeds subseed strength prompts sd directml modules processing py line sample hr pass samples self sampler sample img img self samples noise self hr c self hr uc steps self hr second pass steps self steps image conditioning image conditioning sd directml modules sd samplers kdiffusion py line sample img img samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs sd directml modules sd samplers common py line launch sampling return func sd directml modules sd samplers kdiffusion py line lambda samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs sd directml venv lib site packages torch utils contextlib py line decorate context return func args kwargs sd directml repositories k diffusion k diffusion sampling py line sample euler ancestral denoised model x sigmas extra args sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml modules sd samplers cfg denoiser py line forward x b self inner model x b sigma b cond make condition dict c crossattn image cond b sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml repositories k diffusion k diffusion external py line forward eps self get eps input c self sigma sigma kwargs sd directml repositories k diffusion k diffusion external py line get eps return self inner model apply model args kwargs sd directml modules sd models xl py line apply model return self model x cond sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs sd directml modules sd hijack utils py line call return self sub func self orig func args kwargs sd directml modules sd hijack unet py line apply model result orig func self x noisy devices dtype unet devices dtype unet cond kwargs sd directml repositories generative models sgm modules diffusionmodules wrappers py line forward return self diffusion model sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs sd directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h module h emb context sd directml venv lib site packages torch nn modules module py line call impl result forward call args kwargs sd directml repositories generative models sgm modules diffusionmodules openaimodel py line forward x layer x context sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml repositories generative models sgm modules attention py line forward x block x context context sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml repositories generative models sgm modules attention py line forward return checkpoint sd directml repositories generative models sgm modules diffusionmodules util py line checkpoint return func inputs sd directml repositories generative models sgm modules attention py line forward self attn sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs sd directml modules sd hijack optimizations py line scaled dot product attention forward hidden states torch nn functional scaled dot product attention cpu model intel family model stepping genuineintel count logical count physical ram total gb used gb free gb extensions name sd webui animatediff path sd directml extensions sd webui animatediff commit e bcbae caccfc fd f ea fd branch master remote name sd webui controlnet path sd directml extensions sd webui controlnet commit cec b edf b b e b b b dbd f branch main remote name stable diffusion webui wd tagger path sd directml extensions stable diffusion webui wd tagger commit e bdbed ba e c b ae branch master remote inactive extensions environment commandline args autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae gradio analytics enabled false config ldsr steps ldsr cached false scunet tile scunet tile overlap swin tile swin tile overlap swin torch compile false hypertile enable unet false hypertile enable unet secondpass false hypertile max depth unet hypertile max tile unet hypertile swap size unet hypertile enable vae false hypertile max depth vae hypertile max tile vae hypertile swap size vae sd model checkpoint novaorangexl rev safetensors e sd checkpoint hash e e c e e edb e dc f ee f f e outdir samples outdir txt img samples outputs txt img images outdir img img samples outputs img img images outdir extras samples outputs extras images outdir grids outdir txt img grids outputs txt img grids outdir img img grids outputs img img grids outdir save log images outdir init images outputs init images onnx cached models path sd directml models onnx cache onnx temp dir sd directml models onnx temp samples save true samples format png samples filename pattern save images add number true save images replace action replace grid save true grid format png grid extended filename false grid multiple true grid prevent empty spots false grid zip filename pattern n rows font grid text active color grid text inactive color grid background color ffffff save images face restoration false save images highres fix false save images color correction false save mask false save mask composite false jpeg quality webp lossless false export chan true img downscale threshold target side length img max size mp use original name batch true use upscaler name suffix false save selected true save write log csv true save init img false temp dir clean temp dir start false save incomplete images false notification audio true notification volume save dirs true grid save dirs true use save dirs ui false directories filename pattern date directories max prompt words auto backcompat true use old emphasis implementation false use old karras scheduler sigmas false dpmpp sde batch determinism false use old hires fix width height false hires fix use firstpass conds false use old scheduling false use downcasted alpha bar false refiner switch sample steps false lora functional false extra networks show hidden directories true extra networks dir button function false extra networks hidden models searched extra networks default multiplier extra networks card width extra networks card height extra networks card text scale extra networks card show desc true extra networks card description html false extra networks card order field path extra networks card order ascending extra networks tree view style dirs extra networks tree view default enabled true extra networks tree view default width extra networks add text separator ui extra networks tab reorder textual inversion print load false textual inversion add hashes infotext true sd hypernetwork none sd lora none lora preferred name alias file lora add hashes infotext true lora bundled ti infotext true lora show false lora hide unknown versions lora memory limit lora found warning console false lora found gradio warning false onnx enable false diffusers pipeline onnx stable diffusion diffusers vae upcast default onnx execution provider cudaexecutionprovider onnx cache converted true olive enable false olive submodels olive float true olive vae encoder float false olive static dims true olive cache optimized true cross attention optimization automatic min uncond min uncond false token merging ratio token merging ratio img img token merging ratio hr pad cond uncond false pad cond uncond v false persistent cond cache true batch cond uncond true fp storage disable cache fp weight false directml memory provider performance counter hide samplers eta ddim eta ancestral ddim discretize uniform churn tmin tmax noise sigma min sigma max rho eta noise seed delta always discard next last sigma false sgm noise multiplier false uni pc variant bh uni pc skip type time uniform uni pc order uni pc lower order final true sd noise schedule default skip early cond beta dist alpha beta dist beta sd checkpoints limit sd checkpoints keep cpu true sd checkpoint cache sd unet automatic enable quantization false emphasis original enable batch seeds true comma padding backtrack sdxl clip l skip false clip stop last layers upcast attn false randn source gpu tiling false hires fix refiner pass second pass enable prompt comments true sd enable false sdxl crop top sdxl crop left sdxl refiner low aesthetic score sdxl refiner high aesthetic score sd vae checkpoint cache sd vae sdxlvae sdxlvae safetensors sd vae overrides per model preferences true auto vae precision bfloat false auto vae precision true sd vae encode method full sd vae decode method full inpainting mask weight initial noise multiplier img img extra noise img img color correction false img img fix steps false img img background color ffffff img img editor height img img sketch default brush color ffffff img img inpaint mask brush color ffffff img img inpaint sketch default brush color ffffff return mask false return mask composite false img img batch show results limit overlay inpaint true return grid true show images false js modal lightbox true js modal lightbox initially zoomed true js modal lightbox gamepad false js modal lightbox gamepad repeat sd webui modal lightbox icon opacity sd webui modal lightbox toolbar opacity gallery height open dir button choice subdirectory enable pnginfo true save txt false add model name info true add model hash info true add vae name info true add vae hash info true add user name info false add version infotext true disable weights auto swap true infotext skip pasting infotext styles apply show progressbar true live previews enable true live previews image format png show progress grid true show progress every n steps show progress type approx nn live preview allow lowvram full false live preview content prompt live preview refresh period live preview fast interrupt false js live preview modal lightbox false prevent screen sleep generation true keyedit precision attention keyedit precision extra keyedit delimiters keyedit delimiters whitespace tab carriage return line feed keyedit move true disable token counters false include styles token counters true extra options txt img extra options img img extra options cols extra options accordion false compact prompt box false samplers dropdown true dimensions batch together true sd checkpoint dropdown use short false hires fix show sampler false hires fix show prompts false txt img settings accordion false img img settings accordion false interrupt current true localization none quicksettings list sd model checkpoint clip stop last layers ui tab order hidden tabs ui reorder list gradio theme default gradio themes cache true show progress title true send seed true send size true enable reloading ui scripts false api enable requests true api forbid local requests true api useragent prioritized callbacks app started prioritized callbacks model loaded prioritized callbacks ui settings prioritized callbacks infotext pasted prioritized callbacks script unloaded prioritized callbacks ui prioritized callbacks list optimizers prioritized callbacks token counter prioritized callbacks script process prioritized callbacks script process prioritized callbacks script post sample prioritized callbacks script mask blend prioritized callbacks script postprocess maskoverlay profiling enable false profiling activities cpu profiling record shapes true profiling profile memory true profiling stack true profiling filename trace json auto launch browser local enable console prompts false show warnings false show gradio deprecation warnings true memmon poll rate samples log stdout false multiple tqdm true enable upscale progressbar true print hypernet extra false list hidden files true disable mmap load safetensors false hide ldm prints true dump stacks signal false face restoration false face restoration model codeformer code former weight face restoration unload false postprocessing enable main ui postprocessing disable extras postprocessing operation order upscaling max images cache postprocessing existing caption action ignore esrgan tile esrgan tile overlap realesrgan enabled models r esrgan x r esrgan x anime b dat enabled models dat x dat x dat x dat tile dat tile overlap set scale changing upscaler false unload models training false pin memory false save optimizer state false save training settings txt true dataset filename word regex dataset filename join string training image repeats per epoch training write csv every training xattention optimizations false training enable tensorboard false training tensorboard save images false training tensorboard flush every canvas hotkey zoom alt canvas hotkey adjust ctrl canvas hotkey shrink brush q canvas hotkey grow brush w canvas hotkey move f canvas hotkey fullscreen canvas hotkey reset r canvas hotkey overlap canvas show tooltip true canvas auto expand true canvas blur prompt false canvas disabled functions overlap interrogate keep models memory false interrogate return ranks false interrogate clip num beams interrogate clip min length interrogate clip max length interrogate clip dict limit interrogate clip skip categories interrogate deepbooru score threshold deepbooru sort alpha true deepbooru use spaces true deepbooru escape true deepbooru filter tags disabled extensions disable extensions none animatediff model path animatediff default save formats gif png animatediff save custom true animatediff frame extract path animatediff frame extract remove false animatediff default frame extract method ffmpeg animatediff optimize gif palette false animatediff optimize gif gifsicle false animatediff mp crf animatediff mp preset animatediff mp tune animatediff webp quality animatediff webp lossless false animatediff enable false animatediff host animatediff port animatediff access key animatediff secret key animatediff storge bucket control net detectedmap dir detected maps control net models path control net modules path control net unit count control net model cache size control net inpaint blur sigma control net detectmap false control net detectmap autosaving false control net allow script control false control net sync field args true controlnet show batch images ui false controlnet increment seed batch false controlnet disable openpose edit false controlnet disable photopea edit false controlnet photopea warning true controlnet ignore noninpaint mask false controlnet clip detector cpu false controlnet control type dropdown false tagger filename fmt name output extension tagger count threshold tagger batch recursive true tagger auto serde json true tagger store images false tagger weighted tags files false tagger verbose false tagger repl us true tagger repl us excl u u x x tagger escape false tagger batch size tagger hf cache dir sd directml models interrogators prioritized callbacks ui tabs prioritized callbacks cfg denoiser prioritized callbacks component prioritized callbacks reload prioritized callbacks script process batch prioritized callbacks script postprocess prioritized callbacks script postprocess batch prioritized callbacks script postprocess batch list prioritized callbacks script postprocess image startup total records launcher import torch import gradio setup paths import ldm import sgm initialize shared imports opts onchange setup sd model setup codeformer setup gfpgan set samplers list extensions restore config state file list sd models list localizations load scripts custom code py load scripts img imgalt py load scripts loopback py load scripts outpainting mk py load scripts poor mans outpainting py load scripts postprocessing codeformer py load scripts postprocessing gfpgan py load scripts postprocessing upscale py load scripts prompt matrix py load scripts prompts file py load scripts sd upscale py load scripts xyz grid py load scripts ldsr model py load scripts lora script py load scripts scunet model py load scripts swinir model py load scripts hotkey config py load scripts extra options section py load scripts hypertile script py load scripts postprocessing autosized crop py load scripts postprocessing caption py load scripts postprocessing create flipped copies py load scripts postprocessing focal crop py load scripts postprocessing split oversized py load scripts soft inpainting py load scripts animatediff py load scripts animatediff freeinit py load scripts animatediff ibatch py load scripts animatediff infotext py load scripts animatediff infv v py load scripts animatediff latent py load scripts animatediff logger py load scripts animatediff mm py load scripts animatediff output py load scripts animatediff prompt py load scripts animatediff settings py load scripts animatediff ui py load scripts animatediff utils py load scripts animatediff xyz py load scripts adapter py load scripts api py load scripts batch hijack py load scripts cldm py load scripts controlnet py load scripts controlnet diffusers py load scripts controlnet lllite py load scripts controlnet lora py load scripts controlnet model guess py load scripts controlnet sparsectrl py load scripts controlnet version py load scripts enums py load scripts external code py load scripts global state py load scripts hook py load scripts infotext py load scripts logging py load scripts lvminthin py load scripts movie movie py load scripts supported preprocessor py load scripts utils py load scripts xyz grid support py load scripts tagger py load scripts comments py load scripts refiner py load scripts sampler py load scripts seed py load scripts load upscalers refresh vae refresh textual inversion templates scripts list optimizers scripts list unets reload hypernetworks initialize extra networks scripts ui callback create ui gradio launch add apis app started callback lora script py app started callback api py app started callback tagger py app started callback packages absl py accelerate addict aenum aiofiles aiohappyeyeballs aio aiosignal albumentations alembic altair antlr python runtime anyio astunparse async timeout attrs basicsr beautifulsoup blendmodes certifi cffi charset normalizer clean fid click clip git colorama coloredlogs colorlog contourpy controlnet aux cssselect cycler cython deepdanbooru deprecation depth anything depth anything v diffusers diskcache dsine easydict einops exceptiongroup facexlib fastapi ffmpy filelock filterpy flatbuffers fonttools frozenlist fsspec ftfy future fvcore post gast gdown geffnet gfpgan git gitdb gitpython glob google pasta gradio gradio client greenlet grpcio h h py handrefinerportable huggingface hub humanfriendly idna imageio importlib metadata importlib resources inflection insightface iopath jax jaxlib jinja joblib jsonmerge jsonschema jsonschema specifications keras kiwisolver kornia lark lazy loader libclang lightning utilities llvmlite lmdb lpips lxml mako manifold mapbox earcut markdown markdown py markupsafe matplotlib mdurl mediapipe ml dtypes mpmath multidict namex narwhals networkx numba numpy olive ai omegaconf onnx onnx ir onnxruntime onnxscript open clip torch opencv contrib python opencv python opencv python headless opt einsum optimum optree optuna orjson packaging pandas piexif pillow pillow avif plugin pip platformdirs portalocker prettytable propcache protobuf psutil pycollada pycparser pydantic pydub pygments pyparsing pyreadline pysocks python dateutil post python multipart pytorch lightning pytz pywavelets pywin pyyaml referencing regex reportlab requests resize right rich rpds py rtree safetensors scikit image scikit learn scipy semantic version sentencepiece setuptools shapely six smmap sniffio sounddevice soupsieve spandrel spandrel extra arches sqlalchemy starlette svg path svglib sympy tabulate tb nightly tensorboard tensorboard data server tensorflow tensorflow io gcs filesystem termcolor threadpoolctl tifffile timm tinycss tokenizers tomesd tomli torch torch directml dev torchdiffeq torchmetrics torchsde torchvision tqdm trampoline transformers trimesh typing extensions tzdata urllib uvicorn vhacdx post wcwidth webencodings websockets werkzeug wheel wrapt xxhash yacs yapf yarl zipp console logs shell venv sd directml venv scripts python exe python tags v dd dec msc v bit amd commit hash dfa ae eece cbbab installing requirements loading wd tagger reqs sd directml extensions stable diffusion webui wd tagger requirements txt checking wd tagger requirements launching web ui arguments autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae autolaunch precision full skip torch cuda test opt sdp attention use directml lowvram half vae tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts module xformers processing without module xformers processing without module xformers proceeding without onnx failed initialize failed import optimum onnxruntime modeling diffusion following error look see traceback failed import transformers modeling tf utils following error look see traceback currently installed version keras keras yet supported transformers please install backwards compatible tf keras package pip install tf keras running torch cpu program tested work torch reinstall desired version run commandline flag reinstall torch beware cause lot large files downloaded well reports issues training tab latest version use skip version check commandline argument disable check controlnet preprocessor location sd directml extensions sd webui controlnet annotator downloads controlnet info controlnet v wd tagger gpu uname result system windows node desktop gbpltqv release version machine amd loading weights e sd directml models stable diffusion novaorangexl rev safetensors creating model config sd directml repositories generative models configs inference sd xl base yaml loading vae weights specified settings sd directml models vae sdxlvae sdxlvae safetensors applying attention optimization sdp done model loaded load weights disk create model apply weights model apply half apply dtype vae load vae load weights state dict move model device hijack load textual inversion embeddings calculate empty prompt controlnet info controlnet ui callback registered running local url create public link set share true launch startup time launcher import torch import gradio setup paths initialize shared load scripts create ui gradio launch find vae named sdxl vae safetensors using none instead restoring base vae applying attention optimization sdp done vae weights loaded loading vae weights specified settings sd directml models vae sdxlvae sdxlvae safetensors applying attention optimization sdp done vae weights loaded error completing request arguments task tblrxw xt gradio routes request object x c cde beautiful girl masterpiece best quality ultra detailed face beautiful eyes well arranged eyes nshort layered bob haircut purple eyes slightly upturned nose smile small nose ndeep violet hair mint green gradient tips smooth shiny hair slightly tousled detailed hair strands natural skin texture nslim yet curvy body slender waist wide hips hourglass figure youthful proportions nnatural looking large breasts c cup smooth cleavage nlong legs plump thighs soft skin firm hips well defined back curve shapely arms elegant neck nrealistic yet anime inspired body proportions height around cm nwhite dress shirt glossy slightly sleeves casually rolled elbows ntop buttons undone teal necktie loosely tied natural drape nshort pleated skirt beige brown plaid pattern uniform style folded waistband nthick fabric sharp pleats natural shadows realistic light reflection nschool uniform inspired casually worn n train train interior front view front seat looking away n sitting skirt show panties light blue panties nasakura toru lora asakura toru bad anatomy poorly drawn face asymmetrical eyes extra hair strands blurry face lowres jpeg artifacts nwrong hair color wrong hairstyle deformed monochrome sketch photo n true latent use checkpoint use sampler use scheduler vae sdxl vae safetensors euler karras false false scripts animatediff ui animatediffprocess object x c dfbc controlnetunit ui true input mode inputmode simple simple batch images output dir loopback false enabled false module none model none weight image none resize mode resizemode inner fit crop resize low vram false processor res threshold threshold b guidance start guidance end pixel perfect false control mode controlmode balanced balanced inpaint crop input image false hr option hiresfixoption save detected map true advanced weighting none effective region mask none pulid mode pulidmode fidelity fidelity union control type controlnetunioncontroltype unknown unknown ipadapter input none mask none batch mask dir none animatediff batch false batch modifiers batch image files batch keyframe idx none controlnetunit ui true input mode inputmode simple simple batch images output dir loopback false enabled false module none model none weight image none resize mode resizemode inner fit crop resize low vram false processor res threshold threshold b guidance start guidance end pixel perfect false control mode controlmode balanced balanced inpaint crop input image false hr option hiresfixoption save detected map true advanced weighting none effective region mask none pulid mode pulidmode fidelity fidelity union control type controlnetunioncontroltype unknown unknown ipadapter input none mask none batch mask dir none animatediff batch false batch modifiers batch image files batch keyframe idx none controlnetunit ui true input mode inputmode simple simple batch images output dir loopback false enabled false module none model none weight image none resize mode resizemode inner fit crop resize low vram false processor res threshold threshold b guidance start guidance end pixel perfect false control mode controlmode balanced balanced inpaint crop input image false hr option hiresfixoption save detected map true advanced weighting none effective region mask none pulid mode pulidmode fidelity fidelity union control type controlnetunioncontroltype unknown unknown ipadapter input none mask none batch mask dir none animatediff batch false batch modifiers batch image files batch keyframe idx none false false positive comma false false start true false false false false false false false none none false none none false none none false traceback recent call last file sd directml modules call queue py line f res list func args kwargs file sd directml modules call queue py line f res func args kwargs file sd directml modules call queue py line f res func args kwargs file sd directml modules txt img py line txt img processed processing process images p file sd directml modules processing py line process images res process images inner p file sd directml extensions sd webui controlnet scripts batch hijack py line processing process images hijack return getattr processing controlnet original process images inner p args kwargs file sd directml modules processing py line process images inner samples ddim p sample conditioning p c unconditional conditioning p uc seeds p seeds subseeds p subseeds subseed strength p subseed strength prompts p prompts file sd directml modules processing py line sample return self sample hr pass samples decoded samples seeds subseeds subseed strength prompts file sd directml modules processing py line sample hr pass samples self sampler sample img img self samples noise self hr c self hr uc steps self hr second pass steps self steps image conditioning image conditioning file sd directml modules sd samplers kdiffusion py line sample img img samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs file sd directml modules sd samplers common py line launch sampling return func file sd directml modules sd samplers kdiffusion py line lambda samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs file sd directml venv lib site packages torch utils contextlib py line decorate context return func args kwargs file sd directml repositories k diffusion k diffusion sampling py line sample euler ancestral denoised model x sigmas extra args file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml modules sd samplers cfg denoiser py line forward x b self inner model x b sigma b cond make condition dict c crossattn image cond b file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml repositories k diffusion k diffusion external py line forward eps self get eps input c self sigma sigma kwargs file sd directml repositories k diffusion k diffusion external py line get eps return self inner model apply model args kwargs file sd directml modules sd models xl py line apply model return self model x cond file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file sd directml modules sd hijack utils py line call return self sub func self orig func args kwargs file sd directml modules sd hijack unet py line apply model result orig func self x noisy devices dtype unet devices dtype unet cond kwargs file sd directml repositories generative models sgm modules diffusionmodules wrappers py line forward return self diffusion model file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs file sd directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h module h emb context file sd directml venv lib site packages torch nn modules module py line call impl result forward call args kwargs file sd directml repositories generative models sgm modules diffusionmodules openaimodel py line forward x layer x context file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml repositories generative models sgm modules attention py line forward x block x context context file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml repositories generative models sgm modules attention py line forward return checkpoint file sd directml repositories generative models sgm modules diffusionmodules util py line checkpoint return func inputs file sd directml repositories generative models sgm modules attention py line forward self attn file sd directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file sd directml modules sd hijack optimizations py line scaled dot product attention forward hidden states torch nn functional scaled dot product attention runtimeerror additional information operating system windows insider preview build aware pre release build might contributing factor instability gpu driver intel graphics driver version regularly update drivers latest available problem summary issue consistently occurs highres fix step image generation specifically sdxl models leading runtimeerror happens upscaling denoising strength higher even relatively low base resolutions vram management confirmed vram usage polls per second setting change suggested commandline args identified webui user bat file contains duplicate commandline args entries correct pytorch directml version torch directml version dev seems older development version plan attempt update extensions provided log generated extensions active issue also persisted disable extensions enabled test needed system ram system gb ram approximately gb typically use starting webui make effort close applications free ram image generation
auto1111_webui,issue,17056,[Bug]: Fails to self-correct after failing to create Python venv,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh script fails to activate the Python virtual environment, reporting ""ERROR: Cannot activate python venv, aborting..."". This often occurs after an initial failure due to a missing dependency like python3.10-venv. Even after installing the dependency, subsequent attempts fail.


This happens because an initial run, without the necessary python3.10-venv or if interrupted, can create an incomplete or corrupted venv directory. The webui.sh script's logic checks for an existing venv directory. If it finds one, it doesn't attempt to recreate it, assuming it's valid. However, if this existing venv is corrupted (e.g., missing the activate script), the script then fails to find the activate script, leading to the ""Cannot activate python venv, aborting..."" error. This creates a persistent loop where the script never fixes the broken environment.

Resolution:

Manually remove the corrupted venv directory. This forces webui.sh to treat it as a fresh run and recreate the virtual environment correctly.

Steps to resolve:


1. Ensure all necessary system dependencies (e.g., python3.10-venv) are installed.
2. Navigate to the root directory of the stable-diffusion-webui project.
3. Remove the existing virtual environment directory:

1     rm -rf venv

4. Run the webui.sh script again. It should now successfully create and activate the virtual environment.

### Steps to reproduce the problem

./webui.sh

### What should have happened?

It should check if you have the ability to install a venv before creating the directory, install the dependency rather than failing, and remove a corrupted one if it fails to activate.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-09-04-13.json](https://github.com/user-attachments/files/21134594/sysinfo-2025-07-09-04-13.json)

### Console logs

```Shell
$ ./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on <redacted> user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
ERROR: Cannot activate python venv, aborting...
################################################################
$
```

### Additional information

This is first run without Python 3.10-venv installed. After installing, it still doesn't work because of the now broken, existing, venv. The script tells you to install the dependency, but doesn't clean up the failed creation, and then fails to start, because the venv is broken.",2025-07-09T04:21:15Z,Mechputer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17056,"[Bug]: Fails to self-correct after failing to create Python venv ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh script fails to activate the Python virtual environment, reporting ""ERROR: Cannot activate python venv, aborting..."". This often occurs after an initial failure due to a missing dependency like python3.10-venv. Even after installing the dependency, subsequent attempts fail.


This happens because an initial run, without the necessary python3.10-venv or if interrupted, can create an incomplete or corrupted venv directory. The webui.sh script's logic checks for an existing venv directory. If it finds one, it doesn't attempt to recreate it, assuming it's valid. However, if this existing venv is corrupted (e.g., missing the activate script), the script then fails to find the activate script, leading to the ""Cannot activate python venv, aborting..."" error. This creates a persistent loop where the script never fixes the broken environment.

Resolution:

Manually remove the corrupted venv directory. This forces webui.sh to treat it as a fresh run and recreate the virtual environment correctly.

Steps to resolve:


1. Ensure all necessary system dependencies (e.g., python3.10-venv) are installed.
2. Navigate to the root directory of the stable-diffusion-webui project.
3. Remove the existing virtual environment directory:

1     rm -rf venv

4. Run the webui.sh script again. It should now successfully create and activate the virtual environment.

### Steps to reproduce the problem

./webui.sh

### What should have happened?

It should check if you have the ability to install a venv before creating the directory, install the dependency rather than failing, and remove a corrupted one if it fails to activate.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-09-04-13.json](https://github.com/user-attachments/files/21134594/sysinfo-2025-07-09-04-13.json)

### Console logs

```Shell
$ ./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on <redacted> user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
ERROR: Cannot activate python venv, aborting...
################################################################
$
```

### Additional information

This is first run without Python 3.10-venv installed. After installing, it still doesn't work because of the now broken, existing, venv. The script tells you to install the dependency, but doesn't clean up the failed creation, and then fails to start, because the venv is broken.",bug fails self correct failing create python venv checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened webui sh script fails activate python virtual environment reporting error cannot activate python venv aborting often occurs initial failure due missing dependency like python venv even installing dependency subsequent attempts fail happens initial run without necessary python venv interrupted create incomplete corrupted venv directory webui sh script logic checks existing venv directory finds one attempt recreate assuming valid however existing venv corrupted e g missing activate script script fails find activate script leading cannot activate python venv aborting error creates persistent loop script never fixes broken environment resolution manually remove corrupted venv directory forces webui sh treat fresh run recreate virtual environment correctly steps resolve ensure necessary system dependencies e g python venv installed navigate root directory stable diffusion webui project remove existing virtual environment directory rm rf venv run webui sh script successfully create activate virtual environment steps reproduce problem webui sh happened check ability install venv creating directory install dependency rather failing remove corrupted one fails activate browsers use access ui google chrome sysinfo sysinfo json console logs shell webui sh install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running redacted user repo already cloned using install directory error cannot activate python venv aborting additional information first run without python venv installed installing still work broken existing venv script tells install dependency clean failed creation fails start venv broken
auto1111_webui,comment,17056,,"I am confused.

How did you get broken venv if you did not have python3-venv installed?

If you do not have `python3-venv` installed, you should see this message: `ERROR: python3-venv is not installed, aborting...` before even git clone was executed.

If you have `python3-venv` installed, after cloning the repo, script will create venv folder if it does not exist.

What you describe can only happen if empty venv folder was manually created, or if script was manually aborted during creation of a venv folder. In any other scenario, this should not happen.

I might do some minor improvements when I find some time.

Easiest would be to delete venv if it cannot be activated, before printing this message: `ERROR: Cannot activate python venv, aborting...` After next launch it will be recreated.

To be honest, if this was my repo I would rewrite the whole scipt from scratch. But, since I am just a user who contribute some minor patches from time to time, I will try to keep my changes to minimum.",2025-08-15T20:55:57Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17056#issuecomment-3192732716,"I am confused.

How did you get broken venv if you did not have python3-venv installed?

If you do not have `python3-venv` installed, you should see this message: `ERROR: python3-venv is not installed, aborting...` before even git clone was executed.

If you have `python3-venv` installed, after cloning the repo, script will create venv folder if it does not exist.

What you describe can only happen if empty venv folder was manually created, or if script was manually aborted during creation of a venv folder. In any other scenario, this should not happen.

I might do some minor improvements when I find some time.

Easiest would be to delete venv if it cannot be activated, before printing this message: `ERROR: Cannot activate python venv, aborting...` After next launch it will be recreated.

To be honest, if this was my repo I would rewrite the whole scipt from scratch. But, since I am just a user who contribute some minor patches from time to time, I will try to keep my changes to minimum.",confused get broken venv python venv installed python venv installed see message error python venv installed aborting even git clone executed python venv installed cloning repo script create venv folder exist describe happen empty venv folder manually created script manually aborted creation venv folder scenario happen might minor improvements find time easiest would delete venv cannot activated printing message error cannot activate python venv aborting next launch recreated honest repo would rewrite whole scipt scratch since user contribute minor patches time time try keep changes minimum
auto1111_webui,issue,17054,[Bug]: AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

when trying to generate X/Y/Z plot at the end I get AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'

### Steps to reproduce the problem

I start generation with X/Y/Z plot enabled with several checkpoints

### What should have happened?

--

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-89-g2174ce5a"",
    ""Commit"": ""2174ce5afea90ca489d222f539988dcef59f1027"",
    ""Git status"": ""On branch dev\nYour branch is up to date with 'origin/dev'.\n\nChanges not staged for commit:\n  (use \""git add/rm <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tdeleted:    models/Stable-diffusion/Put Stable Diffusion checkpoints here.txt\n\tmodified:   modules/images.py\n\tmodified:   webui-user.bat\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\tconfigs/anything_v3.yaml\n\tconfigs/v1-inference_clip_skip_2.yaml\n\tconfigs/v1-inference_clip_skip_2_fp16.yaml\n\tconfigs/v1-inference_fp16.yaml\n\tconfigs/v2-inference-v.yaml\n\tconfigs/v2-inference-v_fp32.yaml\n\tconfigs/v2-inference.yaml\n\tconfigs/v2-inference_fp32.yaml\n\tconfigs/v2-inpainting-inference.yaml\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Data path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Extensions dir"": ""C:\\ai_web\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""e650cac89c923089b0558a9bf4646232f85a6b848bc8ca6abf0d011d6fd0e96d"",
    ""Commandline"": [
        ""launch.py"",
        ""--theme"",
        ""dark"",
        ""--autolaunch""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0+cu128"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Майкрософт Windows 10 Pro (10.0.19045 64-разрядная)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86\r"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""576.80"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""onnxruntime-gpu==1.22.0"",
            ""open-clip-torch==2.20.0"",
            ""optree==0.16.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.3"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": ""garbage_collection_threshold:0.9,max_split_size_mb:768"",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz"",
            ""Manufacturer: GenuineIntel"",
            ""Family: 179"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 2401"",
            ""MaxClockSpeed: 2401"",
            ""L2CacheSize: 3584"",
            ""L2CacheSpeed: None"",
            ""Revision: 20225""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in VAE. This could be because there's not enough precision to represent the picture. Try adding --no-half-vae commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\processing.py, line 637, decode_latent_batch"",
                    ""devices.test_for_nans(sample, \""vae\"")""
                ],
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 79 Stepping 1, GenuineIntel"",
        ""count logical"": 28,
        ""count physical"": 14
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""25GB"",
        ""free"": ""39GB""
    },
    ""Extensions"": [
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""C:\\ai_web\\sd.webui\\webui\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--theme dark --autolaunch "",
        ""GRADIO_ANALYTICS_ENABLED"": ""False"",
        ""XFORMERS_PACKAGE"": ""xformers==0.0.30.dev1005""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]"",
        ""sd_checkpoint_hash"": ""9278fc3affba7a41c9a17c29795ae9cb9d5a7f601af22c2817039de5323e901f"",
        ""outdir_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_txt2img_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""H:\\ai_created_my\\outputs\\img2img-images"",
        ""outdir_extras_samples"": ""H:\\ai_created_my\\outputs\\extras-images"",
        ""outdir_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_txt2img_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""H:\\ai_created_my\\outputs\\img2img-grids"",
        ""outdir_save"": ""H:\\ai_created_my\\log\\images"",
        ""outdir_init_images"": ""H:\\ai_created_my\\outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""textual_inversion_image_embedding_data_cache"": false,
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""sub-quadratic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 31337,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""webp"",
        ""show_progress_grid"": false,
        ""show_progress_every_n_steps"": 4,
        ""show_progress_type"": ""TAESD"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": true,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers"",
            ""sd_vae"",
            ""face_restoration"",
            ""interrogate_deepbooru_score_threshold""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""concurrent_git_fetch_limit"": 16,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.19,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": ""censored, yaoi, futa, mosaic censoring, censoring, pubic hair, ugly, x-ray ,furry,, 2boys, 3boys, ugly man, bar censor, animal ears, fat man, food,"",
        ""upscaler_for_img2img"": ""R-ESRGAN 4x+"",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""C:\\ai_web\\sd.webui\\webui\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": []
    },
    ""Startup"": {
        ""total"": 1.3822298049926758,
        ""records"": {
            ""app reload callback"": 0.0,
            ""scripts unloaded callback"": 0.0,
            ""set samplers"": 0.0,
            ""list extensions"": 0.003998756408691406,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.015995025634765625,
            ""list localizations"": 0.0019996166229248047,
            ""load scripts/custom_code.py"": 0.006997108459472656,
            ""load scripts/img2imgalt.py"": 0.0009996891021728516,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0009999275207519531,
            ""load scripts/poor_mans_outpainting.py"": 0.0,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0010001659393310547,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009989738464355469,
            ""load scripts/xyz_grid.py"": 0.00099945068359375,
            ""load scripts/ldsr_model.py"": 0.06201457977294922,
            ""load scripts/lora_script.py"": 0.23192191123962402,
            ""load scripts/scunet_model.py"": 0.034992218017578125,
            ""load scripts/swinir_model.py"": 0.03499341011047363,
            ""load scripts/hotkey_config.py"": 0.0,
            ""load scripts/extra_options_section.py"": 0.0009694099426269531,
            ""load scripts/hypertile_script.py"": 0.07700014114379883,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0010044574737548828,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0009696483612060547,
            ""load scripts/postprocessing_focal_crop.py"": 0.0,
            ""load scripts/postprocessing_split_oversized.py"": 0.001026153564453125,
            ""load scripts/soft_inpainting.py"": 0.000997781753540039,
            ""load scripts/tagger.py"": 0.11196684837341309,
            ""load scripts/comments.py"": 0.038991689682006836,
            ""load scripts/refiner.py"": 0.0010004043579101562,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.000997304916381836,
            ""load scripts"": 0.6118409633636475,
            ""load upscalers"": 0.002003192901611328,
            ""refresh VAE"": 0.001993894577026367,
            ""refresh textual inversion templates"": 0.0010035037994384766,
            ""scripts list_optimizers"": 0.0019981861114501953,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009989738464355469,
            ""initialize extra networks"": 0.0040018558502197266,
            ""scripts before_ui_callback"": 0.0019953250885009766,
            ""create ui"": 0.5678255558013916,
            ""gradio launch"": 0.15555405616760254,
            ""add APIs"": 0.0070226192474365234,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/tagger.py"": 0.003998279571533203,
            ""app_started_callback"": 0.003998279571533203
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.6.15"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.4"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gast==0.6.0"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.0"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.5.0"",
        ""namex==0.1.0"",
        ""narwhals==1.43.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""omegaconf==2.2.3"",
        ""onnxruntime-gpu==1.22.0"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optree==0.16.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.0"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.25.1"",
        ""safetensors==0.4.5"",
        ""scikit-image==0.25.2"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.3"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.14.0"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.34.3"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""yarl==1.20.1""
    ]
}

### Console logs

```Shell
*** Error completing request
*** Arguments: ('task(ja4jazzpwfefl4b)', <gradio.routes.Request object at 0x000001D11E24D810>,*//*, [], 1, 1, 7, 1024, 1384, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 3, 30, 'Euler a', 'Automatic', False, '', 0.8, 2144633961, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 0, '', [], 11, '', ['NAI_novaAnimeXL_ilV5b.safetensors [bb9b24719f]', 'NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]', 'NoobAI-XL-v1.1.safetensors [6681e8e4b1]', 'nova3DCGXL_illustriousV10.safetensors [6316d41b68]', 'PONY_animusmixV10_v10.safetensors [a2ba3c02a1]', 'PONY_SDXL_autismmixSDXL_autismmixPony.safetensors [821aa5537f]', 'waiNsfwBranchRouwei_ePred1_0.7e.safetensors [dd25aa81fe]', 'waiNSFWIllustrious_v140.safetensors [bdb59bac77]'], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\txt2img.py"", line 106, in txt2img
        processed = modules.scripts.scripts_txt2img.run(p, *p.script_args)
      File ""C:\ai_web\sd.webui\webui\modules\scripts.py"", line 780, in run
        processed = script.run(p, *script_args)
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 773, in run
        processed = draw_xyz_grid(
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 382, in draw_xyz_grid
        grid = images.draw_grid_annotations(grid, grid_max_w, grid_max_h, hor_texts, ver_texts, margin_size)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 228, in draw_grid_annotations
        draw_texts(d, x, y, hor_texts[col], fnt, fontsize)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 171, in draw_texts
        while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
    AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'
```

### Additional information

we need to replace multiline_textsize with the new textbbox method.
Steps:
Open the file:
\stable-diffusion-webui\modules\images.py
Find the line (around line 171):
while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
Replace it with:
while drawing.textbbox((0, 0), line.text, font=fnt)[2] > line.allowed_width and fontsize > 0:
Save the file and restart WebUI.",2025-07-08T13:19:09Z,MSCAs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054,"[Bug]: AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize' ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

when trying to generate X/Y/Z plot at the end I get AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'

### Steps to reproduce the problem

I start generation with X/Y/Z plot enabled with several checkpoints

### What should have happened?

--

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-89-g2174ce5a"",
    ""Commit"": ""2174ce5afea90ca489d222f539988dcef59f1027"",
    ""Git status"": ""On branch dev\nYour branch is up to date with 'origin/dev'.\n\nChanges not staged for commit:\n  (use \""git add/rm <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tdeleted:    models/Stable-diffusion/Put Stable Diffusion checkpoints here.txt\n\tmodified:   modules/images.py\n\tmodified:   webui-user.bat\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\tconfigs/anything_v3.yaml\n\tconfigs/v1-inference_clip_skip_2.yaml\n\tconfigs/v1-inference_clip_skip_2_fp16.yaml\n\tconfigs/v1-inference_fp16.yaml\n\tconfigs/v2-inference-v.yaml\n\tconfigs/v2-inference-v_fp32.yaml\n\tconfigs/v2-inference.yaml\n\tconfigs/v2-inference_fp32.yaml\n\tconfigs/v2-inpainting-inference.yaml\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Data path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Extensions dir"": ""C:\\ai_web\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""e650cac89c923089b0558a9bf4646232f85a6b848bc8ca6abf0d011d6fd0e96d"",
    ""Commandline"": [
        ""launch.py"",
        ""--theme"",
        ""dark"",
        ""--autolaunch""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0+cu128"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Майкрософт Windows 10 Pro (10.0.19045 64-разрядная)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86\r"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""576.80"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""onnxruntime-gpu==1.22.0"",
            ""open-clip-torch==2.20.0"",
            ""optree==0.16.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.3"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": ""garbage_collection_threshold:0.9,max_split_size_mb:768"",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz"",
            ""Manufacturer: GenuineIntel"",
            ""Family: 179"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 2401"",
            ""MaxClockSpeed: 2401"",
            ""L2CacheSize: 3584"",
            ""L2CacheSpeed: None"",
            ""Revision: 20225""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in VAE. This could be because there's not enough precision to represent the picture. Try adding --no-half-vae commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\processing.py, line 637, decode_latent_batch"",
                    ""devices.test_for_nans(sample, \""vae\"")""
                ],
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 79 Stepping 1, GenuineIntel"",
        ""count logical"": 28,
        ""count physical"": 14
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""25GB"",
        ""free"": ""39GB""
    },
    ""Extensions"": [
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""C:\\ai_web\\sd.webui\\webui\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--theme dark --autolaunch "",
        ""GRADIO_ANALYTICS_ENABLED"": ""False"",
        ""XFORMERS_PACKAGE"": ""xformers==0.0.30.dev1005""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]"",
        ""sd_checkpoint_hash"": ""9278fc3affba7a41c9a17c29795ae9cb9d5a7f601af22c2817039de5323e901f"",
        ""outdir_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_txt2img_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""H:\\ai_created_my\\outputs\\img2img-images"",
        ""outdir_extras_samples"": ""H:\\ai_created_my\\outputs\\extras-images"",
        ""outdir_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_txt2img_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""H:\\ai_created_my\\outputs\\img2img-grids"",
        ""outdir_save"": ""H:\\ai_created_my\\log\\images"",
        ""outdir_init_images"": ""H:\\ai_created_my\\outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""textual_inversion_image_embedding_data_cache"": false,
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""sub-quadratic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 31337,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""webp"",
        ""show_progress_grid"": false,
        ""show_progress_every_n_steps"": 4,
        ""show_progress_type"": ""TAESD"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": true,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers"",
            ""sd_vae"",
            ""face_restoration"",
            ""interrogate_deepbooru_score_threshold""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""concurrent_git_fetch_limit"": 16,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.19,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": ""censored, yaoi, futa, mosaic censoring, censoring, pubic hair, ugly, x-ray ,furry,, 2boys, 3boys, ugly man, bar censor, animal ears, fat man, food,"",
        ""upscaler_for_img2img"": ""R-ESRGAN 4x+"",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""C:\\ai_web\\sd.webui\\webui\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": []
    },
    ""Startup"": {
        ""total"": 1.3822298049926758,
        ""records"": {
            ""app reload callback"": 0.0,
            ""scripts unloaded callback"": 0.0,
            ""set samplers"": 0.0,
            ""list extensions"": 0.003998756408691406,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.015995025634765625,
            ""list localizations"": 0.0019996166229248047,
            ""load scripts/custom_code.py"": 0.006997108459472656,
            ""load scripts/img2imgalt.py"": 0.0009996891021728516,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0009999275207519531,
            ""load scripts/poor_mans_outpainting.py"": 0.0,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0010001659393310547,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009989738464355469,
            ""load scripts/xyz_grid.py"": 0.00099945068359375,
            ""load scripts/ldsr_model.py"": 0.06201457977294922,
            ""load scripts/lora_script.py"": 0.23192191123962402,
            ""load scripts/scunet_model.py"": 0.034992218017578125,
            ""load scripts/swinir_model.py"": 0.03499341011047363,
            ""load scripts/hotkey_config.py"": 0.0,
            ""load scripts/extra_options_section.py"": 0.0009694099426269531,
            ""load scripts/hypertile_script.py"": 0.07700014114379883,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0010044574737548828,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0009696483612060547,
            ""load scripts/postprocessing_focal_crop.py"": 0.0,
            ""load scripts/postprocessing_split_oversized.py"": 0.001026153564453125,
            ""load scripts/soft_inpainting.py"": 0.000997781753540039,
            ""load scripts/tagger.py"": 0.11196684837341309,
            ""load scripts/comments.py"": 0.038991689682006836,
            ""load scripts/refiner.py"": 0.0010004043579101562,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.000997304916381836,
            ""load scripts"": 0.6118409633636475,
            ""load upscalers"": 0.002003192901611328,
            ""refresh VAE"": 0.001993894577026367,
            ""refresh textual inversion templates"": 0.0010035037994384766,
            ""scripts list_optimizers"": 0.0019981861114501953,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009989738464355469,
            ""initialize extra networks"": 0.0040018558502197266,
            ""scripts before_ui_callback"": 0.0019953250885009766,
            ""create ui"": 0.5678255558013916,
            ""gradio launch"": 0.15555405616760254,
            ""add APIs"": 0.0070226192474365234,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/tagger.py"": 0.003998279571533203,
            ""app_started_callback"": 0.003998279571533203
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.6.15"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.4"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gast==0.6.0"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.0"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.5.0"",
        ""namex==0.1.0"",
        ""narwhals==1.43.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""omegaconf==2.2.3"",
        ""onnxruntime-gpu==1.22.0"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optree==0.16.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.0"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.25.1"",
        ""safetensors==0.4.5"",
        ""scikit-image==0.25.2"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.3"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.14.0"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.34.3"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""yarl==1.20.1""
    ]
}

### Console logs

```Shell
*** Error completing request
*** Arguments: ('task(ja4jazzpwfefl4b)', <gradio.routes.Request object at 0x000001D11E24D810>,*//*, [], 1, 1, 7, 1024, 1384, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 3, 30, 'Euler a', 'Automatic', False, '', 0.8, 2144633961, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 0, '', [], 11, '', ['NAI_novaAnimeXL_ilV5b.safetensors [bb9b24719f]', 'NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]', 'NoobAI-XL-v1.1.safetensors [6681e8e4b1]', 'nova3DCGXL_illustriousV10.safetensors [6316d41b68]', 'PONY_animusmixV10_v10.safetensors [a2ba3c02a1]', 'PONY_SDXL_autismmixSDXL_autismmixPony.safetensors [821aa5537f]', 'waiNsfwBranchRouwei_ePred1_0.7e.safetensors [dd25aa81fe]', 'waiNSFWIllustrious_v140.safetensors [bdb59bac77]'], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\txt2img.py"", line 106, in txt2img
        processed = modules.scripts.scripts_txt2img.run(p, *p.script_args)
      File ""C:\ai_web\sd.webui\webui\modules\scripts.py"", line 780, in run
        processed = script.run(p, *script_args)
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 773, in run
        processed = draw_xyz_grid(
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 382, in draw_xyz_grid
        grid = images.draw_grid_annotations(grid, grid_max_w, grid_max_h, hor_texts, ver_texts, margin_size)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 228, in draw_grid_annotations
        draw_texts(d, x, y, hor_texts[col], fnt, fontsize)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 171, in draw_texts
        while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
    AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'
```

### Additional information

we need to replace multiline_textsize with the new textbbox method.
Steps:
Open the file:
\stable-diffusion-webui\modules\images.py
Find the line (around line 171):
while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
Replace it with:
while drawing.textbbox((0, 0), line.text, font=fnt)[2] > line.allowed_width and fontsize > 0:
Save the file and restart WebUI.",bug attributeerror imagedraw object attribute multiline textsize checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened trying generate x z plot end get attributeerror imagedraw object attribute multiline textsize steps reproduce problem start generation x z plot enabled several checkpoints happened browsers use access ui google chrome sysinfo platform windows sp python version v g ce commit ce afea ca f dcef f git status branch dev nyour branch date origin dev n nchanges staged commit n use git add rm file update committed n use git restore file discard changes working directory n tdeleted models stable diffusion put stable diffusion checkpoints txt n tmodified modules images py n tmodified webui user bat n nuntracked files n use git add file include committed n tconfigs anything v yaml n tconfigs v inference clip skip yaml n tconfigs v inference clip skip fp yaml n tconfigs v inference fp yaml n tconfigs v inference v yaml n tconfigs v inference v fp yaml n tconfigs v inference yaml n tconfigs v inference fp yaml n tconfigs v inpainting inference yaml n nno changes added commit use git add git commit script path c ai web sd webui webui data path c ai web sd webui webui extensions dir c ai web sd webui webui extensions checksum e cac c b bf f b bc ca abf fd e commandline launch py theme dark autolaunch torch env info torch version cu debug build false cuda compiled version gcc version null clang version null cmake version null os windows pro libc version n python version tags v c b bd aug msc v bit amd bit runtime python platform windows sp cuda available true cuda runtime version r cuda module loading lazy nvidia driver version nvidia gpu models gpu nvidia geforce rtx ti cudnn version null pip version pip pip packages numpy onnxruntime gpu open clip torch optree pytorch lightning torch cu torchdiffeq torchmetrics torchsde torchvision cu conda packages null hip compiled version n hip runtime version n miopen runtime version n caching allocator config garbage collection threshold max split size mb xnnpack available true cpu info name intel r xeon r cpu e v ghz manufacturer genuineintel family architecture processortype deviceid cpu currentclockspeed maxclockspeed l cachesize l cachespeed none revision exceptions exception tensor nans produced vae could enough precision represent picture try adding half vae commandline argument fix use disable nan check commandline argument disable check traceback c ai web sd webui webui modules processing py line decode latent batch devices test nans sample vae c ai web sd webui webui modules devices py line test nans raise nansexception message cpu model intel family model stepping genuineintel count logical count physical ram total gb used gb free gb extensions name stable diffusion webui wd tagger path c ai web sd webui webui extensions stable diffusion webui wd tagger commit e bdbed ba e c b ae branch master remote inactive extensions environment commandline args theme dark autolaunch gradio analytics enabled false xformers package xformers dev config ldsr steps ldsr cached false scunet tile scunet tile overlap swin tile swin tile overlap swin torch compile false hypertile enable unet false hypertile enable unet secondpass false hypertile max depth unet hypertile max tile unet hypertile swap size unet hypertile enable vae false hypertile max depth vae hypertile max tile vae hypertile swap size vae sd model checkpoint nai oneobsessionnoob v noobvpredrouwei safetensors fc aff sd checkpoint hash fc affba c c ae cb f af c de e f outdir samples h ai created outputs txt img images outdir txt img samples h ai created outputs txt img images outdir img img samples h ai created outputs img img images outdir extras samples h ai created outputs extras images outdir grids h ai created outputs txt img grids outdir txt img grids h ai created outputs txt img grids outdir img img grids h ai created outputs img img grids outdir save h ai created log images outdir init images h ai created outputs init images samples save true samples format png samples filename pattern save images add number true save images replace action replace grid save true grid format png grid extended filename false grid multiple true grid prevent empty spots false grid zip filename pattern n rows font grid text active color grid text inactive color grid background color ffffff save images face restoration false save images highres fix false save images color correction false save mask false save mask composite false jpeg quality webp lossless false export chan true img downscale threshold target side length img max size mp use original name batch true use upscaler name suffix false save selected true save write log csv true save init img false temp dir clean temp dir start false save incomplete images false notification audio true notification volume save dirs true grid save dirs true use save dirs ui false directories filename pattern date directories max prompt words auto backcompat true use old emphasis implementation false use old karras scheduler sigmas false dpmpp sde batch determinism false use old hires fix width height false hires fix use firstpass conds false use old scheduling false use downcasted alpha bar false refiner switch sample steps false lora functional false extra networks show hidden directories true extra networks dir button function false extra networks hidden models searched extra networks default multiplier extra networks card width extra networks card height extra networks card text scale extra networks card show desc true extra networks card description html false extra networks card order field path extra networks card order ascending extra networks tree view style dirs extra networks tree view default enabled true extra networks tree view default width extra networks add text separator ui extra networks tab reorder textual inversion print load false textual inversion add hashes infotext true sd hypernetwork none textual inversion image embedding data cache false sd lora none lora preferred name alias file lora add hashes infotext true lora bundled ti infotext true lora show false lora hide unknown versions lora memory limit lora found warning console false lora found gradio warning false cross attention optimization sub quadratic min uncond min uncond false token merging ratio token merging ratio img img token merging ratio hr pad cond uncond false pad cond uncond v false persistent cond cache true batch cond uncond true fp storage disable cache fp weight false hide samplers eta ddim eta ancestral ddim discretize uniform churn tmin tmax noise sigma min sigma max rho eta noise seed delta always discard next last sigma false sgm noise multiplier false uni pc variant bh uni pc skip type time uniform uni pc order uni pc lower order final true sd noise schedule default skip early cond beta dist alpha beta dist beta sd checkpoints limit sd checkpoints keep cpu true sd checkpoint cache sd unet automatic enable quantization false emphasis original enable batch seeds true comma padding backtrack sdxl clip l skip false clip stop last layers upcast attn false randn source gpu tiling false hires fix refiner pass second pass enable prompt comments true sd enable false sdxl crop top sdxl crop left sdxl refiner low aesthetic score sdxl refiner high aesthetic score sd vae checkpoint cache sd vae automatic sd vae overrides per model preferences true auto vae precision bfloat false auto vae precision true sd vae encode method full sd vae decode method full inpainting mask weight initial noise multiplier img img extra noise img img color correction false img img fix steps false img img background color ffffff img img editor height img img sketch default brush color ffffff img img inpaint mask brush color ffffff img img inpaint sketch default brush color ffffff return mask false return mask composite false img img batch show results limit overlay inpaint true return grid true show images false js modal lightbox true js modal lightbox initially zoomed true js modal lightbox gamepad false js modal lightbox gamepad repeat sd webui modal lightbox icon opacity sd webui modal lightbox toolbar opacity gallery height open dir button choice subdirectory enable pnginfo true save txt false add model name info true add model hash info true add vae name info true add vae hash info true add user name info false add version infotext true disable weights auto swap true infotext skip pasting infotext styles apply show progressbar true live previews enable true live previews image format webp show progress grid false show progress every n steps show progress type taesd live preview allow lowvram full false live preview content prompt live preview refresh period live preview fast interrupt false js live preview modal lightbox true prevent screen sleep generation true keyedit precision attention keyedit precision extra keyedit delimiters keyedit delimiters whitespace tab carriage return line feed keyedit move true disable token counters false include styles token counters true extra options txt img extra options img img extra options cols extra options accordion false compact prompt box false samplers dropdown true dimensions batch together true sd checkpoint dropdown use short false hires fix show sampler false hires fix show prompts false txt img settings accordion false img img settings accordion false interrupt current true localization none quicksettings list sd model checkpoint clip stop last layers sd vae face restoration interrogate deepbooru score threshold ui tab order hidden tabs ui reorder list gradio theme default gradio themes cache true show progress title true send seed true send size true enable reloading ui scripts false api enable requests true api forbid local requests true api useragent prioritized callbacks app started prioritized callbacks model loaded prioritized callbacks ui settings prioritized callbacks infotext pasted prioritized callbacks script unloaded prioritized callbacks ui prioritized callbacks list optimizers prioritized callbacks token counter prioritized callbacks script process prioritized callbacks script process prioritized callbacks script post sample prioritized callbacks script mask blend prioritized callbacks script postprocess maskoverlay profiling enable false profiling activities cpu profiling record shapes true profiling profile memory true profiling stack true profiling filename trace json auto launch browser local enable console prompts false show warnings false show gradio deprecation warnings true memmon poll rate samples log stdout false multiple tqdm true enable upscale progressbar true print hypernet extra false list hidden files true disable mmap load safetensors false hide ldm prints true dump stacks signal false concurrent git fetch limit face restoration false face restoration model codeformer code former weight face restoration unload false postprocessing enable main ui postprocessing disable extras postprocessing operation order upscaling max images cache postprocessing existing caption action ignore esrgan tile esrgan tile overlap realesrgan enabled models r esrgan x r esrgan x anime b dat enabled models dat x dat x dat x dat tile dat tile overlap set scale changing upscaler false unload models training false pin memory false save optimizer state false save training settings txt true dataset filename word regex dataset filename join string training image repeats per epoch training write csv every training xattention optimizations false training enable tensorboard false training tensorboard save images false training tensorboard flush every canvas hotkey zoom alt canvas hotkey adjust ctrl canvas hotkey shrink brush q canvas hotkey grow brush w canvas hotkey move f canvas hotkey fullscreen canvas hotkey reset r canvas hotkey overlap canvas show tooltip true canvas auto expand true canvas blur prompt false canvas disabled functions overlap interrogate keep models memory false interrogate return ranks false interrogate clip num beams interrogate clip min length interrogate clip max length interrogate clip dict limit interrogate clip skip categories interrogate deepbooru score threshold deepbooru sort alpha true deepbooru use spaces true deepbooru escape true deepbooru filter tags censored yaoi futa mosaic censoring censoring pubic hair ugly x ray furry boys boys ugly man bar censor animal ears fat man food upscaler img img r esrgan x disabled extensions disable extensions none tagger filename fmt name output extension tagger count threshold tagger batch recursive true tagger auto serde json true tagger store images false tagger weighted tags files false tagger verbose false tagger repl us true tagger repl us excl u u x x tagger escape false tagger batch size tagger hf cache dir c ai web sd webui webui models interrogators prioritized callbacks ui tabs startup total records app reload callback scripts unloaded callback set samplers list extensions restore config state file list sd models list localizations load scripts custom code py load scripts img imgalt py load scripts loopback py load scripts outpainting mk py load scripts poor mans outpainting py load scripts postprocessing codeformer py load scripts postprocessing gfpgan py load scripts postprocessing upscale py load scripts prompt matrix py load scripts prompts file py load scripts sd upscale py load scripts xyz grid py load scripts ldsr model py load scripts lora script py load scripts scunet model py load scripts swinir model py load scripts hotkey config py load scripts extra options section py load scripts hypertile script py load scripts postprocessing autosized crop py load scripts postprocessing caption py load scripts postprocessing create flipped copies py load scripts postprocessing focal crop py load scripts postprocessing split oversized py load scripts soft inpainting py load scripts tagger py load scripts comments py load scripts refiner py load scripts sampler py load scripts seed py load scripts load upscalers refresh vae refresh textual inversion templates scripts list optimizers scripts list unets reload hypernetworks initialize extra networks scripts ui callback create ui gradio launch add apis app started callback lora script py app started callback tagger py app started callback packages absl py accelerate aenum aiofiles aiohappyeyeballs aio aiosignal altair antlr python runtime anyio astunparse async timeout attrs blendmodes certifi charset normalizer clean fid click clip colorama coloredlogs contourpy cycler deepdanbooru deprecation diskcache einops exceptiongroup facexlib fastapi ffmpy filelock filterpy flatbuffers fonttools frozenlist fsspec ftfy gast gitdb gitpython google pasta gradio gradio client grpcio h h py huggingface hub humanfriendly idna imageio importlib resources inflection jinja jsonmerge jsonschema jsonschema specifications keras kiwisolver kornia lark lazy loader libclang lightning utilities llvmlite markdown markdown py markupsafe matplotlib mdurl ml dtypes mpmath multidict namex narwhals networkx numba numpy omegaconf onnxruntime gpu open clip torch opencv contrib python opencv python opencv python headless opt einsum optree orjson packaging pandas piexif pillow pillow avif plugin pip propcache protobuf psutil pydantic pydub pygments pyparsing pyreadline python dateutil post python multipart pytorch lightning pytz pywavelets pyyaml referencing regex requests resize right rich rpds py safetensors scikit image scipy semantic version sentencepiece setuptools six smmap sniffio spandrel spandrel extra arches starlette sympy tensorboard tensorboard data server tensorflow tensorflow io gcs filesystem termcolor tifffile timm tokenizers tomesd torch cu torchdiffeq torchmetrics torchsde torchvision cu tqdm trampoline transformers typing extensions tzdata urllib uvicorn wcwidth websockets werkzeug wheel wrapt yarl console logs shell error completing request arguments task ja jazzpwfefl b gradio routes request object x e false latent use checkpoint use sampler use scheduler euler automatic false false false false positive comma false false start nai novaanimexl ilv b safetensors bb b f nai oneobsessionnoob v noobvpredrouwei safetensors fc aff noobai xl v safetensors e e b nova dcgxl illustriousv safetensors b pony animusmixv v safetensors ba c pony sdxl autismmixsdxl autismmixpony safetensors aa f wainsfwbranchrouwei epred e safetensors dd aa fe wainsfwillustrious v safetensors bdb bac true false false false false false false false true traceback recent call last file c ai web sd webui webui modules call queue py line f res list func args kwargs file c ai web sd webui webui modules call queue py line f res func args kwargs file c ai web sd webui webui modules call queue py line f res func args kwargs file c ai web sd webui webui modules txt img py line txt img processed modules scripts scripts txt img run p p script args file c ai web sd webui webui modules scripts py line run processed script run p script args file c ai web sd webui webui scripts xyz grid py line run processed draw xyz grid file c ai web sd webui webui scripts xyz grid py line draw xyz grid grid images draw grid annotations grid grid max w grid max h hor texts ver texts margin size file c ai web sd webui webui modules images py line draw grid annotations draw texts x hor texts col fnt fontsize file c ai web sd webui webui modules images py line draw texts drawing multiline textsize line text font fnt line allowed width fontsize attributeerror imagedraw object attribute multiline textsize additional information need replace multiline textsize new textbbox method steps open file stable diffusion webui modules images py find line around line drawing multiline textsize line text font fnt line allowed width fontsize replace drawing textbbox line text font fnt line allowed width fontsize save file restart webui
auto1111_webui,comment,17054,,"i ask deepseek about it. And he tell me that this problem is related to ""The error AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize' occurs because the multiline_textsize method has been removed in the new version of the Pillow Library (PIL).""",2025-07-08T13:21:52Z,MSCAs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054#issuecomment-3048953294,"i ask deepseek about it. And he tell me that this problem is related to ""The error AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize' occurs because the multiline_textsize method has been removed in the new version of the Pillow Library (PIL).""",ask deepseek tell problem related error attributeerror imagedraw object attribute multiline textsize occurs multiline textsize method removed new version pillow library pil
auto1111_webui,comment,17054,,"You may try to use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which is currently well-maintained and has built-in support for both OpenVINO and IPEX.",2025-07-10T06:45:56Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054#issuecomment-3055864510,"You may try to use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which is currently well-maintained and has built-in support for both OpenVINO and IPEX.",may try use sd next alternative currently well maintained built support openvino ipex
auto1111_webui,issue,17051,[Bug]: ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello,
I'm try to install automatic1111 on my arch linux, I followed the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs but when I try to run the final script I've the following error
`./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
`
Can someone help me to figure out what to do? Looking in the open issue I'm not able to find someone that have the invalid argument as error, what should I check? If needed rocm is on version 6.4.1-1 Thanks!

### Steps to reproduce the problem

Follow the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs and run with ./webui.sh --skip-torch-cuda-test

### What should have happened?

Webui should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

the  --dump-sysinfo return the same error as mentioned 
    ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument


### Console logs

```Shell
./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
```

### Additional information

_No response_",2025-07-05T10:12:28Z,bestbug456,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051,"[Bug]: ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello,
I'm try to install automatic1111 on my arch linux, I followed the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs but when I try to run the final script I've the following error
`./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
`
Can someone help me to figure out what to do? Looking in the open issue I'm not able to find someone that have the invalid argument as error, what should I check? If needed rocm is on version 6.4.1-1 Thanks!

### Steps to reproduce the problem

Follow the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs and run with ./webui.sh --skip-torch-cuda-test

### What should have happened?

Webui should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

the  --dump-sysinfo return the same error as mentioned 
    ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument


### Console logs

```Shell
./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
```

### Additional information

_No response_",bug importerror libamdhip cannot enable executable stack shared object requires invalid argument checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened hello try install automatic arch linux followed guide try run final script following error webui sh skip torch cuda test install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running user repo already cloned using install directory python venv already activate run without venv stable diffusion webui venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload usr lib libtcmalloc minimal python main jul gcc version v commit hash c ae bd abdf eda b e launching web ui arguments skip torch cuda test traceback recent call last file home bestbug documents stable diffusion webui launch py line module main file home bestbug documents stable diffusion webui launch py line main start file home bestbug documents stable diffusion webui modules launch utils py line start import webui file home bestbug documents stable diffusion webui webui py line module initialize imports file home bestbug documents stable diffusion webui modules initialize py line imports import torch noqa f file home bestbug documents stable diffusion webui venv lib python site packages torch init py line module torch c import noqa f importerror libamdhip cannot enable executable stack shared object requires invalid argument someone help figure looking open issue able find someone invalid argument error check needed rocm version thanks steps reproduce problem follow guide run webui sh skip torch cuda test happened webui start browsers use access ui response sysinfo dump sysinfo return error mentioned importerror libamdhip cannot enable executable stack shared object requires invalid argument console logs shell webui sh skip torch cuda test install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running user repo already cloned using install directory python venv already activate run without venv stable diffusion webui venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload usr lib libtcmalloc minimal python main jul gcc version v commit hash c ae bd abdf eda b e launching web ui arguments skip torch cuda test traceback recent call last file home bestbug documents stable diffusion webui launch py line module main file home bestbug documents stable diffusion webui launch py line main start file home bestbug documents stable diffusion webui modules launch utils py line start import webui file home bestbug documents stable diffusion webui webui py line module initialize imports file home bestbug documents stable diffusion webui modules initialize py line imports import torch noqa f file home bestbug documents stable diffusion webui venv lib python site packages torch init py line module torch c import noqa f importerror libamdhip cannot enable executable stack shared object requires invalid argument additional information response
auto1111_webui,comment,17051,,"I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.",2025-07-12T04:07:39Z,dlm21,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3064631280,"I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.",fixed using patchelf clear execstack libamdhip libhiprtc loaded worked hth
auto1111_webui,comment,17051,,"> I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.

This worked great. For anyone else running into this issue later: you can run the following one liner from the projects directory to fix the problem.
```bash
find . \( -name ""libhiprtc.so"" -o -name ""libamdhip64.so"" \) -exec patchelf --clear-execstack {} \;
```",2025-08-14T05:52:48Z,Lethja,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3187055652,"> I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.

This worked great. For anyone else running into this issue later: you can run the following one liner from the projects directory to fix the problem.
```bash
find . \( -name ""libhiprtc.so"" -o -name ""libamdhip64.so"" \) -exec patchelf --clear-execstack {} \;
```",fixed using patchelf clear execstack libamdhip libhiprtc loaded worked hth worked great anyone else running issue later run following one liner projects directory fix problem bash find name libhiprtc name libamdhip exec patchelf clear execstack
auto1111_webui,comment,17051,,It's such a great auto-setup script...,2025-09-09T00:29:05Z,Hatsune-Cthulhu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3268444547,It's such a great auto-setup script...,great auto setup script
auto1111_webui,issue,17047,"[Bug]: Intel Arc GPU (XPU) not detected with PyTorch builds integrating XPU support (e.g., 2.7.1+XPU)","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When attempting to run Stable Diffusion WebUI (Automatic1111) on a Linux system equipped with an Intel Arc A770 GPU and a PyTorch version that natively integrates XPU (Intel GPU) support (such as PyTorch 2.7.1+XPU), the WebUI consistently fails to detect and utilize the Intel Arc GPU. Instead, it defaults to performing image generation on the CPU, even when the `--use-ipex` command-line argument is explicitly provided in `webui-user.sh`.

### Steps to reproduce the problem

1. **System Setup:** Configure a Linux system with an Intel Arc A770 GPU.
2. **Driver Installation:** Ensure the latest Intel GPU drivers for Linux are installed and correctly loaded (e.g., i915 kernel module, level-zero, firmware, etc.).
3. **PyTorch Installation:** Install a PyTorch build with integrated XPU support (e.g., PyTorch 2.7.1+XPU). A relevant community guide for this setup can be found [here](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821).
- **Verification:** Confirm that PyTorch correctly recognizes the XPU by executing `python -c ""import torch; print(torch.xpu.is_available());""` within your PyTorch environment. This command should return `True`.
4. **Stable Diffusion WebUI Setup:** Clone and set up the Automatic1111 Stable Diffusion WebUI.
5. **Configure WebUI Launch:** In your `webui-user.sh` file, ensure `COMMANDLINE_ARGS` includes `--use-ipex`. Example: `export COMMANDLINE_ARGS=""--use-ipex --precision full --no-half ""`.
6. **Launch WebUI:** Start Stable Diffusion WebUI using `./webui.sh`.
7. **Observe Behavior:** Initiate an image generation task. The WebUI will incorrectly utilize the CPU instead of the Intel Arc GPU (XPU).

### What should have happened?

When the `--use-ipex` command-line argument is provided and a PyTorch build with native XPU support (like `PyTorch 2.7.1+XPU`) is correctly installed and `torch.xpu.is_available()` returns `True`, Stable Diffusion WebUI should correctly detect and automatically utilize the Intel Arc GPU (XPU) for accelerated image generation.

### What browsers do you use to access the UI ?

Other

### Sysinfo

not applicable but anyway

[sysinfo-2025-06-28-05-33.json](https://github.com/user-attachments/files/20958988/sysinfo-2025-06-28-05-33.json)

### Console logs

```Shell
not applicable
```

### Additional information

- **GPU Model:** Intel Arc A770
- **Operating System:** Linux (tested on PikaOS; issue likely affects other Linux distributions as well)
- **PyTorch Version:** 2.7.1+XPU (XPU support is integrated into the core PyTorch package, making a separate `intel_extension_for_pytorch` module unnecessary for functionality).

**Root Cause Analysis:**
- The problem lies in the XPU device detection logic within the Stable Diffusion WebUI, specifically in files like `modules/xpu_specific.py`.
- The relevant code snippet for XPU detection (`has_ipex variable`, which translates to `xpu_specific.has_xpu` in `modules/devices.py`) relies on a `try...except` block attempting to import `intel_extension_for_pytorch`.
- Since `PyTorch 2.7.1+XPU` integrates the functionality of `intel_extension_for_pytorch` directly, the standalone `intel_extension_for_pytorch` module is often not installed separately (and is not needed for `torch.xpu.is_available()` to be true).
- Consequently, the `import intel_extension_for_pytorch` call fails within `xpu_specific.py`, causing the detection flag (`has_ipex` / `xpu_specific.has_xpu`) to remain `False`.
- This leads `modules/devices.py`'s `get_optimal_device_name()` function to incorrectly fall back to the CPU, despite the GPU being fully functional and available via `torch.xpu`.

**Temporary Workaround (User's Solution):**
A temporary workaround that resolves the issue is to directly force the XPU backend by manually changing the last line within the `def get_optimal_device_name():` function in `modules/devices.py` from `return ""cpu""` to `return ""xpu""`. This bypasses the flawed detection logic, and the WebUI then successfully uses the Intel Arc GPU.

**Proposed Clean Solution (for `xpu_specific.py`):**
To provide a more robust and future-proof detection mechanism, the XPU availability check in `xpu_specific.py` should be modified to directly query `torch.xpu.is_available()`. This would eliminate the dependency on the presence of the separate `intel_extension_for_pytorch` module for detection.
Example modification within `xpu_specific.py`:

```python
import torch
# ... other necessary imports ...

has_xpu_device_natively_available = False
try:
    if hasattr(torch, 'xpu') and torch.xpu.is_available():
        has_xpu_device_natively_available = True
except Exception:
    # Log error if needed, but ensure has_xpu_device_natively_available remains False
    pass

# This variable should be the one accessed by modules/devices.py
# If it was originally named 'has_ipex', retain that name for compatibility.
has_ipex = has_xpu_device_natively_available

# Ensure get_xpu_device_string() also uses torch.xpu methods directly if present.
```",2025-06-28T05:35:58Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047,"[Bug]: Intel Arc GPU (XPU) not detected with PyTorch builds integrating XPU support (e.g., 2.7.1+XPU) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When attempting to run Stable Diffusion WebUI (Automatic1111) on a Linux system equipped with an Intel Arc A770 GPU and a PyTorch version that natively integrates XPU (Intel GPU) support (such as PyTorch 2.7.1+XPU), the WebUI consistently fails to detect and utilize the Intel Arc GPU. Instead, it defaults to performing image generation on the CPU, even when the `--use-ipex` command-line argument is explicitly provided in `webui-user.sh`.

### Steps to reproduce the problem

1. **System Setup:** Configure a Linux system with an Intel Arc A770 GPU.
2. **Driver Installation:** Ensure the latest Intel GPU drivers for Linux are installed and correctly loaded (e.g., i915 kernel module, level-zero, firmware, etc.).
3. **PyTorch Installation:** Install a PyTorch build with integrated XPU support (e.g., PyTorch 2.7.1+XPU). A relevant community guide for this setup can be found [here](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821).
- **Verification:** Confirm that PyTorch correctly recognizes the XPU by executing `python -c ""import torch; print(torch.xpu.is_available());""` within your PyTorch environment. This command should return `True`.
4. **Stable Diffusion WebUI Setup:** Clone and set up the Automatic1111 Stable Diffusion WebUI.
5. **Configure WebUI Launch:** In your `webui-user.sh` file, ensure `COMMANDLINE_ARGS` includes `--use-ipex`. Example: `export COMMANDLINE_ARGS=""--use-ipex --precision full --no-half ""`.
6. **Launch WebUI:** Start Stable Diffusion WebUI using `./webui.sh`.
7. **Observe Behavior:** Initiate an image generation task. The WebUI will incorrectly utilize the CPU instead of the Intel Arc GPU (XPU).

### What should have happened?

When the `--use-ipex` command-line argument is provided and a PyTorch build with native XPU support (like `PyTorch 2.7.1+XPU`) is correctly installed and `torch.xpu.is_available()` returns `True`, Stable Diffusion WebUI should correctly detect and automatically utilize the Intel Arc GPU (XPU) for accelerated image generation.

### What browsers do you use to access the UI ?

Other

### Sysinfo

not applicable but anyway

[sysinfo-2025-06-28-05-33.json](https://github.com/user-attachments/files/20958988/sysinfo-2025-06-28-05-33.json)

### Console logs

```Shell
not applicable
```

### Additional information

- **GPU Model:** Intel Arc A770
- **Operating System:** Linux (tested on PikaOS; issue likely affects other Linux distributions as well)
- **PyTorch Version:** 2.7.1+XPU (XPU support is integrated into the core PyTorch package, making a separate `intel_extension_for_pytorch` module unnecessary for functionality).

**Root Cause Analysis:**
- The problem lies in the XPU device detection logic within the Stable Diffusion WebUI, specifically in files like `modules/xpu_specific.py`.
- The relevant code snippet for XPU detection (`has_ipex variable`, which translates to `xpu_specific.has_xpu` in `modules/devices.py`) relies on a `try...except` block attempting to import `intel_extension_for_pytorch`.
- Since `PyTorch 2.7.1+XPU` integrates the functionality of `intel_extension_for_pytorch` directly, the standalone `intel_extension_for_pytorch` module is often not installed separately (and is not needed for `torch.xpu.is_available()` to be true).
- Consequently, the `import intel_extension_for_pytorch` call fails within `xpu_specific.py`, causing the detection flag (`has_ipex` / `xpu_specific.has_xpu`) to remain `False`.
- This leads `modules/devices.py`'s `get_optimal_device_name()` function to incorrectly fall back to the CPU, despite the GPU being fully functional and available via `torch.xpu`.

**Temporary Workaround (User's Solution):**
A temporary workaround that resolves the issue is to directly force the XPU backend by manually changing the last line within the `def get_optimal_device_name():` function in `modules/devices.py` from `return ""cpu""` to `return ""xpu""`. This bypasses the flawed detection logic, and the WebUI then successfully uses the Intel Arc GPU.

**Proposed Clean Solution (for `xpu_specific.py`):**
To provide a more robust and future-proof detection mechanism, the XPU availability check in `xpu_specific.py` should be modified to directly query `torch.xpu.is_available()`. This would eliminate the dependency on the presence of the separate `intel_extension_for_pytorch` module for detection.
Example modification within `xpu_specific.py`:

```python
import torch
# ... other necessary imports ...

has_xpu_device_natively_available = False
try:
    if hasattr(torch, 'xpu') and torch.xpu.is_available():
        has_xpu_device_natively_available = True
except Exception:
    # Log error if needed, but ensure has_xpu_device_natively_available remains False
    pass

# This variable should be the one accessed by modules/devices.py
# If it was originally named 'has_ipex', retain that name for compatibility.
has_ipex = has_xpu_device_natively_available

# Ensure get_xpu_device_string() also uses torch.xpu methods directly if present.
```",bug intel arc gpu xpu detected pytorch builds integrating xpu support e g xpu checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened attempting run stable diffusion webui automatic linux system equipped intel arc gpu pytorch version natively integrates xpu intel gpu support pytorch xpu webui consistently fails detect utilize intel arc gpu instead defaults performing image generation cpu even use ipex command line argument explicitly provided webui user sh steps reproduce problem system setup configure linux system intel arc gpu driver installation ensure latest intel gpu drivers linux installed correctly loaded e g kernel module level zero firmware etc pytorch installation install pytorch build integrated xpu support e g pytorch xpu relevant community guide setup found verification confirm pytorch correctly recognizes xpu executing python c import torch print torch xpu available within pytorch environment command return true stable diffusion webui setup clone set automatic stable diffusion webui configure webui launch webui user sh file ensure commandline args includes use ipex example export commandline args use ipex precision full half launch webui start stable diffusion webui using webui sh observe behavior initiate image generation task webui incorrectly utilize cpu instead intel arc gpu xpu happened use ipex command line argument provided pytorch build native xpu support like pytorch xpu correctly installed torch xpu available returns true stable diffusion webui correctly detect automatically utilize intel arc gpu xpu accelerated image generation browsers use access ui sysinfo applicable anyway sysinfo json console logs shell applicable additional information gpu model intel arc operating system linux tested pikaos issue likely affects linux distributions well pytorch version xpu xpu support integrated core pytorch package making separate intel extension pytorch module unnecessary functionality root cause analysis problem lies xpu device detection logic within stable diffusion webui specifically files like modules xpu specific py relevant code snippet xpu detection ipex variable translates xpu specific xpu modules devices py relies try except block attempting import intel extension pytorch since pytorch xpu integrates functionality intel extension pytorch directly standalone intel extension pytorch module often installed separately needed torch xpu available true consequently import intel extension pytorch call fails within xpu specific py causing detection flag ipex xpu specific xpu remain false leads modules devices py get optimal device name function incorrectly fall back cpu despite gpu fully functional available via torch xpu temporary workaround user solution temporary workaround resolves issue directly force xpu backend manually changing last line within def get optimal device name function modules devices py return cpu return xpu bypasses flawed detection logic webui successfully uses intel arc gpu proposed clean solution xpu specific py provide robust future proof detection mechanism xpu availability check xpu specific py modified directly query torch xpu available would eliminate dependency presence separate intel extension pytorch module detection example modification within xpu specific py python import torch necessary imports xpu device natively available false try hasattr torch xpu torch xpu available xpu device natively available true except exception log error needed ensure xpu device natively available remains false pass variable one accessed modules devices py originally named ipex retain name compatibility ipex xpu device natively available ensure get xpu device string also uses torch xpu methods directly present
auto1111_webui,comment,17047,,"Hi all
pls see also here: 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/14461
may be I found a workaround on this, but is in testing actually.
.. see my comment @end.

Regards,
Roger",2025-06-30T08:57:23Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3018345308,"Hi all
pls see also here: 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/14461
may be I found a workaround on this, but is in testing actually.
.. see my comment @end.

Regards,
Roger",hi pls see also may found workaround testing actually see comment end regards roger
auto1111_webui,comment,17047,,"or also in webui-user.sh for simpler method, to be tested:
try that:
# install command for torch
#export TORCH_COMMAND=""pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113""
.. and set u'r appropriate version here for INTEL?
Regards,
Roger",2025-06-30T09:07:41Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3018378315,"or also in webui-user.sh for simpler method, to be tested:
try that:
# install command for torch
#export TORCH_COMMAND=""pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113""
.. and set u'r appropriate version here for INTEL?
Regards,
Roger",also webui user sh simpler method tested try install command torch export torch command pip install torch cu extra index url set u r appropriate version intel regards roger
auto1111_webui,comment,17047,,"I believe my issue in #17047 is slightly different. PyTorch itself correctly detects the XPU (as `torch.xpu.is_available()` returns `True`). The core problem is that the Stable Diffusion WebUI application fails to detect the XPU and falls back to CPU. This happens because it still attempts to import `intel_extension_for_pytorch`, which is no longer separately necessary with newer PyTorch versions (like 2.7.1+XPU) that integrate this functionality directly.

My proposed solution aims to update the detection logic in `modules/xpu_specific.py` to directly query `torch.xpu.is_available()`, removing the dependency on the separate extension module.

Hope this clarifies the distinction. Thanks!",2025-06-30T14:47:42Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3019456144,"I believe my issue in #17047 is slightly different. PyTorch itself correctly detects the XPU (as `torch.xpu.is_available()` returns `True`). The core problem is that the Stable Diffusion WebUI application fails to detect the XPU and falls back to CPU. This happens because it still attempts to import `intel_extension_for_pytorch`, which is no longer separately necessary with newer PyTorch versions (like 2.7.1+XPU) that integrate this functionality directly.

My proposed solution aims to update the detection logic in `modules/xpu_specific.py` to directly query `torch.xpu.is_available()`, removing the dependency on the separate extension module.

Hope this clarifies the distinction. Thanks!",believe issue slightly different pytorch correctly detects xpu torch xpu available returns true core problem stable diffusion webui application fails detect xpu falls back cpu happens still attempts import intel extension pytorch longer separately necessary newer pytorch versions like xpu integrate functionality directly proposed solution aims update detection logic modules xpu specific py directly query torch xpu available removing dependency separate extension module hope clarifies distinction thanks
auto1111_webui,comment,17047,,"@DrThodt2021 
Well, ok, sorry for this misunderstanding.
So, just to get u right, since I still always have to fiddle around with the correct packages on Torch and Pytorch4ARC GPU:
Is it right that u say that latest packages from python on torch will suffice?
And that those packages from Intel's repos are still no longer necessary?
Thanks for clearing up to me.
Regards,
Roger",2025-06-30T16:13:11Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3019811071,"@DrThodt2021 
Well, ok, sorry for this misunderstanding.
So, just to get u right, since I still always have to fiddle around with the correct packages on Torch and Pytorch4ARC GPU:
Is it right that u say that latest packages from python on torch will suffice?
And that those packages from Intel's repos are still no longer necessary?
Thanks for clearing up to me.
Regards,
Roger",drthodt well ok sorry misunderstanding get u right since still always fiddle around correct packages torch pytorch arc gpu right u say latest packages python torch suffice packages intel repos still longer necessary thanks clearing regards roger
auto1111_webui,comment,17047,,"I don't know if 2.7.1+XPU is the latest package; I just followed [this guide](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821) for installation. After that, it should **technically** work, but it doesn't, because of how Automatic1111 tries to recognize the XPU capability of the hardware.

As described, Automatic checks if `--use-ipex` is set **AND** if `intel_extension_for_pytorch` is installed. With PyTorch 2.7.1+XPU already installed and working, the **additional** `Intel_extension_for_pytorch module` is not needed, which causes this check to fail. Consequently, Automatic1111 uses the CPU instead of the GPU.

I forced Automatic1111 to use the GPU by changing a default value in `modules/devices.py`. While this workaround functions in my setup, it's not a safe or proper long-term solution. That's why I provided a concept for a better mechanism to recognize the XPU capability.",2025-06-30T19:44:57Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3020487996,"I don't know if 2.7.1+XPU is the latest package; I just followed [this guide](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821) for installation. After that, it should **technically** work, but it doesn't, because of how Automatic1111 tries to recognize the XPU capability of the hardware.

As described, Automatic checks if `--use-ipex` is set **AND** if `intel_extension_for_pytorch` is installed. With PyTorch 2.7.1+XPU already installed and working, the **additional** `Intel_extension_for_pytorch module` is not needed, which causes this check to fail. Consequently, Automatic1111 uses the CPU instead of the GPU.

I forced Automatic1111 to use the GPU by changing a default value in `modules/devices.py`. While this workaround functions in my setup, it's not a safe or proper long-term solution. That's why I provided a concept for a better mechanism to recognize the XPU capability.",know xpu latest package followed guide installation technically work automatic tries recognize xpu capability hardware described automatic checks use ipex set intel extension pytorch installed pytorch xpu already installed working additional intel extension pytorch module needed causes check fail consequently automatic uses cpu instead gpu forced automatic use gpu changing default value modules devices py workaround functions setup safe proper long term solution provided concept better mechanism recognize xpu capability
auto1111_webui,comment,17047,,"@DrThodt2021:
Hmm, u'r right; I just now ran in to the same issue like u did, BUT trying to setup SDNext with '--use-ipex'. Also installed my own venv, not via using webui.sh, than:
'pip install torch==2.7.1+xpu torchvision==0.22.1+xpu torchaudio==2.7.1+xpu intel-cmplr-lib-rt intel-cmplr-lib-ur intel-cmplr-lic-rt intel-sycl-rt ' like in u'r link,
and when starting/running/first booting with 'python launch.py --debug --use-ipex' I get:
RuntimeError: No XPU devices are available.
So, I will try to also noe additionally to install Intel's extensions for pytorch an report back.
Regards,
Roger",2025-07-01T16:03:42Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3024642967,"@DrThodt2021:
Hmm, u'r right; I just now ran in to the same issue like u did, BUT trying to setup SDNext with '--use-ipex'. Also installed my own venv, not via using webui.sh, than:
'pip install torch==2.7.1+xpu torchvision==0.22.1+xpu torchaudio==2.7.1+xpu intel-cmplr-lib-rt intel-cmplr-lib-ur intel-cmplr-lic-rt intel-sycl-rt ' like in u'r link,
and when starting/running/first booting with 'python launch.py --debug --use-ipex' I get:
RuntimeError: No XPU devices are available.
So, I will try to also noe additionally to install Intel's extensions for pytorch an report back.
Regards,
Roger",drthodt hmm u r right ran issue like u trying setup sdnext use ipex also installed venv via using webui sh pip install torch xpu torchvision xpu torchaudio xpu intel cmplr lib rt intel cmplr lib ur intel cmplr lic rt intel sycl rt like u r link starting running first booting python launch py debug use ipex get runtimeerror xpu devices available try also noe additionally install intel extensions pytorch report back regards roger
auto1111_webui,comment,17047,,"BTW: may u tell me which entry u added in modules/devices.py?
Roger",2025-07-01T16:04:25Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3024645570,"BTW: may u tell me which entry u added in modules/devices.py?
Roger",btw may u tell entry u added modules devices py roger
auto1111_webui,comment,17047,,"Sure. Search for `def get_optimal_device_name():` (approx. at line 50):

```Python
 if torch.cuda.is_available():
        return get_cuda_device_string()

    if has_mps():
        return ""mps""

    if has_xpu():
        return xpu_specific.get_xpu_device_string()

    if npu_specific.has_npu:
        return npu_specific.get_npu_device_string()

    return ""cpu""
```

The last line `return ""cpu""` determine the ""default"" state, which ist used if the above checks (cuda, mps, xpu, npu) fails. I just changed this to `return ""xpu""`. This forces Automatic1111 to use xpu as default (even if the check before failed) and will probably fail if you don't have a propper set up XPU device. So this may work, but it's not recommended, exept you're absolutly sure you have a propper set up XPU GPU.",2025-07-01T19:11:35Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3025217693,"Sure. Search for `def get_optimal_device_name():` (approx. at line 50):

```Python
 if torch.cuda.is_available():
        return get_cuda_device_string()

    if has_mps():
        return ""mps""

    if has_xpu():
        return xpu_specific.get_xpu_device_string()

    if npu_specific.has_npu:
        return npu_specific.get_npu_device_string()

    return ""cpu""
```

The last line `return ""cpu""` determine the ""default"" state, which ist used if the above checks (cuda, mps, xpu, npu) fails. I just changed this to `return ""xpu""`. This forces Automatic1111 to use xpu as default (even if the check before failed) and will probably fail if you don't have a propper set up XPU device. So this may work, but it's not recommended, exept you're absolutly sure you have a propper set up XPU GPU.",sure search def get optimal device name approx line python torch cuda available return get cuda device string mps return mps xpu return xpu specific get xpu device string npu specific npu return npu specific get npu device string return cpu last line return cpu determine default state ist used checks cuda mps xpu npu fails changed return xpu forces automatic use xpu default even check failed probably fail propper set xpu device may work recommended exept absolutly sure propper set xpu gpu
auto1111_webui,comment,17047,,You may try [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) which is currently maintained and support OpenVINO and IPEX im my opinion. ,2025-07-10T06:05:29Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3055723298,You may try [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) which is currently maintained and support OpenVINO and IPEX im my opinion.,may try sd next currently maintained support openvino ipex im opinion
auto1111_webui,comment,17047,,"I would agree, if you can explan me how to overcome the 75 token limit in SD.Next",2025-07-10T14:35:25Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3057714722,"I would agree, if you can explan me how to overcome the 75 token limit in SD.Next",would agree explan overcome token limit sd next
auto1111_webui,issue,17046,[Bug]: error code 128,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

new to install, when running webui-user.bat, this happened..

### Steps to reproduce the problem

open webui-user.bat

### What should have happened?

run ui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

is this necessary to this problem? tell me if it is i'll re-edit that

### Console logs

```Shell
venv ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Couldn't determine assets's hash: 6f7db241d2f8ba7457bac5ca9753331f0c266917, attempting autofix...
Fetching all contents for assets
fatal: detected dubious ownership in repository at 'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets'
'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets' is on a file system that does not record ownership
To add an exception for this directory, call:

        git config --global --add safe.directory D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets
Traceback (most recent call last):
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 411, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch assets.
Command: ""git"" -C ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\repositories\stable-diffusion-webui-assets"" fetch --refetch --no-auto-gc
Error code: 128
请按任意键继续. . .
```

### Additional information

i don't actually know what's going on, i have seen others reported about error code 128 and still not fixed yet...",2025-06-27T22:33:06Z,emai24volts,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17046,"[Bug]: error code 128 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

new to install, when running webui-user.bat, this happened..

### Steps to reproduce the problem

open webui-user.bat

### What should have happened?

run ui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

is this necessary to this problem? tell me if it is i'll re-edit that

### Console logs

```Shell
venv ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Couldn't determine assets's hash: 6f7db241d2f8ba7457bac5ca9753331f0c266917, attempting autofix...
Fetching all contents for assets
fatal: detected dubious ownership in repository at 'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets'
'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets' is on a file system that does not record ownership
To add an exception for this directory, call:

        git config --global --add safe.directory D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets
Traceback (most recent call last):
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 411, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch assets.
Command: ""git"" -C ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\repositories\stable-diffusion-webui-assets"" fetch --refetch --no-auto-gc
Error code: 128
请按任意键继续. . .
```

### Additional information

i don't actually know what's going on, i have seen others reported about error code 128 and still not fixed yet...",bug error code checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently x issue reported fixed yet happened new install running webui user bat happened steps reproduce problem open webui user bat happened run ui browsers use access ui google chrome sysinfo necessary problem tell edit console logs shell venv sdui stable diffusion webui master stable diffusion webui master venv scripts python exe fatal git repository parent directories git fatal git repository parent directories git python tags v c b bd aug msc v bit amd version commit hash none determine assets hash f db f ba bac ca f c attempting autofix fetching contents assets fatal detected dubious ownership repository sdui stable diffusion webui master stable diffusion webui master repositories stable diffusion webui assets sdui stable diffusion webui master stable diffusion webui master repositories stable diffusion webui assets file system record ownership add exception directory call git config global add safe directory sdui stable diffusion webui master stable diffusion webui master repositories stable diffusion webui assets traceback recent call last file sdui stable diffusion webui master stable diffusion webui master launch py line module main file sdui stable diffusion webui master stable diffusion webui master launch py line main prepare environment file sdui stable diffusion webui master stable diffusion webui master modules launch utils py line prepare environment git clone assets repo repo dir stable diffusion webui assets assets assets commit hash file sdui stable diffusion webui master stable diffusion webui master modules launch utils py line git clone current hash run git dir name rev parse head none f determine name hash commithash live false strip file sdui stable diffusion webui master stable diffusion webui master modules launch utils py line run git git fix workspace dir name file sdui stable diffusion webui master stable diffusion webui master modules launch utils py line git fix workspace run f git c dir fetch refetch auto gc f fetching contents name f fetch name live true file sdui stable diffusion webui master stable diffusion webui master modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch assets command git c sdui stable diffusion webui master stable diffusion webui master repositories stable diffusion webui assets fetch refetch auto gc error code additional information actually know going seen others reported error code still fixed yet
auto1111_webui,comment,17046,,"to reinstall using windows-method-1 on teh wiki
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1",2025-06-27T23:06:05Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17046#issuecomment-3014589842,"to reinstall using windows-method-1 on teh wiki
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1",reinstall using windows method teh wiki
auto1111_webui,issue,17041,[Bug]: Cannot do inpainting,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Nothing happens.

### Steps to reproduce the problem

Try to do inpainting on blackwell gpu (setup with torch 2.7.0+cu128 and xformers 0.0.30)

### What should have happened?

Inpainting should work.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-24-02-04.json](https://github.com/user-attachments/files/20874601/sysinfo-2025-06-24-02-04.json)

### Console logs

```Shell
Traceback (most recent call last):███████████████████████████████| 32/32 [00:13<00:00,  2.14it/s]
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 270, in preprocess
    assert isinstance(x, dict)
           ^^^^^^^^^^^^^^^^^^^
AssertionError
```

Sometimes I get this instead:

```
Traceback (most recent call last):
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 290, in preprocess
    mask_im = processing_utils.decode_base64_to_image(mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 58, in decode_base64_to_image
    image_encoded = extract_base64_data(encoding)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 49, in extract_base64_data
    return x.rsplit("","", 1)[-1]
           ^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'rsplit'
```

### Additional information

_No response_",2025-06-24T02:04:40Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041,"[Bug]: Cannot do inpainting ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Nothing happens.

### Steps to reproduce the problem

Try to do inpainting on blackwell gpu (setup with torch 2.7.0+cu128 and xformers 0.0.30)

### What should have happened?

Inpainting should work.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-24-02-04.json](https://github.com/user-attachments/files/20874601/sysinfo-2025-06-24-02-04.json)

### Console logs

```Shell
Traceback (most recent call last):███████████████████████████████| 32/32 [00:13<00:00,  2.14it/s]
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 270, in preprocess
    assert isinstance(x, dict)
           ^^^^^^^^^^^^^^^^^^^
AssertionError
```

Sometimes I get this instead:

```
Traceback (most recent call last):
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 290, in preprocess
    mask_im = processing_utils.decode_base64_to_image(mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 58, in decode_base64_to_image
    image_encoded = extract_base64_data(encoding)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 49, in extract_base64_data
    return x.rsplit("","", 1)[-1]
           ^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'rsplit'
```

### Additional information

_No response_",bug cannot inpainting checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened nothing happens steps reproduce problem try inpainting blackwell gpu setup torch cu xformers happened inpainting work browsers use access ui google chrome sysinfo sysinfo json console logs shell traceback recent call last file opt sdwebui venv lib python site packages gradio routes py line run predict output await app get blocks process api file opt sdwebui venv lib python site packages gradio blocks py line process api inputs self preprocess data fn index inputs state file opt sdwebui venv lib python site packages gradio blocks py line preprocess data processed input append block preprocess inputs file opt sdwebui venv lib python site packages gradio components image py line preprocess assert isinstance x dict assertionerror sometimes get instead traceback recent call last file opt sdwebui venv lib python site packages gradio routes py line run predict output await app get blocks process api file opt sdwebui venv lib python site packages gradio blocks py line process api inputs self preprocess data fn index inputs state file opt sdwebui venv lib python site packages gradio blocks py line preprocess data processed input append block preprocess inputs file opt sdwebui venv lib python site packages gradio components image py line preprocess mask im processing utils decode base image mask file opt sdwebui venv lib python site packages gradio processing utils py line decode base image image encoded extract base data encoding file opt sdwebui venv lib python site packages gradio processing utils py line extract base data return x rsplit attributeerror nonetype object attribute rsplit additional information response
auto1111_webui,comment,17041,,"coming from we believe that this has to do with your 5080 GPU
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussioncomment-13563587

but looking at the logs you provided it does not seem to me that this has anything to do with pytorch or your GPU 5080

from what I can tell for some reason the user interface / webpage is broken

I cannot be certain this case but this seems similar to what would happen sometimes when you have multiple tabs of web UI (webpage) open in browser, then you install / update / enable / disable an extension, after clicking apply to applying and restarting the server, you then use another webui tab that was open before the restart to generated an image, then you might see similar error

this is because when changing extension configurations it might also cause some UI elements to change, and when you try to communicate on our old web page that sends the old configurations to the server things don't line up properly and cause things to break

> I remember some one say that this might also happen just by restarting the server but me personally have not experienced this

---

I guess by this point you have already tried restarting your server and reloading the web page
if restart and reload didn't fix it then I would suggest a clean installation
> If you do so also I recommend you use `git` and switch to `dev` branch
",2025-06-25T12:59:46Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041#issuecomment-3004684998,"coming from we believe that this has to do with your 5080 GPU
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussioncomment-13563587

but looking at the logs you provided it does not seem to me that this has anything to do with pytorch or your GPU 5080

from what I can tell for some reason the user interface / webpage is broken

I cannot be certain this case but this seems similar to what would happen sometimes when you have multiple tabs of web UI (webpage) open in browser, then you install / update / enable / disable an extension, after clicking apply to applying and restarting the server, you then use another webui tab that was open before the restart to generated an image, then you might see similar error

this is because when changing extension configurations it might also cause some UI elements to change, and when you try to communicate on our old web page that sends the old configurations to the server things don't line up properly and cause things to break

> I remember some one say that this might also happen just by restarting the server but me personally have not experienced this

---

I guess by this point you have already tried restarting your server and reloading the web page
if restart and reload didn't fix it then I would suggest a clean installation
> If you do so also I recommend you use `git` and switch to `dev` branch",coming believe gpu looking logs provided seem anything pytorch gpu tell reason user interface webpage broken cannot certain case seems similar would happen sometimes multiple tabs web ui webpage open browser install update enable disable extension clicking apply applying restarting server use another webui tab open restart generated image might see similar error changing extension configurations might also cause ui elements change try communicate old web page sends old configurations server things line properly cause things break remember one say might also happen restarting server personally experienced guess point already tried restarting server reloading web page restart reload fix would suggest clean installation also recommend use git switch dev branch
auto1111_webui,comment,17041,,"> I guess by this point you have already tried restarting your server and reloading the web page if restart and reload didn't fix it then I would suggest a clean installation
> 
> > If you do so also I recommend you use `git` and switch to `dev` branch

Yes, and I already tried doing a clean installation, it already kinda is a clean installation; but I have not tried the dev branch. If you say it seems the webui is broken maybe using another browser would work 🤔 

Yup, I didn't have another browser on hand, but I tried running it in electron, and it worked fine there.

My browser is ungoogled chromium, installed from the cachyos official package.

I believe the binary for my current version comes from here: https://github.com/ungoogled-software/ungoogled-chromium/archive/137.0.7151.119-1.tar.gz

seems like it's happening with default settings.",2025-06-25T22:14:44Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041#issuecomment-3006396191,"> I guess by this point you have already tried restarting your server and reloading the web page if restart and reload didn't fix it then I would suggest a clean installation
> 
> > If you do so also I recommend you use `git` and switch to `dev` branch

Yes, and I already tried doing a clean installation, it already kinda is a clean installation; but I have not tried the dev branch. If you say it seems the webui is broken maybe using another browser would work 🤔 

Yup, I didn't have another browser on hand, but I tried running it in electron, and it worked fine there.

My browser is ungoogled chromium, installed from the cachyos official package.

I believe the binary for my current version comes from here: https://github.com/ungoogled-software/ungoogled-chromium/archive/137.0.7151.119-1.tar.gz

seems like it's happening with default settings.",guess point already tried restarting server reloading web page restart reload fix would suggest clean installation also recommend use git switch dev branch yes already tried clean installation already kinda clean installation tried dev branch say seems webui broken maybe using another browser would work yup another browser hand tried running electron worked fine browser ungoogled chromium installed cachyos official package believe binary current version comes seems like happening default settings
auto1111_webui,issue,17037,[Bug]: 图像缩放后位置出错,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

使用 shift 和 wheel 放大 img2img canvus，当图像再次出现时不在正确的位置。只能使用 CTRL+滚轮进行 Edge Web 浏览器页面缩放，将其放回正确的位置。大部分时间都有效，但有时出错，不得不再做一次

### Steps to reproduce the problem

将图片导入 img2img，使用 Shift 和鼠标滚轮放大，然后缩小，图片不会居中，如果使用 CRTL + 鼠标滚轮，它会改变 Web 浏览器的缩放，才能使图片放回它应该在的位置。然而在某些情况下，图像消失了。之后它仍然会生成，但之后不能再进行任何修复。（需要多次操作才可能触发此bug)

### What should have happened?

页面缩放应将图像放回正确的位置

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now

### Console logs

```Shell
Nothing in logs other than image generations I was doing
```

### Additional information

_No response_",2025-06-19T14:29:39Z,SUN-myriad,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17037,"[Bug]: 图像缩放后位置出错 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

使用 shift 和 wheel 放大 img2img canvus，当图像再次出现时不在正确的位置。只能使用 CTRL+滚轮进行 Edge Web 浏览器页面缩放，将其放回正确的位置。大部分时间都有效，但有时出错，不得不再做一次

### Steps to reproduce the problem

将图片导入 img2img，使用 Shift 和鼠标滚轮放大，然后缩小，图片不会居中，如果使用 CRTL + 鼠标滚轮，它会改变 Web 浏览器的缩放，才能使图片放回它应该在的位置。然而在某些情况下，图像消失了。之后它仍然会生成，但之后不能再进行任何修复。（需要多次操作才可能触发此bug)

### What should have happened?

页面缩放应将图像放回正确的位置

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now

### Console logs

```Shell
Nothing in logs other than image generations I was doing
```

### Additional information

_No response_",bug checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened shift wheel img img canvus ctrl edge web steps reproduce problem img img shift crtl web bug happened browsers use access ui microsoft edge sysinfo sorry unable right console logs shell nothing logs image generations additional information response
auto1111_webui,issue,17035,[Bug]: images corrupting on last step with euler / euler a,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

in txt2img when i generate an image, its fine during generation but corrupts at the last second when specifically using euler / euler a

### Steps to reproduce the problem

1. use img2img
2. select euler or euler a
3. generate

### What should have happened?

image should have output with no corruption, this was working fine yesterday. i changed nothing

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-06-18-02-40.json](https://github.com/user-attachments/files/20787614/sysinfo-2025-06-18-02-40.json)

### Console logs

```Shell
don't know how to do this, but there's no obvious errors
```

### Additional information

_No response_",2025-06-18T02:41:01Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035,"[Bug]: images corrupting on last step with euler / euler a ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

in txt2img when i generate an image, its fine during generation but corrupts at the last second when specifically using euler / euler a

### Steps to reproduce the problem

1. use img2img
2. select euler or euler a
3. generate

### What should have happened?

image should have output with no corruption, this was working fine yesterday. i changed nothing

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-06-18-02-40.json](https://github.com/user-attachments/files/20787614/sysinfo-2025-06-18-02-40.json)

### Console logs

```Shell
don't know how to do this, but there's no obvious errors
```

### Additional information

_No response_",bug images corrupting last step euler euler checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened txt img generate image fine generation corrupts last second specifically using euler euler steps reproduce problem use img img select euler euler generate happened image output corruption working fine yesterday changed nothing browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell know obvious errors additional information response
auto1111_webui,comment,17035,,"![Image](https://github.com/user-attachments/assets/1c13ad36-4d29-473e-8799-4e7228e4c218)
^^ this is what i see while generating^^

![Image](https://github.com/user-attachments/assets/a2b01fb9-4336-41b4-a822-f81b1eaec4cf)
^^ this is what happens after generation is complete ^^",2025-06-18T02:41:47Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982452957,"![Image](https://github.com/user-attachments/assets/1c13ad36-4d29-473e-8799-4e7228e4c218)
^^ this is what i see while generating^^

![Image](https://github.com/user-attachments/assets/a2b01fb9-4336-41b4-a822-f81b1eaec4cf)
^^ this is what happens after generation is complete ^^",image see generating image happens generation complete
auto1111_webui,comment,17035,,"i tried restarting my computer, same problem. idk what happened, it was working fine yesterday",2025-06-18T02:48:09Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982465100,"i tried restarting my computer, same problem. idk what happened, it was working fine yesterday",tried restarting computer problem idk happened working fine yesterday
auto1111_webui,comment,17035,,"did some more testing, euler ONLY works with 25 steps, no more, no less. my friend tested different values and he has no issues. what's happening?
",2025-06-18T03:40:49Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982560712,"did some more testing, euler ONLY works with 25 steps, no more, no less. my friend tested different values and he has no issues. what's happening?",testing euler works steps less friend tested different values issues happening
auto1111_webui,comment,17035,,"Might be a VAE issue.  Often you'll have a good preview until the final step and then you'll get distortion.  Also, you might be able to try changing the scheduler type and fix it that way.",2025-08-10T03:25:40Z,ThatFuckingPanda,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-3172334042,"Might be a VAE issue.  Often you'll have a good preview until the final step and then you'll get distortion.  Also, you might be able to try changing the scheduler type and fix it that way.",might vae issue often good preview final step get distortion also might able try changing scheduler type fix way
auto1111_webui,issue,17032,[Bug]: Firewall issue causes SSLError when attempting to generate,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Using QBittorrent, I've installed the NAI4 model; with the models and attempting to use settings given to recreate a given image.

### Steps to reproduce the problem

No steps known.

### What should have happened?

The image should've generated.

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

[sysinfo-2025-06-13-16-53.json](https://github.com/user-attachments/files/20730124/sysinfo-2025-06-13-16-53.json)

### Console logs

```Shell
Due to Pastebin not accepting the file due to its sheer size (552 KB, 512 KB max) I have posted it to Drive.

https://drive.google.com/file/d/1Y1MR81VtIbUlljOF3gulo3CPGfJAiJjr/view?usp=sharing
```

### Additional information

This is the first run of the UI; I'm running an NVIDIA RTX 3060, I have 32 GB of RAM and a WD_BLACK SN770 1TB disk.",2025-06-13T17:00:59Z,Krmailence,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17032,"[Bug]: Firewall issue causes SSLError when attempting to generate ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Using QBittorrent, I've installed the NAI4 model; with the models and attempting to use settings given to recreate a given image.

### Steps to reproduce the problem

No steps known.

### What should have happened?

The image should've generated.

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

[sysinfo-2025-06-13-16-53.json](https://github.com/user-attachments/files/20730124/sysinfo-2025-06-13-16-53.json)

### Console logs

```Shell
Due to Pastebin not accepting the file due to its sheer size (552 KB, 512 KB max) I have posted it to Drive.

https://drive.google.com/file/d/1Y1MR81VtIbUlljOF3gulo3CPGfJAiJjr/view?usp=sharing
```

### Additional information

This is the first run of the UI; I'm running an NVIDIA RTX 3060, I have 32 GB of RAM and a WD_BLACK SN770 1TB disk.",bug firewall issue causes sslerror attempting generate checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened using qbittorrent installed nai model models attempting use settings given recreate given image steps reproduce problem steps known happened image generated browsers use access ui chrome sysinfo sysinfo json console logs shell due pastebin accepting file due sheer size kb kb max posted drive additional information first run ui running nvidia rtx gb ram wd black sn tb disk
auto1111_webui,issue,17031,[Bug]: Error 403 trying to install pytorch,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh gives an error trying to install pytorch



### Steps to reproduce the problem

1. Clone the repo
2. Execute webui.sh
3. The error is there

### What should have happened?

Webui should have been installed.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cannot install it, but I have:

ArchLinux
Python 3.10
Ryzen 7 5800X3D, RX 5700XT, 32GB RAM, 240GB NVME with 140GB of free space. 

### Console logs

```Shell
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
./webui.sh: line 258: bc: command not found
./webui.sh: line 258: [: -eq: unary operator expected
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
fatal: No names found, cannot describe anything.
Python 3.10.18 (main, Jun 12 2025, 18:48:45) [GCC 15.1.1 20250425]
Version: f2.0.1v1.10.1-1.10.1
Commit hash: e07be6a48fc0ae1840b78d5e55ee36ab78396b30
ROCm: no agent was found
ROCm: version=None
Installing torch and torchvision
Collecting torch==2.0.0.dev20230209+rocm5.2
  ERROR: HTTP error 403 while getting https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
ERROR: Could not install requirement torch==2.0.0.dev20230209+rocm5.2 from https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl for URL https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Traceback (most recent call last):
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 54, in <module>
    main()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 42, in main
    prepare_environment()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 543, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 126, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/jaime/stable-diffusion-webui-amdgpu-forge/venv/bin/python"" -m pip install https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/nightly/rocm5.2/torchvision-0.15.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Error code: 1
```

### Additional information

_No response_",2025-06-12T20:03:12Z,Ciberbago,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031,"[Bug]: Error 403 trying to install pytorch ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh gives an error trying to install pytorch



### Steps to reproduce the problem

1. Clone the repo
2. Execute webui.sh
3. The error is there

### What should have happened?

Webui should have been installed.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cannot install it, but I have:

ArchLinux
Python 3.10
Ryzen 7 5800X3D, RX 5700XT, 32GB RAM, 240GB NVME with 140GB of free space. 

### Console logs

```Shell
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
./webui.sh: line 258: bc: command not found
./webui.sh: line 258: [: -eq: unary operator expected
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
fatal: No names found, cannot describe anything.
Python 3.10.18 (main, Jun 12 2025, 18:48:45) [GCC 15.1.1 20250425]
Version: f2.0.1v1.10.1-1.10.1
Commit hash: e07be6a48fc0ae1840b78d5e55ee36ab78396b30
ROCm: no agent was found
ROCm: version=None
Installing torch and torchvision
Collecting torch==2.0.0.dev20230209+rocm5.2
  ERROR: HTTP error 403 while getting https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
ERROR: Could not install requirement torch==2.0.0.dev20230209+rocm5.2 from https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl for URL https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Traceback (most recent call last):
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 54, in <module>
    main()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 42, in main
    prepare_environment()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 543, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 126, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/jaime/stable-diffusion-webui-amdgpu-forge/venv/bin/python"" -m pip install https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/nightly/rocm5.2/torchvision-0.15.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Error code: 1
```

### Additional information

_No response_",bug error trying install pytorch checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened webui sh gives error trying install pytorch steps reproduce problem clone repo execute webui sh error happened webui installed browsers use access ui response sysinfo cannot install archlinux python ryzen x rx xt gb ram gb nvme gb free space console logs shell launching launch py glibc version check tcmalloc libtcmalloc minimal webui sh line bc command found webui sh line eq unary operator expected libtcmalloc minimal linked libc execute ld preload usr lib libtcmalloc minimal fatal names found cannot describe anything python main jun gcc version f v commit hash e fc ae b e ee ab b rocm agent found rocm version none installing torch torchvision collecting torch dev rocm error http error getting error could install requirement torch dev rocm http error client error forbidden url url traceback recent call last file home jaime stable diffusion webui amdgpu forge launch py line module main file home jaime stable diffusion webui amdgpu forge launch py line main prepare environment file home jaime stable diffusion webui amdgpu forge modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file home jaime stable diffusion webui amdgpu forge modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command home jaime stable diffusion webui amdgpu forge venv bin python pip install error code additional information response
auto1111_webui,comment,17031,,"same error here with practically the same specs and same steps, I also reproduced this error with a stable version `v1.10.1` or cloning the `master` branch",2025-06-18T19:59:15Z,FabioNevesRezende,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-2985531510,"same error here with practically the same specs and same steps, I also reproduced this error with a stable version `v1.10.1` or cloning the `master` branch",error practically specs steps also reproduced error stable version v cloning master branch
auto1111_webui,comment,17031,,same error on OpenSuSe seems like pytorch changed the download location,2025-06-26T23:48:14Z,Exzellius,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3010694922,same error on OpenSuSe seems like pytorch changed the download location,error opensuse seems like pytorch changed download location
auto1111_webui,comment,17031,,Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url,2025-08-09T22:23:41Z,tk-1001,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3172140041,Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url,error rocm reddit post fixes removing nightly url
auto1111_webui,comment,17031,,"> Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url

Thanks. It works.",2025-08-18T13:31:08Z,metalg0su,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3196906315,"> Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url

Thanks. It works.",error rocm reddit post fixes removing nightly url thanks works
auto1111_webui,issue,17030,[Bug]: handrefinerportable: cannot import 'setuptools.build_meta' on ControlNet install,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControlNet, whenever I start Stable Diffusion, the installation of handrefinerportable==2024.2.12.0 begins. However, it always fails with the following error message:

Cannot import 'setuptools.build_meta'

I have already tried reinstalling ControlNet, but the error persists. 

### Steps to reproduce the problem

1. Install ControlNet.
2. Start Stable Diffusion: run.bat
3. The installation of handrefinerportable==2024.2.12.0 begins.
4. The error occurs: Cannot import 'setuptools.build_meta'. Warning: Failed to install handrefinerportable. Some processors will not work.

### What should have happened?

The installation of handrefinerportable should complete successfully without errors.

### What browsers do you use to access the UI ?

Google Chrome, Other

### Sysinfo

[sysinfo-2025-06-12-06-50.json](https://github.com/user-attachments/files/20703595/sysinfo-2025-06-12-06-50.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Installing sd-webui-controlnet requirement: mediapipe
Installing sd-webui-controlnet requirement: changing albumentations version from None to 1.4.3
Installing sd-webui-controlnet requirement: changing controlnet_aux version from None to 0.0.9
Installing sd-webui-controlnet requirement: insightface
Installing sd-webui-controlnet requirement: handrefinerportable
Couldn't install sd-webui-controlnet requirement: handrefinerportable.
Command: ""D:\SD\system\python\python.exe"" -m pip install -U https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl --prefer-binary
Error code: 2
stdout: Collecting handrefinerportable==2024.2.12.0
  Downloading https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl (13.1 MB)
     -------------------------------------- 13.1/13.1 MB 448.4 kB/s eta 0:00:00
Requirement already satisfied: mediapipe in d:\sd\system\python\lib\site-packages (from handrefinerportable==2024.2.12.0) (0.10.21)
Collecting rtree (from handrefinerportable==2024.2.12.0)
  Using cached rtree-1.4.0-py3-none-win_amd64.whl.metadata (2.1 kB)
Collecting trimesh[easy] (from handrefinerportable==2024.2.12.0)
  Using cached trimesh-4.6.12-py3-none-any.whl.metadata (18 kB)
Requirement already satisfied: absl-py in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (2.3.0)
Requirement already satisfied: attrs>=19.1.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.3.0)
Requirement already satisfied: flatbuffers>=2.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.2.10)
Requirement already satisfied: jax in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: jaxlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: matplotlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (3.10.3)
Requirement already satisfied: numpy<2 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (1.26.2)
Requirement already satisfied: opencv-contrib-python in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.11.0.86)
Requirement already satisfied: protobuf<5,>=4.25.3 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.25.8)
Requirement already satisfied: sounddevice>=0.4.4 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.5.2)
Requirement already satisfied: sentencepiece in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.2.0)
Requirement already satisfied: CFFI>=1.0 in d:\sd\system\python\lib\site-packages (from sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (1.17.1)
Requirement already satisfied: pycparser in d:\sd\system\python\lib\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (2.22)
Requirement already satisfied: ml_dtypes>=0.5.0 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (0.5.1)
Requirement already satisfied: opt_einsum in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (3.4.0)
Requirement already satisfied: scipy>=1.11.1 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (1.15.3)
Requirement already satisfied: contourpy>=1.0.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.3.2)
Requirement already satisfied: cycler>=0.10 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (4.58.2)
Requirement already satisfied: kiwisolver>=1.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.4.8)
Requirement already satisfied: packaging>=20.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (25.0)
Requirement already satisfied: pillow>=8 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (9.5.0)
Requirement already satisfied: pyparsing>=2.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (3.2.3)
Requirement already satisfied: python-dateutil>=2.7 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in d:\sd\system\python\lib\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.17.0)
Collecting colorlog (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)
Collecting manifold3d>=2.3.0 (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached manifold3d-3.1.1-cp310-cp310-win_amd64.whl.metadata (18 kB)
Requirement already satisfied: charset-normalizer in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Requirement already satisfied: lxml in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (5.4.0)
Requirement already satisfied: jsonschema in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (4.24.0)
Requirement already satisfied: networkx in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Collecting svg.path (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached svg.path-6.3-py2.py3-none-any.whl.metadata (13 kB)
Collecting pycollada (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached pycollada-0.9.tar.gz (109 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 105, in _run_wrapper
    status = _inner_run()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 96, in _inner_run
    return self.run(options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 68, in wrapper
    return func(self, options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 387, in run
    requirement_set = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 96, in resolve
    result = self._result = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 515, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 444, in resolve
    failure_criterion = self._attempt_to_pin_criterion(name)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 211, in _attempt_to_pin_criterion
    criteria = self._get_updated_criteria(candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 202, in _get_updated_criteria
    self._add_to_criteria(criteria, requirement, parent=candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 141, in _add_to_criteria
    if not criterion.candidates:
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\structs.py"", line 194, in __bool__
    return bool(self._sequence)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 163, in __bool__
    self._bool = any(self)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 147, in <genexpr>
    return (c for c in iterator if id(c) not in self._incompatible_ids)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 37, in _iter_built
    candidate = func()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 187, in _make_candidate_from_link
    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 233, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 306, in __init__
    super().__init__(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 159, in __init__
    self.dist = self._prepare()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 236, in _prepare
    dist = self._prepare_distribution()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 317, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 532, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 647, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 71, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 56, in prepare_distribution_metadata
    self._install_build_reqs(finder)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 126, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 103, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 702, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

Warning: Failed to install handrefinerportable. Some processors will not work.
Launching Web UI with arguments:
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: D:\SD\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-06-12 11:49:26,544 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [879db523c3] from D:\SD\webui\models\Stable-diffusion\dreamshaper_8.safetensors
Creating model from config: D:\SD\webui\configs\v1-inference.yaml
D:\SD\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-06-12 11:49:27,344 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 135.6s (prepare environment: 92.3s, import torch: 22.5s, import gradio: 9.2s, setup paths: 3.2s, initialize shared: 1.0s, other imports: 1.4s, load scripts: 4.4s, create ui: 0.7s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 3.5s (create model: 0.8s, apply weights to model: 2.2s, calculate empty prompt: 0.2s).
```

### Additional information

_No response_",2025-06-12T06:51:25Z,svnsnln,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17030,"[Bug]: handrefinerportable: cannot import 'setuptools.build_meta' on ControlNet install ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControlNet, whenever I start Stable Diffusion, the installation of handrefinerportable==2024.2.12.0 begins. However, it always fails with the following error message:

Cannot import 'setuptools.build_meta'

I have already tried reinstalling ControlNet, but the error persists. 

### Steps to reproduce the problem

1. Install ControlNet.
2. Start Stable Diffusion: run.bat
3. The installation of handrefinerportable==2024.2.12.0 begins.
4. The error occurs: Cannot import 'setuptools.build_meta'. Warning: Failed to install handrefinerportable. Some processors will not work.

### What should have happened?

The installation of handrefinerportable should complete successfully without errors.

### What browsers do you use to access the UI ?

Google Chrome, Other

### Sysinfo

[sysinfo-2025-06-12-06-50.json](https://github.com/user-attachments/files/20703595/sysinfo-2025-06-12-06-50.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Installing sd-webui-controlnet requirement: mediapipe
Installing sd-webui-controlnet requirement: changing albumentations version from None to 1.4.3
Installing sd-webui-controlnet requirement: changing controlnet_aux version from None to 0.0.9
Installing sd-webui-controlnet requirement: insightface
Installing sd-webui-controlnet requirement: handrefinerportable
Couldn't install sd-webui-controlnet requirement: handrefinerportable.
Command: ""D:\SD\system\python\python.exe"" -m pip install -U https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl --prefer-binary
Error code: 2
stdout: Collecting handrefinerportable==2024.2.12.0
  Downloading https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl (13.1 MB)
     -------------------------------------- 13.1/13.1 MB 448.4 kB/s eta 0:00:00
Requirement already satisfied: mediapipe in d:\sd\system\python\lib\site-packages (from handrefinerportable==2024.2.12.0) (0.10.21)
Collecting rtree (from handrefinerportable==2024.2.12.0)
  Using cached rtree-1.4.0-py3-none-win_amd64.whl.metadata (2.1 kB)
Collecting trimesh[easy] (from handrefinerportable==2024.2.12.0)
  Using cached trimesh-4.6.12-py3-none-any.whl.metadata (18 kB)
Requirement already satisfied: absl-py in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (2.3.0)
Requirement already satisfied: attrs>=19.1.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.3.0)
Requirement already satisfied: flatbuffers>=2.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.2.10)
Requirement already satisfied: jax in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: jaxlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: matplotlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (3.10.3)
Requirement already satisfied: numpy<2 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (1.26.2)
Requirement already satisfied: opencv-contrib-python in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.11.0.86)
Requirement already satisfied: protobuf<5,>=4.25.3 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.25.8)
Requirement already satisfied: sounddevice>=0.4.4 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.5.2)
Requirement already satisfied: sentencepiece in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.2.0)
Requirement already satisfied: CFFI>=1.0 in d:\sd\system\python\lib\site-packages (from sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (1.17.1)
Requirement already satisfied: pycparser in d:\sd\system\python\lib\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (2.22)
Requirement already satisfied: ml_dtypes>=0.5.0 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (0.5.1)
Requirement already satisfied: opt_einsum in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (3.4.0)
Requirement already satisfied: scipy>=1.11.1 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (1.15.3)
Requirement already satisfied: contourpy>=1.0.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.3.2)
Requirement already satisfied: cycler>=0.10 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (4.58.2)
Requirement already satisfied: kiwisolver>=1.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.4.8)
Requirement already satisfied: packaging>=20.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (25.0)
Requirement already satisfied: pillow>=8 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (9.5.0)
Requirement already satisfied: pyparsing>=2.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (3.2.3)
Requirement already satisfied: python-dateutil>=2.7 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in d:\sd\system\python\lib\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.17.0)
Collecting colorlog (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)
Collecting manifold3d>=2.3.0 (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached manifold3d-3.1.1-cp310-cp310-win_amd64.whl.metadata (18 kB)
Requirement already satisfied: charset-normalizer in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Requirement already satisfied: lxml in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (5.4.0)
Requirement already satisfied: jsonschema in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (4.24.0)
Requirement already satisfied: networkx in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Collecting svg.path (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached svg.path-6.3-py2.py3-none-any.whl.metadata (13 kB)
Collecting pycollada (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached pycollada-0.9.tar.gz (109 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 105, in _run_wrapper
    status = _inner_run()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 96, in _inner_run
    return self.run(options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 68, in wrapper
    return func(self, options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 387, in run
    requirement_set = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 96, in resolve
    result = self._result = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 515, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 444, in resolve
    failure_criterion = self._attempt_to_pin_criterion(name)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 211, in _attempt_to_pin_criterion
    criteria = self._get_updated_criteria(candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 202, in _get_updated_criteria
    self._add_to_criteria(criteria, requirement, parent=candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 141, in _add_to_criteria
    if not criterion.candidates:
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\structs.py"", line 194, in __bool__
    return bool(self._sequence)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 163, in __bool__
    self._bool = any(self)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 147, in <genexpr>
    return (c for c in iterator if id(c) not in self._incompatible_ids)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 37, in _iter_built
    candidate = func()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 187, in _make_candidate_from_link
    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 233, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 306, in __init__
    super().__init__(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 159, in __init__
    self.dist = self._prepare()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 236, in _prepare
    dist = self._prepare_distribution()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 317, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 532, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 647, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 71, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 56, in prepare_distribution_metadata
    self._install_build_reqs(finder)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 126, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 103, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 702, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

Warning: Failed to install handrefinerportable. Some processors will not work.
Launching Web UI with arguments:
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: D:\SD\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-06-12 11:49:26,544 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [879db523c3] from D:\SD\webui\models\Stable-diffusion\dreamshaper_8.safetensors
Creating model from config: D:\SD\webui\configs\v1-inference.yaml
D:\SD\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-06-12 11:49:27,344 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 135.6s (prepare environment: 92.3s, import torch: 22.5s, import gradio: 9.2s, setup paths: 3.2s, initialize shared: 1.0s, other imports: 1.4s, load scripts: 4.4s, create ui: 0.7s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 3.5s (create model: 0.8s, apply weights to model: 2.2s, calculate empty prompt: 0.2s).
```

### Additional information

_No response_",bug handrefinerportable cannot import setuptools build meta controlnet install checklist issue exists disabling extensions issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened installing controlnet whenever start stable diffusion installation handrefinerportable begins however always fails following error message cannot import setuptools build meta already tried reinstalling controlnet error persists steps reproduce problem install controlnet start stable diffusion run bat installation handrefinerportable begins error occurs cannot import setuptools build meta warning failed install handrefinerportable processors work happened installation handrefinerportable complete successfully without errors browsers use access ui google chrome sysinfo sysinfo json console logs shell python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements installing sd webui controlnet requirement mediapipe installing sd webui controlnet requirement changing albumentations version none installing sd webui controlnet requirement changing controlnet aux version none installing sd webui controlnet requirement insightface installing sd webui controlnet requirement handrefinerportable install sd webui controlnet requirement handrefinerportable command sd system python python exe pip install u prefer binary error code stdout collecting handrefinerportable downloading mb mb kb eta requirement already satisfied mediapipe sd system python lib site packages handrefinerportable collecting rtree handrefinerportable using cached rtree py none win amd whl metadata kb collecting trimesh easy handrefinerportable using cached trimesh py none whl metadata kb requirement already satisfied absl py sd system python lib site packages mediapipe handrefinerportable requirement already satisfied attrs sd system python lib site packages mediapipe handrefinerportable requirement already satisfied flatbuffers sd system python lib site packages mediapipe handrefinerportable requirement already satisfied jax sd system python lib site packages mediapipe handrefinerportable requirement already satisfied jaxlib sd system python lib site packages mediapipe handrefinerportable requirement already satisfied matplotlib sd system python lib site packages mediapipe handrefinerportable requirement already satisfied numpy sd system python lib site packages mediapipe handrefinerportable requirement already satisfied opencv contrib python sd system python lib site packages mediapipe handrefinerportable requirement already satisfied protobuf sd system python lib site packages mediapipe handrefinerportable requirement already satisfied sounddevice sd system python lib site packages mediapipe handrefinerportable requirement already satisfied sentencepiece sd system python lib site packages mediapipe handrefinerportable requirement already satisfied cffi sd system python lib site packages sounddevice mediapipe handrefinerportable requirement already satisfied pycparser sd system python lib site packages cffi sounddevice mediapipe handrefinerportable requirement already satisfied ml dtypes sd system python lib site packages jax mediapipe handrefinerportable requirement already satisfied opt einsum sd system python lib site packages jax mediapipe handrefinerportable requirement already satisfied scipy sd system python lib site packages jax mediapipe handrefinerportable requirement already satisfied contourpy sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied cycler sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied fonttools sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied kiwisolver sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied packaging sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied pillow sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied pyparsing sd system python lib site packages matplotlib mediapipe handrefinerportable requirement already satisfied python dateutil sd system python lib site packages matplotlib mediapipe handrefinerportable post requirement already satisfied six sd system python lib site packages python dateutil matplotlib mediapipe handrefinerportable collecting colorlog trimesh easy handrefinerportable using cached colorlog py none whl metadata kb collecting manifold trimesh easy handrefinerportable using cached manifold cp cp win amd whl metadata kb requirement already satisfied charset normalizer sd system python lib site packages trimesh easy handrefinerportable requirement already satisfied lxml sd system python lib site packages trimesh easy handrefinerportable requirement already satisfied jsonschema sd system python lib site packages trimesh easy handrefinerportable requirement already satisfied networkx sd system python lib site packages trimesh easy handrefinerportable collecting svg path trimesh easy handrefinerportable using cached svg path py py none whl metadata kb collecting pycollada trimesh easy handrefinerportable using cached pycollada tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done stderr error exception traceback recent call last file sd system python lib site packages pip internal cli base command py line run wrapper status inner run file sd system python lib site packages pip internal cli base command py line inner run return self run options args file sd system python lib site packages pip internal cli req command py line wrapper return func self options args file sd system python lib site packages pip internal commands install py line run requirement set resolver resolve file sd system python lib site packages pip internal resolution resolvelib resolver py line resolve result self result resolver resolve file sd system python lib site packages pip vendor resolvelib resolvers resolution py line resolve state resolution resolve requirements max rounds max rounds file sd system python lib site packages pip vendor resolvelib resolvers resolution py line resolve failure criterion self attempt pin criterion name file sd system python lib site packages pip vendor resolvelib resolvers resolution py line attempt pin criterion criteria self get updated criteria candidate file sd system python lib site packages pip vendor resolvelib resolvers resolution py line get updated criteria self add criteria criteria requirement parent candidate file sd system python lib site packages pip vendor resolvelib resolvers resolution py line add criteria criterion candidates file sd system python lib site packages pip vendor resolvelib structs py line bool return bool self sequence file sd system python lib site packages pip internal resolution resolvelib found candidates py line bool self bool self file sd system python lib site packages pip internal resolution resolvelib found candidates py line genexpr return c c iterator id c self incompatible ids file sd system python lib site packages pip internal resolution resolvelib found candidates py line iter built candidate func file sd system python lib site packages pip internal resolution resolvelib factory py line make candidate link base optional basecandidate self make base candidate link file sd system python lib site packages pip internal resolution resolvelib factory py line make base candidate link self link candidate cache link linkcandidate file sd system python lib site packages pip internal resolution resolvelib candidates py line init super init file sd system python lib site packages pip internal resolution resolvelib candidates py line init self dist self prepare file sd system python lib site packages pip internal resolution resolvelib candidates py line prepare dist self prepare distribution file sd system python lib site packages pip internal resolution resolvelib candidates py line prepare distribution return preparer prepare linked requirement self ireq parallel builds true file sd system python lib site packages pip internal operations prepare py line prepare linked requirement return self prepare linked requirement req parallel builds file sd system python lib site packages pip internal operations prepare py line prepare linked requirement dist get prepared distribution file sd system python lib site packages pip internal operations prepare py line get prepared distribution abstract dist prepare distribution metadata file sd system python lib site packages pip internal distributions sdist py line prepare distribution metadata self install build reqs finder file sd system python lib site packages pip internal distributions sdist py line install build reqs build reqs self get build requires wheel file sd system python lib site packages pip internal distributions sdist py line get build requires wheel return backend get requires build wheel file sd system python lib site packages pip internal utils misc py line get requires build wheel return super get requires build wheel config settings cs file sd system python lib site packages pip vendor pyproject hooks impl py line get requires build wheel return self call hook file sd system python lib site packages pip vendor pyproject hooks impl py line call hook raise backendunavailable pip vendor pyproject hooks impl backendunavailable cannot import setuptools build meta warning failed install handrefinerportable processors work launching web ui arguments module xformers processing without module xformers processing without module xformers proceeding without controlnet preprocessor location sd webui extensions sd webui controlnet annotator downloads controlnet info controlnet v loading weights db c sd webui models stable diffusion dreamshaper safetensors creating model config sd webui configs v inference yaml sd system python lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn controlnet info controlnet ui callback registered running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch applying attention optimization doggettx done model loaded create model apply weights model calculate empty prompt additional information response
auto1111_webui,comment,17030,,"Having the same issue, but with fvcore instead of handrefinerportable.

Edit: Following a tip from https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162 and manually running the install with --no-build-isolation added to the command seems to have fixed my issue. I'm not entirely aware of any risks involved using that option, I just tried it 'blindly'.",2025-12-03T09:33:43Z,KatonRyu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17030#issuecomment-3605910721,"Having the same issue, but with fvcore instead of handrefinerportable.

Edit: Following a tip from https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162 and manually running the install with --no-build-isolation added to the command seems to have fixed my issue. I'm not entirely aware of any risks involved using that option, I just tried it 'blindly'.",issue fvcore instead handrefinerportable edit following tip manually running install build isolation added command seems fixed issue entirely aware risks involved using option tried blindly
auto1111_webui,issue,17029,[Bug]: in hires. fix infinity loading,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Infinity loading with try use upscale ESRGAN_4x and 4x-UltraSharp. Loading to 49% and stoped.

My PC: 
MSI 4070 TI Super 16 gb VRAM
64gb DDR5
AMD Ryzen 9 7950X3D
ssd 1tb

![Image](https://github.com/user-attachments/assets/53bf0bf8-cb53-4360-99f5-a3340da79067)


### Steps to reproduce the problem

1. PNG info
2. Upload generated image
3. TextToImage
4. Setup setting from image
5. Generate with hires. fix
6. Ininity loading

### What should have happened?

Should ganarated image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-11-17-57.json](https://github.com/user-attachments/files/20695843/sysinfo-2025-06-11-17-57.json)

### Console logs

```Shell
venv ""D:\Git\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
D:\Git\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [aaee0efd7c] from D:\Git\stable-diffusion-webui\models\Stable-diffusion\nova3DCGXL_illustriousV30.safetensors
Running on local URL:  http://127.0.0.1:7860
Creating model from config: D:\Git\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml

To create a public link, set `share=True` in `launch()`.
D:\Git\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 6.8s (prepare environment: 1.5s, import torch: 2.5s, import gradio: 0.6s, setup paths: 0.4s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 4.1s (load weights from disk: 0.4s, create model: 0.3s, apply weights to model: 3.0s, calculate empty prompt: 0.1s).
100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.60it/s]
==========================================================================================0/75 [00:09<00:04,  5.60it/s]
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
==========================================================================================
tiled upscale: 100%|███████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00,  9.63it/s]
```

### Additional information

_No response_",2025-06-11T17:59:32Z,ostryzhnyi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17029,"[Bug]: in hires. fix infinity loading ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Infinity loading with try use upscale ESRGAN_4x and 4x-UltraSharp. Loading to 49% and stoped.

My PC: 
MSI 4070 TI Super 16 gb VRAM
64gb DDR5
AMD Ryzen 9 7950X3D
ssd 1tb

![Image](https://github.com/user-attachments/assets/53bf0bf8-cb53-4360-99f5-a3340da79067)


### Steps to reproduce the problem

1. PNG info
2. Upload generated image
3. TextToImage
4. Setup setting from image
5. Generate with hires. fix
6. Ininity loading

### What should have happened?

Should ganarated image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-11-17-57.json](https://github.com/user-attachments/files/20695843/sysinfo-2025-06-11-17-57.json)

### Console logs

```Shell
venv ""D:\Git\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
D:\Git\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [aaee0efd7c] from D:\Git\stable-diffusion-webui\models\Stable-diffusion\nova3DCGXL_illustriousV30.safetensors
Running on local URL:  http://127.0.0.1:7860
Creating model from config: D:\Git\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml

To create a public link, set `share=True` in `launch()`.
D:\Git\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 6.8s (prepare environment: 1.5s, import torch: 2.5s, import gradio: 0.6s, setup paths: 0.4s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 4.1s (load weights from disk: 0.4s, create model: 0.3s, apply weights to model: 3.0s, calculate empty prompt: 0.1s).
100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.60it/s]
==========================================================================================0/75 [00:09<00:04,  5.60it/s]
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
==========================================================================================
tiled upscale: 100%|███████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00,  9.63it/s]
```

### Additional information

_No response_",bug hires fix infinity loading checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened infinity loading try use upscale esrgan x x ultrasharp loading stoped pc msi ti super gb vram gb ddr amd ryzen x ssd tb image steps reproduce problem png info upload generated image texttoimage setup setting image generate hires fix ininity loading happened ganarated image browsers use access ui google chrome sysinfo sysinfo json console logs shell venv git stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments git stable diffusion webui venv lib site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without loading weights aaee efd c git stable diffusion webui models stable diffusion nova dcgxl illustriousv safetensors running local url creating model config git stable diffusion webui repositories generative models configs inference sd xl base yaml create public link set share true launch git stable diffusion webui venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch applying attention optimization doggettx done model loaded load weights disk create model apply weights model calculate empty prompt tensor nans produced vae web ui convert vae bit float retry disable behavior disable automatically revert vae bit floats setting always start bit vae use half vae commandline flag tiled upscale additional information response
auto1111_webui,comment,17029,,"likely a case of running low on vram

99% (and 49% when hires fix) is where webui dose VAE decode stage of the sd image gen process
because we don't have a progress showing the VAE decode stage if it taks a long time performing VAE decode it will seems like it 
so it might loosk like it's frozen

VAE decode is notorious in causing a vram usage spike

I have a 3090 with 24GB VRAM, so in order to test what happens on 16GB VRAM, I ran a script to fill my VRAM with 10 GB of junk and keep the junk in active use
> I filled 10 GB of junk and not 8G to compensate for other programs using vram on your system

then I ran a XL model at 768x768 + 2x hires pass
whill my run did not completely froze at 49% and 99%, it does take significantly longer during that stage then it usual would whithout the 10GB of junk that stage 

so I concluded that you're likely running out of VRAM

---

### suggestions to resolve the issue

there are ways to reduce the VRAM usage

method built-in to webui include 

- try some optimizations
for example `--xformers`
also see settings > optimizations > Cross attention optimization
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

- try `--medvram` or `--lowvram`
this reduce vram usage at the cose of performance

- alternatively you can try Tiled VAE from Tiled Diffusion & VAE extension
https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111 

from there [wiki](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111/wiki/Tiled-VAE)
> Dramatically save your VRAM usage on VAE encoding / decoding
> It saves your VRAM at nearly no cost.
> You may not need --lowvram or --medvram anymore.
> You may not need --lowvram or --medv

---

other info
- XL models uses significantly more VRAM than 1.5
- generateing smaller images also has a smaller vram requirements

---

other issues you are getting

```
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
```

if webui is froced to switchs from 16 bit to 32-bit for VAE it also increase VRAM usage (webui use 16bit by default)
so when using XL models it is generally recommended that you switch your VAE to the SDXL 16bit fix VAE form https://huggingface.co/madebyollin/sdxl-vae-fp16-fix
https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors
",2025-06-12T12:15:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17029#issuecomment-2966460988,"likely a case of running low on vram

99% (and 49% when hires fix) is where webui dose VAE decode stage of the sd image gen process
because we don't have a progress showing the VAE decode stage if it taks a long time performing VAE decode it will seems like it 
so it might loosk like it's frozen

VAE decode is notorious in causing a vram usage spike

I have a 3090 with 24GB VRAM, so in order to test what happens on 16GB VRAM, I ran a script to fill my VRAM with 10 GB of junk and keep the junk in active use
> I filled 10 GB of junk and not 8G to compensate for other programs using vram on your system

then I ran a XL model at 768x768 + 2x hires pass
whill my run did not completely froze at 49% and 99%, it does take significantly longer during that stage then it usual would whithout the 10GB of junk that stage 

so I concluded that you're likely running out of VRAM

---

### suggestions to resolve the issue

there are ways to reduce the VRAM usage

method built-in to webui include 

- try some optimizations
for example `--xformers`
also see settings > optimizations > Cross attention optimization
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

- try `--medvram` or `--lowvram`
this reduce vram usage at the cose of performance

- alternatively you can try Tiled VAE from Tiled Diffusion & VAE extension
https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111 

from there [wiki](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111/wiki/Tiled-VAE)
> Dramatically save your VRAM usage on VAE encoding / decoding
> It saves your VRAM at nearly no cost.
> You may not need --lowvram or --medvram anymore.
> You may not need --lowvram or --medv

---

other info
- XL models uses significantly more VRAM than 1.5
- generateing smaller images also has a smaller vram requirements

---

other issues you are getting

```
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
```

if webui is froced to switchs from 16 bit to 32-bit for VAE it also increase VRAM usage (webui use 16bit by default)
so when using XL models it is generally recommended that you switch your VAE to the SDXL 16bit fix VAE form https://huggingface.co/madebyollin/sdxl-vae-fp16-fix
https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors",likely case running low vram hires fix webui dose vae decode stage sd image gen process progress showing vae decode stage taks long time performing vae decode seems like might loosk like frozen vae decode notorious causing vram usage spike gb vram order test happens gb vram ran script fill vram gb junk keep junk active use filled gb junk g compensate programs using vram system ran xl model x x hires pass whill run completely froze take significantly longer stage usual would whithout gb junk stage concluded likely running vram suggestions resolve issue ways reduce vram usage method built webui include try optimizations example xformers also see settings optimizations cross attention optimization try medvram lowvram reduce vram usage cose performance alternatively try tiled vae tiled diffusion vae extension wiki dramatically save vram usage vae encoding decoding saves vram nearly cost may need lowvram medvram anymore may need lowvram medv info xl models uses significantly vram generateing smaller images also smaller vram requirements issues getting tensor nans produced vae web ui convert vae bit float retry disable behavior disable automatically revert vae bit floats setting always start bit vae use half vae commandline flag webui froced switchs bit bit vae also increase vram usage webui use bit default using xl models generally recommended switch vae sdxl bit fix vae form
auto1111_webui,issue,17025,[Bug]: automatic install for AMD with ROCm throws CUDA error.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The automatic install script for AMD as said in https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs#automatic-installation 
Calls out for a CUDA GPU
```
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

The wiki says
```
(As of 1/15/23 you can just run webui.sh and pytorch+rocm should be automatically installed for you.)
```
So I would expect to not run into CUDA issues.

### Steps to reproduce the problem

1. Get a fresh installation of Linux (I use WSL with Ubuntu-24.04)
2. Install Python, git, python-env, etc. (Just setup your system)
3. clone the Webui and go to its directory
4. run `./webui.sh`

### What should have happened?

Installation should have continued without CUDA related issues.

### What browsers do you use to access the UI ?

Other

### Sysinfo

N/A

### Console logs

[logs.txt](https://github.com/user-attachments/files/20640281/logs.txt)
```Shell
// Full log uploaded here ^^

Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-11.2.1 requests-2.32.3 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0 typing-extensions-4.14.0 urllib3-2.4.0
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

### Additional information

I have the latest GPU driver and ROCm supports my GPU.
Environment is a WSL2 environment.
WSL can see my GPU as `rocminfo | grep 'Name'` proves.",2025-06-07T19:24:16Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025,"[Bug]: automatic install for AMD with ROCm throws CUDA error. ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The automatic install script for AMD as said in https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs#automatic-installation 
Calls out for a CUDA GPU
```
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

The wiki says
```
(As of 1/15/23 you can just run webui.sh and pytorch+rocm should be automatically installed for you.)
```
So I would expect to not run into CUDA issues.

### Steps to reproduce the problem

1. Get a fresh installation of Linux (I use WSL with Ubuntu-24.04)
2. Install Python, git, python-env, etc. (Just setup your system)
3. clone the Webui and go to its directory
4. run `./webui.sh`

### What should have happened?

Installation should have continued without CUDA related issues.

### What browsers do you use to access the UI ?

Other

### Sysinfo

N/A

### Console logs

[logs.txt](https://github.com/user-attachments/files/20640281/logs.txt)
```Shell
// Full log uploaded here ^^

Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-11.2.1 requests-2.32.3 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0 typing-extensions-4.14.0 urllib3-2.4.0
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

### Additional information

I have the latest GPU driver and ROCm supports my GPU.
Environment is a WSL2 environment.
WSL can see my GPU as `rocminfo | grep 'Name'` proves.",bug automatic install amd rocm throws cuda error checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened automatic install script amd said calls cuda gpu traceback recent call last file home ralkey stable diffusion webui launch py line module main file home ralkey stable diffusion webui launch py line main prepare environment file home ralkey stable diffusion webui modules launch utils py line prepare environment raise runtimeerror runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check wiki says run webui sh pytorch rocm automatically installed would expect run cuda issues steps reproduce problem get fresh installation linux use wsl ubuntu install python git python env etc setup system clone webui go directory run webui sh happened installation continued without cuda related issues browsers use access ui sysinfo n console logs logs txt shell full log uploaded downloading typing extensions py none whl kb installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna fsspec filelock charset normalizer certifi triton requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock fsspec idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu triton typing extensions urllib traceback recent call last file home ralkey stable diffusion webui launch py line module main file home ralkey stable diffusion webui launch py line main prepare environment file home ralkey stable diffusion webui modules launch utils py line prepare environment raise runtimeerror runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check additional information latest gpu driver rocm supports gpu environment wsl environment wsl see gpu rocminfo grep name proves
auto1111_webui,comment,17025,,"Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))

`source venv/bin/activate`
`pip3 uninstall torch torch vision`
`pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 
the last line will be the code from pytorch website of whatever the lastest version is`

",2025-06-30T00:54:39Z,shimzini,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3017385578,"Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))

`source venv/bin/activate`
`pip3 uninstall torch torch vision`
`pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 
the last line will be the code from pytorch website of whatever the lastest version is`",dunno still error already python use pyenv switch need uninstall torch venv reinstall latest rocm version worked basically go sd folder open terminal following commands find latest version pytorch rocm source venv bin activate pip uninstall torch torch vision pip install torch torchvision torchaudio index url last line code pytorch website whatever lastest version
auto1111_webui,comment,17025,,"> Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))
> 
> `source venv/bin/activate` `pip3 uninstall torch torch vision` `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` the last line will be the code from pytorch website of whatever the lastest version is`

Thank you, I'll try it out the next time I can.",2025-07-01T11:42:27Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3023593181,"> Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))
> 
> `source venv/bin/activate` `pip3 uninstall torch torch vision` `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` the last line will be the code from pytorch website of whatever the lastest version is`

Thank you, I'll try it out the next time I can.",dunno still error already python use pyenv switch need uninstall torch venv reinstall latest rocm version worked basically go sd folder open terminal following commands find latest version pytorch rocm source venv bin activate pip uninstall torch torch vision pip install torch torchvision torchaudio index url last line code pytorch website whatever lastest version thank try next time
auto1111_webui,comment,17025,,"> `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 

You wouldn't happen to know how to fix `ValueError: Memoryview is too large` error, would you?
I checked with `free -mh` and I got `47Gi` of memory available in WSL2.

",2025-07-02T21:01:15Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3029314173,"> `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 

You wouldn't happen to know how to fix `ValueError: Memoryview is too large` error, would you?
I checked with `free -mh` and I got `47Gi` of memory available in WSL2.",pip install torch torchvision torchaudio index url happen know fix valueerror memoryview large error would checked free mh got gi memory available wsl
auto1111_webui,comment,17025,,"Well I managed to install it with this command
`python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.org/whl/rocm6.3`

Full log:
```
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ source venv/bin/activate
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.or
g/whl/rocm6.3
Looking in indexes: https://download.pytorch.org/whl/rocm6.3
Collecting torch
  Downloading https://download.pytorch.org/whl/rocm6.3/torch-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (4543.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 GB 30.8 MB/s eta 0:00:00
Collecting torchvision
  Downloading https://download.pytorch.org/whl/rocm6.3/torchvision-0.22.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 31.6 MB/s eta 0:00:00
Collecting torchaudio
  Downloading https://download.pytorch.org/whl/rocm6.3/torchaudio-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (1.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 36.1 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.10/site-packages (from torch) (4.14.0)
Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2025.5.1)
Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.18.0)
Collecting pytorch-triton-rocm==3.3.1
  Downloading https://download.pytorch.org/whl/pytorch_triton_rocm-3.3.1-cp310-cp310-linux_x86_64.whl (254.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 254.2/254.2 MB 25.2 MB/s eta 0:00:00
Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch) (1.14.0)
Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from pytorch-triton-rocm==3.3.1->torch) (63.2.0)
Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from torchvision) (2.2.6)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (11.3.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)
Installing collected packages: pytorch-triton-rocm, torch, torchvision, torchaudio
Successfully installed pytorch-triton-rocm-3.3.1 torch-2.7.1+rocm6.3 torchaudio-2.7.1+rocm6.3 torchvision-0.22.1+rocm6.3
WARNING: There was an error checking the latest version of pip.
```

But it would seem that with the ROCm supported Torch, it still cannot use the GPU.
Since now I am getting this error.
```
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ deactivate
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on ralkey user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Jul  2 2025, 20:48:19) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```",2025-07-03T19:01:57Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3033313842,"Well I managed to install it with this command
`python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.org/whl/rocm6.3`

Full log:
```
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ source venv/bin/activate
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.or
g/whl/rocm6.3
Looking in indexes: https://download.pytorch.org/whl/rocm6.3
Collecting torch
  Downloading https://download.pytorch.org/whl/rocm6.3/torch-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (4543.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 GB 30.8 MB/s eta 0:00:00
Collecting torchvision
  Downloading https://download.pytorch.org/whl/rocm6.3/torchvision-0.22.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 31.6 MB/s eta 0:00:00
Collecting torchaudio
  Downloading https://download.pytorch.org/whl/rocm6.3/torchaudio-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (1.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 36.1 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.10/site-packages (from torch) (4.14.0)
Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2025.5.1)
Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.18.0)
Collecting pytorch-triton-rocm==3.3.1
  Downloading https://download.pytorch.org/whl/pytorch_triton_rocm-3.3.1-cp310-cp310-linux_x86_64.whl (254.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 254.2/254.2 MB 25.2 MB/s eta 0:00:00
Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch) (1.14.0)
Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from pytorch-triton-rocm==3.3.1->torch) (63.2.0)
Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from torchvision) (2.2.6)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (11.3.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)
Installing collected packages: pytorch-triton-rocm, torch, torchvision, torchaudio
Successfully installed pytorch-triton-rocm-3.3.1 torch-2.7.1+rocm6.3 torchaudio-2.7.1+rocm6.3 torchvision-0.22.1+rocm6.3
WARNING: There was an error checking the latest version of pip.
```

But it would seem that with the ROCm supported Torch, it still cannot use the GPU.
Since now I am getting this error.
```
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ deactivate
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on ralkey user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Jul  2 2025, 20:48:19) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```",well managed install command python pip install torch torchvision torchaudio cache dir index url full log ralkey desktop oq stable diffusion webui source venv bin activate venv ralkey desktop oq stable diffusion webui python pip install torch torchvision torchaudio cache dir index url g whl rocm looking indexes collecting torch downloading mb gb mb eta collecting torchvision downloading mb mb mb eta collecting torchaudio downloading mb mb mb eta requirement already satisfied typing extensions venv lib python site packages torch requirement already satisfied fsspec venv lib python site packages torch requirement already satisfied networkx venv lib python site packages torch requirement already satisfied jinja venv lib python site packages torch requirement already satisfied filelock venv lib python site packages torch collecting pytorch triton rocm downloading mb mb mb eta requirement already satisfied sympy venv lib python site packages torch requirement already satisfied setuptools venv lib python site packages pytorch triton rocm torch requirement already satisfied numpy venv lib python site packages torchvision requirement already satisfied pillow venv lib python site packages torchvision requirement already satisfied mpmath venv lib python site packages sympy torch requirement already satisfied markupsafe venv lib python site packages jinja torch installing collected packages pytorch triton rocm torch torchvision torchaudio successfully installed pytorch triton rocm torch rocm torchaudio rocm torchvision rocm warning error checking latest version pip would seem rocm supported torch still cannot use gpu since getting error venv ralkey desktop oq stable diffusion webui deactivate ralkey desktop oq stable diffusion webui webui sh install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running ralkey user repo already cloned using install directory create activate python venv launching launch py glibc version cannot locate tcmalloc tcmalloc google perftool installed system improves cpu memory usage python main jul gcc version v commit hash c ae bd abdf eda b e traceback recent call last file home ralkey stable diffusion webui launch py line module main file home ralkey stable diffusion webui launch py line main prepare environment file home ralkey stable diffusion webui modules launch utils py line prepare environment raise runtimeerror runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check
auto1111_webui,comment,17025,,"I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
```sh
location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
cd ${location}/torch/lib/
rm libhsa-runtime64.so*
```",2025-07-04T17:35:31Z,PKBeam,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3036943049,"I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
```sh
location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
cd ${location}/torch/lib/
rm libhsa-runtime64.so*
```",problem solved step amd pytorch install guide sh location pip show torch grep location awk f print cd location torch lib rm libhsa runtime
auto1111_webui,comment,17025,,"> I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
> 
> location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
> cd ${location}/torch/lib/
> rm libhsa-runtime64.so*

Thank you so much, after months of working on this issue and talking with more people than I can count, I got proper 100% support on A1111 with my 9070XT!

And I managed to get up to 8 it/s, which is the fastest I have ever gotten!.

I documented my entire installation process, for other people to follow:
https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b",2025-07-05T12:42:54Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3038884508,"> I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
> 
> location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
> cd ${location}/torch/lib/
> rm libhsa-runtime64.so*

Thank you so much, after months of working on this issue and talking with more people than I can count, I got proper 100% support on A1111 with my 9070XT!

And I managed to get up to 8 it/s, which is the fastest I have ever gotten!.

I documented my entire installation process, for other people to follow:
https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b",problem solved step amd pytorch install guide location pip show torch grep location awk f print cd location torch lib rm libhsa runtime thank much months working issue talking people count got proper support xt managed get fastest ever gotten documented entire installation process people follow
auto1111_webui,comment,17025,,"> I documented my entire installation process, for other people to follow: https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b

I'm running Arch, but I followed most of your steps and was able to get this running utilising my GPU to its fullest.
I have an AMD 7800XT.

As you suggested, I installed python3.10 (though I got it from the AUR), then used your suggested wgets. I also do not need the additional flags when running the main script.",2025-12-26T17:40:33Z,Nikolai5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3693155817,"> I documented my entire installation process, for other people to follow: https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b

I'm running Arch, but I followed most of your steps and was able to get this running utilising my GPU to its fullest.
I have an AMD 7800XT.

As you suggested, I installed python3.10 (though I got it from the AUR), then used your suggested wgets. I also do not need the additional flags when running the main script.",documented entire installation process people follow running arch followed steps able get running utilising gpu fullest amd xt suggested installed python though got aur used suggested wgets also need additional flags running main script
auto1111_webui,issue,17024,webui.sh报错，有没有适合中国宝宝体质的安装方式和运行方式,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

rt，谢谢

### Steps to reproduce the problem

rt，谢谢

### What should have happened?

rt，谢谢

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

rt，谢谢

### Console logs

```Shell
rt，谢谢
```

### Additional information

rt，谢谢",2025-06-03T07:43:39Z,XuJianzhi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024,"webui.sh报错，有没有适合中国宝宝体质的安装方式和运行方式 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

rt，谢谢

### Steps to reproduce the problem

rt，谢谢

### What should have happened?

rt，谢谢

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

rt，谢谢

### Console logs

```Shell
rt，谢谢
```

### Additional information

rt，谢谢",webui sh checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened rt steps reproduce problem rt happened rt browsers use access ui response sysinfo rt console logs shell rt additional information rt
auto1111_webui,comment,17024,,这边建议你去找现成的aki做的东西,2025-06-10T04:26:43Z,jsy061030,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024#issuecomment-2957639942,这边建议你去找现成的aki做的东西,aki
auto1111_webui,issue,17014,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installed Ollama, Docker, Open-webui, pyenv, phyton 3.10, Automatic1111 and stable diffusion.
Worked perfectly. install even opened up the browser on 127.0.0.1:7860 and it jsut worked.
i generated a couple of images.

After a reboot the webui do not start 
tried ./webui.sh --listen --api and it will not start

### Steps to reproduce the problem

try to start webui.sh

### What should have happened?

webui should start ! ???

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

cant start so i cant generate ! ?

### Console logs

```Shell
bluescreentt@pop-os:~/stablediff$ ./webui.sh --listen --api

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on bluescreentt user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.35
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python: No module named pip
Traceback (most recent call last):
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

what am i missing ?
",2025-05-30T21:11:57Z,BlueScreenTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17014,"[Bug]: ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installed Ollama, Docker, Open-webui, pyenv, phyton 3.10, Automatic1111 and stable diffusion.
Worked perfectly. install even opened up the browser on 127.0.0.1:7860 and it jsut worked.
i generated a couple of images.

After a reboot the webui do not start 
tried ./webui.sh --listen --api and it will not start

### Steps to reproduce the problem

try to start webui.sh

### What should have happened?

webui should start ! ???

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

cant start so i cant generate ! ?

### Console logs

```Shell
bluescreentt@pop-os:~/stablediff$ ./webui.sh --listen --api

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on bluescreentt user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.35
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python: No module named pip
Traceback (most recent call last):
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

what am i missing ?",bug checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened installed ollama docker open webui pyenv phyton automatic stable diffusion worked perfectly install even opened browser jsut worked generated couple images reboot webui start tried webui sh listen api start steps reproduce problem try start webui sh happened webui start browsers use access ui response sysinfo cant start cant generate console logs shell bluescreentt pop os stablediff webui sh listen api install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running bluescreentt user create activate python venv launching launch py glibc version cannot locate tcmalloc tcmalloc google perftool installed system improves cpu memory usage python main feb gcc version v commit hash c ae bd abdf eda b e installing torch torchvision home bluescreentt stablediff stable diffusion webui venv bin python module named pip traceback recent call last file home bluescreentt stablediff stable diffusion webui launch py line module main file home bluescreentt stablediff stable diffusion webui launch py line main prepare environment file home bluescreentt stablediff stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file home bluescreentt stablediff stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command home bluescreentt stablediff stable diffusion webui venv bin python pip install torch torchvision extra index url error code additional information missing
auto1111_webui,comment,17014,,"so now i am thinking it have to do with python.
if i remove the myenv and env directories and run the webui again it works ! :-/",2025-05-30T21:49:43Z,BlueScreenTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17014#issuecomment-2923581102,"so now i am thinking it have to do with python.
if i remove the myenv and env directories and run the webui again it works ! :-/",thinking python remove myenv env directories run webui works
auto1111_webui,issue,17013,[Feature Request]: Native Regional Prompting Support in txt2img/img2img UI (Like Regional Prompter Extension),"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

## Summary

Please consider implementing **native support for regional prompting** (such as the system used by the Regional Prompter extension) into the main txt2img/img2img UI. 

Right now, A1111 only supports a **global prompt** system, which causes huge complications when generating scenes with multiple subjects (such as a man and a woman). The lack of prompt separation leads to **pose confusion, identity blending, or prompt leakage across characters**, and is a major frustration for many creators.

---

## The Problem

When trying to generate scenes involving **two characters** (e.g., erotic, romantic, or narrative poses involving a man and a woman), A1111 only provides one prompt field and one negative prompt field. This means:

- Descriptions of male and female characters **get merged**.
- Poses or attributes **bleed into each other** (e.g., ""woman with left hand raised"" might apply to both).
- You **cannot assign individual poses, traits, or styles** reliably to specific characters.

This limitation wastes **hours of trial-and-error** and often results in inconsistent or broken images (e.g., multiple hands, flipped body parts, incorrect skin tones, etc.).

---

## Benefits

- Better control over **individual characters** in multi-subject scenes.
- Reduces time wasted on prompt tuning.
- Makes A1111 **more user-friendly for storytelling, erotic, couple, or narrative artwork**.
- Encourages creators to stick with A1111 rather than moving to node-based tools like ComfyUI.

---

## Real-World Use Case

As an artist/storyteller, I’m creating highly specific images involving custom LoRA characters (e.g., one male, one female) in various intimate positions.

Due to lack of regional prompting:

- Prompt confusion constantly occurs (e.g., wrong hand poses, skin tone merging).
- Even with `ControlNet`, the system often overrides the intent due to prompt ambiguity.
- I eventually discovered the **Regional Prompter Extension**, but most users **don't even know this exists**.

Native regional prompt support would make A1111 feel **complete**, even for power users.

---

## Supporting Screenshots & Results

Note: Due to the explicit nature of the art involved (erotic storytelling), I'm not attaching sample images. But the issue is reproducible with any prompt involving two characters and conflicting pose definitions.

---

## Thank You

Thanks for your amazing work. Just wanted to highlight how much this one addition could drastically reduce frustration and unlock a huge amount of use cases.


### Proposed workflow

## Suggested Solution

Integrate a simplified version of **Regional Prompter** into the base UI:

- Add the ability to define **at least two separate prompt regions** in txt2img and img2img.
- Provide region-specific **Prompt+ and Prompt- fields**.
- Allow region-based prompt weighting and masking (optional but helpful).
- Maintain compatibility with `lock seed`, `hires fix`, etc.

This doesn't need to be as complex as full compositional masking — just **prompt isolation between subjects** would already be a massive quality-of-life improvement.

---

### Additional information

_No response_",2025-05-28T22:55:54Z,lovenderdeleon,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17013,"[Feature Request]: Native Regional Prompting Support in txt2img/img2img UI (Like Regional Prompter Extension) ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

## Summary

Please consider implementing **native support for regional prompting** (such as the system used by the Regional Prompter extension) into the main txt2img/img2img UI. 

Right now, A1111 only supports a **global prompt** system, which causes huge complications when generating scenes with multiple subjects (such as a man and a woman). The lack of prompt separation leads to **pose confusion, identity blending, or prompt leakage across characters**, and is a major frustration for many creators.

---

## The Problem

When trying to generate scenes involving **two characters** (e.g., erotic, romantic, or narrative poses involving a man and a woman), A1111 only provides one prompt field and one negative prompt field. This means:

- Descriptions of male and female characters **get merged**.
- Poses or attributes **bleed into each other** (e.g., ""woman with left hand raised"" might apply to both).
- You **cannot assign individual poses, traits, or styles** reliably to specific characters.

This limitation wastes **hours of trial-and-error** and often results in inconsistent or broken images (e.g., multiple hands, flipped body parts, incorrect skin tones, etc.).

---

## Benefits

- Better control over **individual characters** in multi-subject scenes.
- Reduces time wasted on prompt tuning.
- Makes A1111 **more user-friendly for storytelling, erotic, couple, or narrative artwork**.
- Encourages creators to stick with A1111 rather than moving to node-based tools like ComfyUI.

---

## Real-World Use Case

As an artist/storyteller, I’m creating highly specific images involving custom LoRA characters (e.g., one male, one female) in various intimate positions.

Due to lack of regional prompting:

- Prompt confusion constantly occurs (e.g., wrong hand poses, skin tone merging).
- Even with `ControlNet`, the system often overrides the intent due to prompt ambiguity.
- I eventually discovered the **Regional Prompter Extension**, but most users **don't even know this exists**.

Native regional prompt support would make A1111 feel **complete**, even for power users.

---

## Supporting Screenshots & Results

Note: Due to the explicit nature of the art involved (erotic storytelling), I'm not attaching sample images. But the issue is reproducible with any prompt involving two characters and conflicting pose definitions.

---

## Thank You

Thanks for your amazing work. Just wanted to highlight how much this one addition could drastically reduce frustration and unlock a huge amount of use cases.


### Proposed workflow

## Suggested Solution

Integrate a simplified version of **Regional Prompter** into the base UI:

- Add the ability to define **at least two separate prompt regions** in txt2img and img2img.
- Provide region-specific **Prompt+ and Prompt- fields**.
- Allow region-based prompt weighting and masking (optional but helpful).
- Maintain compatibility with `lock seed`, `hires fix`, etc.

This doesn't need to be as complex as full compositional masking — just **prompt isolation between subjects** would already be a massive quality-of-life improvement.

---

### Additional information

_No response_",feature request native regional prompting support txt img img img ui like regional prompter extension existing issue x searched existing issues checked recent builds commits would feature summary please consider implementing native support regional prompting system used regional prompter extension main txt img img img ui right supports global prompt system causes huge complications generating scenes multiple subjects man woman lack prompt separation leads pose confusion identity blending prompt leakage across characters major frustration many creators problem trying generate scenes involving two characters e g erotic romantic narrative poses involving man woman provides one prompt field one negative prompt field means descriptions male female characters get merged poses attributes bleed e g woman left hand raised might apply cannot assign individual poses traits styles reliably specific characters limitation wastes hours trial error often results inconsistent broken images e g multiple hands flipped body parts incorrect skin tones etc benefits better control individual characters multi subject scenes reduces time wasted prompt tuning makes user friendly storytelling erotic couple narrative artwork encourages creators stick rather moving node based tools like comfyui real world use case artist storyteller im creating highly specific images involving custom lora characters e g one male one female various intimate positions due lack regional prompting prompt confusion constantly occurs e g wrong hand poses skin tone merging even controlnet system often overrides intent due prompt ambiguity eventually discovered regional prompter extension users even know exists native regional prompt support would make feel complete even power users supporting screenshots results note due explicit nature art involved erotic storytelling attaching sample images issue reproducible prompt involving two characters conflicting pose definitions thank thanks amazing work wanted highlight much one addition could drastically reduce frustration unlock huge amount use cases proposed workflow suggested solution integrate simplified version regional prompter base ui add ability define least two separate prompt regions txt img img img provide region specific prompt prompt fields allow region based prompt weighting masking optional helpful maintain compatibility lock seed hires fix etc need complex full compositional masking prompt isolation subjects would already massive quality life improvement additional information response
auto1111_webui,issue,17010,[Bug]: IPEX - Native API Error -997 (Command Failed to Enqueue/Execute),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When generating images using `--use-ipex`, I intermittently receive the error `Native API returns: -997`, which corresponds to a failure in command execution under IPEX. While generation occasionally works, it's inconsistent and mostly fails. I attempted using SD1.5 models as well, but encountered the same issue. This problem started only after I reset my PC and recloned the repository.



### Steps to reproduce the problem

Clone the stable-diffusion-webui repository

Modify webui-user.bat to include the --use-ipex flag

Launch WebUI and complete installation

Attempt to generate an image via txt2img or img2img

Observe that image generation either succeeds or fails with error -997

### What should have happened?

Image generation should work normally when using IPEX.



### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

GPU: Intel Arc A770

Driver Version: 31.0.101.5379

CPU: Intel Core i7-12700K

RAM: 32 GB DDR5

OS: Windows 11 Pro 22H2 (64-bit)

Toolkits Installed: Intel OneAPI Base Toolkit, OneAPI HPC Toolkit

Resizable BAR: Enabled

### Console logs

```Shell
venv ""R:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --use-ipex --opt-split-attention --medvram-sdxl
no module 'xformers'. Processing without...
No SDP backend available, likely because you are running in pytorch versions < 2.0. In fact, you are using PyTorch 2.0.0a0+gite9ebda2. You might want to consider upgrading.
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
==============================================================================
You are running torch 2.0.0a0+gite9ebda2.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
Loading weights [b8d425c720] from R:\stable-diffusion-webui\models\Stable-diffusion\AOM3B4_orangemixs.safetensors
Creating model from config: R:\stable-diffusion-webui\configs\v1-inference.yaml
R:\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 7.6s (prepare environment: 0.4s, import torch: 2.2s, import gradio: 0.6s, setup paths: 0.7s, initialize shared: 1.1s, other imports: 0.3s, load scripts: 1.2s, create ui: 0.8s, gradio launch: 0.4s).
Loading VAE weights specified in settings: R:\stable-diffusion-webui\models\VAE\orangemix.vae.pt
Applying attention optimization: Doggettx... done.
Model loaded in 40.9s (load weights from disk: 0.4s, create model: 0.8s, apply weights to model: 2.1s, load VAE: 33.5s, calculate empty prompt: 3.8s).
  0%|                                                                                           | 0/31 [00:08<?, ?it/s]
*** Error completing request
*** Arguments: ('task(knvvwltwmsj4455)', <gradio.routes.Request object at 0x000001C39F2CE9E0>, 0, '1girl, bangs, bed, bed sheet, blush, breasts, cleavage, earrings, green eyes, indoors, jewelry, large breasts, long hair, looking at viewer, navel, on bed, shirt, shorts, solo, thighs, window', '(worst quality, low quality:1.4), (bad-hands-5:1.5), easynegative', [], <PIL.Image.Image image mode=RGBA size=768x1344 at 0x1C39351E080>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 910, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 40, 'DPM++ 2M', 'Align Your Steps', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 988, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 1774, in sample
        samples = self.sampler.sample_img2img(self, self.init_latent, x, conditioning, unconditional_conditioning, image_conditioning=self.image_conditioning)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 36, in __call__
        return self.__orig_func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 858, in apply_model
        x_recon = self.model(x_noisy, t, **cond)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 1335, in forward
        out = self.diffusion_model(x, t, context=cc)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 802, in forward
        h = module(h, emb, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 84, in forward
        x = layer(x, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 96, in spatial_transformer_forward
        x = block(x, context=context[i])
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 269, in forward
        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\util.py"", line 123, in checkpoint
        return func(*inputs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 272, in _forward
        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_optimizations.py"", line 278, in split_cross_attention_forward
        r2 = rearrange(r1, '(b h) n d -> b n (h d)', h=h)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 487, in rearrange
        return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 410, in reduce
        return _apply_recipe(recipe, tensor, reduction_type=reduction)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 239, in _apply_recipe
        return backend.reshape(tensor, final_shapes)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\_backends.py"", line 84, in reshape
        return x.reshape(shape)
    RuntimeError: Native API failed. Native API returns: -997 (Command failed to enqueue/execute) -997 (Command failed to enqueue/execute)

---
```

### Additional information

_No response_",2025-05-26T13:51:46Z,Parvezkhan0,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17010,"[Bug]: IPEX - Native API Error -997 (Command Failed to Enqueue/Execute) ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When generating images using `--use-ipex`, I intermittently receive the error `Native API returns: -997`, which corresponds to a failure in command execution under IPEX. While generation occasionally works, it's inconsistent and mostly fails. I attempted using SD1.5 models as well, but encountered the same issue. This problem started only after I reset my PC and recloned the repository.



### Steps to reproduce the problem

Clone the stable-diffusion-webui repository

Modify webui-user.bat to include the --use-ipex flag

Launch WebUI and complete installation

Attempt to generate an image via txt2img or img2img

Observe that image generation either succeeds or fails with error -997

### What should have happened?

Image generation should work normally when using IPEX.



### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

GPU: Intel Arc A770

Driver Version: 31.0.101.5379

CPU: Intel Core i7-12700K

RAM: 32 GB DDR5

OS: Windows 11 Pro 22H2 (64-bit)

Toolkits Installed: Intel OneAPI Base Toolkit, OneAPI HPC Toolkit

Resizable BAR: Enabled

### Console logs

```Shell
venv ""R:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --use-ipex --opt-split-attention --medvram-sdxl
no module 'xformers'. Processing without...
No SDP backend available, likely because you are running in pytorch versions < 2.0. In fact, you are using PyTorch 2.0.0a0+gite9ebda2. You might want to consider upgrading.
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
==============================================================================
You are running torch 2.0.0a0+gite9ebda2.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
Loading weights [b8d425c720] from R:\stable-diffusion-webui\models\Stable-diffusion\AOM3B4_orangemixs.safetensors
Creating model from config: R:\stable-diffusion-webui\configs\v1-inference.yaml
R:\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 7.6s (prepare environment: 0.4s, import torch: 2.2s, import gradio: 0.6s, setup paths: 0.7s, initialize shared: 1.1s, other imports: 0.3s, load scripts: 1.2s, create ui: 0.8s, gradio launch: 0.4s).
Loading VAE weights specified in settings: R:\stable-diffusion-webui\models\VAE\orangemix.vae.pt
Applying attention optimization: Doggettx... done.
Model loaded in 40.9s (load weights from disk: 0.4s, create model: 0.8s, apply weights to model: 2.1s, load VAE: 33.5s, calculate empty prompt: 3.8s).
  0%|                                                                                           | 0/31 [00:08<?, ?it/s]
*** Error completing request
*** Arguments: ('task(knvvwltwmsj4455)', <gradio.routes.Request object at 0x000001C39F2CE9E0>, 0, '1girl, bangs, bed, bed sheet, blush, breasts, cleavage, earrings, green eyes, indoors, jewelry, large breasts, long hair, looking at viewer, navel, on bed, shirt, shorts, solo, thighs, window', '(worst quality, low quality:1.4), (bad-hands-5:1.5), easynegative', [], <PIL.Image.Image image mode=RGBA size=768x1344 at 0x1C39351E080>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 910, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 40, 'DPM++ 2M', 'Align Your Steps', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 988, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 1774, in sample
        samples = self.sampler.sample_img2img(self, self.init_latent, x, conditioning, unconditional_conditioning, image_conditioning=self.image_conditioning)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 36, in __call__
        return self.__orig_func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 858, in apply_model
        x_recon = self.model(x_noisy, t, **cond)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 1335, in forward
        out = self.diffusion_model(x, t, context=cc)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 802, in forward
        h = module(h, emb, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 84, in forward
        x = layer(x, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 96, in spatial_transformer_forward
        x = block(x, context=context[i])
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 269, in forward
        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\util.py"", line 123, in checkpoint
        return func(*inputs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 272, in _forward
        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_optimizations.py"", line 278, in split_cross_attention_forward
        r2 = rearrange(r1, '(b h) n d -> b n (h d)', h=h)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 487, in rearrange
        return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 410, in reduce
        return _apply_recipe(recipe, tensor, reduction_type=reduction)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 239, in _apply_recipe
        return backend.reshape(tensor, final_shapes)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\_backends.py"", line 84, in reshape
        return x.reshape(shape)
    RuntimeError: Native API failed. Native API returns: -997 (Command failed to enqueue/execute) -997 (Command failed to enqueue/execute)

---
```

### Additional information

_No response_",bug ipex native api error command failed enqueue execute checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened generating images using use ipex intermittently receive error native api returns corresponds failure command execution ipex generation occasionally works inconsistent mostly fails attempted using sd models well encountered issue problem started reset pc recloned repository steps reproduce problem clone stable diffusion webui repository modify webui user bat include use ipex flag launch webui complete installation attempt generate image via txt img img img observe image generation either succeeds fails error happened image generation work normally using ipex browsers use access ui google chrome microsoft edge sysinfo gpu intel arc driver version cpu intel core k ram gb ddr os windows pro h bit toolkits installed intel oneapi base toolkit oneapi hpc toolkit resizable bar enabled console logs shell venv r stable diffusion webui venv scripts python exe python tags v cc apr msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments use ipex opt split attention medvram sdxl module xformers processing without sdp backend available likely running pytorch versions fact using pytorch gite ebda might want consider upgrading module xformers processing without module xformers proceeding without warning caught exception torch compiled cuda enabled memory monitor disabled running torch gite ebda program tested work torch reinstall desired version run commandline flag reinstall torch beware cause lot large files downloaded well reports issues training tab latest version use skip version check commandline argument disable check loading weights b c r stable diffusion webui models stable diffusion aom b orangemixs safetensors creating model config r stable diffusion webui configs v inference yaml r stable diffusion webui venv lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch loading vae weights specified settings r stable diffusion webui models vae orangemix vae pt applying attention optimization doggettx done model loaded load weights disk create model apply weights model load vae calculate empty prompt error completing request arguments task knvvwltwmsj gradio routes request object x c f ce e girl bangs bed bed sheet blush breasts cleavage earrings green eyes indoors jewelry large breasts long hair looking viewer navel bed shirt shorts solo thighs window worst quality low quality bad hands easynegative pil image image image mode rgba size x x c e none none none none none none false upload none false dpm align steps false false cfg scale lower true true true true false linear none p style margin bottom em recommended settings sampling steps sampler euler denoising strength p left right left right false false positive comma false false start p style margin bottom em upscale image selected scale factor use width height sliders set tile size p true false false false false false false false traceback recent call last file r stable diffusion webui modules call queue py line f res list func args kwargs file r stable diffusion webui modules call queue py line f res func args kwargs file r stable diffusion webui modules call queue py line f res func args kwargs file r stable diffusion webui modules img img py line img img processed process images p file r stable diffusion webui modules processing py line process images res process images inner p file r stable diffusion webui modules processing py line process images inner samples ddim p sample conditioning p c unconditional conditioning p uc seeds p seeds subseeds p subseeds subseed strength p subseed strength prompts p prompts file r stable diffusion webui modules processing py line sample samples self sampler sample img img self self init latent x conditioning unconditional conditioning image conditioning self image conditioning file r stable diffusion webui modules sd samplers kdiffusion py line sample img img samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs file r stable diffusion webui modules sd samplers common py line launch sampling return func file r stable diffusion webui modules sd samplers kdiffusion py line lambda samples self launch sampling enc lambda self func self model wrap cfg xi extra args self sampler extra args disable false callback self callback state extra params kwargs file r stable diffusion webui venv lib site packages torch utils contextlib py line decorate context return func args kwargs file r stable diffusion webui repositories k diffusion k diffusion sampling py line sample dpmpp denoised model x sigmas extra args file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui modules sd samplers cfg denoiser py line forward x self inner model x sigma cond make condition dict cond image cond file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui repositories k diffusion k diffusion external py line forward eps self get eps input c self sigma sigma kwargs file r stable diffusion webui repositories k diffusion k diffusion external py line get eps return self inner model apply model args kwargs file r stable diffusion webui modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file r stable diffusion webui modules sd hijack utils py line call return self sub func self orig func args kwargs file r stable diffusion webui modules sd hijack unet py line apply model result orig func self x noisy devices dtype unet devices dtype unet cond kwargs file r stable diffusion webui modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file r stable diffusion webui modules sd hijack utils py line call return self orig func args kwargs file r stable diffusion webui repositories stable diffusion stability ai ldm models diffusion ddpm py line apply model x recon self model x noisy cond file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui repositories stable diffusion stability ai ldm models diffusion ddpm py line forward self diffusion model x context cc file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs file r stable diffusion webui repositories stable diffusion stability ai ldm modules diffusionmodules openaimodel py line forward h module h emb context file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui repositories stable diffusion stability ai ldm modules diffusionmodules openaimodel py line forward x layer x context file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file r stable diffusion webui modules sd hijack utils py line call return self sub func self orig func args kwargs file r stable diffusion webui modules sd hijack unet py line spatial transformer forward x block x context context file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui repositories stable diffusion stability ai ldm modules attention py line forward return checkpoint self forward x context self parameters self checkpoint file r stable diffusion webui repositories stable diffusion stability ai ldm modules diffusionmodules util py line checkpoint return func inputs file r stable diffusion webui repositories stable diffusion stability ai ldm modules attention py line forward x self attn self norm x context context self disable self attn else none x file r stable diffusion webui venv lib site packages torch nn modules module py line call impl return forward call args kwargs file r stable diffusion webui modules sd hijack optimizations py line split cross attention forward r rearrange r b h n b n h h h file r stable diffusion webui venv lib site packages einops einops py line rearrange return reduce tensor pattern reduction rearrange axes lengths file r stable diffusion webui venv lib site packages einops einops py line reduce return apply recipe recipe tensor reduction type reduction file r stable diffusion webui venv lib site packages einops einops py line apply recipe return backend reshape tensor final shapes file r stable diffusion webui venv lib site packages einops backends py line reshape return x reshape shape runtimeerror native api failed native api returns command failed enqueue execute command failed enqueue execute additional information response
auto1111_webui,comment,17010,,"You could try to update your Graphics driver to the latest version https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html 

You could also use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which has built-in support for both OpenVINO and IPEX.",2025-07-10T06:39:58Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17010#issuecomment-3055839947,"You could try to update your Graphics driver to the latest version https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html 

You could also use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which has built-in support for both OpenVINO and IPEX.",could try update graphics driver latest version could also use sd next alternative built support openvino ipex
auto1111_webui,issue,17009,[Bug]: `history.json is not created/written to in v1.10.1 despite successful image generation`,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

**Description of the problem**:
Images are generated successfully, but the `history.json` file is neither created nor found anywhere (e.g., in the Web UI root directory or `outputs` directory).
Manually creating a `history.json` file does not result in generation history being written to it.
The issue persisted across a clean reinstallation.
File write permissions for the directory seem to be correct. (Please attach output of `ls -ld .` and `ls -ld outputs`).
Checked Web UI settings (`Settings` tab) thoroughly, but no explicit option for history saving was found. (Please attach screenshot PDF if relevant sections are visible).
The `--dump-gradio-config` option resulted in an ""unrecognized arguments"" error.
The presence or absence of the `--xformers` option did not affect the issue.
A VAE NaN error occurred with `v1-5-pruned.safetensors` but not with `v1-5-pruned-emaonly.safetensors` or `sd_xl_base_1.0.safetensors`. However, `history.json` was not created regardless of the model used.

**Expected behavior**:
The generated image history should be automatically recorded in a `history.json` file.

### Steps to reproduce the problem

1. starrt webui-user.sh
2. access via a browser, and generate images.
3. find <webui dir> -name history.json

### What should have happened?

 history.json file should be in <webui dir>

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

[sysinfo-2025-05-26-10-48.json](https://github.com/user-attachments/files/20439930/sysinfo-2025-05-26-10-48.json)

### Console logs

```Shell
./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tovy user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --medvram --xformers --listen
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [31e35c80fc] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/sd_xl_base_1.0.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.6s (prepare environment: 1.1s, import torch: 2.0s, import gradio: 0.5s, setup paths: 0.8s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.2s).
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/repositories/generative-models/configs/inference/sd_xl_base.yaml
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: xformers... done.
Model loaded in 2.4s (load weights from disk: 0.6s, create model: 0.3s, apply weights to model: 1.2s, calculate empty prompt: 0.3s).
Reusing loaded model sd_xl_base_1.0.safetensors [31e35c80fc] to load v1-5-pruned-emaonly.safetensors [6ce0161689]
Loading weights [6ce0161689] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: xformers... done.
Model loaded in 9.2s (create model: 0.2s, apply weights to model: 8.5s, apply half(): 0.3s).
100%|█████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.57it/s]
Total progress: 100%|█████████████████████████████████████| 6/6 [00:01<00:00,  3.96it/s]
100%|█████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.86it/s]
Total progress: 100%|█████████████████████████████████████| 6/6 [00:01<00:00,  4.68it/s]
^CInterrupted with signal 2 in <frame at 0x729b1000e690, file '/home/tovy/miniconda3/envs/sd_env_new/lib/python3.10/threading.py', line 324, code wait>

$ find . -name history.json
 nothing
```

### Additional information

**Environment**:
* Web UI Version: `v1.10.1` (Commit hash: `82a973c04367123ae98bd9abdf80d9eda9b910e2`)
* Python Version: `3.10.16` (Conda environment `sd_env_new`)
* OS: `Ubuntu 24.04.2 LTS`
* Kernel: `Linux germany 6.11.0-26-generic #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC`
* GPU: `NVIDIA GeForce RTX 2070 SUPER`
* GPU VRAM: `8GB`
* NVIDIA Driver Version: `570.133.07`
* System CUDA Version: `12.8`
* PyTorch CUDA Version: `2.7.0+cu128`
* `webui-user.sh` `COMMANDLINE_ARGS`: `export COMMANDLINE_ARGS=""--medvram --xformers --listen""` (or your current arguments)
",2025-05-26T10:51:30Z,tovytovy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009,"[Bug]: `history.json is not created/written to in v1.10.1 despite successful image generation` ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

**Description of the problem**:
Images are generated successfully, but the `history.json` file is neither created nor found anywhere (e.g., in the Web UI root directory or `outputs` directory).
Manually creating a `history.json` file does not result in generation history being written to it.
The issue persisted across a clean reinstallation.
File write permissions for the directory seem to be correct. (Please attach output of `ls -ld .` and `ls -ld outputs`).
Checked Web UI settings (`Settings` tab) thoroughly, but no explicit option for history saving was found. (Please attach screenshot PDF if relevant sections are visible).
The `--dump-gradio-config` option resulted in an ""unrecognized arguments"" error.
The presence or absence of the `--xformers` option did not affect the issue.
A VAE NaN error occurred with `v1-5-pruned.safetensors` but not with `v1-5-pruned-emaonly.safetensors` or `sd_xl_base_1.0.safetensors`. However, `history.json` was not created regardless of the model used.

**Expected behavior**:
The generated image history should be automatically recorded in a `history.json` file.

### Steps to reproduce the problem

1. starrt webui-user.sh
2. access via a browser, and generate images.
3. find <webui dir> -name history.json

### What should have happened?

 history.json file should be in <webui dir>

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

[sysinfo-2025-05-26-10-48.json](https://github.com/user-attachments/files/20439930/sysinfo-2025-05-26-10-48.json)

### Console logs

```Shell
./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tovy user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --medvram --xformers --listen
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [31e35c80fc] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/sd_xl_base_1.0.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.6s (prepare environment: 1.1s, import torch: 2.0s, import gradio: 0.5s, setup paths: 0.8s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.2s).
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/repositories/generative-models/configs/inference/sd_xl_base.yaml
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: xformers... done.
Model loaded in 2.4s (load weights from disk: 0.6s, create model: 0.3s, apply weights to model: 1.2s, calculate empty prompt: 0.3s).
Reusing loaded model sd_xl_base_1.0.safetensors [31e35c80fc] to load v1-5-pruned-emaonly.safetensors [6ce0161689]
Loading weights [6ce0161689] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: xformers... done.
Model loaded in 9.2s (create model: 0.2s, apply weights to model: 8.5s, apply half(): 0.3s).
100%|█████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.57it/s]
Total progress: 100%|█████████████████████████████████████| 6/6 [00:01<00:00,  3.96it/s]
100%|█████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.86it/s]
Total progress: 100%|█████████████████████████████████████| 6/6 [00:01<00:00,  4.68it/s]
^CInterrupted with signal 2 in <frame at 0x729b1000e690, file '/home/tovy/miniconda3/envs/sd_env_new/lib/python3.10/threading.py', line 324, code wait>

$ find . -name history.json
 nothing
```

### Additional information

**Environment**:
* Web UI Version: `v1.10.1` (Commit hash: `82a973c04367123ae98bd9abdf80d9eda9b910e2`)
* Python Version: `3.10.16` (Conda environment `sd_env_new`)
* OS: `Ubuntu 24.04.2 LTS`
* Kernel: `Linux germany 6.11.0-26-generic #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC`
* GPU: `NVIDIA GeForce RTX 2070 SUPER`
* GPU VRAM: `8GB`
* NVIDIA Driver Version: `570.133.07`
* System CUDA Version: `12.8`
* PyTorch CUDA Version: `2.7.0+cu128`
* `webui-user.sh` `COMMANDLINE_ARGS`: `export COMMANDLINE_ARGS=""--medvram --xformers --listen""` (or your current arguments)",bug history json created written v despite successful image generation checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened description problem images generated successfully history json file neither created found anywhere e g web ui root directory outputs directory manually creating history json file result generation history written issue persisted across clean reinstallation file write permissions directory seem correct please attach output ls ld ls ld outputs checked web ui settings settings tab thoroughly explicit option history saving found please attach screenshot pdf relevant sections visible dump gradio config option resulted unrecognized arguments error presence absence xformers option affect issue vae nan error occurred v pruned safetensors v pruned emaonly safetensors sd xl base safetensors however history json created regardless model used expected behavior generated image history automatically recorded history json file steps reproduce problem starrt webui user sh access via browser generate images find webui dir name history json happened history json file webui dir browsers use access ui apple safari sysinfo sysinfo json console logs shell webui sh install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running tovy user repo already cloned using install directory create activate python venv launching launch py glibc version cannot locate tcmalloc tcmalloc google perftool installed system improves cpu memory usage python main dec gcc version v commit hash c ae bd abdf eda b e launching web ui arguments medvram xformers listen home tovy ais stable diffusion webui new stable diffusion webui venv lib python site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning loading weights e c fc home tovy ais stable diffusion webui new stable diffusion webui models stable diffusion sd xl base safetensors running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch creating model config home tovy ais stable diffusion webui new stable diffusion webui repositories generative models configs inference sd xl base yaml home tovy ais stable diffusion webui new stable diffusion webui venv lib python site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn applying attention optimization xformers done model loaded load weights disk create model apply weights model calculate empty prompt reusing loaded model sd xl base safetensors e c fc load v pruned emaonly safetensors ce loading weights ce home tovy ais stable diffusion webui new stable diffusion webui models stable diffusion v pruned emaonly safetensors creating model config home tovy ais stable diffusion webui new stable diffusion webui configs v inference yaml applying attention optimization xformers done model loaded create model apply weights model apply half total progress total progress cinterrupted signal frame x b e file home tovy miniconda envs sd env new lib python threading py line code wait find name history json nothing additional information environment web ui version v commit hash c ae bd abdf eda b e python version conda environment sd env new os ubuntu lts kernel linux germany generic ubuntu smp preempt dynamic gpu nvidia geforce rtx super gpu vram gb nvidia driver version system cuda version pytorch cuda version cu webui user sh commandline args export commandline args medvram xformers listen current arguments
auto1111_webui,comment,17009,,"I'm not sure where you get this `history.json` from but as far as I'm with this is not a part of the base web UI
perhaps you're confusing something else
maybe
`params.txt`
`settings > infotext > Create a text file with infotext next to every generated image`

or maybe your referencing an extension

similar for `--dump-gradio-config` it is not a thing in AUTOMATIC1111/stable-diffusion-webui

are you sure you are not reading documentation about some other software and confusing it with this software?",2025-05-26T16:07:19Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2910187743,"I'm not sure where you get this `history.json` from but as far as I'm with this is not a part of the base web UI
perhaps you're confusing something else
maybe
`params.txt`
`settings > infotext > Create a text file with infotext next to every generated image`

or maybe your referencing an extension

similar for `--dump-gradio-config` it is not a thing in AUTOMATIC1111/stable-diffusion-webui

are you sure you are not reading documentation about some other software and confusing it with this software?",sure get history json far part base web ui perhaps confusing something else maybe params txt settings infotext create text file infotext next every generated image maybe referencing extension similar dump gradio config thing automatic stable diffusion webui sure reading documentation software confusing software
auto1111_webui,comment,17009,,"![Image](https://github.com/user-attachments/assets/2e407a24-3b0a-4e53-981b-ef1d60636648)

Yes, you're right. Thank you for pointing that out.

It seems the history.json I referred to isn't part of the standard Stable Diffusion Web UI. I might have confused it with other information.

The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.
I speculated that these arrows weren't showing up because a file for recording history data (which I tentatively called history.json) was either missing or not being written correctly. It seems my initial assumption about the file name was incorrect.

Should I close bug report #17009 and resubmit it with a more direct title like 'History reference arrows are not displayed'?
",2025-05-26T22:21:50Z,tovytovy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2910704313,"![Image](https://github.com/user-attachments/assets/2e407a24-3b0a-4e53-981b-ef1d60636648)

Yes, you're right. Thank you for pointing that out.

It seems the history.json I referred to isn't part of the standard Stable Diffusion Web UI. I might have confused it with other information.

The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.
I speculated that these arrows weren't showing up because a file for recording history data (which I tentatively called history.json) was either missing or not being written correctly. It seems my initial assumption about the file name was incorrect.

Should I close bug report #17009 and resubmit it with a more direct title like 'History reference arrows are not displayed'?",image yes right thank pointing seems history json referred part standard stable diffusion web ui might confused information actual issue facing left right arrow icons appear right end prompt input field browse generated image prompt history completely missing speculated arrows showing file recording history data tentatively called history json either missing written correctly seems initial assumption file name incorrect close bug report resubmit direct title like history reference arrows displayed
auto1111_webui,comment,17009,,"> The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.

there no are histroy button in the base webui
it only displays the images from the current task

I think you're confusing it with some other aspects of UI
for example when you generate multiple images in a single task such as batch count or size > 1
or using scripts such as XYZ gird
but there is no left and right buttons
> you can either directly click on the image or using the keyboard arrow keys to navigate between images

you could also be confusing it with the full screen image viewer which does have left and right buttons

https://github.com/user-attachments/assets/1bab785d-9571-4c97-b905-6b7f2f4e13b1
> notice that the seed parameter does change when I flip through images


but these are not ""history""
> by ""history"" referring to images form past tasks, it only shows image from the current task

---

there's no history view in the basement you
however there are some extensions that add such a feature

couple of ""history"" extentions that can be found on the extensions tab
https://github.com/MINENEMA/sd-webui-quickrecents
https://github.com/namkazt/sd-webui-prompt-history
https://github.com/zanllp/sd-webui-infinite-image-browsing
> note: I don't use these extensions myself so this is not a endorsement",2025-05-27T07:14:43Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2911421734,"> The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.

there no are histroy button in the base webui
it only displays the images from the current task

I think you're confusing it with some other aspects of UI
for example when you generate multiple images in a single task such as batch count or size > 1
or using scripts such as XYZ gird
but there is no left and right buttons
> you can either directly click on the image or using the keyboard arrow keys to navigate between images

you could also be confusing it with the full screen image viewer which does have left and right buttons

https://github.com/user-attachments/assets/1bab785d-9571-4c97-b905-6b7f2f4e13b1
> notice that the seed parameter does change when I flip through images


but these are not ""history""
> by ""history"" referring to images form past tasks, it only shows image from the current task

---

there's no history view in the basement you
however there are some extensions that add such a feature

couple of ""history"" extentions that can be found on the extensions tab
https://github.com/MINENEMA/sd-webui-quickrecents
https://github.com/namkazt/sd-webui-prompt-history
https://github.com/zanllp/sd-webui-infinite-image-browsing
> note: I don't use these extensions myself so this is not a endorsement",actual issue facing left right arrow icons appear right end prompt input field browse generated image prompt history completely missing histroy button base webui displays images current task think confusing aspects ui example generate multiple images single task batch count size using scripts xyz gird left right buttons either directly click image using keyboard arrow keys navigate images could also confusing full screen image viewer left right buttons notice seed parameter change flip images history history referring images form past tasks shows image current task history view basement however extensions add feature couple history extentions found extensions tab note use extensions endorsement
auto1111_webui,issue,17002,"[Bug]: webui.sh start failed on macos, ValueError: When localhost is not accessible, a shareable link must be created.","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

webui.sh start failed on macos


### Steps to reproduce the problem

Follow steps from `Installation on Apple Silicon`

### What should have happened?

WebUi should started

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

Can't go webui

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on xxx user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /Users/xxx/.pyenv/versions/3.10.6/envs/stable-diffusion
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.6 (main, May 22 2025, 10:51:10) [Clang 17.0.0 (clang-1700.0.13.3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [ad2a33c361] from /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.ckpt
Running on local URL:  http://127.0.0.1:7860
Creating model from config: /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.yaml
Traceback (most recent call last):
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/modules/launch_utils.py"", line 469, in start
    webui.webui()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/webui.py"", line 79, in webui
    app, local_url, share_url = shared.demo.launch(
  File ""/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/gradio/blocks.py"", line 1971, in launch
    raise ValueError(
ValueError: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.
 1 .env +                                                                                                                                                                                                          
Applying attention optimization: sub-quadratic... done.
```

### Additional information

Fixed after upgrade gradio
```sh
pip install --upgrade gradio

Successfully installed fastapi-0.115.12 gradio-5.30.0 pydantic-2.11.4 starlette-0.46.2
```",2025-05-22T05:48:32Z,waitpigfly,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17002,"[Bug]: webui.sh start failed on macos, ValueError: When localhost is not accessible, a shareable link must be created. ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

webui.sh start failed on macos


### Steps to reproduce the problem

Follow steps from `Installation on Apple Silicon`

### What should have happened?

WebUi should started

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

Can't go webui

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on xxx user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /Users/xxx/.pyenv/versions/3.10.6/envs/stable-diffusion
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.6 (main, May 22 2025, 10:51:10) [Clang 17.0.0 (clang-1700.0.13.3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [ad2a33c361] from /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.ckpt
Running on local URL:  http://127.0.0.1:7860
Creating model from config: /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.yaml
Traceback (most recent call last):
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/modules/launch_utils.py"", line 469, in start
    webui.webui()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/webui.py"", line 79, in webui
    app, local_url, share_url = shared.demo.launch(
  File ""/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/gradio/blocks.py"", line 1971, in launch
    raise ValueError(
ValueError: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.
 1 .env +                                                                                                                                                                                                          
Applying attention optimization: sub-quadratic... done.
```

### Additional information

Fixed after upgrade gradio
```sh
pip install --upgrade gradio

Successfully installed fastapi-0.115.12 gradio-5.30.0 pydantic-2.11.4 starlette-0.46.2
```",bug webui sh start failed macos valueerror localhost accessible shareable link must created checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened webui sh start failed macos steps reproduce problem follow steps installation apple silicon happened webui started browsers use access ui google chrome sysinfo go webui console logs shell install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running xxx user repo already cloned using install directory python venv already activate run without venv users xxx pyenv versions envs stable diffusion launching launch py python main may clang clang version v commit hash c ae bd abdf eda b e launching web ui arguments skip torch cuda test upcast sampling half vae use cpu interrogate users xxx pyenv versions stable diffusion lib python site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without warning caught exception torch compiled cuda enabled memory monitor disabled loading weights ad c users xxx code llm stable diffusion webui models stable diffusion v ema pruned ckpt running local url creating model config users xxx code llm stable diffusion webui models stable diffusion v ema pruned yaml traceback recent call last file users xxx code llm stable diffusion webui launch py line module main file users xxx code llm stable diffusion webui launch py line main start file users xxx code llm stable diffusion webui modules launch utils py line start webui webui file users xxx code llm stable diffusion webui webui py line webui app local url share url shared demo launch file users xxx pyenv versions stable diffusion lib python site packages gradio blocks py line launch raise valueerror valueerror localhost accessible shareable link must created please set share true check proxy settings allow access localhost env applying attention optimization sub quadratic done additional information fixed upgrade gradio sh pip install upgrade gradio successfully installed fastapi gradio pydantic starlette
auto1111_webui,comment,17002,,You can try with my step by step [guide](https://github.com/viking1304/a1111-setup/discussions/2) or my install script (faster and easier).,2025-07-01T17:51:03Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17002#issuecomment-3024994296,You can try with my step by step [guide](https://github.com/viking1304/a1111-setup/discussions/2) or my install script (faster and easier).,try step step guide install script faster easier
auto1111_webui,issue,16997,[Bug]: Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Steps to reproduce the problem

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Console logs

```Shell
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant
```

### Additional information

_No response_",2025-05-18T14:57:32Z,wzgrx,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16997,"[Bug]: Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Steps to reproduce the problem

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Console logs

```Shell
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant
```

### Additional information

_No response_",bug argument interpolation interpolationmode corresponding pillow integer constant checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened argument interpolation interpolationmode corresponding pillow integer constant steps reproduce problem argument interpolation interpolationmode corresponding pillow integer constant happened argument interpolation interpolationmode corresponding pillow integer constant browsers use access ui microsoft edge sysinfo argument interpolation interpolationmode corresponding pillow integer constant console logs shell argument interpolation interpolationmode corresponding pillow integer constant additional information response
auto1111_webui,comment,16997,,"

### What happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

_sarcasm_
""good"", so it's working as intended?

---

Please fill out the book report form as requested
important information is include
`Steps to reproduce the problem`: we need information on what you did otherwise we can't start debugging let alone fixing it
`Sysinfo`: we need to know what your status of your installation is, read the template to know how to upload this
`Console logs`: need to see the full trace of the error not just a single line


",2025-05-19T03:54:34Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16997#issuecomment-2889534362,"### What happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

_sarcasm_
""good"", so it's working as intended?

---

Please fill out the book report form as requested
important information is include
`Steps to reproduce the problem`: we need information on what you did otherwise we can't start debugging let alone fixing it
`Sysinfo`: we need to know what your status of your installation is, read the template to know how to upload this
`Console logs`: need to see the full trace of the error not just a single line",happened argument interpolation interpolationmode corresponding pillow integer constant happened argument interpolation interpolationmode corresponding pillow integer constant sarcasm good working intended please fill book report form requested important information include steps reproduce problem need information otherwise start debugging let alone fixing sysinfo need know status installation read template know upload console logs need see full trace error single line
auto1111_webui,issue,16991,Trouble launching webui,"When i run `./webui.sh`, even after i deleted the `venv` folder (i don't have a `repositories` folder), I get this error :


################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tristanpichard user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################
Traceback (most recent call last):
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 110, in _get_module_details
    __import__(pkg_name)
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/__init__.py"", line 1, in <module>
    from typing import List, Optional
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__
    self._abc_registry = extra._abc_registry
AttributeError: type object 'Callable' has no attribute '_abc_registry'

################################################################
Launching launch.py...
################################################################
Traceback (most recent call last):
  File ""/Users/tristanpichard/stable-diffusion-webui/launch.py"", line 1, in <module>
    from modules import launch_utils
  File ""/Users/tristanpichard/stable-diffusion-webui/modules/launch_utils.py"", line 9, in <module>
    import importlib.metadata
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/__init__.py"", line 17, in <module>
    from . import _adapters, _meta
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/_meta.py"", line 1, in <module>
    from typing import Any, Dict, Iterator, List, Protocol, TypeVar, Union
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__

Does anyone know how to resolve that ?",2025-05-14T22:17:59Z,XxpintelxX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16991,"Trouble launching webui When i run `./webui.sh`, even after i deleted the `venv` folder (i don't have a `repositories` folder), I get this error :


################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tristanpichard user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################
Traceback (most recent call last):
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 110, in _get_module_details
    __import__(pkg_name)
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/__init__.py"", line 1, in <module>
    from typing import List, Optional
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__
    self._abc_registry = extra._abc_registry
AttributeError: type object 'Callable' has no attribute '_abc_registry'

################################################################
Launching launch.py...
################################################################
Traceback (most recent call last):
  File ""/Users/tristanpichard/stable-diffusion-webui/launch.py"", line 1, in <module>
    from modules import launch_utils
  File ""/Users/tristanpichard/stable-diffusion-webui/modules/launch_utils.py"", line 9, in <module>
    import importlib.metadata
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/__init__.py"", line 17, in <module>
    from . import _adapters, _meta
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/_meta.py"", line 1, in <module>
    from typing import Any, Dict, Iterator, List, Protocol, TypeVar, Union
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__

Does anyone know how to resolve that ?",trouble launching webui run webui sh even deleted venv folder repositories folder get error install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running tristanpichard user repo already cloned using install directory create activate python venv traceback recent call last file opt homebrew cellar python frameworks python framework versions lib python runpy py line run module main mod name mod spec code get module details mod name error file opt homebrew cellar python frameworks python framework versions lib python runpy py line get module details return get module details pkg main name error file opt homebrew cellar python frameworks python framework versions lib python runpy py line get module details import pkg name file library frameworks python framework versions lib python site packages pip init py line module typing import list optional file library frameworks python framework versions lib python site packages typing py line module class callable extra collections abc callable metaclass callablemeta file library frameworks python framework versions lib python site packages typing py line new self abc registry extra abc registry attributeerror type object callable attribute abc registry launching launch py traceback recent call last file users tristanpichard stable diffusion webui launch py line module modules import launch utils file users tristanpichard stable diffusion webui modules launch utils py line module import importlib metadata file opt homebrew cellar python frameworks python framework versions lib python importlib metadata init py line module import adapters meta file opt homebrew cellar python frameworks python framework versions lib python importlib metadata meta py line module typing import dict iterator list protocol typevar union file library frameworks python framework versions lib python site packages typing py line module class callable extra collections abc callable metaclass callablemeta file library frameworks python framework versions lib python site packages typing py line new anyone know resolve
auto1111_webui,issue,16990,[Bug]: SD was running fast and slowed down a lot,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

On the first day after I installed it, SD worked very fast, it took no more than 40 seconds for one picture to be fully generated. The next day, it started spending more than 5-6 minutes on ONE picture. I changed the checkpoint and it started working normally again. The next day, the same thing happened, it started requiring 5-6 minutes to generate, and now both checkpoints. I tried to write different arguments to the .bat file that I could find on the Internet - the problem did not disappear. I tried different drivers for the video card - it did not help. Video card RTX 4060 8GB, processor Ryzen 7 5700X.

### Steps to reproduce the problem

Normal launch of SD via .bat file

### What should have happened?

I can't say anything in this field because my problem doesn't imply anything that could be written here.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-05-12-07-05.json](https://github.com/user-attachments/files/20156299/sysinfo-2025-05-12-07-05.json)

### Console logs

```Shell
Loading weights [bdb59bac77] from C:\Users\CoteLo\Desktop\sd.webui\webui\models\Stable-diffusion\waiNSFWIllustrious_v140.safetensors
Creating model from config: C:\Users\CoteLo\Desktop\sd.webui\webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 11.1s (prepare environment: 2.1s, import torch: 3.7s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 1.0s, create ui: 2.0s, gradio launch: 0.2s).
Applying attention optimization: xformers... done.
Model loaded in 6.2s (load weights from disk: 0.1s, create model: 1.9s, apply weights to model: 3.7s, move model to device: 0.1s, calculate empty prompt: 0.1s).
```

### Additional information

Please help me figure out what happened, I want to continue my work in SD, but I have to wait 5-6 minutes for one generation each time, especially when the final result does not always meet the requirement",2025-05-12T07:22:56Z,bzelenkov,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990,"[Bug]: SD was running fast and slowed down a lot ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

On the first day after I installed it, SD worked very fast, it took no more than 40 seconds for one picture to be fully generated. The next day, it started spending more than 5-6 minutes on ONE picture. I changed the checkpoint and it started working normally again. The next day, the same thing happened, it started requiring 5-6 minutes to generate, and now both checkpoints. I tried to write different arguments to the .bat file that I could find on the Internet - the problem did not disappear. I tried different drivers for the video card - it did not help. Video card RTX 4060 8GB, processor Ryzen 7 5700X.

### Steps to reproduce the problem

Normal launch of SD via .bat file

### What should have happened?

I can't say anything in this field because my problem doesn't imply anything that could be written here.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-05-12-07-05.json](https://github.com/user-attachments/files/20156299/sysinfo-2025-05-12-07-05.json)

### Console logs

```Shell
Loading weights [bdb59bac77] from C:\Users\CoteLo\Desktop\sd.webui\webui\models\Stable-diffusion\waiNSFWIllustrious_v140.safetensors
Creating model from config: C:\Users\CoteLo\Desktop\sd.webui\webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 11.1s (prepare environment: 2.1s, import torch: 3.7s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 1.0s, create ui: 2.0s, gradio launch: 0.2s).
Applying attention optimization: xformers... done.
Model loaded in 6.2s (load weights from disk: 0.1s, create model: 1.9s, apply weights to model: 3.7s, move model to device: 0.1s, calculate empty prompt: 0.1s).
```

### Additional information

Please help me figure out what happened, I want to continue my work in SD, but I have to wait 5-6 minutes for one generation each time, especially when the final result does not always meet the requirement",bug sd running fast slowed lot checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened first day installed sd worked fast took seconds one picture fully generated next day started spending minutes one picture changed checkpoint started working normally next day thing happened started requiring minutes generate checkpoints tried write different arguments bat file could find internet problem disappear tried different drivers video card help video card rtx gb processor ryzen x steps reproduce problem normal launch sd via bat file happened say anything field problem imply anything could written browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell loading weights bdb bac c users cotelo desktop sd webui webui models stable diffusion wainsfwillustrious v safetensors creating model config c users cotelo desktop sd webui webui repositories generative models configs inference sd xl base yaml c users cotelo desktop sd webui webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead model style container false c users cotelo desktop sd webui webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false c users cotelo desktop sd webui webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false c users cotelo desktop sd webui webui extensions stable diffusion webui stable horde scripts main py gradiodeprecationwarning style method deprecated please set arguments constructor instead post processing style container false c users cotelo desktop sd webui system python lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch applying attention optimization xformers done model loaded load weights disk create model apply weights model move model device calculate empty prompt additional information please help figure happened want continue work sd wait minutes one generation time especially final result always meet requirement
auto1111_webui,comment,16990,,"I also tried using v1.0.0-pre for Nvidia cards, but it makes no difference",2025-05-12T07:28:22Z,bzelenkov,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990#issuecomment-2871214788,"I also tried using v1.0.0-pre for Nvidia cards, but it makes no difference",also tried using v pre nvidia cards makes difference
auto1111_webui,comment,16990,,"what is your VRAM usage?

my guess of what's happening is that you VRAM is near full

in nvidia settings there is something called CUDA - Sysmem Fallback Policy
basically this is something that would tell the GPU to use system RAM as VRAM when VRAM is near full
this would sometimes prevent out of memory issues but at the cost of drastically reducing speed
this can be disabled changeing the CUDA - Sysmem Fallback Policy. Set the value to Prefer No Sysmem Fallback in nvidia settings settings, see
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/11063

---

if you are faceing out of memory issues, try [Tiled VAE](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111)
",2025-05-12T22:03:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990#issuecomment-2874305266,"what is your VRAM usage?

my guess of what's happening is that you VRAM is near full

in nvidia settings there is something called CUDA - Sysmem Fallback Policy
basically this is something that would tell the GPU to use system RAM as VRAM when VRAM is near full
this would sometimes prevent out of memory issues but at the cost of drastically reducing speed
this can be disabled changeing the CUDA - Sysmem Fallback Policy. Set the value to Prefer No Sysmem Fallback in nvidia settings settings, see
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/11063

---

if you are faceing out of memory issues, try [Tiled VAE](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111)",vram usage guess happening vram near full nvidia settings something called cuda sysmem fallback policy basically something would tell gpu use system ram vram vram near full would sometimes prevent memory issues cost drastically reducing speed disabled changeing cuda sysmem fallback policy set value prefer sysmem fallback nvidia settings settings see faceing memory issues try tiled vae
auto1111_webui,issue,16986,"[Bug]: WebUI won't start (fresh copy, macOS on Apple Silicon)","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

As I could not find the issue with the search, I hope this is the right place to report it. Today I tried to run the WebUI as a fresh install on a new Mac (about a week old, so System is also a fresh install) with Apple Silicon (M4 Max). 

When running `./webui.sh` I get the following (tried to re-run the same sh after it fails the first time with the same issue): 

```
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Steps to reproduce the problem

1. Fresh copy of this repo on macOS
2. Run `./webui.sh`

### What should have happened?

It should run?

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't, application won't launch.

### Console logs

```Shell
sebastian@Sebastians-MacBookPro2025 stable-diffusion-webui % ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Additional information

_No response_",2025-05-07T19:58:45Z,Sebastian1989101,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986,"[Bug]: WebUI won't start (fresh copy, macOS on Apple Silicon) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

As I could not find the issue with the search, I hope this is the right place to report it. Today I tried to run the WebUI as a fresh install on a new Mac (about a week old, so System is also a fresh install) with Apple Silicon (M4 Max). 

When running `./webui.sh` I get the following (tried to re-run the same sh after it fails the first time with the same issue): 

```
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Steps to reproduce the problem

1. Fresh copy of this repo on macOS
2. Run `./webui.sh`

### What should have happened?

It should run?

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't, application won't launch.

### Console logs

```Shell
sebastian@Sebastians-MacBookPro2025 stable-diffusion-webui % ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Additional information

_No response_",bug webui start fresh copy macos apple silicon checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened could find issue search hope right place report today tried run webui fresh install new mac week old system also fresh install apple silicon max running webui sh get following tried run sh fails first time issue install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running sebastian user repo already cloned using install directory create activate python venv launching launch py python main apr clang clang version v commit hash c ae bd abdf eda b e installing requirements launching web ui arguments skip torch cuda test upcast sampling half vae use cpu interrogate traceback recent call last file volumes external stable diffusion stable diffusion webui launch py line module main file volumes external stable diffusion stable diffusion webui launch py line main start file volumes external stable diffusion stable diffusion webui modules launch utils py line start import webui file volumes external stable diffusion stable diffusion webui webui py line module initialize imports file volumes external stable diffusion stable diffusion webui modules initialize py line imports import pytorch lightning noqa f modulenotfounderror module named pytorch lightning steps reproduce problem fresh copy repo macos run webui sh happened run browsers use access ui google chrome sysinfo application launch console logs shell sebastian sebastians macbookpro stable diffusion webui webui sh install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running sebastian user repo already cloned using install directory create activate python venv launching launch py python main apr clang clang version v commit hash c ae bd abdf eda b e installing requirements launching web ui arguments skip torch cuda test upcast sampling half vae use cpu interrogate traceback recent call last file volumes external stable diffusion stable diffusion webui launch py line module main file volumes external stable diffusion stable diffusion webui launch py line main start file volumes external stable diffusion stable diffusion webui modules launch utils py line start import webui file volumes external stable diffusion stable diffusion webui webui py line module initialize imports file volumes external stable diffusion stable diffusion webui modules initialize py line imports import pytorch lightning noqa f modulenotfounderror module named pytorch lightning additional information response
auto1111_webui,comment,16986,,"I delete venv folder and works, however extremely slow on M4.",2025-06-30T09:49:24Z,ach1llea,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986#issuecomment-3018508210,"I delete venv folder and works, however extremely slow on M4.",delete venv folder works however extremely slow
auto1111_webui,comment,16986,,"> I delete venv folder and works, however extremely slow on M4.

You can try some alternative command lines I posted [here](https://github.com/viking1304/a1111-setup/discussions/2), but do not expect drastic improvements.",2025-07-01T17:43:07Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986#issuecomment-3024971482,"> I delete venv folder and works, however extremely slow on M4.

You can try some alternative command lines I posted [here](https://github.com/viking1304/a1111-setup/discussions/2), but do not expect drastic improvements.",delete venv folder works however extremely slow try alternative command lines posted expect drastic improvements
auto1111_webui,issue,16974,[Bug]: Help installation stable diffusion en linux Ubuntu/PopOS with rtx 5070,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello, I have been trying to install stable diffusion webui in PopOS, similar to Ubuntu, but every time I click on generate image I get this error in the graphical interface

error RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

I get this error in the terminal:

https://pastebin.com/N9E7ERWY

This is my nvidia-smi

https://pastebin.com/3nbmjAKb

I have Python 3.10.6

So, has anyone on Linux managed to get SD WebUI working with the Nvidia 50xx series? It works on Windows, but in my opinion, given the cost of the graphics card, it's not fast enough, and it's always been faster on Linux. If anyone could do it or help me, it would be a great help. Thanks.

### Steps to reproduce the problem

1. Install Ubuntu, PopOs, or similar
2. Make sure you have the NVIDIA drivers, Python 3.10.6, and Git
3. Download stable diffusion webui
4. Run ./webui.sh
5. Click the Generate Image button and the error message will appear.

### What should have happened?

The image has been generated

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-04-30-01-13.json](https://github.com/user-attachments/files/19969546/sysinfo-2025-04-30-01-13.json)

### Console logs

```Shell
https://pastebin.com/N9E7ERWY
```

### Additional information

_No response_",2025-04-30T01:16:48Z,Arion107,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974,"[Bug]: Help installation stable diffusion en linux Ubuntu/PopOS with rtx 5070 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello, I have been trying to install stable diffusion webui in PopOS, similar to Ubuntu, but every time I click on generate image I get this error in the graphical interface

error RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

I get this error in the terminal:

https://pastebin.com/N9E7ERWY

This is my nvidia-smi

https://pastebin.com/3nbmjAKb

I have Python 3.10.6

So, has anyone on Linux managed to get SD WebUI working with the Nvidia 50xx series? It works on Windows, but in my opinion, given the cost of the graphics card, it's not fast enough, and it's always been faster on Linux. If anyone could do it or help me, it would be a great help. Thanks.

### Steps to reproduce the problem

1. Install Ubuntu, PopOs, or similar
2. Make sure you have the NVIDIA drivers, Python 3.10.6, and Git
3. Download stable diffusion webui
4. Run ./webui.sh
5. Click the Generate Image button and the error message will appear.

### What should have happened?

The image has been generated

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-04-30-01-13.json](https://github.com/user-attachments/files/19969546/sysinfo-2025-04-30-01-13.json)

### Console logs

```Shell
https://pastebin.com/N9E7ERWY
```

### Additional information

_No response_",bug help installation stable diffusion en linux ubuntu popos rtx checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened hello trying install stable diffusion webui popos similar ubuntu every time click generate image get error graphical interface error runtimeerror cuda error kernel image available execution device cuda kernel errors might asynchronously reported api call stacktrace might incorrect debugging consider passing cuda launch blocking compile torch use cuda dsa enable device side assertions get error terminal nvidia smi python anyone linux managed get sd webui working nvidia xx series works windows opinion given cost graphics card fast enough always faster linux anyone could help would great help thanks steps reproduce problem install ubuntu popos similar make sure nvidia drivers python git download stable diffusion webui run webui sh click generate image button error message appear happened image generated browsers use access ui google chrome sysinfo sysinfo json console logs shell additional information response
auto1111_webui,comment,16974,,"My setup:
- Debian 12 x86_64, Linux kernel 6.14.3
- NVIDIA drivers 570.144
- Geforce RTX 5060 Ti with 16 GB RAM

I received a similar error message:

```
NVIDIA Graphics Device with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
```

I was able to get it working with the commands below:

```
git switch dev
webui.sh --reinstall-torch
webui.sh --reinstall-xformers
webui.sh
```

Hope it helps. And thanks to w-e-w for the patches!",2025-04-30T18:29:53Z,semolina5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974#issuecomment-2842925084,"My setup:
- Debian 12 x86_64, Linux kernel 6.14.3
- NVIDIA drivers 570.144
- Geforce RTX 5060 Ti with 16 GB RAM

I received a similar error message:

```
NVIDIA Graphics Device with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
```

I was able to get it working with the commands below:

```
git switch dev
webui.sh --reinstall-torch
webui.sh --reinstall-xformers
webui.sh
```

Hope it helps. And thanks to w-e-w for the patches!",setup debian x linux kernel nvidia drivers geforce rtx ti gb ram received similar error message nvidia graphics device cuda capability sm compatible current pytorch installation current pytorch install supports cuda capabilities sm sm sm sm sm sm sm able get working commands git switch dev webui sh reinstall torch webui sh reinstall xformers webui sh hope helps thanks w e w patches
auto1111_webui,comment,16974,,"I'm not sure if this is correct information but base of the below on linux you will need drivers `>= 570.26`
https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html

cuDNN Package | CUDA Toolkit Version | Supports static linking?  | NVIDIA Driver Version for Linux | NVIDIA Driver Version for Windows | CUDA Compute Capability | Supported NVIDIA GPU Architectures
-- | -- | -- | -- | -- | -- | --
cuDNN 9.8.0 for CUDA 12.x | 12.8 | Yes | >=570.26 | >=570.65 | 12.0<br>10.0<br>9.0<br>8.9<br>8.6<br>8.0<br>7.5<br>7.0<br>6.1<br>6.0<br>5.0 | NVIDIA Blackwell<br>NVIDIA Hopper<br>NVIDIA Ada Lovelace<br>NVIDIA Ampere<br>NVIDIA Turing<br>NVIDIA Volta<br>NVIDIA Pascal<br>NVIDIA Maxwell

both of you have drivers `< 570.2` specifically `570.133.07` `570.144`
so maybe try updating your drivers
also 50 series cards should switch to dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussion-7893258",2025-05-02T11:05:00Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974#issuecomment-2846951142,"I'm not sure if this is correct information but base of the below on linux you will need drivers `>= 570.26`
https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html

cuDNN Package | CUDA Toolkit Version | Supports static linking?  | NVIDIA Driver Version for Linux | NVIDIA Driver Version for Windows | CUDA Compute Capability | Supported NVIDIA GPU Architectures
-- | -- | -- | -- | -- | -- | --
cuDNN 9.8.0 for CUDA 12.x | 12.8 | Yes | >=570.26 | >=570.65 | 12.0<br>10.0<br>9.0<br>8.9<br>8.6<br>8.0<br>7.5<br>7.0<br>6.1<br>6.0<br>5.0 | NVIDIA Blackwell<br>NVIDIA Hopper<br>NVIDIA Ada Lovelace<br>NVIDIA Ampere<br>NVIDIA Turing<br>NVIDIA Volta<br>NVIDIA Pascal<br>NVIDIA Maxwell

both of you have drivers `< 570.2` specifically `570.133.07` `570.144`
so maybe try updating your drivers
also 50 series cards should switch to dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussion-7893258",sure correct information base linux need drivers cudnn package cuda toolkit version supports static linking nvidia driver version linux nvidia driver version windows cuda compute capability supported nvidia gpu architectures cudnn cuda x yes br br br br br br br br br br nvidia blackwell br nvidia hopper br nvidia ada lovelace br nvidia ampere br nvidia turing br nvidia volta br nvidia pascal br nvidia maxwell drivers specifically maybe try updating drivers also series cards switch dev branch
auto1111_webui,issue,16973,[Bug]: I cant create any images,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I should probably let you know that I'm extremely new to this and i could very well just be an idiot

I got everything installed, ran into the `connection errored out` issue, it fixed itself, then i selected my model of choice, keyed in my prompt, then hit generate.

It didn't seem to be doing anything at all, considering the loading bar wasn't moving, then it just stopped.
I tried re-running it and i got the same issue.
I then checked the console logs and found `Error completing request` followed by a long wall of directories.

### Steps to reproduce the problem

-> Start the program with `webui_user.bat`
-> Let it hitch and chug my pc before i begin prompting, lol
-> I selected my chosen model, which is `ntrMIXIllustriousXL`
-> Keyed in my prompt
-> Then finally hit generate

### What should have happened?

It should have began generating an image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

""Platform"": ""Windows-10-10.0.22631-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-amd-36-g679c645e"",
    ""Commit"": ""679c645ec84e40dd14d527dbeb03fab259087187"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   requirements.txt\n\tmodified:   requirements_versions.txt\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\t.zluda/\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Data path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Extensions dir"": ""C:\\Users\\User\\stable-diffusion-webui-directml\\extensions"",
    ""Checksum"": ""39d8fc504e48a17308a3bebd7503c5b9eec367af4f0226bf40c43749482f0848"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.4.1+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""N/A"",
        ""gcc_version"": null,
        ""clang_version"": ""19.0.0git (git@github.amd.com:Compute-Mirrors/llvm-project b3dbdf4f03718d63a3292f784216fddb3e73d521)"",
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Pro"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.22631-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""onnx==1.16.2"",
            ""onnxruntime==1.21.1"",
            ""onnxruntime-directml==1.18.0"",
            ""onnxscript==0.2.5"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.4.1"",
            ""torch-directml==0.2.5.dev240914"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.1"",
            ""torchsde==0.2.6"",
            ""torchvision==0.19.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""6.1"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=3400"",
            ""DeviceID=CPU0"",
            ""Family=206"",
            ""L2CacheSize=5120"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=3400"",
            ""Name=13th Gen Intel(R) Core(TM) i3-13100"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"",
            ""traceback"": [
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 831, load_model"",
                    ""sd_model = instantiate_from_config(sd_config.model, state_dict)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 775, instantiate_from_config"",
                    ""return constructor(**params)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\models\\diffusion.py, line 61, __init__"",
                    ""self.conditioner = instantiate_from_config(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 88, __init__"",
                    ""embedder = instantiate_from_config(embconfig)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 361, __init__"",
                    ""self.transformer = CLIPTextModel.from_pretrained(version)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_disable_initialization.py, line 68, CLIPTextModel_from_pretrained"",
                    ""res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 262, _wrapper"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 3540, from_pretrained"",
                    ""resolved_config_file = cached_file(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\utils\\hub.py, line 365, cached_file"",
                    ""raise EnvironmentError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 191 Stepping 5, GenuineIntel"",
        ""count logical"": 8,
        ""count physical"": 4
    },
    ""RAM"": {
        ""total"": ""7GB"",
        ""used"": ""5GB"",
        ""free"": ""2GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""ntrMIXIllustriousXL_xiii.safetensors [1207404b17]"",
        ""sd_checkpoint_hash"": ""1207404b1705a026eaa2896b66953dbef8be5ccde5340e4fd940b674aecb8cf8""
    },
    ""Startup"": {
        ""total"": 55.028228521347046,
        ""records"": {
            ""initial startup"": 0.020017385482788086,
            ""prepare environment/checks"": 0.011029243469238281,
            ""prepare environment/git version info"": 1.6748936176300049,
            ""prepare environment/clone repositores"": 26.568973779678345,
            ""prepare environment/run extensions installers"": 0.001995563507080078,
            ""prepare environment"": 58.2568564414978,
            ""launcher"": 0.002000093460083008,
            ""import torch"": 0.0,
            ""import gradio"": 0.0,
            ""setup paths"": 0.0010006427764892578,
            ""import ldm"": 0.0031473636627197266,
            ""import sgm"": 0.0,
            ""initialize shared"": 9.239458799362183,
            ""other imports"": 0.4272043704986572,
            ""opts onchange"": 0.0010008811950683594,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0020225048065185547,
            ""setup gfpgan"": 0.015314340591430664,
            ""set samplers"": 0.0,
            ""list extensions"": 0.0010004043579101562,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.019205570220947266,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.003504514694213867,
            ""load scripts/img2imgalt.py"": 0.0010044574737548828,
            ""load scripts/loopback.py"": 0.0010004043579101562,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_codeformer.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_gfpgan.py"": 0.0,
            ""load scripts/postprocessing_upscale.py"": 0.0010013580322265625,
            ""load scripts/prompt_matrix.py"": 0.0009980201721191406,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009992122650146484,
            ""load scripts/xyz_grid.py"": 0.0020020008087158203,
            ""load scripts/ldsr_model.py"": 0.23322319984436035,
            ""load scripts/lora_script.py"": 0.16320395469665527,
            ""load scripts/scunet_model.py"": 0.02911067008972168,
            ""load scripts/swinir_model.py"": 0.025522232055664062,
            ""load scripts/hotkey_config.py"": 0.0005097389221191406,
            ""load scripts/extra_options_section.py"": 0.0010046958923339844,
            ""load scripts/hypertile_script.py"": 0.047042131423950195,
            ""load scripts/postprocessing_autosized_crop.py"": 0.001504659652709961,
            ""load scripts/postprocessing_caption.py"": 0.0010068416595458984,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.0019991397857666016,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009989738464355469,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/comments.py"": 0.025876283645629883,
            ""load scripts/refiner.py"": 0.001188516616821289,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0009989738464355469,
            ""load scripts"": 0.5457000732421875,
            ""load upscalers"": 0.0035028457641601562,
            ""refresh VAE"": 0.0010051727294921875,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0009996891021728516,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009996891021728516,
            ""initialize extra networks"": 0.25032877922058105,
            ""scripts before_ui_callback"": 0.0031523704528808594,
            ""create ui"": 1.0891542434692383,
            ""gradio launch"": 0.15899944305419922,
            ""add APIs"": 0.006510496139526367,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback"": 0.0
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.11.18"",
        ""aiosignal==1.3.2"",
        ""alembic==1.15.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.4.26"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diffusers==0.29.2"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.57.0"",
        ""frozenlist==1.6.0"",
        ""fsspec==2025.3.2"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.1"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.30.2"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.6.1"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Mako==1.3.10"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.4.3"",
        ""narwhals==1.36.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""olive-ai==0.8.0"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnxruntime==1.21.1"",
        ""onnxruntime-directml==1.18.0"",
        ""onnxscript==0.2.5"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""optimum==1.24.0"",
        ""optuna==4.3.0"",
        ""orjson==3.10.16"",
        ""packaging==25.0"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1"",
        ""propcache==0.3.1"",
        ""protobuf==3.20.2"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.24.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.40"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.3.30"",
        ""timm==1.0.15"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""torch==2.4.1"",
        ""torch-directml==0.2.5.dev240914"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.19.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""typing_extensions==4.13.2"",
        ""tzdata==2025.2"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
venv ""C:\Users\User\stable-diffusion-webui-directml\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-amd-36-g679c645e
Commit hash: 679c645ec84e40dd14d527dbeb03fab259087187
ROCm: agents=['gfx1031']
ROCm: version=6.1, using agent gfx1031
ZLUDA support: experimental
ZLUDA load: path='C:\Users\User\stable-diffusion-webui-directml\.zluda' nightly=False
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\pytorch_lightning\utilities\distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.
  rank_zero_deprecation(
Launching Web UI with arguments:
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
ONNX failed to initialize: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.
Loading weights [1207404b17] from C:\Users\User\stable-diffusion-webui-directml\models\Stable-diffusion\ntrMIXIllustriousXL_xiii.safetensors
Creating model from config: C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 49.1s (prepare environment: 54.1s, initialize shared: 10.3s, other imports: 0.5s, load scripts: 0.5s, initialize extra networks: 0.2s, create ui: 1.4s, gradio launch: 0.3s).
creating model quickly: OSError
Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 409, in hf_raise_for_status
    response.raise_for_status()
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\requests\models.py"", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 342, in cached_file
    resolved_file = hf_hub_download(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 285, in _request_wrapper
    response = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68110227-167031112a31fc012a3e021f;d725f8d3-a1c3-463e-bdb6-5d09c72f2a1c)

Repository Not Found for url: https://huggingface.co/None/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\shared_items.py"", line 190, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 831, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\models\diffusion.py"", line 61, in __init__
    self.conditioner = instantiate_from_config(
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 88, in __init__
    embedder = instantiate_from_config(embconfig)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 361, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 262, in _wrapper
    return func(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 3540, in from_pretrained
    resolved_config_file = cached_file(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 365, in cached_file
    raise EnvironmentError(
OSError: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

Failed to create model quickly; will retry using slow method.
C:\Users\User\stable-diffusion-webui-directml\modules\safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return unsafe_torch_load(filename, *args, **kwargs)
Applying attention optimization: InvokeAI... done.
Model loaded in 1123.0s (calculate hash: 1.4s, load weights from disk: 1.5s, create model: 439.9s, apply weights to model: 599.1s, apply half(): 14.8s, apply dtype to VAE: 0.2s, load VAE: 0.1s, load weights from state dict: 0.2s, move model to device: 0.1s, hijack: 10.5s, load textual inversion embeddings: 0.4s, scripts callbacks: 0.2s, calculate empty prompt: 54.6s).
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(njs4goici10ce24)', <gradio.routes.Request object at 0x0000021451A90C40>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(fx01jbd3ltger2l)', <gradio.routes.Request object at 0x0000021451A50460>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
```

### Additional information

If theres an issue with the tutorial i used, its https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs",2025-04-29T17:48:52Z,Nowman2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973,"[Bug]: I cant create any images ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I should probably let you know that I'm extremely new to this and i could very well just be an idiot

I got everything installed, ran into the `connection errored out` issue, it fixed itself, then i selected my model of choice, keyed in my prompt, then hit generate.

It didn't seem to be doing anything at all, considering the loading bar wasn't moving, then it just stopped.
I tried re-running it and i got the same issue.
I then checked the console logs and found `Error completing request` followed by a long wall of directories.

### Steps to reproduce the problem

-> Start the program with `webui_user.bat`
-> Let it hitch and chug my pc before i begin prompting, lol
-> I selected my chosen model, which is `ntrMIXIllustriousXL`
-> Keyed in my prompt
-> Then finally hit generate

### What should have happened?

It should have began generating an image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

""Platform"": ""Windows-10-10.0.22631-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-amd-36-g679c645e"",
    ""Commit"": ""679c645ec84e40dd14d527dbeb03fab259087187"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   requirements.txt\n\tmodified:   requirements_versions.txt\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\t.zluda/\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Data path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Extensions dir"": ""C:\\Users\\User\\stable-diffusion-webui-directml\\extensions"",
    ""Checksum"": ""39d8fc504e48a17308a3bebd7503c5b9eec367af4f0226bf40c43749482f0848"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.4.1+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""N/A"",
        ""gcc_version"": null,
        ""clang_version"": ""19.0.0git (git@github.amd.com:Compute-Mirrors/llvm-project b3dbdf4f03718d63a3292f784216fddb3e73d521)"",
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Pro"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.22631-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""onnx==1.16.2"",
            ""onnxruntime==1.21.1"",
            ""onnxruntime-directml==1.18.0"",
            ""onnxscript==0.2.5"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.4.1"",
            ""torch-directml==0.2.5.dev240914"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.1"",
            ""torchsde==0.2.6"",
            ""torchvision==0.19.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""6.1"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=3400"",
            ""DeviceID=CPU0"",
            ""Family=206"",
            ""L2CacheSize=5120"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=3400"",
            ""Name=13th Gen Intel(R) Core(TM) i3-13100"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"",
            ""traceback"": [
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 831, load_model"",
                    ""sd_model = instantiate_from_config(sd_config.model, state_dict)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 775, instantiate_from_config"",
                    ""return constructor(**params)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\models\\diffusion.py, line 61, __init__"",
                    ""self.conditioner = instantiate_from_config(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 88, __init__"",
                    ""embedder = instantiate_from_config(embconfig)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 361, __init__"",
                    ""self.transformer = CLIPTextModel.from_pretrained(version)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_disable_initialization.py, line 68, CLIPTextModel_from_pretrained"",
                    ""res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 262, _wrapper"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 3540, from_pretrained"",
                    ""resolved_config_file = cached_file(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\utils\\hub.py, line 365, cached_file"",
                    ""raise EnvironmentError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 191 Stepping 5, GenuineIntel"",
        ""count logical"": 8,
        ""count physical"": 4
    },
    ""RAM"": {
        ""total"": ""7GB"",
        ""used"": ""5GB"",
        ""free"": ""2GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""ntrMIXIllustriousXL_xiii.safetensors [1207404b17]"",
        ""sd_checkpoint_hash"": ""1207404b1705a026eaa2896b66953dbef8be5ccde5340e4fd940b674aecb8cf8""
    },
    ""Startup"": {
        ""total"": 55.028228521347046,
        ""records"": {
            ""initial startup"": 0.020017385482788086,
            ""prepare environment/checks"": 0.011029243469238281,
            ""prepare environment/git version info"": 1.6748936176300049,
            ""prepare environment/clone repositores"": 26.568973779678345,
            ""prepare environment/run extensions installers"": 0.001995563507080078,
            ""prepare environment"": 58.2568564414978,
            ""launcher"": 0.002000093460083008,
            ""import torch"": 0.0,
            ""import gradio"": 0.0,
            ""setup paths"": 0.0010006427764892578,
            ""import ldm"": 0.0031473636627197266,
            ""import sgm"": 0.0,
            ""initialize shared"": 9.239458799362183,
            ""other imports"": 0.4272043704986572,
            ""opts onchange"": 0.0010008811950683594,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0020225048065185547,
            ""setup gfpgan"": 0.015314340591430664,
            ""set samplers"": 0.0,
            ""list extensions"": 0.0010004043579101562,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.019205570220947266,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.003504514694213867,
            ""load scripts/img2imgalt.py"": 0.0010044574737548828,
            ""load scripts/loopback.py"": 0.0010004043579101562,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_codeformer.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_gfpgan.py"": 0.0,
            ""load scripts/postprocessing_upscale.py"": 0.0010013580322265625,
            ""load scripts/prompt_matrix.py"": 0.0009980201721191406,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009992122650146484,
            ""load scripts/xyz_grid.py"": 0.0020020008087158203,
            ""load scripts/ldsr_model.py"": 0.23322319984436035,
            ""load scripts/lora_script.py"": 0.16320395469665527,
            ""load scripts/scunet_model.py"": 0.02911067008972168,
            ""load scripts/swinir_model.py"": 0.025522232055664062,
            ""load scripts/hotkey_config.py"": 0.0005097389221191406,
            ""load scripts/extra_options_section.py"": 0.0010046958923339844,
            ""load scripts/hypertile_script.py"": 0.047042131423950195,
            ""load scripts/postprocessing_autosized_crop.py"": 0.001504659652709961,
            ""load scripts/postprocessing_caption.py"": 0.0010068416595458984,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.0019991397857666016,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009989738464355469,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/comments.py"": 0.025876283645629883,
            ""load scripts/refiner.py"": 0.001188516616821289,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0009989738464355469,
            ""load scripts"": 0.5457000732421875,
            ""load upscalers"": 0.0035028457641601562,
            ""refresh VAE"": 0.0010051727294921875,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0009996891021728516,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009996891021728516,
            ""initialize extra networks"": 0.25032877922058105,
            ""scripts before_ui_callback"": 0.0031523704528808594,
            ""create ui"": 1.0891542434692383,
            ""gradio launch"": 0.15899944305419922,
            ""add APIs"": 0.006510496139526367,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback"": 0.0
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.11.18"",
        ""aiosignal==1.3.2"",
        ""alembic==1.15.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.4.26"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diffusers==0.29.2"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.57.0"",
        ""frozenlist==1.6.0"",
        ""fsspec==2025.3.2"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.1"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.30.2"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.6.1"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Mako==1.3.10"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.4.3"",
        ""narwhals==1.36.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""olive-ai==0.8.0"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnxruntime==1.21.1"",
        ""onnxruntime-directml==1.18.0"",
        ""onnxscript==0.2.5"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""optimum==1.24.0"",
        ""optuna==4.3.0"",
        ""orjson==3.10.16"",
        ""packaging==25.0"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1"",
        ""propcache==0.3.1"",
        ""protobuf==3.20.2"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.24.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.40"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.3.30"",
        ""timm==1.0.15"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""torch==2.4.1"",
        ""torch-directml==0.2.5.dev240914"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.19.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""typing_extensions==4.13.2"",
        ""tzdata==2025.2"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
venv ""C:\Users\User\stable-diffusion-webui-directml\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-amd-36-g679c645e
Commit hash: 679c645ec84e40dd14d527dbeb03fab259087187
ROCm: agents=['gfx1031']
ROCm: version=6.1, using agent gfx1031
ZLUDA support: experimental
ZLUDA load: path='C:\Users\User\stable-diffusion-webui-directml\.zluda' nightly=False
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\pytorch_lightning\utilities\distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.
  rank_zero_deprecation(
Launching Web UI with arguments:
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
ONNX failed to initialize: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.
Loading weights [1207404b17] from C:\Users\User\stable-diffusion-webui-directml\models\Stable-diffusion\ntrMIXIllustriousXL_xiii.safetensors
Creating model from config: C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 49.1s (prepare environment: 54.1s, initialize shared: 10.3s, other imports: 0.5s, load scripts: 0.5s, initialize extra networks: 0.2s, create ui: 1.4s, gradio launch: 0.3s).
creating model quickly: OSError
Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 409, in hf_raise_for_status
    response.raise_for_status()
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\requests\models.py"", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 342, in cached_file
    resolved_file = hf_hub_download(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 285, in _request_wrapper
    response = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68110227-167031112a31fc012a3e021f;d725f8d3-a1c3-463e-bdb6-5d09c72f2a1c)

Repository Not Found for url: https://huggingface.co/None/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\shared_items.py"", line 190, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 831, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\models\diffusion.py"", line 61, in __init__
    self.conditioner = instantiate_from_config(
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 88, in __init__
    embedder = instantiate_from_config(embconfig)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 361, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 262, in _wrapper
    return func(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 3540, in from_pretrained
    resolved_config_file = cached_file(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 365, in cached_file
    raise EnvironmentError(
OSError: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

Failed to create model quickly; will retry using slow method.
C:\Users\User\stable-diffusion-webui-directml\modules\safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return unsafe_torch_load(filename, *args, **kwargs)
Applying attention optimization: InvokeAI... done.
Model loaded in 1123.0s (calculate hash: 1.4s, load weights from disk: 1.5s, create model: 439.9s, apply weights to model: 599.1s, apply half(): 14.8s, apply dtype to VAE: 0.2s, load VAE: 0.1s, load weights from state dict: 0.2s, move model to device: 0.1s, hijack: 10.5s, load textual inversion embeddings: 0.4s, scripts callbacks: 0.2s, calculate empty prompt: 54.6s).
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(njs4goici10ce24)', <gradio.routes.Request object at 0x0000021451A90C40>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(fx01jbd3ltger2l)', <gradio.routes.Request object at 0x0000021451A50460>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
```

### Additional information

If theres an issue with the tutorial i used, its https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs",bug cant create images checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened probably let know extremely new could well idiot got everything installed ran connection errored issue fixed selected model choice keyed prompt hit generate seem anything considering loading bar moving stopped tried running got issue checked console logs found error completing request followed long wall directories steps reproduce problem start program webui user bat let hitch chug pc begin prompting lol selected chosen model ntrmixillustriousxl keyed prompt finally hit generate happened began generating image browsers use access ui google chrome sysinfo platform windows sp python version v amd g c e commit c ec e dd dbeb fab git status branch master nyour branch date origin master n nchanges staged commit n use git add file update committed n use git restore file discard changes working directory n tmodified requirements txt n tmodified requirements versions txt n nuntracked files n use git add file include committed n zluda n nno changes added commit use git add git commit script path c users user stable diffusion webui directml data path c users user stable diffusion webui directml extensions dir c users user stable diffusion webui directml extensions checksum fc e bebd c b eec af f bf c f commandline launch py torch env info torch version cpu debug build false cuda compiled version n gcc version null clang version git git github amd com compute mirrors llvm project b dbdf f f fddb e cmake version null os microsoft windows pro libc version n python version tags v c b bd aug msc v bit amd bit runtime python platform windows sp cuda available false cuda runtime version null cuda module loading n nvidia driver version null nvidia gpu models null cudnn version null pip version pip pip packages numpy onnx onnxruntime onnxruntime directml onnxscript open clip torch pytorch lightning torch torch directml dev torchdiffeq torchmetrics torchsde torchvision conda packages null hip compiled version hip runtime version n miopen runtime version n caching allocator config xnnpack available true cpu info architecture currentclockspeed deviceid cpu family l cachesize l cachespeed manufacturer genuineintel maxclockspeed name th gen intel r core tm processortype revision exceptions exception none local folder valid model identifier listed private repository make sure pass token permission repo either logging huggingface cli login passing token token traceback c users user stable diffusion webui directml modules sd models py line load model sd model instantiate config sd config model state dict c users user stable diffusion webui directml modules sd models py line instantiate config return constructor params c users user stable diffusion webui directml repositories generative models sgm models diffusion py line init self conditioner instantiate config c users user stable diffusion webui directml repositories generative models sgm util py line instantiate config return get obj str config target config get params dict c users user stable diffusion webui directml repositories generative models sgm modules encoders modules py line init embedder instantiate config embconfig c users user stable diffusion webui directml repositories generative models sgm util py line instantiate config return get obj str config target config get params dict c users user stable diffusion webui directml repositories generative models sgm modules encoders modules py line init self transformer cliptextmodel pretrained version c users user stable diffusion webui directml modules sd disable initialization py line cliptextmodel pretrained res self cliptextmodel pretrained none model args config pretrained model name path state dict kwargs c users user stable diffusion webui directml venv lib site packages transformers modeling utils py line wrapper return func args kwargs c users user stable diffusion webui directml venv lib site packages transformers modeling utils py line pretrained resolved config file cached file c users user stable diffusion webui directml venv lib site packages transformers utils hub py line cached file raise environmenterror cpu model intel family model stepping genuineintel count logical count physical ram total gb used gb free gb extensions inactive extensions environment gradio analytics enabled false config ldsr steps ldsr cached false scunet tile scunet tile overlap swin tile swin tile overlap swin torch compile false hypertile enable unet false hypertile enable unet secondpass false hypertile max depth unet hypertile max tile unet hypertile swap size unet hypertile enable vae false hypertile max depth vae hypertile max tile vae hypertile swap size vae sd model checkpoint ntrmixillustriousxl xiii safetensors b sd checkpoint hash b eaa b dbef ccde e fd b aecb cf startup total records initial startup prepare environment checks prepare environment git version info prepare environment clone repositores prepare environment run extensions installers prepare environment launcher import torch import gradio setup paths import ldm import sgm initialize shared imports opts onchange setup sd model setup codeformer setup gfpgan set samplers list extensions restore config state file list sd models list localizations load scripts custom code py load scripts img imgalt py load scripts loopback py load scripts outpainting mk py load scripts poor mans outpainting py load scripts postprocessing codeformer py load scripts postprocessing gfpgan py load scripts postprocessing upscale py load scripts prompt matrix py load scripts prompts file py load scripts sd upscale py load scripts xyz grid py load scripts ldsr model py load scripts lora script py load scripts scunet model py load scripts swinir model py load scripts hotkey config py load scripts extra options section py load scripts hypertile script py load scripts postprocessing autosized crop py load scripts postprocessing caption py load scripts postprocessing create flipped copies py load scripts postprocessing focal crop py load scripts postprocessing split oversized py load scripts soft inpainting py load scripts comments py load scripts refiner py load scripts sampler py load scripts seed py load scripts load upscalers refresh vae refresh textual inversion templates scripts list optimizers scripts list unets reload hypernetworks initialize extra networks scripts ui callback create ui gradio launch add apis app started callback lora script py app started callback packages accelerate aenum aiofiles aiohappyeyeballs aio aiosignal alembic altair antlr python runtime anyio async timeout attrs blendmodes certifi charset normalizer clean fid click clip colorama coloredlogs colorlog contourpy cycler deprecation diffusers diskcache einops exceptiongroup facexlib fastapi ffmpy filelock filterpy flatbuffers fonttools frozenlist fsspec ftfy gitdb gitpython gradio gradio client greenlet h huggingface hub humanfriendly idna imageio importlib metadata importlib resources inflection jinja jsonmerge jsonschema jsonschema specifications kiwisolver kornia lark lazy loader lightning utilities llvmlite mako markupsafe matplotlib ml dtypes mpmath multidict narwhals networkx numba numpy olive ai omegaconf onnx onnxruntime onnxruntime directml onnxscript open clip torch opencv python optimum optuna orjson packaging pandas piexif pillow pillow avif plugin pip propcache protobuf psutil pydantic pydub pyparsing pyreadline python dateutil post python multipart pytorch lightning pytz pywavelets pyyaml referencing regex requests resize right rpds py safetensors scikit image scipy semantic version sentencepiece setuptools six smmap sniffio spandrel spandrel extra arches sqlalchemy starlette sympy tifffile timm tokenizers tomesd torch torch directml dev torchdiffeq torchmetrics torchsde torchvision tqdm trampoline transformers typing extensions tzdata urllib uvicorn wcwidth websockets yarl zipp console logs shell venv c users user stable diffusion webui directml venv scripts python exe python tags v c b bd aug msc v bit amd version v amd g c e commit hash c ec e dd dbeb fab rocm agents gfx rocm version using agent gfx zluda support experimental zluda load path c users user stable diffusion webui directml zluda nightly false c users user stable diffusion webui directml venv lib site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without c users user stable diffusion webui directml venv lib site packages pytorch lightning utilities distributed py lightningdeprecationwarning pytorch lightning utilities distributed rank zero deprecated v removed v import pytorch lightning utilities instead rank zero deprecation launching web ui arguments warning caught exception torch compiled cuda enabled memory monitor disabled onnx failed initialize dll load failed importing onnx cpp py export dynamic link library dll initialization routine failed loading weights b c users user stable diffusion webui directml models stable diffusion ntrmixillustriousxl xiii safetensors creating model config c users user stable diffusion webui directml repositories generative models configs inference sd xl base yaml running local url create public link set share true launch startup time prepare environment initialize shared imports load scripts initialize extra networks create ui gradio launch creating model quickly oserror traceback recent call last file c users user stable diffusion webui directml venv lib site packages huggingface hub utils line hf raise status response raise status file c users user stable diffusion webui directml venv lib site packages requests models py line raise status raise response self requests exceptions client error unauthorized url exception direct cause following exception traceback recent call last file c users user stable diffusion webui directml venv lib site packages transformers utils hub py line cached file resolved file hf hub download file c users user stable diffusion webui directml venv lib site packages huggingface hub utils validators py line inner fn return fn args kwargs file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line hf hub download return hf hub download cache dir file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line hf hub download cache dir raise head call error head call error force download local files file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line raise head call error raise head call error file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line get metadata catch error metadata get hf file metadata file c users user stable diffusion webui directml venv lib site packages huggingface hub utils validators py line inner fn return fn args kwargs file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line get hf file metadata r request wrapper file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line request wrapper response request wrapper file c users user stable diffusion webui directml venv lib site packages huggingface hub file download py line request wrapper hf raise status response file c users user stable diffusion webui directml venv lib site packages huggingface hub utils line hf raise status raise format repositorynotfounderror message response e huggingface hub errors repositorynotfounderror client error request id root fc e f f c e bdb c f c repository found url please make sure specified correct repo id repo type trying access private gated repo make sure authenticated details see invalid username password exception direct cause following exception traceback recent call last file c users user appdata local programs python python lib threading py line bootstrap self bootstrap inner file c users user appdata local programs python python lib threading py line bootstrap inner self run file c users user appdata local programs python python lib threading py line run self target self args self kwargs file c users user stable diffusion webui directml modules initialize py line load model shared sd model noqa b file c users user stable diffusion webui directml modules shared items py line sd model return modules sd models model data get sd model file c users user stable diffusion webui directml modules sd models py line get sd model load model file c users user stable diffusion webui directml modules sd models py line load model sd model instantiate config sd config model state dict file c users user stable diffusion webui directml modules sd models py line instantiate config return constructor params file c users user stable diffusion webui directml repositories generative models sgm models diffusion py line init self conditioner instantiate config file c users user stable diffusion webui directml repositories generative models sgm util py line instantiate config return get obj str config target config get params dict file c users user stable diffusion webui directml repositories generative models sgm modules encoders modules py line init embedder instantiate config embconfig file c users user stable diffusion webui directml repositories generative models sgm util py line instantiate config return get obj str config target config get params dict file c users user stable diffusion webui directml repositories generative models sgm modules encoders modules py line init self transformer cliptextmodel pretrained version file c users user stable diffusion webui directml modules sd disable initialization py line cliptextmodel pretrained res self cliptextmodel pretrained none model args config pretrained model name path state dict kwargs file c users user stable diffusion webui directml venv lib site packages transformers modeling utils py line wrapper return func args kwargs file c users user stable diffusion webui directml venv lib site packages transformers modeling utils py line pretrained resolved config file cached file file c users user stable diffusion webui directml venv lib site packages transformers utils hub py line cached file raise environmenterror oserror none local folder valid model identifier listed private repository make sure pass token permission repo either logging huggingface cli login passing token token failed create model quickly retry using slow method c users user stable diffusion webui directml modules safe py futurewarning using torch load weights false current default value uses default pickle module implicitly possible construct malicious pickle data execute arbitrary code unpickling see details future release default value weights flipped true limits functions could executed unpickling arbitrary objects longer allowed loaded via mode unless explicitly allowlisted user via torch serialization add safe globals recommend start setting weights true use case full control loaded file please open issue github issues related experimental feature return unsafe torch load filename args kwargs applying attention optimization invokeai done model loaded calculate hash load weights disk create model apply weights model apply half apply dtype vae load vae load weights state dict move model device hijack load textual inversion embeddings scripts callbacks calculate empty prompt error completing request arguments task njs goici ce gradio routes request object x c yep false latent use checkpoint use sampler use scheduler dpm automatic false false false false positive comma false false start true false false false false false false false traceback recent call last file c users user stable diffusion webui directml modules call queue py line f res list func args kwargs file c users user stable diffusion webui directml modules call queue py line f res func args kwargs file c users user stable diffusion webui directml modules call queue py line f res func args kwargs file c users user stable diffusion webui directml modules txt img py line txt img processed processing process images p file c users user stable diffusion webui directml modules processing py line process images res process images inner p file c users user stable diffusion webui directml modules processing py line process images inner samples ddim p sample conditioning p c unconditional conditioning p uc seeds p seeds subseeds p subseeds subseed strength p subseed strength prompts p prompts file c users user stable diffusion webui directml modules processing py line sample samples self sampler sample self x conditioning unconditional conditioning image conditioning self txt img image conditioning x file c users user stable diffusion webui directml modules sd samplers kdiffusion py line sample samples self launch sampling steps lambda self func self model wrap cfg x extra args self sampler extra args disable false callback self callback state extra params kwargs file c users user stable diffusion webui directml modules sd samplers common py line launch sampling return func file c users user stable diffusion webui directml modules sd samplers kdiffusion py line lambda samples self launch sampling steps lambda self func self model wrap cfg x extra args self sampler extra args disable false callback self callback state extra params kwargs file c users user stable diffusion webui directml venv lib site packages torch utils contextlib py line decorate context return func args kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion sampling py line sample dpmpp denoised model x sigmas extra args file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd samplers cfg denoiser py line forward x self inner model x sigma cond make condition dict cond image cond file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion external py line forward eps self get eps input c self sigma sigma kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion external py line get eps return self inner model apply model args kwargs file c users user stable diffusion webui directml modules sd models xl py line apply model return self model x cond file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file c users user stable diffusion webui directml modules sd hijack utils py line call return self sub func self orig func args kwargs file c users user stable diffusion webui directml modules sd hijack unet py line apply model result orig func self x noisy devices dtype unet devices dtype unet cond kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules wrappers py line forward return self diffusion model file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h module h emb context file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward x layer x emb file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward return checkpoint file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules util py line checkpoint return func inputs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h self layers x file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules container py line forward input module input file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules util py line forward return super forward x float type x dtype file c users user stable diffusion webui directml extensions builtin lora networks py line network groupnorm forward return originals groupnorm forward self input file c users user stable diffusion webui directml venv lib site packages torch nn modules normalization py line forward return f group norm file c users user stable diffusion webui directml venv lib site packages torch nn functional py line group norm return torch group norm input num groups weight bias eps torch backends cudnn enabled runtimeerror mixed dtype cpu expect parameter scalar type float error completing request arguments task fx jbd ltger l gradio routes request object x yep false latent use checkpoint use sampler use scheduler dpm automatic false false false false positive comma false false start true false false false false false false false traceback recent call last file c users user stable diffusion webui directml modules call queue py line f res list func args kwargs file c users user stable diffusion webui directml modules call queue py line f res func args kwargs file c users user stable diffusion webui directml modules call queue py line f res func args kwargs file c users user stable diffusion webui directml modules txt img py line txt img processed processing process images p file c users user stable diffusion webui directml modules processing py line process images res process images inner p file c users user stable diffusion webui directml modules processing py line process images inner samples ddim p sample conditioning p c unconditional conditioning p uc seeds p seeds subseeds p subseeds subseed strength p subseed strength prompts p prompts file c users user stable diffusion webui directml modules processing py line sample samples self sampler sample self x conditioning unconditional conditioning image conditioning self txt img image conditioning x file c users user stable diffusion webui directml modules sd samplers kdiffusion py line sample samples self launch sampling steps lambda self func self model wrap cfg x extra args self sampler extra args disable false callback self callback state extra params kwargs file c users user stable diffusion webui directml modules sd samplers common py line launch sampling return func file c users user stable diffusion webui directml modules sd samplers kdiffusion py line lambda samples self launch sampling steps lambda self func self model wrap cfg x extra args self sampler extra args disable false callback self callback state extra params kwargs file c users user stable diffusion webui directml venv lib site packages torch utils contextlib py line decorate context return func args kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion sampling py line sample dpmpp denoised model x sigmas extra args file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd samplers cfg denoiser py line forward x self inner model x sigma cond make condition dict cond image cond file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion external py line forward eps self get eps input c self sigma sigma kwargs file c users user stable diffusion webui directml repositories k diffusion k diffusion external py line get eps return self inner model apply model args kwargs file c users user stable diffusion webui directml modules sd models xl py line apply model return self model x cond file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd hijack utils py line lambda setattr resolved obj func path lambda args kwargs self args kwargs file c users user stable diffusion webui directml modules sd hijack utils py line call return self sub func self orig func args kwargs file c users user stable diffusion webui directml modules sd hijack unet py line apply model result orig func self x noisy devices dtype unet devices dtype unet cond kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules wrappers py line forward return self diffusion model file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h module h emb context file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward x layer x emb file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward return checkpoint file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules util py line checkpoint return func inputs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules openaimodel py line forward h self layers x file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules container py line forward input module input file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users user stable diffusion webui directml venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users user stable diffusion webui directml repositories generative models sgm modules diffusionmodules util py line forward return super forward x float type x dtype file c users user stable diffusion webui directml extensions builtin lora networks py line network groupnorm forward return originals groupnorm forward self input file c users user stable diffusion webui directml venv lib site packages torch nn modules normalization py line forward return f group norm file c users user stable diffusion webui directml venv lib site packages torch nn functional py line group norm return torch group norm input num groups weight bias eps torch backends cudnn enabled runtimeerror mixed dtype cpu expect parameter scalar type float additional information theres issue tutorial used
auto1111_webui,comment,16973,,Did you install cuda? Your torch is compiled with cpu and  you may check your cuda version and reinstall torch that compiled with your cuda version. ,2025-04-30T11:02:51Z,AUTOMATIC2222,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2841612075,Did you install cuda? Your torch is compiled with cpu and  you may check your cuda version and reinstall torch that compiled with your cuda version.,install cuda torch compiled cpu may check cuda version reinstall torch compiled cuda version
auto1111_webui,comment,16973,,"> Did you install cuda? Your torch is compiled with cpu and you may check your cuda version and reinstall torch that compiled with your cuda version.

Because im using an amd gpu (rx6700xt), i dont use cuda, i use zluda.
How do i reinstall torch on the cpu?",2025-04-30T15:50:25Z,Nowman2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2842455304,"> Did you install cuda? Your torch is compiled with cpu and you may check your cuda version and reinstall torch that compiled with your cuda version.

Because im using an amd gpu (rx6700xt), i dont use cuda, i use zluda.
How do i reinstall torch on the cpu?",install cuda torch compiled cpu may check cuda version reinstall torch compiled cuda version im using amd gpu rx xt dont use cuda use zluda reinstall torch cpu
auto1111_webui,comment,16973,,"you are using stable-diffusion-webui-amdgpu aka stable-diffusion-webui-directml
so please report your issue over at https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu
",2025-05-02T17:14:45Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2847716795,"you are using stable-diffusion-webui-amdgpu aka stable-diffusion-webui-directml
so please report your issue over at https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu",using stable diffusion webui amdgpu aka stable diffusion webui directml please report issue
auto1111_webui,issue,16971,[Bug]: zluda resolution bug,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I'm trying to generate an image rather 800x800 or higher the pc will freeze and it give me

OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation. See documentation for Memory Management (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Time taken: 22 min. 58.9 sec.

I tried a lot to fix it but no avail,  I re installed the wepui multiple times and zluda + hip too 

Is there any fix for that? Or should I go to comfy ai?
Well I got the same problem if I went to comfy?

My gpu rx6700xt 12GB vram I installed gfx1031 the image generation gose well if I low down the resolution but I don't want to

### Steps to reproduce the problem

Low down resolution, disable upscale

### What should have happened?

Normal image generation without freezing on 99%

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

""starlette==0.26.1"",
        ""svg.path==6.3"",
        ""svglib==1.5.1"",
        ""sympy==1.13.1"",
        ""tabulate==0.9.0"",
        ""termcolor==3.0.1"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.3.30"",
        ""timm==0.6.7"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.6.0+cu118"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.21.0+cu118"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.6.8"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.2"",
        ""ultralytics==8.3.119"",
        ""ultralytics-thop==2.0.14"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""win32_setctime==1.2.0"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\repositories\generative-models\sgm\modules\diffusionmodules\model.py"", line 132, in forward
        h = self.conv1(h)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```

### Additional information

When I mentioned freezing at 99% I mean the whole pc freezes not only the browser ",2025-04-29T05:44:05Z,Neko21421,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16971,"[Bug]: zluda resolution bug ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I'm trying to generate an image rather 800x800 or higher the pc will freeze and it give me

OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation. See documentation for Memory Management (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Time taken: 22 min. 58.9 sec.

I tried a lot to fix it but no avail,  I re installed the wepui multiple times and zluda + hip too 

Is there any fix for that? Or should I go to comfy ai?
Well I got the same problem if I went to comfy?

My gpu rx6700xt 12GB vram I installed gfx1031 the image generation gose well if I low down the resolution but I don't want to

### Steps to reproduce the problem

Low down resolution, disable upscale

### What should have happened?

Normal image generation without freezing on 99%

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

""starlette==0.26.1"",
        ""svg.path==6.3"",
        ""svglib==1.5.1"",
        ""sympy==1.13.1"",
        ""tabulate==0.9.0"",
        ""termcolor==3.0.1"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.3.30"",
        ""timm==0.6.7"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.6.0+cu118"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.21.0+cu118"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.6.8"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.2"",
        ""ultralytics==8.3.119"",
        ""ultralytics-thop==2.0.14"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""win32_setctime==1.2.0"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\repositories\generative-models\sgm\modules\diffusionmodules\model.py"", line 132, in forward
        h = self.conv1(h)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```

### Additional information

When I mentioned freezing at 99% I mean the whole pc freezes not only the browser",bug zluda resolution bug checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened trying generate image rather x higher pc freeze give outofmemoryerror cuda memory tried allocate gib gpu total capacity gib bytes free allocated memory gib allocated pytorch gib reserved pytorch unallocated reserved unallocated memory large try setting pytorch cuda alloc conf expandable segments true avoid fragmentation see documentation memory management time taken min sec tried lot fix avail installed wepui multiple times zluda hip fix go comfy ai well got problem went comfy gpu rx xt gb vram installed gfx image generation gose well low resolution want steps reproduce problem low resolution disable upscale happened normal image generation without freezing browsers use access ui microsoft edge sysinfo starlette svg path svglib sympy tabulate termcolor threadpoolctl tifffile timm tinycss tokenizers tomesd tomli torch cu torchdiffeq torchmetrics torchsde torchvision cu tqdm trampoline transformers trimesh typing extensions tzdata ultralytics ultralytics thop urllib uvicorn vhacdx post wcwidth webencodings websockets win setctime xxhash yacs yapf yarl zipp console logs shell file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users owner stable diffusion webui stable diffusion webui amdgpu repositories generative models sgm modules diffusionmodules model py line forward h self conv h file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules module py line call impl return forward call args kwargs file c users owner stable diffusion webui stable diffusion webui amdgpu extensions builtin lora networks py line network conv forward return originals conv forward self input file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules conv py line forward return self conv forward input self weight self bias file c users owner stable diffusion webui stable diffusion webui amdgpu venv lib site packages torch nn modules conv py line conv forward return f conv torch outofmemoryerror cuda memory tried allocate gib gpu total capacity gib bytes free allocated memory gib allocated pytorch gib reserved pytorch unallocated reserved unallocated memory large try setting pytorch cuda alloc conf expandable segments true avoid fragmentation see documentation memory management additional information mentioned freezing mean whole pc freezes browser
auto1111_webui,issue,16965,[Bug]: Better Tutorials for Running with AMD,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

the libs need to be set up in the zip files like this:

ROCm\6.2\bin\rocblas\library
and
ROCm\6.2\bin\rocblas.dll

with the directories intact. this is what's causing the confusion and frustration when ppl are attempting to install ais. no one's tutorial mentions what to do with the rocblas.dll so this is the majority of ppls errors. i had to comb zluda forums just to see if even using the dll was supposed to happen. you need to tell users after this fix to drag and drop these files into the main amd directory in program files in the tutorials after backing the files up.

### Steps to reproduce the problem

better tutorial

### What should have happened?

better tutorial

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

better tutorial

### Console logs

```Shell
better tutorial
```

### Additional information

_No response_",2025-04-27T19:57:49Z,shinra358,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16965,"[Bug]: Better Tutorials for Running with AMD ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

the libs need to be set up in the zip files like this:

ROCm\6.2\bin\rocblas\library
and
ROCm\6.2\bin\rocblas.dll

with the directories intact. this is what's causing the confusion and frustration when ppl are attempting to install ais. no one's tutorial mentions what to do with the rocblas.dll so this is the majority of ppls errors. i had to comb zluda forums just to see if even using the dll was supposed to happen. you need to tell users after this fix to drag and drop these files into the main amd directory in program files in the tutorials after backing the files up.

### Steps to reproduce the problem

better tutorial

### What should have happened?

better tutorial

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

better tutorial

### Console logs

```Shell
better tutorial
```

### Additional information

_No response_",bug better tutorials running amd checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently x issue reported fixed yet happened libs need set zip files like rocm bin rocblas library rocm bin rocblas dll directories intact causing confusion frustration ppl attempting install ais one tutorial mentions rocblas dll majority ppls errors comb zluda forums see even using dll supposed happen need tell users fix drag drop files main amd directory program files tutorials backing files steps reproduce problem better tutorial happened better tutorial browsers use access ui response sysinfo better tutorial console logs shell better tutorial additional information response
auto1111_webui,comment,16965,,"I'd just like to add that things seem to be just as messed up on Linux, at least with AMD hardware.

I had A1111 working perfectly on Arch (Garuda) with a 7900 XT, but at some point it stopped recognizing my card, likely due to an update, and all of my attempts to fix it with a reinstall have failed. 

I've tried, in vain, to get it working with different versions of Python and Torch, and nothing has succeeded. I've spent hours and hours messing around with venv and pyenv and nothing works. 

I think the problem is that my system ROCm libraries are too new. I messed around with Docker, too, but that was too much of a mess, and I got nowhere.

I should note that I can get Invoke and CozyUI to work with no trouble, but I cannot get the same results with them no matter how much I try. They just flat out prompt worse. So don't tell me to switch front ends, I have tried already.",2025-05-12T03:40:12Z,NessusIgnis,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16965#issuecomment-2870713922,"I'd just like to add that things seem to be just as messed up on Linux, at least with AMD hardware.

I had A1111 working perfectly on Arch (Garuda) with a 7900 XT, but at some point it stopped recognizing my card, likely due to an update, and all of my attempts to fix it with a reinstall have failed. 

I've tried, in vain, to get it working with different versions of Python and Torch, and nothing has succeeded. I've spent hours and hours messing around with venv and pyenv and nothing works. 

I think the problem is that my system ROCm libraries are too new. I messed around with Docker, too, but that was too much of a mess, and I got nowhere.

I should note that I can get Invoke and CozyUI to work with no trouble, but I cannot get the same results with them no matter how much I try. They just flat out prompt worse. So don't tell me to switch front ends, I have tried already.",like add things seem messed linux least amd hardware working perfectly arch garuda xt point stopped recognizing card likely due update attempts fix reinstall failed tried vain get working different versions python torch nothing succeeded spent hours hours messing around venv pyenv nothing works think problem system rocm libraries new messed around docker much mess got nowhere note get invoke cozyui work trouble cannot get results matter much try flat prompt worse tell switch front ends tried already
auto1111_webui,issue,16961,"[Bug]: Does not store ""Use old karras scheduler sigmas (0.1 to 10)."" in metadata","### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

if you check ""Use old karras scheduler sigmas (0.1 to 10)."" it is not stored in the image metadata. So when you try to reproduce the image ""Use old karras scheduler sigmas (0.1 to 10)."" is not checked.

### Steps to reproduce the problem

1. Enable ""Use_old_karras_scheduler_sigmas"" in the: Settings > Userinterface >Quicksettings List
2. Reload interface
3. Create an image while checking ""Use old karras scheduler sigmas (0.1 to 10)""
4. Drag and drop created image in PNG info window. 
5. The use old karras scheduler sigma settings is not stored.

### What should have happened?

Should have stored the ""Use old karras scheduler sigmas (0.1 to 10)"" flag.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-26-17-22.json](https://github.com/user-attachments/files/19924222/sysinfo-2025-04-26-17-22.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
No module 'xformers'. Proceeding without it.
CHv1.8.13: Get Custom Model Folder
CivitAI Browser+: Aria2 RPC started
Using sqlite file: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-agent-scheduler\task_scheduler.sqlite3
ControlNet preprocessor location: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-04-26 18:25:04,633 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [42546b14d2] from P:\SD\sd-webui-1.10\webui\models\Stable-diffusion\SD\SardonyxBlend_v12_❴42546B14D2❵.safetensors
CHv1.8.13: Set Proxy:
Creating model from config: P:\SD\sd-webui-1.10\webui\configs\v1-inference.yaml
C:\Users\Saber\AppData\Local\Programs\Python\Python310\lib\site-packages\huggingface_hub\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-04-26 18:25:05,369 - ControlNet - INFO - ControlNet UI callback registered.
[ERROR]: Config states P:\SD\sd-webui-1.10\webui\config_states\civitai_subfolders.json, ""created_at"" does not exist
Running on local URL:  http://127.0.0.1:7860

Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB

To create a public link, set `share=True` in `launch()`.
IIB Database file has been successfully backed up to the backup folder.
Startup time: 15.9s (prepare environment: 3.0s, import torch: 4.0s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 2.8s, create ui: 1.8s, gradio launch: 0.2s, app_started_callback: 1.9s).
Loading VAE weights specified in settings: P:\SD\sd-webui-1.10\webui\models\VAE\vae-ft-mse-840000-ema-pruned_❴735E4C3A44❵.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 4.6s (create model: 0.5s, apply weights to model: 3.1s, apply half(): 0.3s, load VAE: 0.2s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.1s).
```

### Additional information

_No response_",2025-04-26T17:26:31Z,ShardM,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16961,"[Bug]: Does not store ""Use old karras scheduler sigmas (0.1 to 10)."" in metadata ### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

if you check ""Use old karras scheduler sigmas (0.1 to 10)."" it is not stored in the image metadata. So when you try to reproduce the image ""Use old karras scheduler sigmas (0.1 to 10)."" is not checked.

### Steps to reproduce the problem

1. Enable ""Use_old_karras_scheduler_sigmas"" in the: Settings > Userinterface >Quicksettings List
2. Reload interface
3. Create an image while checking ""Use old karras scheduler sigmas (0.1 to 10)""
4. Drag and drop created image in PNG info window. 
5. The use old karras scheduler sigma settings is not stored.

### What should have happened?

Should have stored the ""Use old karras scheduler sigmas (0.1 to 10)"" flag.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-26-17-22.json](https://github.com/user-attachments/files/19924222/sysinfo-2025-04-26-17-22.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
No module 'xformers'. Proceeding without it.
CHv1.8.13: Get Custom Model Folder
CivitAI Browser+: Aria2 RPC started
Using sqlite file: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-agent-scheduler\task_scheduler.sqlite3
ControlNet preprocessor location: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-04-26 18:25:04,633 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [42546b14d2] from P:\SD\sd-webui-1.10\webui\models\Stable-diffusion\SD\SardonyxBlend_v12_❴42546B14D2❵.safetensors
CHv1.8.13: Set Proxy:
Creating model from config: P:\SD\sd-webui-1.10\webui\configs\v1-inference.yaml
C:\Users\Saber\AppData\Local\Programs\Python\Python310\lib\site-packages\huggingface_hub\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-04-26 18:25:05,369 - ControlNet - INFO - ControlNet UI callback registered.
[ERROR]: Config states P:\SD\sd-webui-1.10\webui\config_states\civitai_subfolders.json, ""created_at"" does not exist
Running on local URL:  http://127.0.0.1:7860

Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB

To create a public link, set `share=True` in `launch()`.
IIB Database file has been successfully backed up to the backup folder.
Startup time: 15.9s (prepare environment: 3.0s, import torch: 4.0s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 2.8s, create ui: 1.8s, gradio launch: 0.2s, app_started_callback: 1.9s).
Loading VAE weights specified in settings: P:\SD\sd-webui-1.10\webui\models\VAE\vae-ft-mse-840000-ema-pruned_❴735E4C3A44❵.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 4.6s (create model: 0.5s, apply weights to model: 3.1s, apply half(): 0.3s, load VAE: 0.2s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.1s).
```

### Additional information

_No response_",bug store use old karras scheduler sigmas metadata checklist x issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened check use old karras scheduler sigmas stored image metadata try reproduce image use old karras scheduler sigmas checked steps reproduce problem enable use old karras scheduler sigmas settings userinterface quicksettings list reload interface create image checking use old karras scheduler sigmas drag drop created image png info window use old karras scheduler sigma settings stored happened stored use old karras scheduler sigmas flag browsers use access ui response sysinfo sysinfo json console logs shell python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments module xformers proceeding without chv get custom model folder civitai browser aria rpc started using sqlite file p sd sd webui webui extensions sd webui agent scheduler task scheduler sqlite controlnet preprocessor location p sd sd webui webui extensions sd webui controlnet annotator downloads controlnet info controlnet v loading weights b p sd sd webui webui models stable diffusion sd sardonyxblend v b safetensors chv set proxy creating model config p sd sd webui webui configs v inference yaml c users saber appdata local programs python python lib site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn controlnet info controlnet ui callback registered error config states p sd sd webui webui config states civitai subfolders json created exist running local url thanks gradio user questions feedback please join discord server chat us create public link set share true launch iib database file successfully backed backup folder startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch app started callback loading vae weights specified settings p sd sd webui webui models vae vae ft mse ema pruned e c safetensors applying attention optimization doggettx done model loaded create model apply weights model apply half load vae load textual inversion embeddings calculate empty prompt additional information response
auto1111_webui,issue,16960,"[Bug]: checkpoint merger missing ""none"" option","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

there is no ""None"" option in the checkpoint merger selector, i have to restart the Stable difussion ui in order to clear the dropdown menues in order to merge 2 checkpoints

### Steps to reproduce the problem

1. go to checkpoint merger
2. select any checkpoints/safetensor files in the 3 dropdown menues
3. merge into new checkpoint/safetensor file
4. restart the UI
5. go to step 1

### What should have happened?

please add a ""none"" at the top of the dropdown menues

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

sys info not required

### Console logs

```Shell
console log not required
```

### Additional information

![Image](https://github.com/user-attachments/assets/a0e75f24-9515-4763-8964-d859817c3752)",2025-04-26T13:43:16Z,johnjacquier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16960,"[Bug]: checkpoint merger missing ""none"" option ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

there is no ""None"" option in the checkpoint merger selector, i have to restart the Stable difussion ui in order to clear the dropdown menues in order to merge 2 checkpoints

### Steps to reproduce the problem

1. go to checkpoint merger
2. select any checkpoints/safetensor files in the 3 dropdown menues
3. merge into new checkpoint/safetensor file
4. restart the UI
5. go to step 1

### What should have happened?

please add a ""none"" at the top of the dropdown menues

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

sys info not required

### Console logs

```Shell
console log not required
```

### Additional information

![Image](https://github.com/user-attachments/assets/a0e75f24-9515-4763-8964-d859817c3752)",bug checkpoint merger missing none option checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened none option checkpoint merger selector restart stable difussion ui order clear dropdown menues order merge checkpoints steps reproduce problem go checkpoint merger select checkpoints safetensor files dropdown menues merge new checkpoint safetensor file restart ui go step happened please add none top dropdown menues browsers use access ui response sysinfo sys info required console logs shell console log required additional information image
auto1111_webui,issue,16958,[Feature Request]: Toggle to disable editing generation settings,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello! I use A1111 a lot from my mobile device and when it is on landscape mode it is very common I missclick image width or height since those are very close left edge of the screen. Sometimes I don't even notice before generating a gibberish image. I wish there was a toggle somewhere that would allow me to disable editing or freeze those fields. Prompt fields aren't a problem since those at least trigger the keyboard to pop up.

### Proposed workflow

1. In a sensible place there is a checkbox/etc to disable inputs inside `#txt2img_settings`
2. Toggle it to control if generation settings, like image width, should be editable


### Additional information

As a dirty quick fix for myself I did this addition `footer.html` before all other links. It does the job but is not the prererable way to go.

`<a href=""#"" onclick=""javascript:document.getElementById('txt2img_settings').style.display === 'none' ? document.getElementById('txt2img_settings').style.display = 'flex' : document.getElementById('txt2img_settings').style.display = 'none'"">Toggle Gen Info</a>  • `",2025-04-24T16:26:09Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958,"[Feature Request]: Toggle to disable editing generation settings ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello! I use A1111 a lot from my mobile device and when it is on landscape mode it is very common I missclick image width or height since those are very close left edge of the screen. Sometimes I don't even notice before generating a gibberish image. I wish there was a toggle somewhere that would allow me to disable editing or freeze those fields. Prompt fields aren't a problem since those at least trigger the keyboard to pop up.

### Proposed workflow

1. In a sensible place there is a checkbox/etc to disable inputs inside `#txt2img_settings`
2. Toggle it to control if generation settings, like image width, should be editable


### Additional information

As a dirty quick fix for myself I did this addition `footer.html` before all other links. It does the job but is not the prererable way to go.

`<a href=""#"" onclick=""javascript:document.getElementById('txt2img_settings').style.display === 'none' ? document.getElementById('txt2img_settings').style.display = 'flex' : document.getElementById('txt2img_settings').style.display = 'none'"">Toggle Gen Info</a>  • `",feature request toggle disable editing generation settings existing issue x searched existing issues checked recent builds commits would feature hello use lot mobile device landscape mode common missclick image width height since close left edge screen sometimes even notice generating gibberish image wish toggle somewhere would allow disable editing freeze fields prompt fields problem since least trigger keyboard pop proposed workflow sensible place checkbox etc disable inputs inside txt img settings toggle control generation settings like image width editable additional information dirty quick fix addition footer html links job prererable way go href onclick javascript document getelementbyid txt img settings style display none document getelementbyid txt img settings style display flex document getelementbyid txt img settings style display none toggle gen info
auto1111_webui,comment,16958,,I am sorry if this is a duplicate. Honestly there is just too many issues to go through even with filtering.,2025-04-24T16:57:20Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-2828278918,I am sorry if this is a duplicate. Honestly there is just too many issues to go through even with filtering.,sorry duplicate honestly many issues go even filtering
auto1111_webui,comment,16958,,"In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` *(like the `Hires. fix` thingy)*. So you can just collapse the settings when you're generating to avoid touching them.",2025-05-29T01:30:24Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-2917974789,"In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` *(like the `Hires. fix` thingy)*. So you can just collapse the settings when you're generating to avoid touching them.",meantime use setting moves parameters accordion like hires fix thingy collapse settings generating avoid touching
auto1111_webui,comment,16958,,"> In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` _(like the `Hires. fix` thingy)_. So you can just collapse the settings when you're generating to avoid touching them.

This has worked well but I still wish for an option to ""lock"" or ""freeze"" the various sliders etc. inputs so they would still be visible.",2025-12-06T14:04:06Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-3620433958,"> In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` _(like the `Hires. fix` thingy)_. So you can just collapse the settings when you're generating to avoid touching them.

This has worked well but I still wish for an option to ""lock"" or ""freeze"" the various sliders etc. inputs so they would still be visible.",meantime use setting moves parameters accordion like hires fix thingy collapse settings generating avoid touching worked well still wish option lock freeze various sliders etc inputs would still visible
auto1111_webui,issue,16957,[Feature Request]: Docker compose example,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Can you add in the README an example of ready to use docker-compose.yml to run Stable Diffusion with Nvidia acceleration and API enabled?
I try to run forge as a backend for OpenWebUI, but have some difficulties to make it work.
I need CUDA 12.8 for RTX 5000 support

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-04-24T16:03:49Z,SuperPat45,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16957,"[Feature Request]: Docker compose example ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Can you add in the README an example of ready to use docker-compose.yml to run Stable Diffusion with Nvidia acceleration and API enabled?
I try to run forge as a backend for OpenWebUI, but have some difficulties to make it work.
I need CUDA 12.8 for RTX 5000 support

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request docker compose example existing issue x searched existing issues checked recent builds commits would feature add readme example ready use docker compose yml run stable diffusion nvidia acceleration api enabled try run forge backend openwebui difficulties make work need cuda rtx support proposed workflow go press additional information response
auto1111_webui,comment,16957,,I have done a quick docker setup here: https://github.com/VladFlorinIlie/sd-docker,2025-08-24T13:24:53Z,VladFlorinIlie,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16957#issuecomment-3218103751,I have done a quick docker setup here: https://github.com/VladFlorinIlie/sd-docker,done quick docker setup
auto1111_webui,issue,16955,[Bug]: Inpaint and page zoom causes image to dissapear,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I zoom in on img2img canvus using shift and wheel, then come out again, the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place. It works most of the time, but sometimes this bug ruins my workflow and i have to do it agian.

### Steps to reproduce the problem

import an image into img2img, use shift and mouse wheel to zoom in, then zoom out, the image will not be centered, so if you do CRTL + mouse wheel it will change the web browser zoom (im on edge), which puts the image back where it should be. then in some cases the image dissapears. It will still generate but cant do any more inpainting after that. You may have to do it 10 times and it should happen a few times.
Cant remember if it does it on inpaint-sketch, it might.

### What should have happened?

The page zoom should put the image back in the right place.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now.

### Console logs

```Shell
Nothing in logs other than image generations I was doing.
```

### Additional information

_No response_",2025-04-23T00:34:52Z,palentir,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16955,"[Bug]: Inpaint and page zoom causes image to dissapear ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I zoom in on img2img canvus using shift and wheel, then come out again, the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place. It works most of the time, but sometimes this bug ruins my workflow and i have to do it agian.

### Steps to reproduce the problem

import an image into img2img, use shift and mouse wheel to zoom in, then zoom out, the image will not be centered, so if you do CRTL + mouse wheel it will change the web browser zoom (im on edge), which puts the image back where it should be. then in some cases the image dissapears. It will still generate but cant do any more inpainting after that. You may have to do it 10 times and it should happen a few times.
Cant remember if it does it on inpaint-sketch, it might.

### What should have happened?

The page zoom should put the image back in the right place.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now.

### Console logs

```Shell
Nothing in logs other than image generations I was doing.
```

### Additional information

_No response_",bug inpaint page zoom causes image dissapear checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened zoom img img canvus using shift wheel come image right place edge web browser page zoom using ctrl wheel puts back correct place works time sometimes bug ruins workflow agian steps reproduce problem import image img img use shift mouse wheel zoom zoom image centered crtl mouse wheel change web browser zoom im edge puts image back cases image dissapears still generate cant inpainting may times happen times cant remember inpaint sketch might happened page zoom put image back right place browsers use access ui microsoft edge sysinfo sorry unable right console logs shell nothing logs image generations additional information response
auto1111_webui,comment,16955,,">  the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place

why not use hotkey `R` to Reset zoom and canvas position?
> note your mouse needs to be hovering over the canvas",2025-05-03T20:36:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16955#issuecomment-2848798858,">  the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place

why not use hotkey `R` to Reset zoom and canvas position?
> note your mouse needs to be hovering over the canvas",image right place edge web browser page zoom using ctrl wheel puts back correct place use hotkey r reset zoom canvas position note mouse needs hovering canvas
auto1111_webui,issue,16954,[Bug]: ROCm version turns stupid (super low quality as if skipping steps),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The output when using ROCm is severely degraded from what it should be.  Even with maximum steps specified it is as if it has use very few (as if 4 or so) steps.  This happens on multiple installs in multiple systems.  (Please see the greater details below.)

### Steps to reproduce the problem

1. Run with ROCm.
2. Generate an image.
3. Resist the urge to vomit.

### What should have happened?

It should produce an image of standard quality.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-04-22-15-01.json](https://github.com/user-attachments/files/19852125/sysinfo-2025-04-22-15-01.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on nazo user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --no-progressbar-hiding --theme dark --listen --medvram
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [6ce0161689] from /media/2tbssd/ml/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 22.5s (prepare environment: 6.8s, import torch: 7.0s, import gradio: 0.9s, setup paths: 4.5s, initialize shared: 0.1s, other imports: 0.4s, load scripts: 0.3s, initialize extra networks: 0.3s, create ui: 0.4s, gradio launch: 1.7s).
Creating model from config: /media/2tbssd/ml/stable-diffusion-webui/configs/v1-inference.yaml
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 263.3s (load weights from disk: 94.4s, create model: 5.5s, apply weights to model: 87.6s, apply half(): 61.9s, apply dtype to VAE: 2.2s, hijack: 0.5s, load textual inversion embeddings: 0.1s, calculate empty prompt: 10.8s).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]
Total progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]
Total progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:05<00:00,  6.82it/s]
```

### Additional information

First, to clarify, I use the term stupid because when I first saw this occur I was on Arch and I also was having issues with KoboldCPP (LLM engine built on llama.cpp) where it would produce output that could only be described as stupid.  Failing to follow directions well, almost nonsense output, etc etc.  The intriguing thing about that was I also have a Linux Mint installation as a stable backup and when I ran Stable Diffusion within it at that time it was fine (as was KoboldCPP.)  So I filed Mint away as my stable backup.  I assumed the issue was the ROCm installation itself since Arch is not really supported at all by AMD and is just sort of manually ported by the AUR community.

However, I recently switched to Debian and wanted to try again.  Debian is sort of unofficially supported by AMD (they even have official setup instructions for Debian 12 now.)  In Debian, KoboldCPP was fine, so I tried StableDiffusion and at first it was fine.  I messed something up somewhere along the way of installing a bunch of stuff on the Debian system, so I decided to reinstall StableDiffusion (and accidentally deleted the old one instead of backing it up.  Turns out if you accidentally mv a folder to the same name as another folder it just quietly disappears into the void instead.)  When I reinstalled StableDiffusion it was broken like this again.  So I gave up and tried it in Mint, but it was broken in Mint too.  I tried deleting the folder and reinstalling in Mint, but it was still broken.  I also tried completely redoing my Debian system from scratch without the stuff StableDiffusion didn't seem to like last time on a fresh clean install and it's _still_ broken.  I want to add here that since the Mint setup is intended to be my ""stable"" backup, I don't update it.  Nothing has changed in it since the last time StableDiffusion worked.  So first I want to strongly emphasize that this setup was working as-is before and it is now failing where it worked before with a fresh installation.

Now, I want to add here that in both Mint and Debian, KoboldCPP works fine with ROCm.  The LLM acts completely normal.  The issue I saw outside of StableDiffusion is not present in Debian.  Thus I believe it is safe to say the issue here is _not_ the ROCm installation after all.  (I just assumed it was since I had such similar results in two different things back on Arch, but after all pytorch is separate.)  I've reinstalled several times in either the Mint setup or the Debian setup, but the results are the same every time.  I've tried a number of different parameters including the suggested --precision full and --no-half or alternately --upcast-sampling and various combinations of the three with no change in results.  Those weren't needed before anyway.  (Yes, it worked fine before without any of them.  No crash, no errors.)  I've tried a completely clean setup with no extensions or themes or anything and I've tried going through every single setting I could think of that could in _any_ way affect output quality.  I've tried with the system Python (3.11 in the case of Debian Bookworm, so I was surprised it worked as-is) and with Miniconda3 (since it seems to prefer 3.10.)  I've even tried manually installing different pytorch installations into the venv just to see what would happen (even the official AMD pytorch release just to see.)  Note that the above logs and etc are all made with just a fresh clean install (I only downloaded a few extensions so they'd be available offline) and the default venv, I am only saying that I tried it.  Yes, I even tried it without forcing dark mode on the theme and through all of my eye bleeding I could see the image output was still horrible.

I am not sure if it is related or not, but I should add here that it takes strangely long even to load the model.  As in quite a number of minutes (close to six or so for a non-XL model, even longer for XL) even without --medvram or --lowvram.  First gen takes incredibly long to start too.  Something is definitely going on there, but I don't know if it is related or not.  It doesn't take remotely close to as long to load on my old 3070Ti.  Even swapping models is still faster than six minutes on it.

I've attached a sample of an image generated with 150 (maximum!) steps using the default SD1.5 model.  You wouldn't expect it to be super great since it's only SD1.5, but you'll note that it looks like parts of it were produced at an incredibly low number of steps (like 4 or so) despite me setting the maximum.  (No, low numbers don't produce a good image either, I'm just demonstrating that 150 doesn't produce remotely close to what it should.)  The prompt was just a simple positive ""a person standing in a park and waving"" / negative ""from behind"" (I had to do the negative so it would show the face) which is as simple as it gets.

![Image](https://github.com/user-attachments/assets/38e61cae-5c1b-4f56-af2f-846208762811)",2025-04-22T15:33:21Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16954,"[Bug]: ROCm version turns stupid (super low quality as if skipping steps) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The output when using ROCm is severely degraded from what it should be.  Even with maximum steps specified it is as if it has use very few (as if 4 or so) steps.  This happens on multiple installs in multiple systems.  (Please see the greater details below.)

### Steps to reproduce the problem

1. Run with ROCm.
2. Generate an image.
3. Resist the urge to vomit.

### What should have happened?

It should produce an image of standard quality.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-04-22-15-01.json](https://github.com/user-attachments/files/19852125/sysinfo-2025-04-22-15-01.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on nazo user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --no-progressbar-hiding --theme dark --listen --medvram
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [6ce0161689] from /media/2tbssd/ml/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 22.5s (prepare environment: 6.8s, import torch: 7.0s, import gradio: 0.9s, setup paths: 4.5s, initialize shared: 0.1s, other imports: 0.4s, load scripts: 0.3s, initialize extra networks: 0.3s, create ui: 0.4s, gradio launch: 1.7s).
Creating model from config: /media/2tbssd/ml/stable-diffusion-webui/configs/v1-inference.yaml
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 263.3s (load weights from disk: 94.4s, create model: 5.5s, apply weights to model: 87.6s, apply half(): 61.9s, apply dtype to VAE: 2.2s, hijack: 0.5s, load textual inversion embeddings: 0.1s, calculate empty prompt: 10.8s).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]
Total progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]
Total progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:05<00:00,  6.82it/s]
```

### Additional information

First, to clarify, I use the term stupid because when I first saw this occur I was on Arch and I also was having issues with KoboldCPP (LLM engine built on llama.cpp) where it would produce output that could only be described as stupid.  Failing to follow directions well, almost nonsense output, etc etc.  The intriguing thing about that was I also have a Linux Mint installation as a stable backup and when I ran Stable Diffusion within it at that time it was fine (as was KoboldCPP.)  So I filed Mint away as my stable backup.  I assumed the issue was the ROCm installation itself since Arch is not really supported at all by AMD and is just sort of manually ported by the AUR community.

However, I recently switched to Debian and wanted to try again.  Debian is sort of unofficially supported by AMD (they even have official setup instructions for Debian 12 now.)  In Debian, KoboldCPP was fine, so I tried StableDiffusion and at first it was fine.  I messed something up somewhere along the way of installing a bunch of stuff on the Debian system, so I decided to reinstall StableDiffusion (and accidentally deleted the old one instead of backing it up.  Turns out if you accidentally mv a folder to the same name as another folder it just quietly disappears into the void instead.)  When I reinstalled StableDiffusion it was broken like this again.  So I gave up and tried it in Mint, but it was broken in Mint too.  I tried deleting the folder and reinstalling in Mint, but it was still broken.  I also tried completely redoing my Debian system from scratch without the stuff StableDiffusion didn't seem to like last time on a fresh clean install and it's _still_ broken.  I want to add here that since the Mint setup is intended to be my ""stable"" backup, I don't update it.  Nothing has changed in it since the last time StableDiffusion worked.  So first I want to strongly emphasize that this setup was working as-is before and it is now failing where it worked before with a fresh installation.

Now, I want to add here that in both Mint and Debian, KoboldCPP works fine with ROCm.  The LLM acts completely normal.  The issue I saw outside of StableDiffusion is not present in Debian.  Thus I believe it is safe to say the issue here is _not_ the ROCm installation after all.  (I just assumed it was since I had such similar results in two different things back on Arch, but after all pytorch is separate.)  I've reinstalled several times in either the Mint setup or the Debian setup, but the results are the same every time.  I've tried a number of different parameters including the suggested --precision full and --no-half or alternately --upcast-sampling and various combinations of the three with no change in results.  Those weren't needed before anyway.  (Yes, it worked fine before without any of them.  No crash, no errors.)  I've tried a completely clean setup with no extensions or themes or anything and I've tried going through every single setting I could think of that could in _any_ way affect output quality.  I've tried with the system Python (3.11 in the case of Debian Bookworm, so I was surprised it worked as-is) and with Miniconda3 (since it seems to prefer 3.10.)  I've even tried manually installing different pytorch installations into the venv just to see what would happen (even the official AMD pytorch release just to see.)  Note that the above logs and etc are all made with just a fresh clean install (I only downloaded a few extensions so they'd be available offline) and the default venv, I am only saying that I tried it.  Yes, I even tried it without forcing dark mode on the theme and through all of my eye bleeding I could see the image output was still horrible.

I am not sure if it is related or not, but I should add here that it takes strangely long even to load the model.  As in quite a number of minutes (close to six or so for a non-XL model, even longer for XL) even without --medvram or --lowvram.  First gen takes incredibly long to start too.  Something is definitely going on there, but I don't know if it is related or not.  It doesn't take remotely close to as long to load on my old 3070Ti.  Even swapping models is still faster than six minutes on it.

I've attached a sample of an image generated with 150 (maximum!) steps using the default SD1.5 model.  You wouldn't expect it to be super great since it's only SD1.5, but you'll note that it looks like parts of it were produced at an incredibly low number of steps (like 4 or so) despite me setting the maximum.  (No, low numbers don't produce a good image either, I'm just demonstrating that 150 doesn't produce remotely close to what it should.)  The prompt was just a simple positive ""a person standing in a park and waving"" / negative ""from behind"" (I had to do the negative so it would show the face) which is as simple as it gets.

![Image](https://github.com/user-attachments/assets/38e61cae-5c1b-4f56-af2f-846208762811)",bug rocm version turns stupid super low quality skipping steps checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened output using rocm severely degraded even maximum steps specified use steps happens multiple installs multiple systems please see greater details steps reproduce problem run rocm generate image resist urge vomit happened produce image standard quality browsers use access ui mozilla firefox sysinfo sysinfo json console logs shell install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running nazo user repo already cloned using install directory create activate python venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload lib x linux gnu libtcmalloc minimal python main dec gcc version v commit hash c ae bd abdf eda b e launching web ui arguments progressbar hiding theme dark listen medvram media tbssd ml stable diffusion webui venv lib python site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without loading weights ce media tbssd ml stable diffusion webui models stable diffusion v pruned emaonly safetensors running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts initialize extra networks create ui gradio launch creating model config media tbssd ml stable diffusion webui configs v inference yaml media tbssd ml stable diffusion webui venv lib python site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn applying attention optimization doggettx done model loaded load weights disk create model apply weights model apply half apply dtype vae hijack load textual inversion embeddings calculate empty prompt total progress total progress additional information first clarify use term stupid first saw occur arch also issues koboldcpp llm engine built llama cpp would produce output could described stupid failing follow directions well almost nonsense output etc etc intriguing thing also linux mint installation stable backup ran stable diffusion within time fine koboldcpp filed mint away stable backup assumed issue rocm installation since arch really supported amd sort manually ported aur community however recently switched debian wanted try debian sort unofficially supported amd even official setup instructions debian debian koboldcpp fine tried stablediffusion first fine messed something somewhere along way installing bunch stuff debian system decided reinstall stablediffusion accidentally deleted old one instead backing turns accidentally mv folder name another folder quietly disappears void instead reinstalled stablediffusion broken like gave tried mint broken mint tried deleting folder reinstalling mint still broken also tried completely redoing debian system scratch without stuff stablediffusion seem like last time fresh clean install still broken want add since mint setup intended stable backup update nothing changed since last time stablediffusion worked first want strongly emphasize setup working failing worked fresh installation want add mint debian koboldcpp works fine rocm llm acts completely normal issue saw outside stablediffusion present debian thus believe safe say issue rocm installation assumed since similar results two different things back arch pytorch separate reinstalled several times either mint setup debian setup results every time tried number different parameters including suggested precision full half alternately upcast sampling various combinations three change results needed anyway yes worked fine without crash errors tried completely clean setup extensions themes anything tried going every single setting could think could way affect output quality tried system python case debian bookworm surprised worked miniconda since seems prefer even tried manually installing different pytorch installations venv see would happen even official amd pytorch release see note logs etc made fresh clean install downloaded extensions available offline default venv saying tried yes even tried without forcing dark mode theme eye bleeding could see image output still horrible sure related add takes strangely long even load model quite number minutes close six non xl model even longer xl even without medvram lowvram first gen takes incredibly long start something definitely going know related take remotely close long load old ti even swapping models still faster six minutes attached sample image generated maximum steps using default sd model expect super great since sd note looks like parts produced incredibly low number steps like despite setting maximum low numbers produce good image either demonstrating produce remotely close prompt simple positive person standing park waving negative behind negative would show face simple gets image
auto1111_webui,comment,16954,,"Ok, so this is strange, but I had it working correctly for like two days.  I had gone through messing with all kinds of settings and have no clue whatsoever what did it.  Now it's broken again.  I messed with some setting I guess.  I'm not even sure anymore.

On the parts that get really slow sometimes, I've often noticed git --version hanging in the task list for long periods of time sometimes.  There are all those warnings about resume_download being depreciated showing up a lot.  I tried messing with some of the settings and arguments like --do-not-download-clip and I notice that despite these settings it's still doing a lot of online connections.  It really didn't like it if I tried to make it go all offline.  I'm starting to wonder if maybe Huggingface or one of the other things it's constantly accessing might be limiting connections.  I don't know if that is in any way related or not, but if it requires connections to a server for every single use, that's a problem waiting to happen anyway.  If so, perhaps it broke because I was having connection problems earlier and things were timing out a lot.

I'll keep messing with settings and see if I can narrow something down, but at least I have proved it _can_ work in this setup by having it actually do so for a time.",2025-04-26T05:38:37Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16954#issuecomment-2831873557,"Ok, so this is strange, but I had it working correctly for like two days.  I had gone through messing with all kinds of settings and have no clue whatsoever what did it.  Now it's broken again.  I messed with some setting I guess.  I'm not even sure anymore.

On the parts that get really slow sometimes, I've often noticed git --version hanging in the task list for long periods of time sometimes.  There are all those warnings about resume_download being depreciated showing up a lot.  I tried messing with some of the settings and arguments like --do-not-download-clip and I notice that despite these settings it's still doing a lot of online connections.  It really didn't like it if I tried to make it go all offline.  I'm starting to wonder if maybe Huggingface or one of the other things it's constantly accessing might be limiting connections.  I don't know if that is in any way related or not, but if it requires connections to a server for every single use, that's a problem waiting to happen anyway.  If so, perhaps it broke because I was having connection problems earlier and things were timing out a lot.

I'll keep messing with settings and see if I can narrow something down, but at least I have proved it _can_ work in this setup by having it actually do so for a time.",ok strange working correctly like two days gone messing kinds settings clue whatsoever broken messed setting guess even sure anymore parts get really slow sometimes often noticed git version hanging task list long periods time sometimes warnings resume download depreciated showing lot tried messing settings arguments like download clip notice despite settings still lot online connections really like tried make go offline starting wonder maybe huggingface one things constantly accessing might limiting connections know way related requires connections server every single use problem waiting happen anyway perhaps broke connection problems earlier things timing lot keep messing settings see narrow something least proved work setup actually time
auto1111_webui,issue,16950,[Bug]: ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file`,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

it all just happened, because I haven't used A1111 for a long time. Lately I've been experimenting a lot with ComfyUi.

### Steps to reproduce the problem

since the application started.

### What should have happened?

Idk, I have done a clean install, but this still happens.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-16-05-27.json](https://github.com/user-attachments/files/19770960/sysinfo-2025-04-16-05-27.json)

### Console logs

```Shell
Creating model from config: E:\AI\TensorRT\webui\configs\v1-inference.yaml
creating model quickly: ValueError
Traceback (most recent call last):
  File ""threading.py"", line 973, in _bootstrap
  File ""threading.py"", line 1016, in _bootstrap_inner
  File ""E:\AI\TensorRT\system\python\lib\site-packages\anyio\_backends\_asyncio.py"", line 807, in run
    result = context.run(func, *args)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\gradio\utils.py"", line 707, in wrapper
    response = f(*args, **kwargs)
  File ""contextlib.py"", line 78, in inner
  File ""E:\AI\TensorRT\webui\extensions\sd-webui-EasyPhoto\scripts\sdwebui.py"", line 64, in __exit__
    sd_models.reload_model_weights()
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 820, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 563, in __init__
    self.instantiate_cond_stage(cond_stage_config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 630, in instantiate_cond_stage
    model = instantiate_from_config(config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\util.py"", line 89, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\modules\encoders\modules.py"", line 104, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""E:\AI\TensorRT\webui\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(pretrained_model_name_or_path, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 279, in _wrapper
    return func(*args, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 3994, in from_pretrained
    raise ValueError(
ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file`. Use one of the two loading strategies.

Failed to create model quickly; will retry using slow method.
Loading VAE weights specified in settings: E:\AI\TensorRT\webui\models\VAE\madebyollin-sdxl-vae-fp16-fix.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 10.6s (create model: 1.6s, apply weights to model: 8.1s, load VAE: 0.5s, move model to device: 0.2s).
Restoring base VAE
Applying attention optimization: Doggettx... done.
VAE weights loaded.
```

### Additional information

_No response_",2025-04-16T05:28:46Z,farizy4n,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16950,"[Bug]: ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file` ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

it all just happened, because I haven't used A1111 for a long time. Lately I've been experimenting a lot with ComfyUi.

### Steps to reproduce the problem

since the application started.

### What should have happened?

Idk, I have done a clean install, but this still happens.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-16-05-27.json](https://github.com/user-attachments/files/19770960/sysinfo-2025-04-16-05-27.json)

### Console logs

```Shell
Creating model from config: E:\AI\TensorRT\webui\configs\v1-inference.yaml
creating model quickly: ValueError
Traceback (most recent call last):
  File ""threading.py"", line 973, in _bootstrap
  File ""threading.py"", line 1016, in _bootstrap_inner
  File ""E:\AI\TensorRT\system\python\lib\site-packages\anyio\_backends\_asyncio.py"", line 807, in run
    result = context.run(func, *args)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\gradio\utils.py"", line 707, in wrapper
    response = f(*args, **kwargs)
  File ""contextlib.py"", line 78, in inner
  File ""E:\AI\TensorRT\webui\extensions\sd-webui-EasyPhoto\scripts\sdwebui.py"", line 64, in __exit__
    sd_models.reload_model_weights()
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 820, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 563, in __init__
    self.instantiate_cond_stage(cond_stage_config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 630, in instantiate_cond_stage
    model = instantiate_from_config(config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\util.py"", line 89, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\modules\encoders\modules.py"", line 104, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""E:\AI\TensorRT\webui\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(pretrained_model_name_or_path, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 279, in _wrapper
    return func(*args, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 3994, in from_pretrained
    raise ValueError(
ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file`. Use one of the two loading strategies.

Failed to create model quickly; will retry using slow method.
Loading VAE weights specified in settings: E:\AI\TensorRT\webui\models\VAE\madebyollin-sdxl-vae-fp16-fix.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 10.6s (create model: 1.6s, apply weights to model: 8.1s, load VAE: 0.5s, move model to device: 0.2s).
Restoring base VAE
Applying attention optimization: Doggettx... done.
VAE weights loaded.
```

### Additional information

_No response_",bug valueerror state dict cannot passed together model name gguf file checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened happened used long time lately experimenting lot comfyui steps reproduce problem since application started happened idk done clean install still happens browsers use access ui response sysinfo sysinfo json console logs shell creating model config e ai tensorrt webui configs v inference yaml creating model quickly valueerror traceback recent call last file threading py line bootstrap file threading py line bootstrap inner file e ai tensorrt system python lib site packages anyio backends asyncio py line run result context run func args file e ai tensorrt system python lib site packages gradio utils py line wrapper response f args kwargs file contextlib py line inner file e ai tensorrt webui extensions sd webui easyphoto scripts sdwebui py line exit sd models reload model weights file e ai tensorrt webui modules sd models py line reload model weights load model checkpoint info already loaded state dict state dict file e ai tensorrt webui modules sd models py line load model sd model instantiate config sd config model state dict file e ai tensorrt webui modules sd models py line instantiate config return constructor params file e ai tensorrt webui repositories stable diffusion stability ai ldm models diffusion ddpm py line init self instantiate cond stage cond stage config file e ai tensorrt webui repositories stable diffusion stability ai ldm models diffusion ddpm py line instantiate cond stage model instantiate config config file e ai tensorrt webui repositories stable diffusion stability ai ldm util py line instantiate config return get obj str config target config get params dict file e ai tensorrt webui repositories stable diffusion stability ai ldm modules encoders modules py line init self transformer cliptextmodel pretrained version file e ai tensorrt webui modules sd disable initialization py line cliptextmodel pretrained res self cliptextmodel pretrained pretrained model name path model args config pretrained model name path state dict kwargs file e ai tensorrt system python lib site packages transformers modeling utils py line wrapper return func args kwargs file e ai tensorrt system python lib site packages transformers modeling utils py line pretrained raise valueerror valueerror state dict cannot passed together model name gguf file use one two loading strategies failed create model quickly retry using slow method loading vae weights specified settings e ai tensorrt webui models vae madebyollin sdxl vae fp fix safetensors applying attention optimization doggettx done model loaded create model apply weights model load vae move model device restoring base vae applying attention optimization doggettx done vae weights loaded additional information response
auto1111_webui,comment,16950,,"I also encountered the same problem, how did you solve it in the end?",2025-06-18T08:28:59Z,duzhixing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16950#issuecomment-2983214927,"I also encountered the same problem, how did you solve it in the end?",also encountered problem solve end
auto1111_webui,issue,16946,[Feature Request]: image size settings presets,"I really appreciate all the work that’s gone into this project—it’s an amazing tool. That said, I’d love to request a small but impactful quality-of-life feature: the ability to create and quickly switch between image size presets. (or have a ready made one in place)

Why This Would Be Helpful:
When generating large batches of images, especially in different resolutions, it can get frustrating having to manually re-enter the width and height values every time. It would be extremely helpful to have a few preset sizes (e.g. 512x512, 768x1024, 1024x1024) that we can select with a single click.

Even just having the ability to define and save custom image size presets—either in the UI or a config file—would make the workflow a lot smoother.

Suggested Features:
A dropdown or button group in the UI to select from commonly used image sizes.

Option to define and save custom presets.

Selecting a preset would automatically fill the Width and Height fields.

Manual entry should still be available as a fallback.

Benefits:
Speeds up batch workflows and experimentation.

Reduces repetitive steps and input errors.

Makes the user experience cleaner and more efficient.

Thanks again for your hard work on this project. This small feature would really go a long way for those of us generating lots of content regularly.",2025-04-13T22:13:51Z,ajayeola,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946,"[Feature Request]: image size settings presets I really appreciate all the work that’s gone into this project—it’s an amazing tool. That said, I’d love to request a small but impactful quality-of-life feature: the ability to create and quickly switch between image size presets. (or have a ready made one in place)

Why This Would Be Helpful:
When generating large batches of images, especially in different resolutions, it can get frustrating having to manually re-enter the width and height values every time. It would be extremely helpful to have a few preset sizes (e.g. 512x512, 768x1024, 1024x1024) that we can select with a single click.

Even just having the ability to define and save custom image size presets—either in the UI or a config file—would make the workflow a lot smoother.

Suggested Features:
A dropdown or button group in the UI to select from commonly used image sizes.

Option to define and save custom presets.

Selecting a preset would automatically fill the Width and Height fields.

Manual entry should still be available as a fallback.

Benefits:
Speeds up batch workflows and experimentation.

Reduces repetitive steps and input errors.

Makes the user experience cleaner and more efficient.

Thanks again for your hard work on this project. This small feature would really go a long way for those of us generating lots of content regularly.",feature request image size settings presets really appreciate work thats gone projectits amazing tool said id love request small impactful quality life feature ability create quickly switch image size presets ready made one place would helpful generating large batches images especially different resolutions get frustrating manually enter width height values every time would extremely helpful preset sizes e g x x x select single click even ability define save custom image size presetseither ui config filewould make workflow lot smoother suggested features dropdown button group ui select commonly used image sizes option define save custom presets selecting preset would automatically fill width height fields manual entry still available fallback benefits speeds batch workflows experimentation reduces repetitive steps input errors makes user experience cleaner efficient thanks hard work project small feature would really go long way us generating lots content regularly
auto1111_webui,comment,16946,,"You're wasting your time. A1111 is dead.  Jump to ComfyUI, InvokeAI or whatever takes your fancy",2025-04-13T23:23:28Z,yushan777,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946#issuecomment-2800176291,"You're wasting your time. A1111 is dead.  Jump to ComfyUI, InvokeAI or whatever takes your fancy",wasting time dead jump comfyui invokeai whatever takes fancy
auto1111_webui,comment,16946,,"on Extention tab > Available tab > search for keyword `Ratio` or `Preset`
you can find a bunch of extensions that does pretty much exactly what you are asking

https://github.com/gutris1/sd-simple-dimension-preset
https://github.com/altoiddealer/--sd-webui-ar-plusplus
https://github.com/xhoxye/sd-webui-ar_xhox
https://github.com/LEv145/--sd-webui-ar-plus
https://github.com/thomasasfk/sd-webui-aspect-ratio-helper
https://github.com/bit9labs/sd-ratio-lock
https://github.com/alemelis/sd-webui-ar
https://github.com/Zyin055/Config-Presets",2025-05-03T20:17:34Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946#issuecomment-2848789868,"on Extention tab > Available tab > search for keyword `Ratio` or `Preset`
you can find a bunch of extensions that does pretty much exactly what you are asking

https://github.com/gutris1/sd-simple-dimension-preset
https://github.com/altoiddealer/--sd-webui-ar-plusplus
https://github.com/xhoxye/sd-webui-ar_xhox
https://github.com/LEv145/--sd-webui-ar-plus
https://github.com/thomasasfk/sd-webui-aspect-ratio-helper
https://github.com/bit9labs/sd-ratio-lock
https://github.com/alemelis/sd-webui-ar
https://github.com/Zyin055/Config-Presets",extention tab available tab search keyword ratio preset find bunch extensions pretty much exactly asking
auto1111_webui,issue,16945,[Feature Request]: Architecture change support,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

After purchasing the 5080, I ran into the problem of not being able to run my version of webUi. After searching the discussions, I found a working version for my configuration and successfully launched it. However, now I can't change the architecture, being able to use only sd (switching to flux or xl from the previous version doesn't work, because the switchover switch is missing in the UI)

My build is 

![Image](https://github.com/user-attachments/assets/56a4f690-6971-4d33-83c6-b722bb476a55)

### Proposed workflow

1. Install last version from https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818
2. Launh app
3. No tool to change the architecture 


### Additional information

_No response_",2025-04-12T19:36:58Z,LoksliSpb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16945,"[Feature Request]: Architecture change support ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

After purchasing the 5080, I ran into the problem of not being able to run my version of webUi. After searching the discussions, I found a working version for my configuration and successfully launched it. However, now I can't change the architecture, being able to use only sd (switching to flux or xl from the previous version doesn't work, because the switchover switch is missing in the UI)

My build is 

![Image](https://github.com/user-attachments/assets/56a4f690-6971-4d33-83c6-b722bb476a55)

### Proposed workflow

1. Install last version from https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818
2. Launh app
3. No tool to change the architecture 


### Additional information

_No response_",feature request architecture change support existing issue x searched existing issues checked recent builds commits would feature purchasing ran problem able run version webui searching discussions found working version configuration successfully launched however change architecture able use sd switching flux xl previous version work switchover switch missing ui build image proposed workflow install last version launh app tool change architecture additional information response
auto1111_webui,issue,16942,VAE,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello, I tried to modify the number of output channels of the decoder but failed, the display does not match, can you explain why, I tried to retrain or fine-tune the VAE

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-04-11T06:53:58Z,smy123666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16942,"VAE ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello, I tried to modify the number of output channels of the decoder but failed, the display does not match, can you explain why, I tried to retrain or fine-tune the VAE

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",vae existing issue x searched existing issues checked recent builds commits would feature hello tried modify number output channels decoder failed display match explain tried retrain fine tune vae proposed workflow go press additional information response
auto1111_webui,issue,16941,[Bug]: Torch is not able to use GPU,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Failed to open

### Steps to reproduce the problem

Click on run.bat dosnt open

### What should have happened?

Open

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

..

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\modules\launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
Press any key to continue . . .
```

### Additional information

How do i fix this ?

System info:
AMD Ryzen 7 7800X3D 8-Core Processor              4.20 GHz
32,0 GB RAM
4070 TI Nvidia GPU",2025-04-10T19:32:26Z,Sirfluffykinz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16941,"[Bug]: Torch is not able to use GPU ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Failed to open

### Steps to reproduce the problem

Click on run.bat dosnt open

### What should have happened?

Open

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

..

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\modules\launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
Press any key to continue . . .
```

### Additional information

How do i fix this ?

System info:
AMD Ryzen 7 7800X3D 8-Core Processor              4.20 GHz
32,0 GB RAM
4070 TI Nvidia GPU",bug torch able use gpu checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened failed open steps reproduce problem click run bat dosnt open happened open browsers use access ui google chrome sysinfo console logs shell python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e traceback recent call last file c users steve desktop stable diffusion webui launch py line module main file c users steve desktop stable diffusion webui launch py line main prepare environment file c users steve desktop stable diffusion webui modules launch utils py line prepare environment raise runtimeerror runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check press key continue additional information fix system info amd ryzen x core processor ghz gb ram ti nvidia gpu
auto1111_webui,comment,16941,,"It may be trying to use the CPU's integrated graphics. You should be able to disable it the motherboard's BIOS settings,

Otherwise, try adding `--device-id 0` or `--device-id 1` to [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L6).

> ### Sysinfo
> ..

If you can't open webui, sysinfo can be obtained by adding `--dump-sysinfo` to webui-user.bat.",2025-04-10T21:07:52Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16941#issuecomment-2795170575,"It may be trying to use the CPU's integrated graphics. You should be able to disable it the motherboard's BIOS settings,

Otherwise, try adding `--device-id 0` or `--device-id 1` to [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L6).

> ### Sysinfo
> ..

If you can't open webui, sysinfo can be obtained by adding `--dump-sysinfo` to webui-user.bat.",may trying use cpu integrated graphics able disable motherboard bios settings otherwise try adding device id device id webui user bat sysinfo open webui sysinfo obtained adding dump sysinfo webui user bat
auto1111_webui,issue,16939,[Feature Request]: Allow DBclient Connection Port Override for UserLAnd Compatibility,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When launching Stable Diffusion WebUI in a UserLAnd environment on my smartphone, DBclient fails to connect and shows a ""Connection refused"" error. The issue occurs because DBclient is trying to use port 2022 rather than port 22, which is used by the SSH server in UserLAnd.


### Steps to reproduce the problem

1. Install Stable Diffusion WebUI on a smartphone using UserLAnd.
2. Start the webui on a clean installation with no extensions enabled.
3. Launch DBclient from within the WebUI.
4. Observe that DBclient attempts to connect on port 2022 and fails, displaying a ""Connection refused"" error.


### What should have happened?

DBclient should either automatically detect the correct port or provide an option to override the hard-coded port. In a UserLAnd environment, it should be able to connect using port 22, allowing the WebUI to function correctly without throwing a connection error.


### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[Attach the sysinfo file generated from the WebUI settings here. Please ensure that the file does not contain any sensitive information.]


### Console logs

```Shell
[Attach the full command-line/terminal logs from when you started the UI until the error occurred. If the logs are too long, provide a link to a pastebin or similar service.]
```

### Additional information

- The issue exists on a clean installation of the WebUI with all extensions disabled.
- I have encountered this problem on the current version of the WebUI.
- This bug appears to be related to DBclient being hardcoded to use port 2022, which is incompatible with UserLAnd's default SSH configuration on port 22.
（",2025-04-09T18:48:00Z,yuuki-0723,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939,"[Feature Request]: Allow DBclient Connection Port Override for UserLAnd Compatibility ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When launching Stable Diffusion WebUI in a UserLAnd environment on my smartphone, DBclient fails to connect and shows a ""Connection refused"" error. The issue occurs because DBclient is trying to use port 2022 rather than port 22, which is used by the SSH server in UserLAnd.


### Steps to reproduce the problem

1. Install Stable Diffusion WebUI on a smartphone using UserLAnd.
2. Start the webui on a clean installation with no extensions enabled.
3. Launch DBclient from within the WebUI.
4. Observe that DBclient attempts to connect on port 2022 and fails, displaying a ""Connection refused"" error.


### What should have happened?

DBclient should either automatically detect the correct port or provide an option to override the hard-coded port. In a UserLAnd environment, it should be able to connect using port 22, allowing the WebUI to function correctly without throwing a connection error.


### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[Attach the sysinfo file generated from the WebUI settings here. Please ensure that the file does not contain any sensitive information.]


### Console logs

```Shell
[Attach the full command-line/terminal logs from when you started the UI until the error occurred. If the logs are too long, provide a link to a pastebin or similar service.]
```

### Additional information

- The issue exists on a clean installation of the WebUI with all extensions disabled.
- I have encountered this problem on the current version of the WebUI.
- This bug appears to be related to DBclient being hardcoded to use port 2022, which is incompatible with UserLAnd's default SSH configuration on port 22.
（",feature request allow dbclient connection port override userland compatibility checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened launching stable diffusion webui userland environment smartphone dbclient fails connect shows connection refused error issue occurs dbclient trying use port rather port used ssh server userland steps reproduce problem install stable diffusion webui smartphone using userland start webui clean installation extensions enabled launch dbclient within webui observe dbclient attempts connect port fails displaying connection refused error happened dbclient either automatically detect correct port provide option override hard coded port userland environment able connect using port allowing webui function correctly without throwing connection error browsers use access ui google chrome sysinfo attach sysinfo file generated webui settings please ensure file contain sensitive information console logs shell attach full command line terminal logs started ui error occurred logs long provide link pastebin similar service additional information issue exists clean installation webui extensions disabled encountered problem current version webui bug appears related dbclient hardcoded use port incompatible userland default ssh configuration port
auto1111_webui,comment,16939,,I fail to follow how this has to do stable-diffusion-webu,2025-05-03T20:32:41Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939#issuecomment-2848796720,I fail to follow how this has to do stable-diffusion-webu,fail follow stable diffusion webu
auto1111_webui,comment,16939,,"> I fail to follow how this has to do stable-diffusion-webu

Thank you very much for your opinion.
As you pointed out, the problem is not a bug in ""Stable Diffusion WebUI"", but rather is due to a restriction in UserLAnd. The only way to solve it is to find a way to change the port settings used by DBclient on the UserLAnd side, or to have Dropbear wait on port 2022.
However, I thought I'd post this in case any of my comrades who are trying to launch ""Stable Diffusion WebUI"" using a smartphone and UserLAnd are facing the same problem.",2025-05-05T03:25:19Z,yuuki-0723,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939#issuecomment-2849816531,"> I fail to follow how this has to do stable-diffusion-webu

Thank you very much for your opinion.
As you pointed out, the problem is not a bug in ""Stable Diffusion WebUI"", but rather is due to a restriction in UserLAnd. The only way to solve it is to find a way to change the port settings used by DBclient on the UserLAnd side, or to have Dropbear wait on port 2022.
However, I thought I'd post this in case any of my comrades who are trying to launch ""Stable Diffusion WebUI"" using a smartphone and UserLAnd are facing the same problem.",fail follow stable diffusion webu thank much opinion pointed problem bug stable diffusion webui rather due restriction userland way solve find way change port settings used dbclient userland side dropbear wait port however thought post case comrades trying launch stable diffusion webui using smartphone userland facing problem
auto1111_webui,issue,16938,[Bug]: Python version is too recent,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I've just installed required dependencies for Uubuntu (64 bits 24.04.2) as described in the readme. Gave permissions to webui.sh and started it. But it seems that my Python version is too recent.

### Steps to reproduce the problem

1. Install Ubuntu 24.04.2 on your 64bits machine
2. Installed required dependencies as described in the readme
3. Run webui.sh from the terminal

### What should have happened?

WebUi should have installed the stable diffusion program.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't access to WebUi yet.

### Console logs

[pastebin](https://pastebin.com/pNwVgkUG)

### Additional information

This is my configuration

![Image](https://github.com/user-attachments/assets/6f053f34-4578-470b-a30a-72eeca413513)",2025-04-07T13:45:23Z,loloof64,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938,"[Bug]: Python version is too recent ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I've just installed required dependencies for Uubuntu (64 bits 24.04.2) as described in the readme. Gave permissions to webui.sh and started it. But it seems that my Python version is too recent.

### Steps to reproduce the problem

1. Install Ubuntu 24.04.2 on your 64bits machine
2. Installed required dependencies as described in the readme
3. Run webui.sh from the terminal

### What should have happened?

WebUi should have installed the stable diffusion program.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't access to WebUi yet.

### Console logs

[pastebin](https://pastebin.com/pNwVgkUG)

### Additional information

This is my configuration

![Image](https://github.com/user-attachments/assets/6f053f34-4578-470b-a30a-72eeca413513)",bug python version recent checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened installed required dependencies uubuntu bits described readme gave permissions webui sh started seems python version recent steps reproduce problem install ubuntu bits machine installed required dependencies described readme run webui sh terminal happened webui installed stable diffusion program browsers use access ui google chrome sysinfo access webui yet console logs pastebin additional information configuration image
auto1111_webui,comment,16938,,"The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.",2025-04-07T19:30:59Z,ZephyrCodesStuff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2784428022,"The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.",fact repo still needs python ridiculous wasted around hours trying get install dependencies start gave went invokeai worked beautifully
auto1111_webui,comment,16938,,"A1111 is dead, move to another platform.  ComfUI, Invoke.. you choose",2025-04-13T23:13:37Z,yushan777,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2800172541,"A1111 is dead, move to another platform.  ComfUI, Invoke.. you choose",dead move another platform comfui invoke choose
auto1111_webui,comment,16938,,"> The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.

2hours to add this to .bat? i think you should step away from the terminal 
:: Force use of Python 3.10.6 explicitly
set PYTHON=",2025-04-19T10:07:00Z,MyNuggets666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2816640484,"> The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.

2hours to add this to .bat? i think you should step away from the terminal 
:: Force use of Python 3.10.6 explicitly
set PYTHON=",fact repo still needs python ridiculous wasted around hours trying get install dependencies start gave went invokeai worked beautifully hours add bat think step away terminal force use python explicitly set python
auto1111_webui,comment,16938,,"> > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> 
> 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=

“Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.",2025-04-19T19:56:30Z,ZephyrCodesStuff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2816845740,"> > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> 
> 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=

“Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.",fact repo still needs python ridiculous wasted around hours trying get install dependencies start gave went invokeai worked beautifully hours add bat think step away terminal force use python explicitly set python step away terminal please favour google meaning rolling release maybe accept everyone flexible environment able multiple python versions installed necessity use latest updates
auto1111_webui,comment,16938,,"> > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > 
> > 
> > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> 
> “Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.

go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer ' ",2025-04-22T01:04:43Z,MyNuggets666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2819804622,"> > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > 
> > 
> > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> 
> “Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.

go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer '",fact repo still needs python ridiculous wasted around hours trying get install dependencies start gave went invokeai worked beautifully hours add bat think step away terminal force use python explicitly set python step away terminal please favour google meaning rolling release maybe accept everyone flexible environment able multiple python versions installed necessity use latest updates go watch youtube video venv use version nothing newer
auto1111_webui,comment,16938,,"> > > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > > 
> > > 
> > > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> > 
> > 
> > “Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.
> 
> go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer '

How about  not being so condescending and provide some help for those that may not be as up to speed as you.  I'm having the same issue as well.  I'd love to be able to install Python 3.10 and torch to support this application, however it appears that they have all been taken down an are no longer available.  So is this thing dead and no longer supported or just behind on updates?  It's looking for old versions of torch and Python.  If you have a place to get Python 3.10, torch 2.0.0, and torchvision 0.15.1 let me know.  Currently oldest version of torch are 2.5.0 and torchvision 0.21.0.   Tks, Jeff.... ",2025-05-13T18:14:54Z,jonesjl,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2877520399,"> > > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > > 
> > > 
> > > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> > 
> > 
> > “Step away from the terminal”, please do yourself a favour and google what the meaning of “rolling release” is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.
> 
> go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer '

How about  not being so condescending and provide some help for those that may not be as up to speed as you.  I'm having the same issue as well.  I'd love to be able to install Python 3.10 and torch to support this application, however it appears that they have all been taken down an are no longer available.  So is this thing dead and no longer supported or just behind on updates?  It's looking for old versions of torch and Python.  If you have a place to get Python 3.10, torch 2.0.0, and torchvision 0.15.1 let me know.  Currently oldest version of torch are 2.5.0 and torchvision 0.21.0.   Tks, Jeff....",fact repo still needs python ridiculous wasted around hours trying get install dependencies start gave went invokeai worked beautifully hours add bat think step away terminal force use python explicitly set python step away terminal please favour google meaning rolling release maybe accept everyone flexible environment able multiple python versions installed necessity use latest updates go watch youtube video venv use version nothing newer condescending provide help may speed issue well love able install python torch support application however appears taken longer available thing dead longer supported behind updates looking old versions torch python place get python torch torchvision let know currently oldest version torch torchvision tks jeff
auto1111_webui,issue,16930,[Bug]: Extensions list (lora list sometimes) not properly showing,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After startup the extensions list is not showing up and after hitting ""refresh"" the extension list shows up but is still greyed out. Same thing sometimes happens to the lora/checkpoint list. It then looks like this:
[https://imgur.com/a/gs9hjMx](url)


### Steps to reproduce the problem

1. startup 1111
2. wait for startup to finish
3. open http://127.0.0.1:7860/
4. go to extensions tab or lora/checkpoint list

### What should have happened?

Webui should list all loras/checkpoints and extensions installed

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

Sysinfo:
https://pastebin.com/ievDm8vk

### Console logs

```Shell
CMD log:
https://pastebin.com/hzrE1u7v
```

### Additional information

I believe it's any of my extensions that causes this behaviour as i previusly encountered this. But previously either the cmd log or the sysinfo gave hints on what is going wrong. This time everything appears to load properly",2025-04-01T19:34:14Z,DHow2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16930,"[Bug]: Extensions list (lora list sometimes) not properly showing ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After startup the extensions list is not showing up and after hitting ""refresh"" the extension list shows up but is still greyed out. Same thing sometimes happens to the lora/checkpoint list. It then looks like this:
[https://imgur.com/a/gs9hjMx](url)


### Steps to reproduce the problem

1. startup 1111
2. wait for startup to finish
3. open http://127.0.0.1:7860/
4. go to extensions tab or lora/checkpoint list

### What should have happened?

Webui should list all loras/checkpoints and extensions installed

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

Sysinfo:
https://pastebin.com/ievDm8vk

### Console logs

```Shell
CMD log:
https://pastebin.com/hzrE1u7v
```

### Additional information

I believe it's any of my extensions that causes this behaviour as i previusly encountered this. But previously either the cmd log or the sysinfo gave hints on what is going wrong. This time everything appears to load properly",bug extensions list lora list sometimes properly showing checklist issue exists disabling extensions issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened startup extensions list showing hitting refresh extension list shows still greyed thing sometimes happens lora checkpoint list looks like steps reproduce problem startup wait startup finish open go extensions tab lora checkpoint list happened webui list loras checkpoints extensions installed browsers use access ui chrome sysinfo sysinfo console logs shell cmd log additional information believe extensions causes behaviour previusly encountered previously either cmd log sysinfo gave hints going wrong time everything appears load properly
auto1111_webui,issue,16924,[Feature Request]: EXTRA_INDEX_URL env var for pip,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have a `EXTRA_INDEX_URL` environment variable like the `INDEX_URL` environment var used in [modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/launch_utils.py) to set the pip `--extra-index-url` argument.

Alternative : Deprecate `INDEX_URL` and document using the pip env vars `PIP_INDEX_URL` and `PIP_EXTRA_INDEX_URL`

### Proposed workflow

Set the `EXTRA_INDEX_URL` to something like `https://download.pytorch.org/whl/rocm6.2.4`
Run `launch.py` and let it install requirements using the extra index url and the default implicit one

### Additional information

https://pip.pypa.io/en/stable/cli/pip_install/#cmdoption-extra-index-url",2025-03-28T00:28:01Z,AR2000AR,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16924,"[Feature Request]: EXTRA_INDEX_URL env var for pip ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have a `EXTRA_INDEX_URL` environment variable like the `INDEX_URL` environment var used in [modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/launch_utils.py) to set the pip `--extra-index-url` argument.

Alternative : Deprecate `INDEX_URL` and document using the pip env vars `PIP_INDEX_URL` and `PIP_EXTRA_INDEX_URL`

### Proposed workflow

Set the `EXTRA_INDEX_URL` to something like `https://download.pytorch.org/whl/rocm6.2.4`
Run `launch.py` and let it install requirements using the extra index url and the default implicit one

### Additional information

https://pip.pypa.io/en/stable/cli/pip_install/#cmdoption-extra-index-url",feature request extra index url env var pip existing issue x searched existing issues checked recent builds commits would feature would nice extra index url environment variable like index url environment var used modules launch utils py set pip extra index url argument alternative deprecate index url document using pip env vars pip index url pip extra index url proposed workflow set extra index url something like run launch py let install requirements using extra index url default implicit one additional information
auto1111_webui,issue,16917,[Bug]: FINISH ISSUE,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Steps to reproduce the problem

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What should have happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Console logs

```Shell
venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
```

### Additional information

_No response_",2025-03-24T19:41:09Z,krisz2333,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16917,"[Bug]: FINISH ISSUE ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Steps to reproduce the problem

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What should have happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Console logs

```Shell
venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
```

### Additional information

_No response_",bug finish issue checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened venv c users krisz desktop web ui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file c users krisz desktop web ui stable diffusion webui launch py line module main file c users krisz desktop web ui stable diffusion webui launch py line main prepare environment file c users krisz desktop web ui stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file c users krisz desktop web ui stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users krisz desktop web ui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command c users krisz desktop web ui stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done preparing metadata pyproject toml started preparing metadata pyproject toml finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy zip kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status error stderr error subprocess exited error getting requirements build wheel run successfully exit code lines output traceback recent call last file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line module main file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line main json return val hook hook input kwargs file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line get requires build wheel return hook config settings file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get requires build wheel return self get build requires config settings requirements file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get build requires self run setup file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup super run setup setup script setup script file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup exec code locals file string line module file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line setup install setup requires attrs file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line install setup requires dist parse config files ignore option errors true file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files self parse config files filenames inifiles file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files opt self enforce underscore opt section file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line enforce underscore raise invalidconfigerror setuptools errors invalidconfigerror invalid dash separated key description file metadata setup cfg please use underscore name description file instead end output note error originates subprocess likely problem pip error subprocess exited error getting requirements build wheel run successfully exit code see output note error originates subprocess likely problem pip steps reproduce problem venv c users krisz desktop web ui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file c users krisz desktop web ui stable diffusion webui launch py line module main file c users krisz desktop web ui stable diffusion webui launch py line main prepare environment file c users krisz desktop web ui stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file c users krisz desktop web ui stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users krisz desktop web ui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command c users krisz desktop web ui stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done preparing metadata pyproject toml started preparing metadata pyproject toml finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy zip kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status error stderr error subprocess exited error getting requirements build wheel run successfully exit code lines output traceback recent call last file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line module main file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line main json return val hook hook input kwargs file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line get requires build wheel return hook config settings file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get requires build wheel return self get build requires config settings requirements file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get build requires self run setup file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup super run setup setup script setup script file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup exec code locals file string line module file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line setup install setup requires attrs file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line install setup requires dist parse config files ignore option errors true file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files self parse config files filenames inifiles file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files opt self enforce underscore opt section file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line enforce underscore raise invalidconfigerror setuptools errors invalidconfigerror invalid dash separated key description file metadata setup cfg please use underscore name description file instead end output note error originates subprocess likely problem pip error subprocess exited error getting requirements build wheel run successfully exit code see output note error originates subprocess likely problem pip happened venv c users krisz desktop web ui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file c users krisz desktop web ui stable diffusion webui launch py line module main file c users krisz desktop web ui stable diffusion webui launch py line main prepare environment file c users krisz desktop web ui stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file c users krisz desktop web ui stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users krisz desktop web ui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command c users krisz desktop web ui stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done preparing metadata pyproject toml started preparing metadata pyproject toml finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy zip kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status error stderr error subprocess exited error getting requirements build wheel run successfully exit code lines output traceback recent call last file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line module main file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line main json return val hook hook input kwargs file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line get requires build wheel return hook config settings file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get requires build wheel return self get build requires config settings requirements file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get build requires self run setup file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup super run setup setup script setup script file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup exec code locals file string line module file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line setup install setup requires attrs file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line install setup requires dist parse config files ignore option errors true file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files self parse config files filenames inifiles file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files opt self enforce underscore opt section file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line enforce underscore raise invalidconfigerror setuptools errors invalidconfigerror invalid dash separated key description file metadata setup cfg please use underscore name description file instead end output note error originates subprocess likely problem pip error subprocess exited error getting requirements build wheel run successfully exit code see output note error originates subprocess likely problem pip browsers use access ui response sysinfo venv c users krisz desktop web ui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file c users krisz desktop web ui stable diffusion webui launch py line module main file c users krisz desktop web ui stable diffusion webui launch py line main prepare environment file c users krisz desktop web ui stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file c users krisz desktop web ui stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users krisz desktop web ui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command c users krisz desktop web ui stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done preparing metadata pyproject toml started preparing metadata pyproject toml finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy zip kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status error stderr error subprocess exited error getting requirements build wheel run successfully exit code lines output traceback recent call last file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line module main file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line main json return val hook hook input kwargs file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line get requires build wheel return hook config settings file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get requires build wheel return self get build requires config settings requirements file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get build requires self run setup file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup super run setup setup script setup script file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup exec code locals file string line module file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line setup install setup requires attrs file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line install setup requires dist parse config files ignore option errors true file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files self parse config files filenames inifiles file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files opt self enforce underscore opt section file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line enforce underscore raise invalidconfigerror setuptools errors invalidconfigerror invalid dash separated key description file metadata setup cfg please use underscore name description file instead end output note error originates subprocess likely problem pip error subprocess exited error getting requirements build wheel run successfully exit code see output note error originates subprocess likely problem pip console logs shell venv c users krisz desktop web ui stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file c users krisz desktop web ui stable diffusion webui launch py line module main file c users krisz desktop web ui stable diffusion webui launch py line main prepare environment file c users krisz desktop web ui stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file c users krisz desktop web ui stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file c users krisz desktop web ui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command c users krisz desktop web ui stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status done preparing metadata pyproject toml started preparing metadata pyproject toml finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch c users krisz desktop web ui stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml c users krisz desktop web ui stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests c users krisz desktop web ui stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy zip kb installing build dependencies started installing build dependencies finished status done getting requirements build wheel started getting requirements build wheel finished status error stderr error subprocess exited error getting requirements build wheel run successfully exit code lines output traceback recent call last file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line module main file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line main json return val hook hook input kwargs file c users krisz desktop web ui stable diffusion webui venv lib site packages pip vendor pyproject hooks process process py line get requires build wheel return hook config settings file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get requires build wheel return self get build requires config settings requirements file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line get build requires self run setup file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup super run setup setup script setup script file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools build meta py line run setup exec code locals file string line module file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line setup install setup requires attrs file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools init py line install setup requires dist parse config files ignore option errors true file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files self parse config files filenames inifiles file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line parse config files opt self enforce underscore opt section file c users krisz appdata local temp pip build env fw gzotl overlay lib site packages setuptools dist py line enforce underscore raise invalidconfigerror setuptools errors invalidconfigerror invalid dash separated key description file metadata setup cfg please use underscore name description file instead end output note error originates subprocess likely problem pip error subprocess exited error getting requirements build wheel run successfully exit code see output note error originates subprocess likely problem pip additional information response
auto1111_webui,issue,16912,[Feature Request]: about  webui-user.bat,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

when i  have run the  file of  webui-user.bat,  The download speed is too slow。so ,I have already downloaded Partial files  through other means and installed it via pip。next, when i  run  the file  of  webui-user.bat, It still requires downloading the file I've already installed。

### Proposed workflow

Can webui-user.bat skip already installed files


### Additional information

_No response_",2025-03-22T15:15:59Z,KaiXin1977,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912,"[Feature Request]: about  webui-user.bat ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

when i  have run the  file of  webui-user.bat,  The download speed is too slow。so ,I have already downloaded Partial files  through other means and installed it via pip。next, when i  run  the file  of  webui-user.bat, It still requires downloading the file I've already installed。

### Proposed workflow

Can webui-user.bat skip already installed files


### Additional information

_No response_",feature request webui user bat existing issue x searched existing issues checked recent builds commits would feature run file webui user bat download speed slowso already downloaded partial files means installed via pipnext run file webui user bat still requires downloading file already installed proposed workflow webui user bat skip already installed files additional information response
auto1111_webui,comment,16912,,"Make sure you're installing it in a [venv](https://docs.python.org/3.10/library/venv.html).

Create a venv with `python -m venv venv`
Activate it with `venv\scripts\activate`
Then install your packages with pip

Alternatively, you can use it without a venv by setting [`VENV_DIR`](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L5) to `-`",2025-03-22T23:08:00Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-2745907896,"Make sure you're installing it in a [venv](https://docs.python.org/3.10/library/venv.html).

Create a venv with `python -m venv venv`
Activate it with `venv\scripts\activate`
Then install your packages with pip

Alternatively, you can use it without a venv by setting [`VENV_DIR`](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L5) to `-`",make sure installing venv create venv python venv venv activate venv scripts activate install packages pip alternatively use without venv setting venv dir
auto1111_webui,comment,16912,,"Когда я запускаю webui-user.bat у меня ошибка загрузки : unable to create venv directory "" системе не удается найти указанный путь. Что делать подскажите?
",2025-04-03T04:24:46Z,Andryrich,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-2774459307,"Когда я запускаю webui-user.bat у меня ошибка загрузки : unable to create venv directory "" системе не удается найти указанный путь. Что делать подскажите?",webui user bat unable create venv directory
auto1111_webui,comment,16912,,"> Когда я запускаю webui-user.bat у меня ошибка загрузки : unable to create venv directory "" системе не удается найти указанный путь. Что делать подскажите?

Просто в webui-user.bar  установи полный путь к ven. В моем  случае ""set VENV_DIR=E:\stable-diffusion-webui\venv""",2025-10-27T18:50:04Z,N1K0D4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-3452815521,"> Когда я запускаю webui-user.bat у меня ошибка загрузки : unable to create venv directory "" системе не удается найти указанный путь. Что делать подскажите?

Просто в webui-user.bar  установи полный путь к ven. В моем  случае ""set VENV_DIR=E:\stable-diffusion-webui\venv""",webui user bat unable create venv directory webui user bar ven set venv dir e stable diffusion webui venv
auto1111_webui,issue,16910,Someone is impersonating AUTOMATIC1111 for crypto,"Thanks to @Jessiebase and users on Discord
It has been brought to our attention that someone on Twitter (X) is impersonating @AUTOMATIC1111 and using project to promote a crypto wallet
- for details see orignal post #16908

We have not set up any form of donation to this project, nor am I aware that @AUTOMATIC1111 have any personal donation means
As far as I'm aware no one hase been in contact @AUTOMATIC1111 since 2024/10/19

Consider any announcement that did not come directly from GitHub to be a impersonation of some kind",2025-03-21T19:57:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16910,"Someone is impersonating AUTOMATIC1111 for crypto Thanks to @Jessiebase and users on Discord
It has been brought to our attention that someone on Twitter (X) is impersonating @AUTOMATIC1111 and using project to promote a crypto wallet
- for details see orignal post #16908

We have not set up any form of donation to this project, nor am I aware that @AUTOMATIC1111 have any personal donation means
As far as I'm aware no one hase been in contact @AUTOMATIC1111 since 2024/10/19

Consider any announcement that did not come directly from GitHub to be a impersonation of some kind",someone impersonating automatic crypto thanks jessiebase users discord brought attention someone twitter x impersonating automatic using project promote crypto wallet details see orignal post set form donation project aware automatic personal donation means far aware one hase contact automatic since consider announcement come directly github impersonation kind
auto1111_webui,issue,16908,[Bug]: Someone use your project luanching a token. Is it yourself?,"### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Steps to reproduce the problem

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What should have happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Console logs

```Shell
https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)
```

### Additional information

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)
",2025-03-21T06:59:47Z,Jessiebase,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16908,"[Bug]: Someone use your project luanching a token. Is it yourself? ### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Steps to reproduce the problem

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What should have happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Console logs

```Shell
https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)
```

### Additional information

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)",bug someone use project luanching token checklist x issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened hi twitter luanched token rug image steps reproduce problem hi twitter luanched token rug image happened hi twitter luanched token rug image browsers use access ui response sysinfo hi twitter luanched token rug image console logs shell hi twitter luanched token rug image additional information hi twitter luanched token rug image
auto1111_webui,comment,16908,,"99.999999% sure this is not @AUTOMATIC1111 
for context, last I have any communication is on 2024/10/19",2025-03-21T19:22:35Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16908#issuecomment-2744259638,"99.999999% sure this is not @AUTOMATIC1111 
for context, last I have any communication is on 2024/10/19",sure automatic context last communication
auto1111_webui,issue,16907,[Feature Request]: Newer version of Python,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I was getting a little bit of help from Arch Linux community and when they saw I am installing Python 310 they frowned. I argued: ""Big apps can't really catch up that fast to newer versions of libraries they are using. It break compatibility in nasty ways and there is tradeoff between fixing that and other stuff""
They said: ""That argument falls kinda flat being python 310 is dead and eol for nearly 2 years already and even things like blender are on python 3.13""

### Proposed workflow

I is a software dependency related issue.

### Additional information

_No response_",2025-03-20T06:11:52Z,siakc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907,"[Feature Request]: Newer version of Python ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I was getting a little bit of help from Arch Linux community and when they saw I am installing Python 310 they frowned. I argued: ""Big apps can't really catch up that fast to newer versions of libraries they are using. It break compatibility in nasty ways and there is tradeoff between fixing that and other stuff""
They said: ""That argument falls kinda flat being python 310 is dead and eol for nearly 2 years already and even things like blender are on python 3.13""

### Proposed workflow

I is a software dependency related issue.

### Additional information

_No response_",feature request newer version python existing issue x searched existing issues checked recent builds commits would feature getting little bit help arch linux community saw installing python frowned argued big apps really catch fast newer versions libraries using break compatibility nasty ways tradeoff fixing stuff said argument falls kinda flat python dead eol nearly years already even things like blender python proposed workflow software dependency related issue additional information response
auto1111_webui,comment,16907,,"https://devguide.python.org/versions/

Python 3.10 doesn't EOL until 2026.
",2025-03-20T23:10:51Z,jagauthier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-2741858990,"https://devguide.python.org/versions/

Python 3.10 doesn't EOL until 2026.",python eol
auto1111_webui,comment,16907,,"I did manage to get the whole thing working on a 5090 with Python 3.12... however, not without blood, sweat and tears..
If you are prepared to manually modify filenames, wait for your computer to compile flash attention wheels (that took 5 hours on a 9800X3D) and wanting to go through LOADS of .py files and manually modify very specific lines due to incompatibilities between old python code and new code... be my guest :P

Otherwise, stick to the version advised or wait for the guys that created this and other modules to update everything :)",2025-03-21T10:40:59Z,KickAssDave,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-2742982185,"I did manage to get the whole thing working on a 5090 with Python 3.12... however, not without blood, sweat and tears..
If you are prepared to manually modify filenames, wait for your computer to compile flash attention wheels (that took 5 hours on a 9800X3D) and wanting to go through LOADS of .py files and manually modify very specific lines due to incompatibilities between old python code and new code... be my guest :P

Otherwise, stick to the version advised or wait for the guys that created this and other modules to update everything :)",manage get whole thing working python however without blood sweat tears prepared manually modify filenames wait computer compile flash attention wheels took hours x wanting go loads py files manually modify specific lines due incompatibilities old python code new code guest p otherwise stick version advised wait guys created modules update everything
auto1111_webui,comment,16907,,How does one install an older version of Python on linux without clobbering their system-wide Python version?,2025-10-18T10:50:03Z,jasonculligan,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-3418212092,How does one install an older version of Python on linux without clobbering their system-wide Python version?,one install older version python linux without clobbering system wide python version
auto1111_webui,issue,16902,[Bug]: Unable to install older versions of SD,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Unable to successfully launch older version of SD after installation. Specifically version 1.4.0, 1.5.2 and I think I also tried 1.6.0.

### Steps to reproduce the problem

1. Delete all folders in: %LocalAppData%\pip\Cache
2. Download 1.5.2 from [releases page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases)
3. Install [Python 3.10.6](https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe) (64-bit) (ticking Add to PATH), and [git](https://github.com/git-for-windows/git/releases/download/v2.39.2.windows.1/Git-2.39.2-64-bit.exe)
4. Unzip the 1.5.2 zip file
5. Set the correct paths in the webui-user.bat and then run

### What should have happened?

Get error:

> Launching Web UI with arguments:
> Traceback (most recent call last):
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
>     main()
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
>     start()
>   File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
>     import webui
>   File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
>     import gradio  # noqa: F401
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
>     import gradio.components as components
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
>     from gradio import processing_utils, utils
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
>     class AsyncRequest:
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
>     client = httpx.AsyncClient()
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
>     self._transport = self._init_transport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
>     return AsyncHTTPTransport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
>     self._pool = httpcore.AsyncConnectionPool(
> TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
> Press any key to continue . . .

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

NA

### Console logs

```Shell
Creating venv in directory Z:\stable-diffusion-webui-1.5.2\venv using python ""C:\Users\Saber\AppData\Local\Programs\Python\Python310\python.exe""
venv ""Z:\stable-diffusion-webui-1.5.2\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.5.2
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118
Collecting torch==2.0.1
  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-win_amd64.whl (2619.1 MB)
Collecting torchvision==0.15.2
  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-win_amd64.whl (4.9 MB)
Collecting typing-extensions
  Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting filelock
  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
Collecting jinja2
  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Collecting networkx
  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Collecting sympy
  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting pillow!=8.3.*,>=5.3.0
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Collecting numpy
  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)
Collecting MarkupSafe>=2.0
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.10-py3-none-any.whl (70 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Collecting mpmath<1.4,>=1.1.0
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.0.1+cu118 torchvision-0.15.2+cu118 typing-extensions-4.12.2 urllib3-2.3.0

[notice] A new release of pip available: 22.2.1 -> 25.0.1
[notice] To update, run: Z:\stable-diffusion-webui-1.5.2\venv\Scripts\python.exe -m pip install --upgrade pip
Installing gfpgan
Installing clip
Installing open_clip
Cloning Stable Diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)Receiving objects:  77% (447/580), 71.79 MiB | Receiving objects:  79% (459/580), 71.79 MiB | 11.12 MiB/s
Receiving objects: 100% (580/580), 73.44 MiB | 11.03 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into Z:\stable-diffusion-webui-1.5.2\repositories\generative-models...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (499/499), done.
remote: Compressing objects: 100% (136/136), done.
remote: Total 1064 (delta 399), reused 363 (delta 363), pack-reused 565 (from 1)Receiving objects:  95% (1011/1064), 52.Receiving objects:
Receiving objects: 100% (1064/1064), 53.60 MiB | 10.50 MiB/s, done.
Resolving deltas: 100% (560/560), done.
Cloning K-diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 4.49 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning CodeFormer into Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer'...
remote: Enumerating objects: 614, done.
remote: Counting objects: 100% (292/292), done.

remote: Total 614 (delta 202), reused 176 (delta 176), pack-reused 322 (from 3)Receiving objects:  98% (602/614), 16.06 MiB | 10.70 MiB/s
Receiving objects: 100% (614/614), 17.31 MiB | 10.72 MiB/s, done.
Resolving deltas: 100% (296/296), done.
Cloning BLIP into Z:\stable-diffusion-webui-1.5.2\repositories\BLIP...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 10.35 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements for CodeFormer
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
    main()
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
    start()
  File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
    import webui
  File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
    import gradio  # noqa: F401
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
    import gradio.components as components
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
    from gradio import processing_utils, utils
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
    class AsyncRequest:
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
    client = httpx.AsyncClient()
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
    self._transport = self._init_transport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
    return AsyncHTTPTransport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
    self._pool = httpcore.AsyncConnectionPool(
TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
Press any key to continue . . .
```

### Additional information

_No response_",2025-03-19T03:34:46Z,JingJang,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16902,"[Bug]: Unable to install older versions of SD ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Unable to successfully launch older version of SD after installation. Specifically version 1.4.0, 1.5.2 and I think I also tried 1.6.0.

### Steps to reproduce the problem

1. Delete all folders in: %LocalAppData%\pip\Cache
2. Download 1.5.2 from [releases page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases)
3. Install [Python 3.10.6](https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe) (64-bit) (ticking Add to PATH), and [git](https://github.com/git-for-windows/git/releases/download/v2.39.2.windows.1/Git-2.39.2-64-bit.exe)
4. Unzip the 1.5.2 zip file
5. Set the correct paths in the webui-user.bat and then run

### What should have happened?

Get error:

> Launching Web UI with arguments:
> Traceback (most recent call last):
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
>     main()
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
>     start()
>   File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
>     import webui
>   File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
>     import gradio  # noqa: F401
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
>     import gradio.components as components
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
>     from gradio import processing_utils, utils
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
>     class AsyncRequest:
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
>     client = httpx.AsyncClient()
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
>     self._transport = self._init_transport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
>     return AsyncHTTPTransport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
>     self._pool = httpcore.AsyncConnectionPool(
> TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
> Press any key to continue . . .

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

NA

### Console logs

```Shell
Creating venv in directory Z:\stable-diffusion-webui-1.5.2\venv using python ""C:\Users\Saber\AppData\Local\Programs\Python\Python310\python.exe""
venv ""Z:\stable-diffusion-webui-1.5.2\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.5.2
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118
Collecting torch==2.0.1
  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-win_amd64.whl (2619.1 MB)
Collecting torchvision==0.15.2
  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-win_amd64.whl (4.9 MB)
Collecting typing-extensions
  Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting filelock
  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
Collecting jinja2
  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Collecting networkx
  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Collecting sympy
  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting pillow!=8.3.*,>=5.3.0
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Collecting numpy
  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)
Collecting MarkupSafe>=2.0
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.10-py3-none-any.whl (70 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Collecting mpmath<1.4,>=1.1.0
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.0.1+cu118 torchvision-0.15.2+cu118 typing-extensions-4.12.2 urllib3-2.3.0

[notice] A new release of pip available: 22.2.1 -> 25.0.1
[notice] To update, run: Z:\stable-diffusion-webui-1.5.2\venv\Scripts\python.exe -m pip install --upgrade pip
Installing gfpgan
Installing clip
Installing open_clip
Cloning Stable Diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)Receiving objects:  77% (447/580), 71.79 MiB | Receiving objects:  79% (459/580), 71.79 MiB | 11.12 MiB/s
Receiving objects: 100% (580/580), 73.44 MiB | 11.03 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into Z:\stable-diffusion-webui-1.5.2\repositories\generative-models...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (499/499), done.
remote: Compressing objects: 100% (136/136), done.
remote: Total 1064 (delta 399), reused 363 (delta 363), pack-reused 565 (from 1)Receiving objects:  95% (1011/1064), 52.Receiving objects:
Receiving objects: 100% (1064/1064), 53.60 MiB | 10.50 MiB/s, done.
Resolving deltas: 100% (560/560), done.
Cloning K-diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 4.49 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning CodeFormer into Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer'...
remote: Enumerating objects: 614, done.
remote: Counting objects: 100% (292/292), done.

remote: Total 614 (delta 202), reused 176 (delta 176), pack-reused 322 (from 3)Receiving objects:  98% (602/614), 16.06 MiB | 10.70 MiB/s
Receiving objects: 100% (614/614), 17.31 MiB | 10.72 MiB/s, done.
Resolving deltas: 100% (296/296), done.
Cloning BLIP into Z:\stable-diffusion-webui-1.5.2\repositories\BLIP...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 10.35 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements for CodeFormer
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
    main()
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
    start()
  File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
    import webui
  File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
    import gradio  # noqa: F401
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
    import gradio.components as components
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
    from gradio import processing_utils, utils
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
    class AsyncRequest:
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
    client = httpx.AsyncClient()
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
    self._transport = self._init_transport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
    return AsyncHTTPTransport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
    self._pool = httpcore.AsyncConnectionPool(
TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
Press any key to continue . . .
```

### Additional information

_No response_",bug unable install older versions sd checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened unable successfully launch older version sd installation specifically version think also tried steps reproduce problem delete folders localappdata pip cache download releases page install python bit ticking add path git unzip zip file set correct paths webui user bat run happened get error launching web ui arguments traceback recent call last file z stable diffusion webui launch py line module main file z stable diffusion webui launch py line main start file z stable diffusion webui modules launch utils py line start import webui file z stable diffusion webui webui py line module import gradio noqa f file z stable diffusion webui venv lib site packages gradio init py line module import gradio components components file z stable diffusion webui venv lib site packages gradio components py line module gradio import processing utils utils file z stable diffusion webui venv lib site packages gradio utils py line module class asyncrequest file z stable diffusion webui venv lib site packages gradio utils py line asyncrequest client file z stable diffusion webui venv lib site packages line init self transport self init transport file z stable diffusion webui venv lib site packages line init transport return async file z stable diffusion webui venv lib site packages line init self pool typeerror asyncconnectionpool init got unexpected keyword argument socket options press key continue browsers use access ui response sysinfo na console logs shell creating venv directory z stable diffusion webui venv using python c users saber appdata local programs python python python exe venv z stable diffusion webui venv scripts python exe fatal git repository parent directories git fatal git repository parent directories git python tags v c b bd aug msc v bit amd version commit hash none installing torch torchvision looking indexes collecting torch using cached mb collecting torchvision using cached mb collecting typing extensions using cached kb collecting filelock using cached filelock py none whl kb collecting jinja using cached jinja py none whl kb collecting networkx using cached networkx py none whl mb collecting sympy using cached sympy py none whl mb collecting requests using cached requests py none whl kb collecting pillow using cached pillow cp cp win amd whl mb collecting numpy using cached numpy cp cp win amd whl mb collecting markupsafe using cached markupsafe cp cp win amd whl kb collecting charset normalizer using cached charset normalizer cp cp win amd whl kb collecting urllib using cached urllib py none whl kb collecting idna using cached idna py none whl kb collecting certifi using cached certifi py none whl kb collecting mpmath using cached kb installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna filelock charset normalizer certifi requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu typing extensions urllib notice new release pip available notice update run z stable diffusion webui venv scripts python exe pip install upgrade pip installing gfpgan installing clip installing open clip cloning stable diffusion z stable diffusion webui repositories stable diffusion stability ai cloning z stable diffusion webui repositories stable diffusion stability ai remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib receiving objects mib mib receiving objects mib mib done resolving deltas done cloning stable diffusion xl z stable diffusion webui repositories generative models cloning z stable diffusion webui repositories generative models remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects receiving objects receiving objects mib mib done resolving deltas done cloning k diffusion z stable diffusion webui repositories k diffusion cloning z stable diffusion webui repositories k diffusion remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done resolving deltas done cloning codeformer z stable diffusion webui repositories codeformer cloning z stable diffusion webui repositories codeformer remote enumerating objects done remote counting objects done remote total delta reused delta pack reused receiving objects mib mib receiving objects mib mib done resolving deltas done cloning blip z stable diffusion webui repositories blip cloning z stable diffusion webui repositories blip remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done installing requirements codeformer installing requirements launching web ui arguments traceback recent call last file z stable diffusion webui launch py line module main file z stable diffusion webui launch py line main start file z stable diffusion webui modules launch utils py line start import webui file z stable diffusion webui webui py line module import gradio noqa f file z stable diffusion webui venv lib site packages gradio init py line module import gradio components components file z stable diffusion webui venv lib site packages gradio components py line module gradio import processing utils utils file z stable diffusion webui venv lib site packages gradio utils py line module class asyncrequest file z stable diffusion webui venv lib site packages gradio utils py line asyncrequest client file z stable diffusion webui venv lib site packages line init self transport self init transport file z stable diffusion webui venv lib site packages line init transport return async file z stable diffusion webui venv lib site packages line init self pool typeerror asyncconnectionpool init got unexpected keyword argument socket options press key continue additional information response
auto1111_webui,issue,16896,"same issue, fixed?","same issue, fixed?

_最初由 Sensanko52123 在 https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2725201568 发布_



It can be opened now, but it’s not completely working. Currently, I can only open it using the following method:

1. Open Command Prompt as Administrator (press Win + R, type cmd, and then press Ctrl + Shift + Enter).


2. Type cd and navigate to the folder where your sd-web-ui is located.


3. Then type webui-user.bat to launch the program.



I can only open it this way at the moment; clicking directly on the file causes an error.


---

This is the error log when trying to start directly:

venv ""C:\stable-diffusion-webui\venv\Scripts\Python.exe""

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]

Version: v1.10.1

Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2

Couldn't determine Stable Diffusion XL's hash: 45c443b316737a4ab6e40413d7794a7f5657c19f, attempting autofix...

Fetching all contents for Stable Diffusion XL

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

fatal: detected dubious ownership in repository at 'C:/stable-diffusion-webui/repositories/generative-models'

'C:/stable-diffusion-webui/repositories/generative-models' is owned by:

BUILTIN/Administrators (S-1-5-32-544)

but the current user is:

DESKTOP-9PK31L6/jerem (S-1-5-21-2914250175-1236065574-3379173521-1001)

To add an exception for this directory, call:

git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models

Traceback (most recent call last):

File ""C:\stable-diffusion-webui\launch.py"", line 48, in <module>

main()

File ""C:\stable-diffusion-webui\launch.py"", line 39, in main

prepare_environment()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 413, in prepare_environment

git_clone(stable_diffusion_xl_repo, repo_dir('generative-models'), ""Stable Diffusion XL"", stable_diffusion_xl_commit_hash)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone

current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git

git_fix_workspace(dir, name)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace

run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run

raise RuntimeError(""\n"".join(error_bits))

RuntimeError: Couldn't fetch Stable Diffusion XL.

Command: ""git"" -C ""C:\stable-diffusion-webui\repositories\generative-models"" fetch --refetch --no-auto-gc

Error code: 128

Press any key to continue...",2025-03-16T04:20:54Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896,"same issue, fixed? same issue, fixed?

_最初由 Sensanko52123 在 https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2725201568 发布_



It can be opened now, but it’s not completely working. Currently, I can only open it using the following method:

1. Open Command Prompt as Administrator (press Win + R, type cmd, and then press Ctrl + Shift + Enter).


2. Type cd and navigate to the folder where your sd-web-ui is located.


3. Then type webui-user.bat to launch the program.



I can only open it this way at the moment; clicking directly on the file causes an error.


---

This is the error log when trying to start directly:

venv ""C:\stable-diffusion-webui\venv\Scripts\Python.exe""

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]

Version: v1.10.1

Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2

Couldn't determine Stable Diffusion XL's hash: 45c443b316737a4ab6e40413d7794a7f5657c19f, attempting autofix...

Fetching all contents for Stable Diffusion XL

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/桌面/工具/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

fatal: detected dubious ownership in repository at 'C:/stable-diffusion-webui/repositories/generative-models'

'C:/stable-diffusion-webui/repositories/generative-models' is owned by:

BUILTIN/Administrators (S-1-5-32-544)

but the current user is:

DESKTOP-9PK31L6/jerem (S-1-5-21-2914250175-1236065574-3379173521-1001)

To add an exception for this directory, call:

git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models

Traceback (most recent call last):

File ""C:\stable-diffusion-webui\launch.py"", line 48, in <module>

main()

File ""C:\stable-diffusion-webui\launch.py"", line 39, in main

prepare_environment()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 413, in prepare_environment

git_clone(stable_diffusion_xl_repo, repo_dir('generative-models'), ""Stable Diffusion XL"", stable_diffusion_xl_commit_hash)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone

current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git

git_fix_workspace(dir, name)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace

run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run

raise RuntimeError(""\n"".join(error_bits))

RuntimeError: Couldn't fetch Stable Diffusion XL.

Command: ""git"" -C ""C:\stable-diffusion-webui\repositories\generative-models"" fetch --refetch --no-auto-gc

Error code: 128

Press any key to continue...",issue fixed issue fixed sensanko opened completely working currently open using following method open command prompt administrator press win r type cmd press ctrl shift enter type cd navigate folder sd web ui located type webui user bat launch program open way moment clicking directly file causes error error log trying start directly venv c stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e determine stable diffusion xl hash c b ab e f c f attempting autofix fetching contents stable diffusion xl warning safe directory c users jerem onedrive stable diffusion webui repositories stable diffusion webui assets absolute warning safe directory c users jerem onedrive stable diffusion webui repositories stable diffusion webui assets absolute warning safe directory c users jerem onedrive stable diffusion webui repositories stable diffusion webui assets absolute warning safe directory c users jerem onedrive stable diffusion webui repositories stable diffusion webui assets absolute warning safe directory c users jerem onedrive stable diffusion webui repositories stable diffusion webui assets absolute fatal detected dubious ownership repository c stable diffusion webui repositories generative models c stable diffusion webui repositories generative models owned builtin administrators current user desktop pk l jerem add exception directory call git config global add safe directory c stable diffusion webui repositories generative models traceback recent call last file c stable diffusion webui launch py line module main file c stable diffusion webui launch py line main prepare environment file c stable diffusion webui modules launch utils py line prepare environment git clone stable diffusion xl repo repo dir generative models stable diffusion xl stable diffusion xl commit hash file c stable diffusion webui modules launch utils py line git clone current hash run git dir name rev parse head none f determine name hash commithash live false strip file c stable diffusion webui modules launch utils py line run git git fix workspace dir name file c stable diffusion webui modules launch utils py line git fix workspace run f git c dir fetch refetch auto gc f fetching contents name f fetch name live true file c stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror fetch stable diffusion xl command git c c stable diffusion webui repositories generative models fetch refetch auto gc error code press key continue
auto1111_webui,comment,16896,,"Hey, I am not a contributor here but I think this issue appears to be related to Git safe directory settings and ownership conflicts in Windows.
To fix it, try running:

`git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models`
If the issue persists, running Command Prompt as Administrator and launching webui-user.bat may help.
Additionally, manually resetting the repo using:

```
cd C:\stable-diffusion-webui\repositories\generative-models
git fetch --all
git reset --hard origin/main
```
might resolve the issue.",2025-03-18T17:57:43Z,minhaj3,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896#issuecomment-2734237948,"Hey, I am not a contributor here but I think this issue appears to be related to Git safe directory settings and ownership conflicts in Windows.
To fix it, try running:

`git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models`
If the issue persists, running Command Prompt as Administrator and launching webui-user.bat may help.
Additionally, manually resetting the repo using:

```
cd C:\stable-diffusion-webui\repositories\generative-models
git fetch --all
git reset --hard origin/main
```
might resolve the issue.",hey contributor think issue appears related git safe directory settings ownership conflicts windows fix try running git config global add safe directory c stable diffusion webui repositories generative models issue persists running command prompt administrator launching webui user bat may help additionally manually resetting repo using cd c stable diffusion webui repositories generative models git fetch git reset hard origin main might resolve issue
auto1111_webui,comment,16896,,is this fixed? i'm facing the same problem and i tried the solution mentioned upper but still not fixed...,2025-06-27T22:19:21Z,emai24volts,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896#issuecomment-3014487979,is this fixed? i'm facing the same problem and i tried the solution mentioned upper but still not fixed...,fixed facing problem tried solution mentioned upper still fixed
auto1111_webui,issue,16891,[Bug]:,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

torch don't istalling

### Steps to reproduce the problem

1. Start UI
2. Wait

### What should have happened?

WebUI should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

can't generate

### Console logs

```Shell
venv ""V:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    torch==2.1.2 from https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl#sha256=9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9:
        Expected sha256 9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9
             Got        3edee9eaa79a7a477e6dbd294393416de5527aac9d81ce5a9b37df6759cda4b8

Traceback (most recent call last):
  File ""V:\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""V:\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""V:\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

added git pull and --autolaunch",2025-03-14T16:33:29Z,Sensanko52123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891,"[Bug]: ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

torch don't istalling

### Steps to reproduce the problem

1. Start UI
2. Wait

### What should have happened?

WebUI should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

can't generate

### Console logs

```Shell
venv ""V:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    torch==2.1.2 from https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl#sha256=9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9:
        Expected sha256 9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9
             Got        3edee9eaa79a7a477e6dbd294393416de5527aac9d81ce5a9b37df6759cda4b8

Traceback (most recent call last):
  File ""V:\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""V:\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""V:\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

added git pull and --autolaunch",bug checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened torch istalling steps reproduce problem start ui wait happened webui start browsers use access ui response sysinfo generate console logs shell venv v stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes collecting torch using cached mb error packages match hashes requirements file updated package versions please update hashes otherwise examine package contents carefully someone may tampered torch expected sha dece e c eb ef e b f dcea b got edee eaa e dbd de aac ce b df cda b traceback recent call last file v stable diffusion webui launch py line module main file v stable diffusion webui launch py line main prepare environment file v stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file v stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command v stable diffusion webui venv scripts python exe pip install torch torchvision extra index url error code additional information added git pull autolaunch
auto1111_webui,comment,16891,,It looks like the cached copy of torch is corrupt. Run `pip cache remove torch` or `pip cache purge` and try again.,2025-03-17T23:09:50Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891#issuecomment-2731158540,It looks like the cached copy of torch is corrupt. Run `pip cache remove torch` or `pip cache purge` and try again.,looks like cached copy torch corrupt run pip cache remove torch pip cache purge try
auto1111_webui,comment,16891,,"After doing `pip cache purge`, you can install torch with something like this:
`pip install --no-cache-dir torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121`
 
Or you can also try some earlier version of torch",2025-03-18T18:02:23Z,minhaj3,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891#issuecomment-2734258856,"After doing `pip cache purge`, you can install torch with something like this:
`pip install --no-cache-dir torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121`
 
Or you can also try some earlier version of torch",pip cache purge install torch something like pip install cache dir torch torchvision extra index url also try earlier version torch
auto1111_webui,issue,16890,[Bug]: Could not find a version that satisfies the requirement torch==2.0.0a0 on --use-ipex,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when launching webui with python3.10 i get torch cannot be install when usng --use-ipex option, why is that? i dont see that option even in documentation, i only found out about ipex is here 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/13853

### Steps to reproduce the problem

1. install
2. try with --use-ipex

### What should have happened?

WORK

### What browsers do you use to access the UI ?

Other

### Sysinfo

cant

### Console logs

```Shell
./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
Clone stable-diffusion-webui
################################################################
Cloning into 'stable-diffusion-webui'...
remote: Enumerating objects: 34945, done.
remote: Counting objects: 100% (26/26), done.
remote: Compressing objects: 100% (16/16), done.
remote: Total 34945 (delta 18), reused 10 (delta 10), pack-reused 34919 (from 3)
Receiving objects: 100% (34945/34945), 35.48 MiB | 40.60 MiB/s, done.
Resolving deltas: 100% (24389/24389), done.

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.10.1/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
ERROR: Could not find a version that satisfies the requirement torch==2.0.0a0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0a0+git6c9b55e, 1.13.0a0+gitb1dde16, 1.13.0, 1.13.1, 2.0.0, 2.0.1a0+cxx11.abi, 2.0.1, 2.1.0a0+cxx11.abi, 2.1.0, 2.1.0.post0+cxx11.abi, 2.1.0.post2+cxx11.abi, 2.1.0.post3+cxx11.abi, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.3.1+cxx11.abi, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.5.1+cxx11.abi, 2.6.0)
ERROR: No matching distribution found for torch==2.0.0a0
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/picarica/git/stable-diffusion-webui-1.10.1/venv/bin/python3.10"" -m pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
Error code: 1
```

### Additional information

_No response_",2025-03-12T19:11:46Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890,"[Bug]: Could not find a version that satisfies the requirement torch==2.0.0a0 on --use-ipex ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when launching webui with python3.10 i get torch cannot be install when usng --use-ipex option, why is that? i dont see that option even in documentation, i only found out about ipex is here 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/13853

### Steps to reproduce the problem

1. install
2. try with --use-ipex

### What should have happened?

WORK

### What browsers do you use to access the UI ?

Other

### Sysinfo

cant

### Console logs

```Shell
./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
Clone stable-diffusion-webui
################################################################
Cloning into 'stable-diffusion-webui'...
remote: Enumerating objects: 34945, done.
remote: Counting objects: 100% (26/26), done.
remote: Compressing objects: 100% (16/16), done.
remote: Total 34945 (delta 18), reused 10 (delta 10), pack-reused 34919 (from 3)
Receiving objects: 100% (34945/34945), 35.48 MiB | 40.60 MiB/s, done.
Resolving deltas: 100% (24389/24389), done.

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.10.1/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
ERROR: Could not find a version that satisfies the requirement torch==2.0.0a0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0a0+git6c9b55e, 1.13.0a0+gitb1dde16, 1.13.0, 1.13.1, 2.0.0, 2.0.1a0+cxx11.abi, 2.0.1, 2.1.0a0+cxx11.abi, 2.1.0, 2.1.0.post0+cxx11.abi, 2.1.0.post2+cxx11.abi, 2.1.0.post3+cxx11.abi, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.3.1+cxx11.abi, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.5.1+cxx11.abi, 2.6.0)
ERROR: No matching distribution found for torch==2.0.0a0
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/picarica/git/stable-diffusion-webui-1.10.1/venv/bin/python3.10"" -m pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
Error code: 1
```

### Additional information

_No response_",bug could find version satisfies requirement torch use ipex checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui x issue reported recently issue reported fixed yet happened launching webui python get torch cannot install usng use ipex option dont see option even documentation found ipex steps reproduce problem install try use ipex happened work browsers use access ui sysinfo cant console logs shell webui sh use ipex install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running picarica user clone stable diffusion webui cloning stable diffusion webui remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done python venv already activate run without venv home picarica git stable diffusion webui venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload usr lib libtcmalloc minimal python main dec gcc version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes error could find version satisfies requirement torch versions git c b e gitb dde cxx abi cxx abi post cxx abi post cxx abi post cxx abi cxx abi cxx abi error matching distribution found torch traceback recent call last file home picarica git stable diffusion webui stable diffusion webui launch py line module main file home picarica git stable diffusion webui stable diffusion webui launch py line main prepare environment file home picarica git stable diffusion webui stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file home picarica git stable diffusion webui stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command home picarica git stable diffusion webui venv bin python pip install torch intel extension pytorch gitba f c extra index url error code additional information response
auto1111_webui,comment,16890,,"tried renaming fbroken link versions 

-            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url {torch_index_url}"")
+            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.1.0 intel-extension-for-pytorch==2.1.10 --extra-index-url {torch_index_url}"")^M
     requirements_file = os.environ.get('REQS_FILE', ""requirements_versions.txt"")
     requirements_file_for_npu = os.environ.get('REQS_FILE_FOR_NPU', ""requirements_npu.txt"")

but still doeesnt work 
```

$ ./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv
################################################################

################################################################
Launching launch.py...
################################################################
Using TCMalloc: libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing open_clip
Cloning assets into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 2.07 MiB/s, done.
Cloning Stable Diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)
Receiving objects: 100% (580/580), 73.44 MiB | 45.91 MiB/s, done.
Resolving deltas: 100% (281/281), done.
Cloning Stable Diffusion XL into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (483/483), done.
remote: Compressing objects: 100% (126/126), done.
remote: Total 1064 (delta 380), reused 357 (delta 357), pack-reused 581 (from 1)
Receiving objects: 100% (1064/1064), 53.60 MiB | 40.44 MiB/s, done.
Resolving deltas: 100% (562/562), done.
Cloning K-diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 3.65 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning BLIP into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 30.40 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Launching Web UI with arguments: --use-ipex
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx', memory monitor disabled
Downloading: ""https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors"" to /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.97G/3.97G [01:11<00:00, 60.0MB/s]
Calculating sha256 for /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 119.9s (prepare environment: 42.0s, import torch: 3.0s, import gradio: 0.5s, setup paths: 0.7s, initialize shared: 0.1s, other imports: 0.3s, list SD models: 72.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.3s).
6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: RuntimeError
Traceback (most recent call last):
  File ""/usr/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/usr/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
    _lazy_init()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx


Stable diffusion model failed to load
changing setting sd_model_checkpoint to v1-5-pruned-emaonly.safetensors: RuntimeError
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/options.py"", line 165, in set
    option.onchange()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 14, in f
    res = func(*args, **kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize_util.py"", line 181, in <lambda>
    shared.opts.onchange(""sd_model_checkpoint"", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 845, in load_model
    load_model_weights(sd_model, checkpoint_info, state_dict, timer)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 440, in load_model_weights
    model.load_state_dict(state_dict, strict=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for LatentDiffusion:
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_ids"", whose dimensions in the model are torch.Size([1, 77]) and whose dimensions in the checkpoint are torch.Size([1, 77]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.token_embedding.weight"", whose dimensions in the model are torch.Size([49408, 768]) and whose dimensions in the checkpoint are torch.Size([49408, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_embedding.weight"", whose dimensions in the model are torch.Size([77, 768]) and whose dimensions in the checkpoint are torch.Size([77, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).

Using already loaded model v1-5-pruned-emaonly.safetensors [6ce0161689]: done in 0.0s
*** Error completing request
*** Arguments: ('task(j9egb4adhyrywz0)', <gradio.routes.Request object at 0x792d6e8bcd00>, 'smal little girlyu dancing aaay', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
        _lazy_init()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
        torch._C._cuda_init()
    RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx

---
^CInterrupted with signal 2 in <frame at 0x5923c2036250, file '/usr/lib/python3.10/threading.py', line 324, code wait>


```",2025-03-12T20:48:39Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-2719091658,"tried renaming fbroken link versions 

-            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url {torch_index_url}"")
+            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.1.0 intel-extension-for-pytorch==2.1.10 --extra-index-url {torch_index_url}"")^M
     requirements_file = os.environ.get('REQS_FILE', ""requirements_versions.txt"")
     requirements_file_for_npu = os.environ.get('REQS_FILE_FOR_NPU', ""requirements_npu.txt"")

but still doeesnt work 
```

$ ./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv
################################################################

################################################################
Launching launch.py...
################################################################
Using TCMalloc: libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing open_clip
Cloning assets into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 2.07 MiB/s, done.
Cloning Stable Diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)
Receiving objects: 100% (580/580), 73.44 MiB | 45.91 MiB/s, done.
Resolving deltas: 100% (281/281), done.
Cloning Stable Diffusion XL into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (483/483), done.
remote: Compressing objects: 100% (126/126), done.
remote: Total 1064 (delta 380), reused 357 (delta 357), pack-reused 581 (from 1)
Receiving objects: 100% (1064/1064), 53.60 MiB | 40.44 MiB/s, done.
Resolving deltas: 100% (562/562), done.
Cloning K-diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 3.65 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning BLIP into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 30.40 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Launching Web UI with arguments: --use-ipex
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx', memory monitor disabled
Downloading: ""https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors"" to /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.97G/3.97G [01:11<00:00, 60.0MB/s]
Calculating sha256 for /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 119.9s (prepare environment: 42.0s, import torch: 3.0s, import gradio: 0.5s, setup paths: 0.7s, initialize shared: 0.1s, other imports: 0.3s, list SD models: 72.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.3s).
6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: RuntimeError
Traceback (most recent call last):
  File ""/usr/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/usr/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
    _lazy_init()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx


Stable diffusion model failed to load
changing setting sd_model_checkpoint to v1-5-pruned-emaonly.safetensors: RuntimeError
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/options.py"", line 165, in set
    option.onchange()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 14, in f
    res = func(*args, **kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize_util.py"", line 181, in <lambda>
    shared.opts.onchange(""sd_model_checkpoint"", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 845, in load_model
    load_model_weights(sd_model, checkpoint_info, state_dict, timer)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 440, in load_model_weights
    model.load_state_dict(state_dict, strict=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for LatentDiffusion:
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_ids"", whose dimensions in the model are torch.Size([1, 77]) and whose dimensions in the checkpoint are torch.Size([1, 77]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.token_embedding.weight"", whose dimensions in the model are torch.Size([49408, 768]) and whose dimensions in the checkpoint are torch.Size([49408, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_embedding.weight"", whose dimensions in the model are torch.Size([77, 768]) and whose dimensions in the checkpoint are torch.Size([77, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).

Using already loaded model v1-5-pruned-emaonly.safetensors [6ce0161689]: done in 0.0s
*** Error completing request
*** Arguments: ('task(j9egb4adhyrywz0)', <gradio.routes.Request object at 0x792d6e8bcd00>, 'smal little girlyu dancing aaay', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
        _lazy_init()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
        torch._C._cuda_init()
    RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx

---
^CInterrupted with signal 2 in <frame at 0x5923c2036250, file '/usr/lib/python3.10/threading.py', line 324, code wait>


```",tried renaming fbroken link versions torch command os environ get torch command f pip install torch intel extension pytorch gitba f c extra index url torch index url torch command os environ get torch command f pip install torch intel extension pytorch extra index url torch index url requirements file os environ get reqs file requirements versions txt requirements file npu os environ get reqs file npu requirements npu txt still doeesnt work webui sh use ipex install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running picarica user python venv already activate run without venv home picarica git stable diffusion webui rc venv launching launch py using tcmalloc libtcmalloc minimal python main dec gcc version v commit hash c ae bd abdf eda b e installing open clip cloning assets home picarica git stable diffusion webui rc stable diffusion webui repositories stable diffusion webui assets cloning home picarica git stable diffusion webui rc stable diffusion webui repositories stable diffusion webui assets remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done cloning stable diffusion home picarica git stable diffusion webui rc stable diffusion webui repositories stable diffusion stability ai cloning home picarica git stable diffusion webui rc stable diffusion webui repositories stable diffusion stability ai remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done cloning stable diffusion xl home picarica git stable diffusion webui rc stable diffusion webui repositories generative models cloning home picarica git stable diffusion webui rc stable diffusion webui repositories generative models remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done cloning k diffusion home picarica git stable diffusion webui rc stable diffusion webui repositories k diffusion cloning home picarica git stable diffusion webui rc stable diffusion webui repositories k diffusion remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done resolving deltas done cloning blip home picarica git stable diffusion webui rc stable diffusion webui repositories blip cloning home picarica git stable diffusion webui rc stable diffusion webui repositories blip remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done installing requirements launching web ui arguments use ipex home picarica git stable diffusion webui rc venv lib python site packages timm models layers init py futurewarning importing timm models layers deprecated please import via timm layers warnings warn f importing name deprecated please import via timm layers futurewarning module xformers processing without module xformers processing without module xformers proceeding without warning caught exception found nvidia driver system please check nvidia gpu installed driver memory monitor disabled downloading home picarica git stable diffusion webui rc stable diffusion webui models stable diffusion v pruned emaonly safetensors g g mb calculating sha home picarica git stable diffusion webui rc stable diffusion webui models stable diffusion v pruned emaonly safetensors running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports list sd models load scripts create ui gradio launch ce b acaa ec eafe f ced bee f fa fa loading weights ce home picarica git stable diffusion webui rc stable diffusion webui models stable diffusion v pruned emaonly safetensors creating model config home picarica git stable diffusion webui rc stable diffusion webui configs v inference yaml home picarica git stable diffusion webui rc venv lib python site packages huggingface hub file download py futurewarning resume download deprecated removed version downloads always resume possible want force new download use force download true warnings warn loading weights ce home picarica git stable diffusion webui rc stable diffusion webui models stable diffusion v pruned emaonly safetensors creating model config home picarica git stable diffusion webui rc stable diffusion webui configs v inference yaml applying attention optimization invokeai done loading stable diffusion model runtimeerror traceback recent call last file usr lib python threading py line bootstrap self bootstrap inner file usr lib python threading py line bootstrap inner self run file usr lib python threading py line run self target self args self kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules initialize py line load model shared sd model noqa b file home picarica git stable diffusion webui rc stable diffusion webui modules shared items py line sd model return modules sd models model data get sd model file home picarica git stable diffusion webui rc stable diffusion webui modules sd models py line get sd model load model file home picarica git stable diffusion webui rc stable diffusion webui modules sd models py line load model devices autocast torch grad file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line autocast xpu mps cuda autocast file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line cuda autocast device id get cuda device id file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line get cuda device id torch cuda current device file home picarica git stable diffusion webui rc venv lib python site packages torch cuda init py line current device lazy init file home picarica git stable diffusion webui rc venv lib python site packages torch cuda init py line lazy init torch c cuda init runtimeerror found nvidia driver system please check nvidia gpu installed driver stable diffusion model failed load changing setting sd model checkpoint v pruned emaonly safetensors runtimeerror traceback recent call last file home picarica git stable diffusion webui rc stable diffusion webui modules options py line set option onchange file home picarica git stable diffusion webui rc stable diffusion webui modules call queue py line f res func args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules initialize util py line lambda shared opts onchange sd model checkpoint wrap queued call lambda sd models reload model weights call false file home picarica git stable diffusion webui rc stable diffusion webui modules sd models py line reload model weights load model checkpoint info already loaded state dict state dict file home picarica git stable diffusion webui rc stable diffusion webui modules sd models py line load model load model weights sd model checkpoint info state dict timer file home picarica git stable diffusion webui rc stable diffusion webui modules sd models py line load model weights model load state dict state dict strict false file home picarica git stable diffusion webui rc stable diffusion webui modules sd disable initialization py line lambda module load state dict self replace torch nn module load state dict lambda args kwargs load state dict module load state dict args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules sd disable initialization py line load state dict original module state dict strict strict file home picarica git stable diffusion webui rc stable diffusion webui modules sd disable initialization py line lambda module load state dict self replace torch nn module load state dict lambda args kwargs load state dict module load state dict args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules sd disable initialization py line load state dict original module state dict strict strict file home picarica git stable diffusion webui rc venv lib python site packages torch nn modules module py line load state dict raise runtimeerror runtimeerror error loading state dict latentdiffusion copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model input blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model middle block layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks layers bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model output blocks transformer blocks norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named model diffusion model bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid attn norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid attn norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model encoder norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid attn norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid attn norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder mid block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder block norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named first stage model decoder norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model embeddings position ids whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model embeddings token embedding weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model embeddings position embedding weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model encoder layers layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model final layer norm weight whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data copying parameter named cond stage model transformer text model final layer norm bias whose dimensions model torch size whose dimensions checkpoint torch size exception occurred cannot copy meta tensor data using already loaded model v pruned emaonly safetensors ce done error completing request arguments task j egb adhyrywz gradio routes request object x e bcd smal little girlyu dancing aaay false latent use checkpoint use sampler use scheduler dpm automatic false false false false positive comma false false start true false false false false false false false traceback recent call last file home picarica git stable diffusion webui rc stable diffusion webui modules call queue py line f res list func args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules call queue py line f res func args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules call queue py line f res func args kwargs file home picarica git stable diffusion webui rc stable diffusion webui modules txt img py line txt img processed processing process images p file home picarica git stable diffusion webui rc stable diffusion webui modules processing py line process images res process images inner p file home picarica git stable diffusion webui rc stable diffusion webui modules processing py line process images inner devices autocast file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line autocast xpu mps cuda autocast file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line cuda autocast device id get cuda device id file home picarica git stable diffusion webui rc stable diffusion webui modules devices py line get cuda device id torch cuda current device file home picarica git stable diffusion webui rc venv lib python site packages torch cuda init py line current device lazy init file home picarica git stable diffusion webui rc venv lib python site packages torch cuda init py line lazy init torch c cuda init runtimeerror found nvidia driver system please check nvidia gpu installed driver cinterrupted signal frame x c file usr lib python threading py line code wait
auto1111_webui,comment,16890,,this issue still presists,2025-03-28T10:59:46Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-2761008956,this issue still presists,issue still presists
auto1111_webui,comment,16890,,"https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821

Don't know if this helps. I got it to Work but SD is still using CPU onstead of GPU 

Edit: I've got it working. Please also consider #17047 ",2025-06-28T03:06:43Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3014876020,"https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821

Don't know if this helps. I got it to Work but SD is still using CPU onstead of GPU 

Edit: I've got it working. Please also consider #17047",know helps got work sd still using cpu onstead gpu edit got working please also consider
auto1111_webui,comment,16890,,"In my opinion, SD.Next is a better experience right now if you're using Intel Arc GPUs. I followed the guide here: https://vladmandic.github.io/sdnext-docs/Intel-ARC/

Once I had the driver and Python environment set up, I was generating 512x512 images in about 1 second. Very stable, and no Torch version headaches.",2025-07-10T06:25:59Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3055792878,"In my opinion, SD.Next is a better experience right now if you're using Intel Arc GPUs. I followed the guide here: https://vladmandic.github.io/sdnext-docs/Intel-ARC/

Once I had the driver and Python environment set up, I was generating 512x512 images in about 1 second. Very stable, and no Torch version headaches.",opinion sd next better experience right using intel arc gpus followed guide driver python environment set generating x images second stable torch version headaches
auto1111_webui,comment,16890,,"I tried SD.Next and would agree, BUT SD.Next has a huge downside (for me): it does not support chunking of tokens so you're limited to 75 Tokens. If you don't need more then SD.Next is surely a very good alternative.",2025-07-10T14:27:03Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3057685464,"I tried SD.Next and would agree, BUT SD.Next has a huge downside (for me): it does not support chunking of tokens so you're limited to 75 Tokens. If you don't need more then SD.Next is surely a very good alternative.",tried sd next would agree sd next huge downside support chunking tokens limited tokens need sd next surely good alternative
auto1111_webui,issue,16883,[Bug]: SD 2.1 not working: NansException: A tensor with NaNs was produced in Unet.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SD 1.5 is working fine, but 2.1 always gives this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.

I tried using the ""Upcast cross attention layer to float32"", it just produces random colors junk images.
I tried using the --no-half commandline argument, it gives a different error: ""RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same""
Using the --disable-nan-check just produces completely black images.

I had this issue both on my previous GPU (1080 ti) and my current GPU (5070 ti) on the latest 1111 version. The issue is somewhat fixed by using the commandline argument --opt-sdp-attention but it randomly starts producing junk images again after a while.

### Steps to reproduce the problem

Launch 1111, load SD 2.1 model and try to generate any image at all.

### What should have happened?

No error and the image generating correctly and no requiring workarounds that still don't quite work well.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

```
{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nnothing to commit, working tree clean"",
    ""Script path"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui"",
    ""Data path"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui"",
    ""Extensions dir"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""c3cc7fd239dd28b2e8e8bb58895e72cc061397318d61485fb53c42005a5a2b0b"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 10 Pro (10.0.19045 64 bits)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""572.70"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5070 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0.dev20250306+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.6.2"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0.dev20250307+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: AMD Ryzen 7 3800X 8-Core Processor             "",
            ""Manufacturer: AuthenticAMD"",
            ""Family: 107"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 3901"",
            ""MaxClockSpeed: 3901"",
            ""L2CacheSize: 4096"",
            ""L2CacheSpeed: None"",
            ""Revision: 28928""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the \""Upcast cross attention layer to float32\"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 847, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 998, process_images_inner"",
                    ""devices.test_for_nans(samples_ddim, \""unet\"")""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD"",
        ""count logical"": 16,
        ""count physical"": 8
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""14GB"",
        ""free"": ""50GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v2-1_768-nonema-pruned.safetensors [ff144a4984]"",
        ""sd_checkpoint_hash"": ""ff144a49841cf383adbc68841272ce639e1032b0a1f0f6586347feb953c244f4"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 1,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 13.905688762664795,
        ""records"": {
            ""initial startup"": 0.02599954605102539,
            ""prepare environment/checks"": 0.011003732681274414,
            ""prepare environment/git version info"": 0.04699993133544922,
            ""prepare environment/torch GPU test"": 2.5370242595672607,
            ""prepare environment/clone repositores"": 0.14800119400024414,
            ""prepare environment/run extensions installers"": 0.0,
            ""prepare environment"": 2.791030168533325,
            ""launcher"": 0.0029985904693603516,
            ""import torch"": 6.068175315856934,
            ""import gradio"": 1.115126132965088,
            ""setup paths"": 1.5516905784606934,
            ""import ldm"": 0.00800013542175293,
            ""import sgm"": 0.0,
            ""initialize shared"": 0.24499988555908203,
            ""other imports"": 0.3900015354156494,
            ""opts onchange"": 0.0,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0019998550415039062,
            ""setup gfpgan"": 0.019559144973754883,
            ""set samplers"": 0.0,
            ""list extensions"": 0.002000093460083008,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.02800130844116211,
            ""list localizations"": 0.0009987354278564453,
            ""load scripts/custom_code.py"": 0.006000041961669922,
            ""load scripts/img2imgalt.py"": 0.0,
            ""load scripts/loopback.py"": 0.0009999275207519531,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010004043579101562,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0,
            ""load scripts/prompts_from_file.py"": 0.0009996891021728516,
            ""load scripts/sd_upscale.py"": 0.0,
            ""load scripts/xyz_grid.py"": 0.002000093460083008,
            ""load scripts/ldsr_model.py"": 0.2525498867034912,
            ""load scripts/lora_script.py"": 0.15400195121765137,
            ""load scripts/scunet_model.py"": 0.026000261306762695,
            ""load scripts/swinir_model.py"": 0.02499985694885254,
            ""load scripts/hotkey_config.py"": 0.0010001659393310547,
            ""load scripts/extra_options_section.py"": 0.00099945068359375,
            ""load scripts/hypertile_script.py"": 0.04699850082397461,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0,
            ""load scripts/postprocessing_caption.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.003002166748046875,
            ""load scripts/postprocessing_split_oversized.py"": 0.0,
            ""load scripts/soft_inpainting.py"": 0.0010004043579101562,
            ""load scripts/comments.py"": 0.02399754524230957,
            ""load scripts/refiner.py"": 0.0010001659393310547,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0010013580322265625,
            ""load scripts"": 0.5495524406433105,
            ""load upscalers"": 0.004997968673706055,
            ""refresh VAE"": 0.0009999275207519531,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0019996166229248047,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0010006427764892578,
            ""initialize extra networks"": 0.015000581741333008,
            ""scripts before_ui_callback"": 0.002999544143676758,
            ""create ui"": 0.5135579109191895,
            ""gradio launch"": 0.6030018329620361,
            ""add APIs"": 0.00899815559387207,
            ""app_started_callback/lora_script.py"": 0.0010001659393310547,
            ""app_started_callback"": 0.0010001659393310547
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.15"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.5.0"",
        ""aiohttp==3.11.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.1.0"",
        ""blendmodes==2022"",
        ""certifi==2025.1.31"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""contourpy==1.3.1"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.17.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.56.0"",
        ""frozenlist==1.5.0"",
        ""fsspec==2025.2.0"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.29.2"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2024.10.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.0"",
        ""llvmlite==0.44.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.1.0"",
        ""narwhals==1.29.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.0"",
        ""numpy==1.26.2"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.15"",
        ""packaging==24.2"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.0.1"",
        ""propcache==0.3.0"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.21"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.1"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.23.1"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.2.18"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0.dev20250306+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.6.2"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0.dev20250307+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.1"",
        ""urllib3==2.3.0"",
        ""uvicorn==0.34.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""wheel==0.45.1"",
        ""yarl==1.18.3""
    ]
}
```

### Console logs

```Shell
*** Arguments: ('task(p553ty28wmhx6g8)', <gradio.routes.Request object at 0x0000021D9031B7C0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.


Stable diffusion model failed to load
*** Error completing request
*** Arguments: ('task(hua4dyxcv2tgm0o)', <gradio.routes.Request object at 0x00000204D07008B0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 830, in process_images
        sd_models.reload_model_weights()
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models.py"", line 969, in reload_model_weights
        checkpoint_config = sd_models_config.find_checkpoint_config(state_dict, checkpoint_info)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 125, in find_checkpoint_config
        return guess_model_config_from_state_dict(state_dict, info.filename)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 98, in guess_model_config_from_state_dict
        elif is_using_v_parameterization_for_sd2(sd):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 67, in is_using_v_parameterization_for_sd2
        out = (unet(x_test, torch.asarray([999], device=device), context=test_cond) - x_test).mean().cpu().item()
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 797, in forward
        h = module(h, emb, context)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 86, in forward
        x = layer(x)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same
```

### Additional information

As already mentioned, I already had this bug on my 1080 ti and now have it again on 5070 ti. I made a fresh install, but it's still no use.",2025-03-08T06:25:05Z,fireYtail,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16883,"[Bug]: SD 2.1 not working: NansException: A tensor with NaNs was produced in Unet. ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SD 1.5 is working fine, but 2.1 always gives this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.

I tried using the ""Upcast cross attention layer to float32"", it just produces random colors junk images.
I tried using the --no-half commandline argument, it gives a different error: ""RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same""
Using the --disable-nan-check just produces completely black images.

I had this issue both on my previous GPU (1080 ti) and my current GPU (5070 ti) on the latest 1111 version. The issue is somewhat fixed by using the commandline argument --opt-sdp-attention but it randomly starts producing junk images again after a while.

### Steps to reproduce the problem

Launch 1111, load SD 2.1 model and try to generate any image at all.

### What should have happened?

No error and the image generating correctly and no requiring workarounds that still don't quite work well.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

```
{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nnothing to commit, working tree clean"",
    ""Script path"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui"",
    ""Data path"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui"",
    ""Extensions dir"": ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""c3cc7fd239dd28b2e8e8bb58895e72cc061397318d61485fb53c42005a5a2b0b"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 10 Pro (10.0.19045 64 bits)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""572.70"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5070 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0.dev20250306+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.6.2"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0.dev20250307+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: AMD Ryzen 7 3800X 8-Core Processor             "",
            ""Manufacturer: AuthenticAMD"",
            ""Family: 107"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 3901"",
            ""MaxClockSpeed: 3901"",
            ""L2CacheSize: 4096"",
            ""L2CacheSpeed: None"",
            ""Revision: 28928""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the \""Upcast cross attention layer to float32\"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 847, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 998, process_images_inner"",
                    ""devices.test_for_nans(samples_ddim, \""unet\"")""
                ],
                [
                    ""A:\\Sin Sincronización\\Chrome\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD"",
        ""count logical"": 16,
        ""count physical"": 8
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""14GB"",
        ""free"": ""50GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v2-1_768-nonema-pruned.safetensors [ff144a4984]"",
        ""sd_checkpoint_hash"": ""ff144a49841cf383adbc68841272ce639e1032b0a1f0f6586347feb953c244f4"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 1,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 13.905688762664795,
        ""records"": {
            ""initial startup"": 0.02599954605102539,
            ""prepare environment/checks"": 0.011003732681274414,
            ""prepare environment/git version info"": 0.04699993133544922,
            ""prepare environment/torch GPU test"": 2.5370242595672607,
            ""prepare environment/clone repositores"": 0.14800119400024414,
            ""prepare environment/run extensions installers"": 0.0,
            ""prepare environment"": 2.791030168533325,
            ""launcher"": 0.0029985904693603516,
            ""import torch"": 6.068175315856934,
            ""import gradio"": 1.115126132965088,
            ""setup paths"": 1.5516905784606934,
            ""import ldm"": 0.00800013542175293,
            ""import sgm"": 0.0,
            ""initialize shared"": 0.24499988555908203,
            ""other imports"": 0.3900015354156494,
            ""opts onchange"": 0.0,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0019998550415039062,
            ""setup gfpgan"": 0.019559144973754883,
            ""set samplers"": 0.0,
            ""list extensions"": 0.002000093460083008,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.02800130844116211,
            ""list localizations"": 0.0009987354278564453,
            ""load scripts/custom_code.py"": 0.006000041961669922,
            ""load scripts/img2imgalt.py"": 0.0,
            ""load scripts/loopback.py"": 0.0009999275207519531,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010004043579101562,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0,
            ""load scripts/prompts_from_file.py"": 0.0009996891021728516,
            ""load scripts/sd_upscale.py"": 0.0,
            ""load scripts/xyz_grid.py"": 0.002000093460083008,
            ""load scripts/ldsr_model.py"": 0.2525498867034912,
            ""load scripts/lora_script.py"": 0.15400195121765137,
            ""load scripts/scunet_model.py"": 0.026000261306762695,
            ""load scripts/swinir_model.py"": 0.02499985694885254,
            ""load scripts/hotkey_config.py"": 0.0010001659393310547,
            ""load scripts/extra_options_section.py"": 0.00099945068359375,
            ""load scripts/hypertile_script.py"": 0.04699850082397461,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0,
            ""load scripts/postprocessing_caption.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.003002166748046875,
            ""load scripts/postprocessing_split_oversized.py"": 0.0,
            ""load scripts/soft_inpainting.py"": 0.0010004043579101562,
            ""load scripts/comments.py"": 0.02399754524230957,
            ""load scripts/refiner.py"": 0.0010001659393310547,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0010013580322265625,
            ""load scripts"": 0.5495524406433105,
            ""load upscalers"": 0.004997968673706055,
            ""refresh VAE"": 0.0009999275207519531,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0019996166229248047,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0010006427764892578,
            ""initialize extra networks"": 0.015000581741333008,
            ""scripts before_ui_callback"": 0.002999544143676758,
            ""create ui"": 0.5135579109191895,
            ""gradio launch"": 0.6030018329620361,
            ""add APIs"": 0.00899815559387207,
            ""app_started_callback/lora_script.py"": 0.0010001659393310547,
            ""app_started_callback"": 0.0010001659393310547
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.15"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.5.0"",
        ""aiohttp==3.11.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.1.0"",
        ""blendmodes==2022"",
        ""certifi==2025.1.31"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""contourpy==1.3.1"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.17.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.56.0"",
        ""frozenlist==1.5.0"",
        ""fsspec==2025.2.0"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.29.2"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2024.10.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.0"",
        ""llvmlite==0.44.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.1.0"",
        ""narwhals==1.29.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.0"",
        ""numpy==1.26.2"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.15"",
        ""packaging==24.2"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.0.1"",
        ""propcache==0.3.0"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.21"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.1"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.23.1"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.2.18"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0.dev20250306+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.6.2"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0.dev20250307+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.1"",
        ""urllib3==2.3.0"",
        ""uvicorn==0.34.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""wheel==0.45.1"",
        ""yarl==1.18.3""
    ]
}
```

### Console logs

```Shell
*** Arguments: ('task(p553ty28wmhx6g8)', <gradio.routes.Request object at 0x0000021D9031B7C0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.


Stable diffusion model failed to load
*** Error completing request
*** Arguments: ('task(hua4dyxcv2tgm0o)', <gradio.routes.Request object at 0x00000204D07008B0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\processing.py"", line 830, in process_images
        sd_models.reload_model_weights()
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models.py"", line 969, in reload_model_weights
        checkpoint_config = sd_models_config.find_checkpoint_config(state_dict, checkpoint_info)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 125, in find_checkpoint_config
        return guess_model_config_from_state_dict(state_dict, info.filename)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 98, in guess_model_config_from_state_dict
        elif is_using_v_parameterization_for_sd2(sd):
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 67, in is_using_v_parameterization_for_sd2
        out = (unet(x_test, torch.asarray([999], device=device), context=test_cond) - x_test).mean().cpu().item()
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 797, in forward
        h = module(h, emb, context)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 86, in forward
        x = layer(x)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin Sincronización\Chrome\sd.webui\webui\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""A:\Sin Sincronización\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same
```

### Additional information

As already mentioned, I already had this bug on my 1080 ti and now have it again on 5070 ti. I made a fresh install, but it's still no use.",bug sd working nansexception tensor nans produced unet checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened sd working fine always gives error nansexception tensor nans produced unet could either enough precision represent picture video card support half type try setting upcast cross attention layer float option settings stable diffusion using half commandline argument fix use disable nan check commandline argument disable check tried using upcast cross attention layer float produces random colors junk images tried using half commandline argument gives different error runtimeerror input type float bias type struct c half using disable nan check produces completely black images issue previous gpu ti current gpu ti latest version issue somewhat fixed using commandline argument opt sdp attention randomly starts producing junk images steps reproduce problem launch load sd model try generate image happened error image generating correctly requiring workarounds still quite work well browsers use access ui mozilla firefox sysinfo platform windows sp python version v commit c ae bd abdf eda b e git status branch master nyour branch date origin master n nnothing commit working tree clean script path sin sincronizacion chrome sd webui webui data path sin sincronizacion chrome sd webui webui extensions dir sin sincronizacion chrome sd webui webui extensions checksum c cc fd dd b e e bb e cc fb c b b commandline launch py torch env info torch version debug build false cuda compiled version gcc version null clang version null cmake version null os microsoft windows pro bits libc version n python version tags v c b bd aug msc v bit amd bit runtime python platform windows sp cuda available true cuda runtime version null cuda module loading lazy nvidia driver version nvidia gpu models gpu nvidia geforce rtx ti cudnn version null pip version pip pip packages numpy open clip torch pytorch lightning torch dev cu torchdiffeq torchmetrics torchsde torchvision dev cu conda packages null hip compiled version n hip runtime version n miopen runtime version n caching allocator config xnnpack available true cpu info name amd ryzen x core processor manufacturer authenticamd family architecture processortype deviceid cpu currentclockspeed maxclockspeed l cachesize l cachespeed none revision exceptions exception tensor nans produced unet could either enough precision represent picture video card support half type try setting upcast cross attention layer float option settings stable diffusion using half commandline argument fix use disable nan check commandline argument disable check traceback sin sincronizacion chrome sd webui webui modules call queue py line f res list func args kwargs sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs sin sincronizacion chrome sd webui webui modules txt img py line txt img processed processing process images p sin sincronizacion chrome sd webui webui modules processing py line process images res process images inner p sin sincronizacion chrome sd webui webui modules processing py line process images inner devices test nans samples ddim unet sin sincronizacion chrome sd webui webui modules devices py line test nans raise nansexception message cpu model amd family model stepping authenticamd count logical count physical ram total gb used gb free gb extensions inactive extensions environment gradio analytics enabled false config ldsr steps ldsr cached false scunet tile scunet tile overlap swin tile swin tile overlap swin torch compile false hypertile enable unet false hypertile enable unet secondpass false hypertile max depth unet hypertile max tile unet hypertile swap size unet hypertile enable vae false hypertile max depth vae hypertile max tile vae hypertile swap size vae sd model checkpoint v nonema pruned safetensors ff sd checkpoint hash ff cf adbc ce e b f f feb c f outdir samples outdir txt img samples outputs txt img images outdir img img samples outputs img img images outdir extras samples outputs extras images outdir grids outdir txt img grids outputs txt img grids outdir img img grids outputs img img grids outdir save log images outdir init images outputs init images samples save true samples format png samples filename pattern save images add number true save images replace action replace grid save true grid format png grid extended filename false grid multiple true grid prevent empty spots false grid zip filename pattern n rows font grid text active color grid text inactive color grid background color ffffff save images face restoration false save images highres fix false save images color correction false save mask false save mask composite false jpeg quality webp lossless false export chan true img downscale threshold target side length img max size mp use original name batch true use upscaler name suffix false save selected true save write log csv true save init img false temp dir clean temp dir start false save incomplete images false notification audio true notification volume save dirs true grid save dirs true use save dirs ui false directories filename pattern date directories max prompt words auto backcompat true use old emphasis implementation false use old karras scheduler sigmas false dpmpp sde batch determinism false use old hires fix width height false hires fix use firstpass conds false use old scheduling false use downcasted alpha bar false refiner switch sample steps false lora functional false extra networks show hidden directories true extra networks dir button function false extra networks hidden models searched extra networks default multiplier extra networks card width extra networks card height extra networks card text scale extra networks card show desc true extra networks card description html false extra networks card order field path extra networks card order ascending extra networks tree view style dirs extra networks tree view default enabled true extra networks tree view default width extra networks add text separator ui extra networks tab reorder textual inversion print load false textual inversion add hashes infotext true sd hypernetwork none sd lora none lora preferred name alias file lora add hashes infotext true lora bundled ti infotext true lora show false lora hide unknown versions lora memory limit lora found warning console false lora found gradio warning false cross attention optimization automatic min uncond min uncond false token merging ratio token merging ratio img img token merging ratio hr pad cond uncond false pad cond uncond v false persistent cond cache true batch cond uncond true fp storage disable cache fp weight false hide samplers eta ddim eta ancestral ddim discretize uniform churn tmin tmax noise sigma min sigma max rho eta noise seed delta always discard next last sigma false sgm noise multiplier false uni pc variant bh uni pc skip type time uniform uni pc order uni pc lower order final true sd noise schedule default skip early cond beta dist alpha beta dist beta sd checkpoints limit sd checkpoints keep cpu true sd checkpoint cache sd unet automatic enable quantization false emphasis original enable batch seeds true comma padding backtrack sdxl clip l skip false clip stop last layers upcast attn false randn source gpu tiling false hires fix refiner pass second pass enable prompt comments true sd enable false sdxl crop top sdxl crop left sdxl refiner low aesthetic score sdxl refiner high aesthetic score sd vae checkpoint cache sd vae automatic sd vae overrides per model preferences true auto vae precision bfloat false auto vae precision true sd vae encode method full sd vae decode method full inpainting mask weight initial noise multiplier img img extra noise img img color correction false img img fix steps false img img background color ffffff img img editor height img img sketch default brush color ffffff img img inpaint mask brush color ffffff img img inpaint sketch default brush color ffffff return mask false return mask composite false img img batch show results limit overlay inpaint true return grid true show images false js modal lightbox true js modal lightbox initially zoomed true js modal lightbox gamepad false js modal lightbox gamepad repeat sd webui modal lightbox icon opacity sd webui modal lightbox toolbar opacity gallery height open dir button choice subdirectory enable pnginfo true save txt false add model name info true add model hash info true add vae name info true add vae hash info true add user name info false add version infotext true disable weights auto swap true infotext skip pasting infotext styles apply show progressbar true live previews enable true live previews image format png show progress grid true show progress every n steps show progress type approx nn live preview allow lowvram full false live preview content prompt live preview refresh period live preview fast interrupt false js live preview modal lightbox false prevent screen sleep generation true keyedit precision attention keyedit precision extra keyedit delimiters keyedit delimiters whitespace tab carriage return line feed keyedit move true disable token counters false include styles token counters true extra options txt img extra options img img extra options cols extra options accordion false compact prompt box false samplers dropdown true dimensions batch together true sd checkpoint dropdown use short false hires fix show sampler false hires fix show prompts false txt img settings accordion false img img settings accordion false interrupt current true localization none quicksettings list sd model checkpoint ui tab order hidden tabs ui reorder list gradio theme default gradio themes cache true show progress title true send seed true send size true enable reloading ui scripts false api enable requests true api forbid local requests true api useragent prioritized callbacks app started prioritized callbacks model loaded prioritized callbacks ui settings prioritized callbacks infotext pasted prioritized callbacks script unloaded prioritized callbacks ui prioritized callbacks list optimizers prioritized callbacks token counter prioritized callbacks script process prioritized callbacks script process prioritized callbacks script post sample prioritized callbacks script mask blend prioritized callbacks script postprocess maskoverlay profiling enable false profiling activities cpu profiling record shapes true profiling profile memory true profiling stack true profiling filename trace json auto launch browser local enable console prompts false show warnings false show gradio deprecation warnings true memmon poll rate samples log stdout false multiple tqdm true enable upscale progressbar true print hypernet extra false list hidden files true disable mmap load safetensors false hide ldm prints true dump stacks signal false face restoration false face restoration model codeformer code former weight face restoration unload false postprocessing enable main ui postprocessing disable extras postprocessing operation order upscaling max images cache postprocessing existing caption action ignore esrgan tile esrgan tile overlap realesrgan enabled models r esrgan x r esrgan x anime b dat enabled models dat x dat x dat x dat tile dat tile overlap set scale changing upscaler false unload models training false pin memory false save optimizer state false save training settings txt true dataset filename word regex dataset filename join string training image repeats per epoch training write csv every training xattention optimizations false training enable tensorboard false training tensorboard save images false training tensorboard flush every canvas hotkey zoom alt canvas hotkey adjust ctrl canvas hotkey shrink brush q canvas hotkey grow brush w canvas hotkey move f canvas hotkey fullscreen canvas hotkey reset r canvas hotkey overlap canvas show tooltip true canvas auto expand true canvas blur prompt false canvas disabled functions overlap interrogate keep models memory false interrogate return ranks false interrogate clip num beams interrogate clip min length interrogate clip max length interrogate clip dict limit interrogate clip skip categories interrogate deepbooru score threshold deepbooru sort alpha true deepbooru use spaces true deepbooru escape true deepbooru filter tags disabled extensions disable extensions none startup total records initial startup prepare environment checks prepare environment git version info prepare environment torch gpu test prepare environment clone repositores prepare environment run extensions installers prepare environment launcher import torch import gradio setup paths import ldm import sgm initialize shared imports opts onchange setup sd model setup codeformer setup gfpgan set samplers list extensions restore config state file list sd models list localizations load scripts custom code py load scripts img imgalt py load scripts loopback py load scripts outpainting mk py load scripts poor mans outpainting py load scripts postprocessing codeformer py load scripts postprocessing gfpgan py load scripts postprocessing upscale py load scripts prompt matrix py load scripts prompts file py load scripts sd upscale py load scripts xyz grid py load scripts ldsr model py load scripts lora script py load scripts scunet model py load scripts swinir model py load scripts hotkey config py load scripts extra options section py load scripts hypertile script py load scripts postprocessing autosized crop py load scripts postprocessing caption py load scripts postprocessing create flipped copies py load scripts postprocessing focal crop py load scripts postprocessing split oversized py load scripts soft inpainting py load scripts comments py load scripts refiner py load scripts sampler py load scripts seed py load scripts load upscalers refresh vae refresh textual inversion templates scripts list optimizers scripts list unets reload hypernetworks initialize extra networks scripts ui callback create ui gradio launch add apis app started callback lora script py app started callback packages accelerate aenum aiofiles aiohappyeyeballs aio aiosignal altair antlr python runtime anyio async timeout attrs blendmodes certifi charset normalizer clean fid click clip colorama contourpy cycler deprecation diskcache einops exceptiongroup facexlib fastapi ffmpy filelock filterpy fonttools frozenlist fsspec ftfy gitdb gitpython gradio gradio client h huggingface hub idna imageio importlib resources inflection jinja jsonmerge jsonschema jsonschema specifications kiwisolver kornia lark lazy loader lightning utilities llvmlite markupsafe matplotlib mpmath multidict narwhals networkx numba numpy omegaconf open clip torch opencv python orjson packaging pandas piexif pillow pillow avif plugin pip propcache protobuf psutil pydantic pydub pyparsing python dateutil post python multipart pytorch lightning pytz pywavelets pyyaml referencing regex requests resize right rpds py safetensors scikit image scipy semantic version sentencepiece setuptools six smmap sniffio spandrel spandrel extra arches starlette sympy tifffile timm tokenizers tomesd torch dev cu torchdiffeq torchmetrics torchsde torchvision dev cu tqdm trampoline transformers typing extensions tzdata urllib uvicorn wcwidth websockets wheel yarl console logs shell arguments task p ty wmhx g gradio routes request object x b c false latent use checkpoint use sampler use scheduler dpm automatic false false false false positive comma false false start true false false false false false false false traceback recent call last file sin sincronizacion chrome sd webui webui modules call queue py line f res list func args kwargs file sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs file sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs file sin sincronizacion chrome sd webui webui modules txt img py line txt img processed processing process images p file sin sincronizacion chrome sd webui webui modules processing py line process images res process images inner p file sin sincronizacion chrome sd webui webui modules processing py line process images inner devices test nans samples ddim unet file sin sincronizacion chrome sd webui webui modules devices py line test nans raise nansexception message modules devices nansexception tensor nans produced unet could either enough precision represent picture video card support half type try setting upcast cross attention layer float option settings stable diffusion using half commandline argument fix use disable nan check commandline argument disable check stable diffusion model failed load error completing request arguments task hua dyxcv tgm gradio routes request object x b false latent use checkpoint use sampler use scheduler dpm automatic false false false false positive comma false false start true false false false false false false false traceback recent call last file sin sincronizacion chrome sd webui webui modules call queue py line f res list func args kwargs file sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs file sin sincronizacion chrome sd webui webui modules call queue py line f res func args kwargs file sin sincronizacion chrome sd webui webui modules txt img py line txt img processed processing process images p file sin sincronizacion chrome sd webui webui modules processing py line process images sd models reload model weights file sin sincronizacion chrome sd webui webui modules sd models py line reload model weights checkpoint config sd models config find checkpoint config state dict checkpoint info file sin sincronizacion chrome sd webui webui modules sd models config py line find checkpoint config return guess model config state dict state dict info filename file sin sincronizacion chrome sd webui webui modules sd models config py line guess model config state dict elif using v parameterization sd sd file sin sincronizacion chrome sd webui webui modules sd models config py line using v parameterization sd unet x test torch asarray device device context test cond x test mean cpu item file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line call impl return forward call args kwargs file sin sincronizacion chrome sd webui webui modules sd unet py line unetmodel forward return original forward self x timesteps context args kwargs file sin sincronizacion chrome sd webui webui repositories stable diffusion stability ai ldm modules diffusionmodules openaimodel py line forward h module h emb context file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line call impl return forward call args kwargs file sin sincronizacion chrome sd webui webui repositories stable diffusion stability ai ldm modules diffusionmodules openaimodel py line forward x layer x file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line wrapped call impl return self call impl args kwargs file sin sincronizacion chrome sd webui system python lib site packages torch nn modules module py line call impl return forward call args kwargs file sin sincronizacion chrome sd webui webui extensions builtin lora networks py line network conv forward return originals conv forward self input file sin sincronizacion chrome sd webui system python lib site packages torch nn modules conv py line forward return self conv forward input self weight self bias file sin sincronizacion chrome sd webui system python lib site packages torch nn modules conv py line conv forward return f conv runtimeerror input type float bias type struct c half additional information already mentioned already bug ti ti made fresh install still use
auto1111_webui,comment,16883,,"This bug has apparently existed for months, SD 2.1 is really old now, is it ever gonna be fixed?",2025-03-11T15:38:09Z,fireYtail,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16883#issuecomment-2714802080,"This bug has apparently existed for months, SD 2.1 is really old now, is it ever gonna be fixed?",bug apparently existed months sd really old ever gonna fixed
auto1111_webui,issue,16882,"[Bug]: Stable Diffusion WebUI Startup Error: Insufficient Memory, Unable to Install Torch","### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I try to open webui-user.bat in stable-diffusion-webui, I repeatedly encounter the error ""Error code: 1,"" indicating that there is insufficient memory. However, I have 25.6GB/32GB of RAM and 11.4GB/12GB of VRAM, which should be sufficient. I have also tried installing PyTorch and pip, and both were installed correctly, but the problem persists. I also tried running webui-user.bat as an administrator, but this causes it to fail to start, briefly flashing and closing without doing anything.               



### Steps to reproduce the problem

Go to the [Stable Diffusion WebUI] folder (e.g., C:\Users\jerem\stable-diffusion-webui).
Locate and run the webui-user.bat file.
Observe the error message stating ""Insufficient memory"" and that torch cannot be installed, even though there is enough system RAM and GPU memory.
Try running webui-user.bat as an administrator, but the window flashes and disappears without launching properly.
Check the startup logs and find the error message: ""Could not install packages due to an OSError: ('Connection broken: OSError(12, 'Insufficient memory, cannot process this command')"".

### What should have happened?

Under normal circumstances, when I run the webui-user.bat file, Stable Diffusion WebUI should start successfully, and the necessary packages (such as PyTorch and torchvision) should be installed or initialized without any errors. There should be no ""insufficient memory"" error even though the system has sufficient RAM and GPU memory. The startup process should complete smoothly, and I should be able to access the WebUI interface and begin using Stable Diffusion.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't open the web UI, and when I try using --dump-sysinfo, it also throws an error. 

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Requirement already satisfied: torch==2.1.2 in c:\users\jerem\stable-diffusion-webui\venv\lib\site-packages (2.1.2+cu121)
ERROR: Could not install packages due to an OSError: (""Connection broken: OSError(12, '記憶體資源不足，無法處理此命令。', None, 8, None)"", OSError(12, '記憶體資源不足，無法處理此命令。', None, 8, None))

WARNING: There was an error checking the latest version of pip.
Traceback (most recent call last):
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\jerem\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",2025-03-08T04:19:41Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882,"[Bug]: Stable Diffusion WebUI Startup Error: Insufficient Memory, Unable to Install Torch ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I try to open webui-user.bat in stable-diffusion-webui, I repeatedly encounter the error ""Error code: 1,"" indicating that there is insufficient memory. However, I have 25.6GB/32GB of RAM and 11.4GB/12GB of VRAM, which should be sufficient. I have also tried installing PyTorch and pip, and both were installed correctly, but the problem persists. I also tried running webui-user.bat as an administrator, but this causes it to fail to start, briefly flashing and closing without doing anything.               



### Steps to reproduce the problem

Go to the [Stable Diffusion WebUI] folder (e.g., C:\Users\jerem\stable-diffusion-webui).
Locate and run the webui-user.bat file.
Observe the error message stating ""Insufficient memory"" and that torch cannot be installed, even though there is enough system RAM and GPU memory.
Try running webui-user.bat as an administrator, but the window flashes and disappears without launching properly.
Check the startup logs and find the error message: ""Could not install packages due to an OSError: ('Connection broken: OSError(12, 'Insufficient memory, cannot process this command')"".

### What should have happened?

Under normal circumstances, when I run the webui-user.bat file, Stable Diffusion WebUI should start successfully, and the necessary packages (such as PyTorch and torchvision) should be installed or initialized without any errors. There should be no ""insufficient memory"" error even though the system has sufficient RAM and GPU memory. The startup process should complete smoothly, and I should be able to access the WebUI interface and begin using Stable Diffusion.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't open the web UI, and when I try using --dump-sysinfo, it also throws an error. 

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Requirement already satisfied: torch==2.1.2 in c:\users\jerem\stable-diffusion-webui\venv\lib\site-packages (2.1.2+cu121)
ERROR: Could not install packages due to an OSError: (""Connection broken: OSError(12, '記憶體資源不足，無法處理此命令。', None, 8, None)"", OSError(12, '記憶體資源不足，無法處理此命令。', None, 8, None))

WARNING: There was an error checking the latest version of pip.
Traceback (most recent call last):
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\jerem\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",bug stable diffusion webui startup error insufficient memory unable install torch checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened try open webui user bat stable diffusion webui repeatedly encounter error error code indicating insufficient memory however gb gb ram gb gb vram sufficient also tried installing pytorch pip installed correctly problem persists also tried running webui user bat administrator causes fail start briefly flashing closing without anything steps reproduce problem go stable diffusion webui folder e g c users jerem stable diffusion webui locate run webui user bat file observe error message stating insufficient memory torch cannot installed even though enough system ram gpu memory try running webui user bat administrator window flashes disappears without launching properly check startup logs find error message could install packages due oserror connection broken oserror insufficient memory cannot process command happened normal circumstances run webui user bat file stable diffusion webui start successfully necessary packages pytorch torchvision installed initialized without errors insufficient memory error even though system sufficient ram gpu memory startup process complete smoothly able access webui interface begin using stable diffusion browsers use access ui google chrome sysinfo open web ui try using dump sysinfo also throws error console logs shell python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes requirement already satisfied torch c users jerem stable diffusion webui venv lib site packages cu error could install packages due oserror connection broken oserror none none oserror none none warning error checking latest version pip traceback recent call last file c users jerem stable diffusion webui launch py line module main file c users jerem stable diffusion webui launch py line main prepare environment file c users jerem stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file c users jerem stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command c users jerem stable diffusion webui venv scripts python exe pip install torch torchvision extra index url error code additional information response
auto1111_webui,comment,16882,,"python: 3.10.6

OS: WIN11 23H2

CPU:  i5 14500

GPU:  RTX 4070

RAM:  32G

SSD:  1T+2T



",2025-03-08T14:49:15Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2708336360,"python: 3.10.6

OS: WIN11 23H2

CPU:  i5 14500

GPU:  RTX 4070

RAM:  32G

SSD:  1T+2T",python os win h cpu gpu rtx ram g ssd
auto1111_webui,comment,16882,,"same issue, fixed?",2025-03-14T16:36:04Z,Sensanko52123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2725201568,"same issue, fixed?",issue fixed
auto1111_webui,issue,16881,[Bug]: Failed to install requirements,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing sd.webui, running update.bat and run.bat, run.bat tells me that it can't install the requirements

### Steps to reproduce the problem

1. Download sd.webui.zip
2. Extract it into the clean folder
3. Run update.bat
4. Run run.bat

### What should have happened?

Should have installed the requirements, i guess...

### What browsers do you use to access the UI ?

Other

### Sysinfo

uh... I can't do that until it downloads the requirements

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""G:\Stable_Diffusion\sd.webui\system\python\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)

stderr: ERROR: Could not install packages due to an OSError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))
```

### Additional information

_No response_",2025-03-06T05:55:42Z,Kylada,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881,"[Bug]: Failed to install requirements ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing sd.webui, running update.bat and run.bat, run.bat tells me that it can't install the requirements

### Steps to reproduce the problem

1. Download sd.webui.zip
2. Extract it into the clean folder
3. Run update.bat
4. Run run.bat

### What should have happened?

Should have installed the requirements, i guess...

### What browsers do you use to access the UI ?

Other

### Sysinfo

uh... I can't do that until it downloads the requirements

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""G:\Stable_Diffusion\sd.webui\system\python\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)

stderr: ERROR: Could not install packages due to an OSError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))
```

### Additional information

_No response_",bug failed install requirements checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened installing sd webui running update bat run bat run bat tells install requirements steps reproduce problem download sd webui zip extract clean folder run update bat run run bat happened installed requirements guess browsers use access ui sysinfo uh downloads requirements console logs shell python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing requirements traceback recent call last file g stable diffusion sd webui webui launch py line module main file g stable diffusion sd webui webui launch py line main prepare environment file g stable diffusion sd webui webui modules launch utils py line prepare environment run pip f install r requirements file requirements file g stable diffusion sd webui webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file g stable diffusion sd webui webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command g stable diffusion sd webui system python python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge tar gz kb preparing metadata setup py started preparing metadata setup py finished status done collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf g stable diffusion sd webui system python lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch g stable diffusion sd webui system python lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb stderr error could install packages due oserror received response content encoding gzip failed decode error error decompressing data incorrect header check additional information response
auto1111_webui,comment,16881,,"OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?",2025-03-07T17:50:35Z,gaggid,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881#issuecomment-2707056447,"OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?",operationalerror column size string literal single quotes
auto1111_webui,comment,16881,,"Try `pip cache purge` from the venv?

python packages are distributed via gzip-compressed tarballs. It looks like one of the cached packages contained a malformed tarball. At least that's my theory.",2025-04-02T16:33:56Z,richardsonnick,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881#issuecomment-2773134592,"Try `pip cache purge` from the venv?

python packages are distributed via gzip-compressed tarballs. It looks like one of the cached packages contained a malformed tarball. At least that's my theory.",try pip cache purge venv python packages distributed via gzip compressed tarballs looks like one cached packages contained malformed tarball least theory
auto1111_webui,issue,16879,[Bug]: Error code:1 Could't install torch,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Unable to launch webui

### Steps to reproduce the problem

1. Open webui-user.bat
2. Check console

### What should have happened?

Launch the WebUI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Worked on same PC before just did new clean windows install

### Console logs

```Shell
git: 'PULL' is not a git command. See 'git --help'.
'""E:\A1111\stable-diffusion-webui\venv\Scripts\activate.bat""' is not recognized as an internal or external command,
operable program or batch file.
venv ""E:\A1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Traceback (most recent call last):
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\__main__.py"", line 29, in <module>
    from pip._internal.cli.main import main as _main
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main.py"", line 9, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\autocompletion.py"", line 10, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main_parser.py"", line 8, in <module>
    from pip._internal.cli import cmdoptions
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\cmdoptions.py"", line 24, in <module>
    from pip._internal.cli.parser import ConfigOptionParser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\parser.py"", line 12, in <module>
    from pip._internal.configuration import Configuration, ConfigurationError
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\configuration.py"", line 20, in <module>
    from pip._internal.exceptions import (
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\exceptions.py"", line 13, in <module>
    from pip._vendor.requests.models import Request, Response
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\requests\__init__.py"", line 43, in <module>
    from pip._vendor import urllib3
ImportError: cannot import name 'urllib3' from 'pip._vendor' (E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\__init__.py)
Traceback (most recent call last):
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""E:\A1111\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
Press any key to continue . . .
```

### Additional information

_No response_",2025-03-05T02:33:29Z,kazumaduy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16879,"[Bug]: Error code:1 Could't install torch ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Unable to launch webui

### Steps to reproduce the problem

1. Open webui-user.bat
2. Check console

### What should have happened?

Launch the WebUI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Worked on same PC before just did new clean windows install

### Console logs

```Shell
git: 'PULL' is not a git command. See 'git --help'.
'""E:\A1111\stable-diffusion-webui\venv\Scripts\activate.bat""' is not recognized as an internal or external command,
operable program or batch file.
venv ""E:\A1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Traceback (most recent call last):
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\__main__.py"", line 29, in <module>
    from pip._internal.cli.main import main as _main
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main.py"", line 9, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\autocompletion.py"", line 10, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main_parser.py"", line 8, in <module>
    from pip._internal.cli import cmdoptions
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\cmdoptions.py"", line 24, in <module>
    from pip._internal.cli.parser import ConfigOptionParser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\parser.py"", line 12, in <module>
    from pip._internal.configuration import Configuration, ConfigurationError
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\configuration.py"", line 20, in <module>
    from pip._internal.exceptions import (
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\exceptions.py"", line 13, in <module>
    from pip._vendor.requests.models import Request, Response
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\requests\__init__.py"", line 43, in <module>
    from pip._vendor import urllib3
ImportError: cannot import name 'urllib3' from 'pip._vendor' (E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\__init__.py)
Traceback (most recent call last):
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""E:\A1111\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
Press any key to continue . . .
```

### Additional information

_No response_",bug error code could install torch checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently x issue reported fixed yet happened unable launch webui steps reproduce problem open webui user bat check console happened launch webui browsers use access ui response sysinfo worked pc new clean windows install console logs shell git pull git command see git help e stable diffusion webui venv scripts activate bat recognized internal external command operable program batch file venv e stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision traceback recent call last file c users notduy appdata local programs python python lib runpy py line run module main return run code code main globals none file c users notduy appdata local programs python python lib runpy py line run code exec code run globals file e stable diffusion webui venv lib site packages pip main py line module pip internal cli main import main main file e stable diffusion webui venv lib site packages pip internal cli main py line module pip internal cli autocompletion import autocomplete file e stable diffusion webui venv lib site packages pip internal cli autocompletion py line module pip internal cli main parser import create main parser file e stable diffusion webui venv lib site packages pip internal cli main parser py line module pip internal cli import cmdoptions file e stable diffusion webui venv lib site packages pip internal cli cmdoptions py line module pip internal cli parser import configoptionparser file e stable diffusion webui venv lib site packages pip internal cli parser py line module pip internal configuration import configuration configurationerror file e stable diffusion webui venv lib site packages pip internal configuration py line module pip internal exceptions import file e stable diffusion webui venv lib site packages pip internal exceptions py line module pip vendor requests models import request response file e stable diffusion webui venv lib site packages pip vendor requests init py line module pip vendor import urllib importerror cannot import name urllib pip vendor e stable diffusion webui venv lib site packages pip vendor init py traceback recent call last file e stable diffusion webui launch py line module main file e stable diffusion webui launch py line main prepare environment file e stable diffusion webui modules launch utils py line prepare environment run f python torch command installing torch torchvision install torch live true file e stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install torch command e stable diffusion webui venv scripts python exe pip install torch torchvision extra index url error code press key continue additional information response
auto1111_webui,comment,16879,,"Seems to work if I put the A1111 folder in my C: drive, but would like it to work in my bigger drive",2025-03-05T02:38:46Z,kazumaduy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16879#issuecomment-2699608279,"Seems to work if I put the A1111 folder in my C: drive, but would like it to work in my bigger drive",seems work put folder c drive would like work bigger drive
auto1111_webui,issue,16876,[Bug]: function parse_generation_parameter removes lastline if multiple loras are embedded in final text,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

File: modules/infotext_utils.py 
Line(s): 255 -> if len(re_param.findall(lastline)) < 3:

The function parse_generation_parameters from modules/infotext_utils.py has a built in functionality to ignore the last line of a text passed in if len(re_param.findall(lastline)) < 3, when this criteria is met the last line will not be added to the lines variable list.

### Steps to reproduce the problem

Under the scenario a standalone prompt text such as this below is passed in, the last line will be ignored:

promptDescription1, promptDescription2,
<lora: loraname1 v1:1>, <lora: loraname2 v1:1>, <lora: loraname3 v1:1>, extraDescription, etc

### What should have happened?

I believe the loras format <lora: loraname> should be included in the regex so it does not ignore it when multiple ones are called in the last line.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Could not generate file

### Console logs

```Shell
no console log errors for this bug
```

### Additional information

More curious as to if this is intended to not detect multiple lora formats for a last line in text since most geninfo are not composed of only the prompt.",2025-03-02T09:50:19Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876,"[Bug]: function parse_generation_parameter removes lastline if multiple loras are embedded in final text ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

File: modules/infotext_utils.py 
Line(s): 255 -> if len(re_param.findall(lastline)) < 3:

The function parse_generation_parameters from modules/infotext_utils.py has a built in functionality to ignore the last line of a text passed in if len(re_param.findall(lastline)) < 3, when this criteria is met the last line will not be added to the lines variable list.

### Steps to reproduce the problem

Under the scenario a standalone prompt text such as this below is passed in, the last line will be ignored:

promptDescription1, promptDescription2,
<lora: loraname1 v1:1>, <lora: loraname2 v1:1>, <lora: loraname3 v1:1>, extraDescription, etc

### What should have happened?

I believe the loras format <lora: loraname> should be included in the regex so it does not ignore it when multiple ones are called in the last line.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Could not generate file

### Console logs

```Shell
no console log errors for this bug
```

### Additional information

More curious as to if this is intended to not detect multiple lora formats for a last line in text since most geninfo are not composed of only the prompt.",bug function parse generation parameter removes lastline multiple loras embedded final text checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened file modules infotext utils py line len param findall lastline function parse generation parameters modules infotext utils py built functionality ignore last line text passed len param findall lastline criteria met last line added lines variable list steps reproduce problem scenario standalone prompt text passed last line ignored promptdescription promptdescription lora loraname v lora loraname v lora loraname v extradescription etc happened believe loras format lora loraname included regex ignore multiple ones called last line browsers use access ui mozilla firefox sysinfo could generate file console logs shell console log errors bug additional information curious intended detect multiple lora formats last line text since geninfo composed prompt
auto1111_webui,comment,16876,,"The specific line you are talking about is meant to detect if the infotext contains parameters, such as `Steps:`, `Sampler:`, `Seed:`, etc.

A normal infotext will contain an arbitary number of lines of positive prompts and negative prompts, but the parameters will always be in the last line, hence this script. Also, immediately under that line, it gets added back into the `lines` if the check passes anyway...

**TL;DR:** This does not do what you think it does",2025-03-06T09:05:54Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703230473,"The specific line you are talking about is meant to detect if the infotext contains parameters, such as `Steps:`, `Sampler:`, `Seed:`, etc.

A normal infotext will contain an arbitary number of lines of positive prompts and negative prompts, but the parameters will always be in the last line, hence this script. Also, immediately under that line, it gets added back into the `lines` if the check passes anyway...

**TL;DR:** This does not do what you think it does",specific line talking meant detect infotext contains parameters steps sampler seed etc normal infotext contain arbitary number lines positive prompts negative prompts parameters always last line hence script also immediately line gets added back lines check passes anyway tl dr think
auto1111_webui,comment,16876,,"@Haoming02 yeah, real question was if this method ever had a use-case for parsing a text composed of only the prompt info and without the additional geninfo (steps: seed: etc..). this could be transitioned to a feature request if its beyond intended functionality.",2025-03-06T09:58:25Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703361927,"@Haoming02 yeah, real question was if this method ever had a use-case for parsing a text composed of only the prompt info and without the additional geninfo (steps: seed: etc..). this could be transitioned to a feature request if its beyond intended functionality.",haoming yeah real question method ever use case parsing text composed prompt info without additional geninfo steps seed etc could transitioned feature request beyond intended functionality
auto1111_webui,comment,16876,,"Again, if the `last_line` does not contain parameters, then it is added back into regular `lines` ",2025-03-06T10:00:18Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703366782,"Again, if the `last_line` does not contain parameters, then it is added back into regular `lines`",last line contain parameters added back regular lines
auto1111_webui,comment,16876,,"@Haoming02 that is not the case in this scenario, the example I showed the 3 loras on the last line will lead it to be ignored and not added back based on the regex match.
let me know if you get a different result from the text example provided. 👍",2025-03-06T10:37:09Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703459037,"@Haoming02 that is not the case in this scenario, the example I showed the 3 loras on the last line will lead it to be ignored and not added back based on the regex match.
let me know if you get a different result from the text example provided. 👍",haoming case scenario example showed loras last line lead ignored added back based regex match let know get different result text example provided
auto1111_webui,comment,16876,,"Ah, I finally get what you meant

<hr>

**TL;DR:** The current ""[re_param_code](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/infotext_utils.py#L16)"" also matches the LoRA syntax. So if your last line contains 3 or more LoRAs, then the line will be considered parameters instead.",2025-03-06T13:09:59Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703810335,"Ah, I finally get what you meant

<hr>

**TL;DR:** The current ""[re_param_code](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/infotext_utils.py#L16)"" also matches the LoRA syntax. So if your last line contains 3 or more LoRAs, then the line will be considered parameters instead.",ah finally get meant hr tl dr current param code also matches lora syntax last line contains loras line considered parameters instead
auto1111_webui,comment,16876,,But... when would this become a problem though?,2025-03-06T13:10:35Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703811873,But... when would this become a problem though?,would become problem though
auto1111_webui,issue,16874,[Feature Request]: fp16 accumulation,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

The Torch nightly version supports FP16 acceleration (up to the NVIDIA RTX 3000 series).
Users will need to manually manage the Torch nightly version and Xformers,
but it will improve generation speed.

It seems that it is already available in forge&ReForge and ComfyUI.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

https://github.com/bedovyy/stable-diffusion-webui-forge/commit/9f84043
https://github.com/comfyanonymous/ComfyUI/commit/43a74c0",2025-03-01T16:42:29Z,namemechan,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16874,"[Feature Request]: fp16 accumulation ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

The Torch nightly version supports FP16 acceleration (up to the NVIDIA RTX 3000 series).
Users will need to manually manage the Torch nightly version and Xformers,
but it will improve generation speed.

It seems that it is already available in forge&ReForge and ComfyUI.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

https://github.com/bedovyy/stable-diffusion-webui-forge/commit/9f84043
https://github.com/comfyanonymous/ComfyUI/commit/43a74c0",feature request fp accumulation existing issue x searched existing issues checked recent builds commits would feature torch nightly version supports fp acceleration nvidia rtx series users need manually manage torch nightly version xformers improve generation speed seems already available forge reforge comfyui proposed workflow go press additional information
auto1111_webui,issue,16871,[Feature Request]: Add warning when extensions cannot be installed to Extensions > Available tab,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be good for the UI to indicate that extensions cannot currently be installed because --enable-insecure-extension-access wasn't specified at startup.

from log:
AssertionError: extension access disabled because of command line flags



### Proposed workflow

1. Run  webui.sh
2. Select [Extension] tab
3. Select [Available] sub-tab

A warning should precede the list of available extensions. Moreover, the [Install] buttons should be grayed out.

### Additional information

_No response_",2025-03-01T06:05:28Z,tomasohara,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16871,"[Feature Request]: Add warning when extensions cannot be installed to Extensions > Available tab ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be good for the UI to indicate that extensions cannot currently be installed because --enable-insecure-extension-access wasn't specified at startup.

from log:
AssertionError: extension access disabled because of command line flags



### Proposed workflow

1. Run  webui.sh
2. Select [Extension] tab
3. Select [Available] sub-tab

A warning should precede the list of available extensions. Moreover, the [Install] buttons should be grayed out.

### Additional information

_No response_",feature request add warning extensions cannot installed extensions available tab existing issue x searched existing issues checked recent builds commits would feature would good ui indicate extensions cannot currently installed enable insecure extension access specified startup log assertionerror extension access disabled command line flags proposed workflow run webui sh select extension tab select available sub tab warning precede list available extensions moreover install buttons grayed additional information response
auto1111_webui,issue,16868,[Bug]: loading stable diffusion model: UnpicklingError,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.
Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Stable diffusion model failed to load, exiting

I searched the web for this error and got mostly answers that would add 'weights_only=True', but I don't know where to add this line of code

### Steps to reproduce the problem

1. run run.bat
2. Error occurs

### What should have happened?

WebUI should run successfully.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I couldn't generate the file.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.


Stable diffusion model failed to load, exiting
请按任意键继续. . .
```

### Additional information

_No response_",2025-02-26T13:54:45Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868,"[Bug]: loading stable diffusion model: UnpicklingError ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.
Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Stable diffusion model failed to load, exiting

I searched the web for this error and got mostly answers that would add 'weights_only=True', but I don't know where to add this line of code

### Steps to reproduce the problem

1. run run.bat
2. Error occurs

### What should have happened?

WebUI should run successfully.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I couldn't generate the file.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.


Stable diffusion model failed to load, exiting
请按任意键继续. . .
```

### Additional information

_No response_",bug loading stable diffusion model unpicklingerror checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened python tags v c b bd aug msc v bit amd commit hash de fea e f df df fddf f b installing requirements web ui launching web ui arguments lowvram precision full half f ai stable diffusion webui system python lib site packages urllib connectionpool py insecurerequestwarning unverified request made host api gradio app adding certificate verification strongly advised see warnings warn module xformers proceeding without warning caught exception torch compiled cuda enabled memory monitor disabled latentdiffusion running eps prediction mode diffusionwrapper params loading weights e f ai stable diffusion webui webui models stable diffusion v pruned ckpt loading stable diffusion model unpicklingerror traceback recent call last file f ai stable diffusion webui webui webui py line initialize modules sd models load model file f ai stable diffusion webui webui modules sd models py line load model load model weights sd model checkpoint info file f ai stable diffusion webui webui modules sd models py line load model weights sd read state dict checkpoint info filename file f ai stable diffusion webui webui modules sd models py line read state dict pl sd torch load checkpoint file map location map location shared weight load location file f ai stable diffusion webui webui modules safe py line load return load extra filename extra handler global extra handler args kwargs file f ai stable diffusion webui webui modules safe py line load extra return unsafe torch load filename args kwargs file f ai stable diffusion webui system python lib site packages torch serialization py line load raise pickle unpicklingerror get wo message str e none pickle unpicklingerror weights load failed file still loaded two options steps trust source checkpoint pytorch changed default value weights argument torch load false true running torch load weights set false likely succeed result arbitrary code execution got file trusted source alternatively load weights true please check recommended steps following error message weightsunpickler error unsupported global global pytorch lightning callbacks model checkpoint modelcheckpoint allowed global default please use torch serialization add safe globals modelcheckpoint torch serialization safe globals modelcheckpoint context manager allowlist global trust class function check documentation torch load learn types accepted default weights stable diffusion model failed load exiting searched web error got mostly answers would add weights true know add line code steps reproduce problem run run bat error occurs happened webui run successfully browsers use access ui response sysinfo generate file console logs shell python tags v c b bd aug msc v bit amd commit hash de fea e f df df fddf f b installing requirements web ui launching web ui arguments lowvram precision full half f ai stable diffusion webui system python lib site packages urllib connectionpool py insecurerequestwarning unverified request made host api gradio app adding certificate verification strongly advised see warnings warn module xformers proceeding without warning caught exception torch compiled cuda enabled memory monitor disabled latentdiffusion running eps prediction mode diffusionwrapper params loading weights e f ai stable diffusion webui webui models stable diffusion v pruned ckpt loading stable diffusion model unpicklingerror traceback recent call last file f ai stable diffusion webui webui webui py line initialize modules sd models load model file f ai stable diffusion webui webui modules sd models py line load model load model weights sd model checkpoint info file f ai stable diffusion webui webui modules sd models py line load model weights sd read state dict checkpoint info filename file f ai stable diffusion webui webui modules sd models py line read state dict pl sd torch load checkpoint file map location map location shared weight load location file f ai stable diffusion webui webui modules safe py line load return load extra filename extra handler global extra handler args kwargs file f ai stable diffusion webui webui modules safe py line load extra return unsafe torch load filename args kwargs file f ai stable diffusion webui system python lib site packages torch serialization py line load raise pickle unpicklingerror get wo message str e none pickle unpicklingerror weights load failed file still loaded two options steps trust source checkpoint pytorch changed default value weights argument torch load false true running torch load weights set false likely succeed result arbitrary code execution got file trusted source alternatively load weights true please check recommended steps following error message weightsunpickler error unsupported global global pytorch lightning callbacks model checkpoint modelcheckpoint allowed global default please use torch serialization add safe globals modelcheckpoint torch serialization safe globals modelcheckpoint context manager allowlist global trust class function check documentation torch load learn types accepted default weights stable diffusion model failed load exiting additional information response
auto1111_webui,comment,16868,,"I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem 😄 ",2025-02-26T14:25:11Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2685179569,"I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem 😄",change sd models py line pl sd torch load checkpoint file map location map location shared weight load location weights false solved problem
auto1111_webui,comment,16868,,"Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...",2025-02-27T06:42:49Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2687050399,"Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...",well using ckpt checkpoint nowadays anyway much less base v pruned checkpoint like years old point
auto1111_webui,comment,16868,,"> Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...

Thank you, I just started using this and am not familiar with the model, can you tell me what model I should use ：）",2025-02-27T10:28:14Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2687530408,"> Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...

Thank you, I just started using this and am not familiar with the model, can you tell me what model I should use ：）",well using ckpt checkpoint nowadays anyway much less base v pruned checkpoint like years old point thank started using familiar model tell model use
auto1111_webui,comment,16868,,"If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)

btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there",2025-02-27T13:42:08Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2688003154,"If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)

btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there",starting try good ol reliable realistic vision btw civitai site hosts lot checkpoints take look
auto1111_webui,comment,16868,,"> If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)
> 
> btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there

thank you ：）",2025-02-27T14:19:16Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2688099772,"> If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)
> 
> btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there

thank you ：）",starting try good ol reliable realistic vision btw civitai site hosts lot checkpoints take look thank
auto1111_webui,comment,16868,,You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.,2025-02-28T02:35:06Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2689573154,You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.,also using webui version january update git pull delete venv folder
auto1111_webui,comment,16868,,"> You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.

thanks, I just use [this](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.10.1) to download it",2025-02-28T14:55:02Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2690845776,"> You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.

thanks, I just use [this](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.10.1) to download it",also using webui version january update git pull delete venv folder thanks use download
auto1111_webui,comment,16868,,"> I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem 😄

yes, modify to False,not True. My line is  323",2025-03-02T04:38:47Z,lapertme2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2692554154,"> I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem 😄

yes, modify to False,not True. My line is  323",change sd models py line pl sd torch load checkpoint file map location map location shared weight load location weights false solved problem yes modify false true line
auto1111_webui,issue,16861,[Bug]: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The error message is not intuitive. It's a batch file, not an executable. I am a developer but not versed in anything being used. I had the impression that Automatic1111 would just work. Here is the dump for AMD 3800 / 32GB /  RX 6800 / 10 x64 22H2:

> Creating venv in directory D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv using python ""C:\Users\John\AppData\Local\Programs\Python\Python310\python.exe""
> Requirement already satisfied: pip in d:\my documents\desktop\stable-diffusion-webui-1.10.1\venv\lib\site-packages (22.2.1)
> Collecting pip
>   Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)
> Installing collected packages: pip
>   Attempting uninstall: pip
>     Found existing installation: pip 22.2.1
>     Uninstalling pip-22.2.1:
>       Successfully uninstalled pip-22.2.1
> Successfully installed pip-25.0.1
> venv ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv\Scripts\Python.exe""
> fatal: not a git repository (or any of the parent directories): .git
> fatal: not a git repository (or any of the parent directories): .git
> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
> Version: 1.10.1
> Commit hash: <none>
> Installing torch and torchvision
> Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
> Collecting torch==2.1.2
>   Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
> Collecting torchvision==0.16.2
>   Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
> Collecting filelock (from torch==2.1.2)
>   Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
> Collecting typing-extensions (from torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
> Collecting sympy (from torch==2.1.2)
>   Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
> Collecting networkx (from torch==2.1.2)
>   Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
> Collecting jinja2 (from torch==2.1.2)
>   Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
> Collecting fsspec (from torch==2.1.2)
>   Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)
> Collecting numpy (from torchvision==0.16.2)
>   Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl.metadata (60 kB)
> Collecting requests (from torchvision==0.16.2)
>   Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
> Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
>   Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
> Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
>   Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
> Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
>   Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
> Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
>   Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
> Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
>   Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
> Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
>   Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
> Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
> Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
> Using cached filelock-3.17.0-py3-none-any.whl (16 kB)
> Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)
> Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
> Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
> Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl (12.9 MB)
> Using cached requests-2.32.3-py3-none-any.whl (64 kB)
> Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
> Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
> Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
> Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
> Using cached idna-3.10-py3-none-any.whl (70 kB)
> Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
> Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
> Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
> Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.2.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.3 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
> Traceback (most recent call last):
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 48, in <module>
>     main()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 39, in main
>     prepare_environment()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\modules\launch_utils.py"", line 387, in prepare_environment
>     raise RuntimeError(
> RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
> Press any key to continue . . .

### Steps to reproduce the problem

Open webui-user.bat

### What should have happened?

The program should make an attempt to not bomb out on this error or at least provide a useful and up-to-date debugging suggestion.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

N/A because it never successfully installed!

### Console logs

```Shell
N/A
```

### Additional information

_No response_",2025-02-23T05:33:01Z,jabcreations,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861,"[Bug]: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The error message is not intuitive. It's a batch file, not an executable. I am a developer but not versed in anything being used. I had the impression that Automatic1111 would just work. Here is the dump for AMD 3800 / 32GB /  RX 6800 / 10 x64 22H2:

> Creating venv in directory D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv using python ""C:\Users\John\AppData\Local\Programs\Python\Python310\python.exe""
> Requirement already satisfied: pip in d:\my documents\desktop\stable-diffusion-webui-1.10.1\venv\lib\site-packages (22.2.1)
> Collecting pip
>   Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)
> Installing collected packages: pip
>   Attempting uninstall: pip
>     Found existing installation: pip 22.2.1
>     Uninstalling pip-22.2.1:
>       Successfully uninstalled pip-22.2.1
> Successfully installed pip-25.0.1
> venv ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv\Scripts\Python.exe""
> fatal: not a git repository (or any of the parent directories): .git
> fatal: not a git repository (or any of the parent directories): .git
> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
> Version: 1.10.1
> Commit hash: <none>
> Installing torch and torchvision
> Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
> Collecting torch==2.1.2
>   Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
> Collecting torchvision==0.16.2
>   Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
> Collecting filelock (from torch==2.1.2)
>   Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
> Collecting typing-extensions (from torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
> Collecting sympy (from torch==2.1.2)
>   Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
> Collecting networkx (from torch==2.1.2)
>   Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
> Collecting jinja2 (from torch==2.1.2)
>   Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
> Collecting fsspec (from torch==2.1.2)
>   Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)
> Collecting numpy (from torchvision==0.16.2)
>   Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl.metadata (60 kB)
> Collecting requests (from torchvision==0.16.2)
>   Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
> Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
>   Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
> Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
>   Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
> Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
>   Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
> Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
>   Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
> Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
>   Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
> Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
>   Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
> Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
> Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
> Using cached filelock-3.17.0-py3-none-any.whl (16 kB)
> Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)
> Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
> Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
> Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl (12.9 MB)
> Using cached requests-2.32.3-py3-none-any.whl (64 kB)
> Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
> Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
> Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
> Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
> Using cached idna-3.10-py3-none-any.whl (70 kB)
> Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
> Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
> Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
> Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.2.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.3 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
> Traceback (most recent call last):
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 48, in <module>
>     main()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 39, in main
>     prepare_environment()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\modules\launch_utils.py"", line 387, in prepare_environment
>     raise RuntimeError(
> RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
> Press any key to continue . . .

### Steps to reproduce the problem

Open webui-user.bat

### What should have happened?

The program should make an attempt to not bomb out on this error or at least provide a useful and up-to-date debugging suggestion.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

N/A because it never successfully installed!

### Console logs

```Shell
N/A
```

### Additional information

_No response_",bug torch able use gpu add skip torch cuda test commandline args variable disable check checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened error message intuitive batch file executable developer versed anything used impression automatic would work dump amd gb rx x h creating venv directory documents desktop stable diffusion webui venv using python c users john appdata local programs python python python exe requirement already satisfied pip documents desktop stable diffusion webui venv lib site packages collecting pip using cached pip py none whl mb installing collected packages pip attempting uninstall pip found existing installation pip uninstalling pip successfully uninstalled pip successfully installed pip venv documents desktop stable diffusion webui venv scripts python exe fatal git repository parent directories git fatal git repository parent directories git python tags v c b bd aug msc v bit amd version commit hash none installing torch torchvision looking indexes collecting torch using cached mb collecting torchvision using cached mb collecting filelock torch using cached filelock py none whl metadata kb collecting typing extensions torch using cached kb collecting sympy torch using cached sympy py none whl metadata kb collecting networkx torch using cached networkx py none whl metadata kb collecting jinja torch using cached jinja py none whl metadata kb collecting fsspec torch using cached fsspec py none whl metadata kb collecting numpy torchvision using cached numpy cp cp win amd whl metadata kb collecting requests torchvision using cached requests py none whl metadata kb collecting pillow torchvision using cached pillow cp cp win amd whl metadata kb collecting markupsafe jinja torch using cached markupsafe cp cp win amd whl metadata kb collecting charset normalizer requests torchvision using cached charset normalizer cp cp win amd whl metadata kb collecting idna requests torchvision using cached idna py none whl metadata kb collecting urllib requests torchvision using cached urllib py none whl metadata kb collecting certifi requests torchvision using cached certifi py none whl metadata kb collecting mpmath sympy torch using cached kb using cached pillow cp cp win amd whl mb using cached filelock py none whl kb using cached fsspec py none whl kb using cached jinja py none whl kb using cached networkx py none whl mb using cached numpy cp cp win amd whl mb using cached requests py none whl kb using cached sympy py none whl mb using cached kb using cached certifi py none whl kb using cached charset normalizer cp cp win amd whl kb using cached idna py none whl kb using cached markupsafe cp cp win amd whl kb using cached urllib py none whl kb installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna fsspec filelock charset normalizer certifi requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock fsspec idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu typing extensions urllib traceback recent call last file documents desktop stable diffusion webui launch py line module main file documents desktop stable diffusion webui launch py line main prepare environment file documents desktop stable diffusion webui modules launch utils py line prepare environment raise runtimeerror runtimeerror torch able use gpu add skip torch cuda test commandline args variable disable check press key continue steps reproduce problem open webui user bat happened program make attempt bomb error least provide useful date debugging suggestion browsers use access ui response sysinfo n never successfully installed console logs shell n additional information response
auto1111_webui,comment,16861,,"AMD + Windows not supported, only on linux
please read the installation instructions
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs
> Windows+AMD support has not officially been made for webui,
but you can install lshqqytiger's fork of webui that uses Direct-ml. https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu

",2025-02-23T09:25:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2676736395,"AMD + Windows not supported, only on linux
please read the installation instructions
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs
> Windows+AMD support has not officially been made for webui,
but you can install lshqqytiger's fork of webui that uses Direct-ml. https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu",amd windows supported linux please read installation instructions windows amd support officially made webui install lshqqytiger fork webui uses direct ml
auto1111_webui,comment,16861,,"AMD GPUs are listed, then the index page should probably be updated to say ""AMD on Linux only"" or you'll just keep getting lot of disappointed people posting bugs.

On the upside thank you for the fork recommendation.",2025-02-23T19:02:00Z,jabcreations,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2677064006,"AMD GPUs are listed, then the index page should probably be updated to say ""AMD on Linux only"" or you'll just keep getting lot of disappointed people posting bugs.

On the upside thank you for the fork recommendation.",amd gpus listed index page probably updated say amd linux keep getting lot disappointed people posting bugs upside thank fork recommendation
auto1111_webui,comment,16861,,"the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 

Windows 10
Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
RTX 2060 12 GB my gpu has been fine with this before 
32GB of ram 

I've done hundreds of clean installs same error
it wont even load  lol this thing a completely dead and garbage project",2025-02-25T12:11:14Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681755463,"the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 

Windows 10
Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
RTX 2060 12 GB my gpu has been fine with this before 
32GB of ram 

I've done hundreds of clean installs same error
it wont even load  lol this thing a completely dead and garbage project",funny thing thing broken nothing works anymore im rtx error nothing try fixes really needs full code rewrite seeing activity months highly doubt going case windows cuda even tried cuda rtx gb gpu fine gb ram done hundreds clean installs error wont even load lol thing completely dead garbage project
auto1111_webui,comment,16861,,"> the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 
> 
> Windows 10
> Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
> RTX 2060 12 GB my gpu has been fine with this before 
> 32GB of ram 
> 
> I've done hundreds of clean installs same error
> it wont even load  lol this thing a completely dead and garbage project

I got similar error on windows + rtx3060 several days ago, the problem was in the python version missmatch. (warning appears if this is the case) 

After downgrading python works just fine 

Anyway, I moved to ComfyUI shortly after ",2025-02-25T12:14:33Z,vptyp,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681763336,"> the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 
> 
> Windows 10
> Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
> RTX 2060 12 GB my gpu has been fine with this before 
> 32GB of ram 
> 
> I've done hundreds of clean installs same error
> it wont even load  lol this thing a completely dead and garbage project

I got similar error on windows + rtx3060 several days ago, the problem was in the python version missmatch. (warning appears if this is the case) 

After downgrading python works just fine 

Anyway, I moved to ComfyUI shortly after",funny thing thing broken nothing works anymore im rtx error nothing try fixes really needs full code rewrite seeing activity months highly doubt going case windows cuda even tried cuda rtx gb gpu fine gb ram done hundreds clean installs error wont even load lol thing completely dead garbage project got similar error windows rtx several days ago problem python version missmatch warning appears case downgrading python works fine anyway moved comfyui shortly
auto1111_webui,comment,16861,,"i have been using the same Python version  ""3.10.6"" as what was always in the docs
",2025-02-25T12:16:46Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681770103,"i have been using the same Python version  ""3.10.6"" as what was always in the docs",using python version always docs
auto1111_webui,comment,16861,,the other problem is I primarily use it to train models and I haven't found anything else that will allow me,2025-02-25T12:18:41Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681774626,the other problem is I primarily use it to train models and I haven't found anything else that will allow me,problem primarily use train models found anything else allow
auto1111_webui,issue,16859,[Bug]: Error code: 128,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128

### Steps to reproduce the problem

1. Use webui-user.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

operagx

### Console logs

```Shell
Traceback (most recent call last):
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

I deleted repositories, not help",2025-02-21T19:15:27Z,PavelVLasovich,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16859,"[Bug]: Error code: 128 ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128

### Steps to reproduce the problem

1. Use webui-user.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

operagx

### Console logs

```Shell
Traceback (most recent call last):
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128
Для продолжения нажмите любую клавишу . . .
```

### Additional information

I deleted repositories, not help",bug error code checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened runtimeerror clone stable diffusion command git clone config core filemode false c soft stable diffusion webui master repositories stable diffusion stability ai error code steps reproduce problem use webui user bat happened know browsers use access ui response sysinfo operagx console logs shell traceback recent call last file c soft stable diffusion webui master launch py line module main file c soft stable diffusion webui master launch py line main prepare environment file c soft stable diffusion webui master modules launch utils py line prepare environment git clone stable diffusion repo repo dir stable diffusion stability ai stable diffusion stable diffusion commit hash file c soft stable diffusion webui master modules launch utils py line git clone run f git clone config core filemode false url dir f cloning name dir f clone name live true file c soft stable diffusion webui master modules launch utils py line run raise runtimeerror n join error bits runtimeerror clone stable diffusion command git clone config core filemode false c soft stable diffusion webui master repositories stable diffusion stability ai error code additional information deleted repositories help
auto1111_webui,comment,16859,,"This might be related to your network.  You can try to see if the network can connect to GitHub.
Then I think what's even more important is that your PyCharm environment has not been set up properly.  
I solved this problem by setting the path for the downloaded git.exe in the Git of Version Control.
",2025-06-19T03:00:24Z,ausch11,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16859#issuecomment-2986429278,"This might be related to your network.  You can try to see if the network can connect to GitHub.
Then I think what's even more important is that your PyCharm environment has not been set up properly.  
I solved this problem by setting the path for the downloaded git.exe in the Git of Version Control.",might related network try see network connect github think even important pycharm environment set properly solved problem setting path downloaded git exe git version control
auto1111_webui,issue,16858,[Feature Request]: AI Assistant for Prompt Optimization in A1111,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I’d like to propose an AI-powered assistant integrated into Automatic1111's WebUI to help users optimize their prompts, troubleshoot issues, and improve image generation results.

Many users struggle with:

Getting the AI to follow instructions like (full-body images, specific poses, avoiding unwanted elements).
Understanding the best settings for samplers, CFG scale, and resolution.
Fixing common issues (bad hands, incorrect poses, composition problems).
Having an AI assistant built into A1111 could help automate prompt improvements, suggest better settings, and troubleshoot generation issues in real time.

How It Could Work
Prompt Optimization:

Suggests refinements to user prompts for better accuracy.
Detects vague or weak prompts and provides improvements.
Example: If a user types ""girl laying on her back,"" but the model struggles, the AI can suggest adding ""top-down view, lying supine, arms resting on ground.""
Smart Setting Recommendations:

Suggests ideal sampling steps, CFG scale, and samplers based on the prompt.
Recommends resolution changes like (if a full-body image is requested but the resolution is too low).
Troubleshooting Mode:

Detects common mistakes (like using a high CFG scale that causes overbaked results).
Offers fixes for weird anatomy, poor hands, awkward compositions.
Integrates with ControlNet/OpenPose to guide users on using pose references.
Why This Would Be a Game-Changer
 Makes A1111 more beginner-friendly.
 Improves accuracy and consistency of image generations.
 Saves users time by automating trial-and-error prompt adjustments.
 Bridges the gap between casual users and advanced features (like ControlNet).

Would love to hear feedback from the community! If there’s interest, maybe this could be explored as a built-in feature or an extension.


If the A1111 team is open to this, I’d love for this to be implemented. Maybe it could work as an AI-powered chatbot inside the UI or as a ""Prompt Optimization"" button next to the Generate button.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

i am still a beginner to this (started about a week ago) and you have NO IDEA ! how much ChatGPT helped me on my journey, from guiding my Automatic1111 installation step by step to helping me with setting a good prompts, good CFG scale, using the right sampling method, schedule type, resolution, how to use hires.fix,  refiner, inpaint, and today i installed and used ControlNet successfully for the first time! along with making a styles.csv file and adding all those amazing styles to use and so on, AI has been a god-send for me and helping me on my learning journey, so i thought to myself imagine if everyone can have ChatGPT or any AI at their side to help them get their imagination to life in the right way.
(Sorry for typing too much, tried to make this request clear, simple and informative, I hope everyone love this request)
Much Love and Respect.",2025-02-21T17:06:08Z,4MagicLight4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16858,"[Feature Request]: AI Assistant for Prompt Optimization in A1111 ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I’d like to propose an AI-powered assistant integrated into Automatic1111's WebUI to help users optimize their prompts, troubleshoot issues, and improve image generation results.

Many users struggle with:

Getting the AI to follow instructions like (full-body images, specific poses, avoiding unwanted elements).
Understanding the best settings for samplers, CFG scale, and resolution.
Fixing common issues (bad hands, incorrect poses, composition problems).
Having an AI assistant built into A1111 could help automate prompt improvements, suggest better settings, and troubleshoot generation issues in real time.

How It Could Work
Prompt Optimization:

Suggests refinements to user prompts for better accuracy.
Detects vague or weak prompts and provides improvements.
Example: If a user types ""girl laying on her back,"" but the model struggles, the AI can suggest adding ""top-down view, lying supine, arms resting on ground.""
Smart Setting Recommendations:

Suggests ideal sampling steps, CFG scale, and samplers based on the prompt.
Recommends resolution changes like (if a full-body image is requested but the resolution is too low).
Troubleshooting Mode:

Detects common mistakes (like using a high CFG scale that causes overbaked results).
Offers fixes for weird anatomy, poor hands, awkward compositions.
Integrates with ControlNet/OpenPose to guide users on using pose references.
Why This Would Be a Game-Changer
 Makes A1111 more beginner-friendly.
 Improves accuracy and consistency of image generations.
 Saves users time by automating trial-and-error prompt adjustments.
 Bridges the gap between casual users and advanced features (like ControlNet).

Would love to hear feedback from the community! If there’s interest, maybe this could be explored as a built-in feature or an extension.


If the A1111 team is open to this, I’d love for this to be implemented. Maybe it could work as an AI-powered chatbot inside the UI or as a ""Prompt Optimization"" button next to the Generate button.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

i am still a beginner to this (started about a week ago) and you have NO IDEA ! how much ChatGPT helped me on my journey, from guiding my Automatic1111 installation step by step to helping me with setting a good prompts, good CFG scale, using the right sampling method, schedule type, resolution, how to use hires.fix,  refiner, inpaint, and today i installed and used ControlNet successfully for the first time! along with making a styles.csv file and adding all those amazing styles to use and so on, AI has been a god-send for me and helping me on my learning journey, so i thought to myself imagine if everyone can have ChatGPT or any AI at their side to help them get their imagination to life in the right way.
(Sorry for typing too much, tried to make this request clear, simple and informative, I hope everyone love this request)
Much Love and Respect.",feature request ai assistant prompt optimization existing issue x searched existing issues checked recent builds commits would feature id like propose ai powered assistant integrated automatic webui help users optimize prompts troubleshoot issues improve image generation results many users struggle getting ai follow instructions like full body images specific poses avoiding unwanted elements understanding best settings samplers cfg scale resolution fixing common issues bad hands incorrect poses composition problems ai assistant built could help automate prompt improvements suggest better settings troubleshoot generation issues real time could work prompt optimization suggests refinements user prompts better accuracy detects vague weak prompts provides improvements example user types girl laying back model struggles ai suggest adding top view lying supine arms resting ground smart setting recommendations suggests ideal sampling steps cfg scale samplers based prompt recommends resolution changes like full body image requested resolution low troubleshooting mode detects common mistakes like using high cfg scale causes overbaked results offers fixes weird anatomy poor hands awkward compositions integrates controlnet openpose guide users using pose references would game changer makes beginner friendly improves accuracy consistency image generations saves users time automating trial error prompt adjustments bridges gap casual users advanced features like controlnet would love hear feedback community theres interest maybe could explored built feature extension team open id love implemented maybe could work ai powered chatbot inside ui prompt optimization button next generate button proposed workflow go press additional information still beginner started week ago idea much chatgpt helped journey guiding automatic installation step step helping setting good prompts good cfg scale using right sampling method schedule type resolution use hires fix refiner inpaint today installed used controlnet successfully first time along making styles csv file adding amazing styles use ai god send helping learning journey thought imagine everyone chatgpt ai side help get imagination life right way sorry typing much tried make request clear simple informative hope everyone love request much love respect
auto1111_webui,issue,16856,"[Bug]:sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I installed the WebUI on my newly purchased Macbook，After the installation, when I executed./webui.sh again, there was an issue,Then I selected a model in the WebUI, but it failed to load.


### Steps to reproduce the problem

1. Execute ./webui.sh in the Shell.
2. Load models in the WebUI.

### What should have happened?

The WebUI can load models normally.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-19-23-43.json](https://github.com/user-attachments/files/18877124/sysinfo-2025-02-19-23-43.json)

### Console logs

```Shell
reading metadata for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 83, in __init__
    self.metadata = cache.cached_data_for_file('safetensors-metadata', ""checkpoint/"" + name, filename, read_metadata)
  File ""/Users/waylon/stable-diffusion-webui/modules/cache.py"", line 119, in cached_data_for_file
    existing_cache[title] = entry
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?

Calculating sha256 for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/AnythingV5Ink_v5RE.ckpt: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 3.5s (prepare environment: 0.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 0.3s, initialize shared: 0.1s, other imports: 0.3s, load scripts: 0.1s, create ui: 0.1s, gradio launch: 0.2s).
5b12f296e7577a3e0c832ba60d79d5bfbae0df9f692a00834f97f86283a9c332
loading stable diffusion model: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/waylon/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/Users/waylon/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 802, in load_model
    state_dict = get_checkpoint_state_dict(checkpoint_info, timer)
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 333, in get_checkpoint_state_dict
    sd_model_hash = checkpoint_info.calculate_shorthash()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 108, in calculate_shorthash
    self.sha256 = hashes.sha256(self.filename, f""checkpoint/{self.name}"")
  File ""/Users/waylon/stable-diffusion-webui/modules/hashes.py"", line 59, in sha256
    hashes[title] = {
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?
```

### Additional information

It seems that other AI tools also have this problem.
- https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669
- https://github.com/easydiffusion/easydiffusion/issues/1905",2025-02-19T23:51:15Z,waylonwang,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856,"[Bug]:sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes? ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I installed the WebUI on my newly purchased Macbook，After the installation, when I executed./webui.sh again, there was an issue,Then I selected a model in the WebUI, but it failed to load.


### Steps to reproduce the problem

1. Execute ./webui.sh in the Shell.
2. Load models in the WebUI.

### What should have happened?

The WebUI can load models normally.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-19-23-43.json](https://github.com/user-attachments/files/18877124/sysinfo-2025-02-19-23-43.json)

### Console logs

```Shell
reading metadata for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 83, in __init__
    self.metadata = cache.cached_data_for_file('safetensors-metadata', ""checkpoint/"" + name, filename, read_metadata)
  File ""/Users/waylon/stable-diffusion-webui/modules/cache.py"", line 119, in cached_data_for_file
    existing_cache[title] = entry
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?

Calculating sha256 for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/AnythingV5Ink_v5RE.ckpt: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 3.5s (prepare environment: 0.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 0.3s, initialize shared: 0.1s, other imports: 0.3s, load scripts: 0.1s, create ui: 0.1s, gradio launch: 0.2s).
5b12f296e7577a3e0c832ba60d79d5bfbae0df9f692a00834f97f86283a9c332
loading stable diffusion model: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/waylon/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/Users/waylon/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 802, in load_model
    state_dict = get_checkpoint_state_dict(checkpoint_info, timer)
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 333, in get_checkpoint_state_dict
    sd_model_hash = checkpoint_info.calculate_shorthash()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 108, in calculate_shorthash
    self.sha256 = hashes.sha256(self.filename, f""checkpoint/{self.name}"")
  File ""/Users/waylon/stable-diffusion-webui/modules/hashes.py"", line 59, in sha256
    hashes[title] = {
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?
```

### Additional information

It seems that other AI tools also have this problem.
- https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669
- https://github.com/easydiffusion/easydiffusion/issues/1905",bug sqlite operationalerror column size string literal single quotes checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened installed webui newly purchased macbookafter installation executed webui sh issue selected model webui failed load steps reproduce problem execute webui sh shell load models webui happened webui load models normally browsers use access ui microsoft edge sysinfo sysinfo json console logs shell reading metadata users waylon stable diffusion webui models stable diffusion v pruned emaonly safetensors operationalerror traceback recent call last file users waylon stable diffusion webui modules sd models py line init self metadata cache cached data file safetensors metadata checkpoint name filename read metadata file users waylon stable diffusion webui modules cache py line cached data file existing cache title entry file users waylon stable diffusion webui venv lib python site packages diskcache core py line setitem self set key value retry true file users waylon stable diffusion webui venv lib python site packages diskcache core py line set self row insert db key raw columns file users waylon stable diffusion webui venv lib python site packages diskcache core py line row insert sql sqlite operationalerror column size string literal single quotes calculating sha users waylon stable diffusion webui models stable diffusion anythingv ink v ckpt running local url create public link set share true launch startup time prepare environment import torch import gradio setup paths initialize shared imports load scripts create ui gradio launch b f e e c ba bfbae df f f f c loading stable diffusion model operationalerror traceback recent call last file users waylon miniforge envs py sd lib python threading py line bootstrap self bootstrap inner file users waylon miniforge envs py sd lib python threading py line bootstrap inner self run file users waylon miniforge envs py sd lib python threading py line run self target self args self kwargs file users waylon stable diffusion webui modules initialize py line load model shared sd model noqa b file users waylon stable diffusion webui modules shared items py line sd model return modules sd models model data get sd model file users waylon stable diffusion webui modules sd models py line get sd model load model file users waylon stable diffusion webui modules sd models py line load model state dict get checkpoint state dict checkpoint info timer file users waylon stable diffusion webui modules sd models py line get checkpoint state dict sd model hash checkpoint info calculate shorthash file users waylon stable diffusion webui modules sd models py line calculate shorthash self sha hashes sha self filename f checkpoint self name file users waylon stable diffusion webui modules hashes py line sha hashes title file users waylon stable diffusion webui venv lib python site packages diskcache core py line setitem self set key value retry true file users waylon stable diffusion webui venv lib python site packages diskcache core py line set self row insert db key raw columns file users waylon stable diffusion webui venv lib python site packages diskcache core py line row insert sql sqlite operationalerror column size string literal single quotes additional information seems ai tools also problem
auto1111_webui,comment,16856,,"the URL to issues you linked is broken so I fixed via editing your post

as of now I'm not able to reproduce the issue
investigate later when I have time",2025-02-20T04:28:42Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670435177,"the URL to issues you linked is broken so I fixed via editing your post

as of now I'm not able to reproduce the issue
investigate later when I have time",url issues linked broken fixed via editing post able reproduce issue investigate later time
auto1111_webui,comment,16856,,"can someone who is experiencing this issue upload their `cache` dir directory in webui root and upload it here
this might help figuring out what's going on
> I belive you would need to compress it into a zip archive

note: by uploaded this you would essentially upload a list of your all your models info (not the actual models just information about the models) and extensions infos, they could potentially be other things as well created by extensions
normally they shouldn't be anything I personally would consider sensitive in it, but if you're not comfortable with someone knowing what models you have or what extensions you're using, don't upload it.
",2025-02-20T08:41:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670814371,"can someone who is experiencing this issue upload their `cache` dir directory in webui root and upload it here
this might help figuring out what's going on
> I belive you would need to compress it into a zip archive

note: by uploaded this you would essentially upload a list of your all your models info (not the actual models just information about the models) and extensions infos, they could potentially be other things as well created by extensions
normally they shouldn't be anything I personally would consider sensitive in it, but if you're not comfortable with someone knowing what models you have or what extensions you're using, don't upload it.",someone experiencing issue upload cache dir directory webui root upload might help figuring going belive would need compress zip archive note uploaded would essentially upload list models info actual models information models extensions infos could potentially things well created extensions normally anything personally would consider sensitive comfortable someone knowing models extensions using upload
auto1111_webui,comment,16856,,"I also experience the same error. ""sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?"". I have extracted the corresponding cache as requested.

[cache.zip](https://github.com/user-attachments/files/18883839/cache.zip)",2025-02-20T09:12:29Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670885243,"I also experience the same error. ""sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?"". I have extracted the corresponding cache as requested.

[cache.zip](https://github.com/user-attachments/files/18883839/cache.zip)",also experience error sqlite operationalerror column size string literal single quotes extracted corresponding cache requested cache zip
auto1111_webui,comment,16856,,"@m-balcewicz 
I looked at your cache and it seems normal (other then it's empty so I'm guessing this is a new installation)
currently I bleive the cache files itself is likely not the issue

can you also share your sysinfo.json
goto: webui setting tab > sysinfo > download sysinfo",2025-02-20T10:21:58Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671067547,"@m-balcewicz 
I looked at your cache and it seems normal (other then it's empty so I'm guessing this is a new installation)
currently I bleive the cache files itself is likely not the issue

can you also share your sysinfo.json
goto: webui setting tab > sysinfo > download sysinfo",balcewicz looked cache seems normal empty guessing new installation currently bleive cache files likely issue also share sysinfo json goto webui setting tab sysinfo download sysinfo
auto1111_webui,comment,16856,,"Yes, you're right. It's a new installation. Here is the sysinfo…

[sysinfo-2025-02-20-10-25.json](https://github.com/user-attachments/files/18884967/sysinfo-2025-02-20-10-25.json)",2025-02-20T10:26:45Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671078997,"Yes, you're right. It's a new installation. Here is the sysinfo…

[sysinfo-2025-02-20-10-25.json](https://github.com/user-attachments/files/18884967/sysinfo-2025-02-20-10-25.json)",yes right new installation sysinfo sysinfo json
auto1111_webui,comment,16856,,"someone have a theroy about sqlite 3.49.1 beeing the issue
I wish to know your sqlite version

you should be about to find out by running these command
1. cd to webui root
for you it should be
```
cd ""/Users/martin/Library/Mobile Documents/com~apple~CloudDocs/MYDATA/CODING_WORLD/GITHUB_WORLD/stable-diffusion-webui""
```

2. activate the venv
```
source venv/bin/activate
```
3. run python and read version
```
python -c ""import sqlite3; print(sqlite3.sqlite_version)""
```
this should out put a version number like 3.49.1 or 3.42.0
",2025-02-20T11:22:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671211067,"someone have a theroy about sqlite 3.49.1 beeing the issue
I wish to know your sqlite version

you should be about to find out by running these command
1. cd to webui root
for you it should be
```
cd ""/Users/martin/Library/Mobile Documents/com~apple~CloudDocs/MYDATA/CODING_WORLD/GITHUB_WORLD/stable-diffusion-webui""
```

2. activate the venv
```
source venv/bin/activate
```
3. run python and read version
```
python -c ""import sqlite3; print(sqlite3.sqlite_version)""
```
this should out put a version number like 3.49.1 or 3.42.0",someone theroy sqlite beeing issue wish know sqlite version find running command cd webui root cd users martin library mobile documents com apple clouddocs mydata coding world github world stable diffusion webui activate venv source venv bin activate run python read version python c import sqlite print sqlite sqlite version put version number like
auto1111_webui,comment,16856,,"Well, this looks fine I guess.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
>> 3.49.1
```",2025-02-20T11:28:00Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671222613,"Well, this looks fine I guess.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
>> 3.49.1
```",well looks fine guess venv martin martins mbp stable diffusion webui python c import sqlite print sqlite sqlite version
auto1111_webui,comment,16856,,"> Well, this looks fine I guess.
> 
> ```
> (venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
> >> 3.49.1
> ```

I think there might be a miscommunication

it is likely that sqlite3 3.49.1 is the cause
base on https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2670889693

3.49.1 was was released around 2 days ago https://www.sqlite.org/changes.html
",2025-02-20T11:36:42Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671241217,"> Well, this looks fine I guess.
> 
> ```
> (venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
> >> 3.49.1
> ```

I think there might be a miscommunication

it is likely that sqlite3 3.49.1 is the cause
base on https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2670889693

3.49.1 was was released around 2 days ago https://www.sqlite.org/changes.html",well looks fine guess venv martin martins mbp stable diffusion webui python c import sqlite print sqlite sqlite version think might miscommunication likely sqlite cause base released around days ago
auto1111_webui,comment,16856,,"I'm not sure how would you do so but maybe you could try downgrading `sqlite` on mac
note: it may not be called `sqlite`",2025-02-20T11:45:58Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671260902,"I'm not sure how would you do so but maybe you could try downgrading `sqlite` on mac
note: it may not be called `sqlite`",sure would maybe could try downgrading sqlite mac note may called sqlite
auto1111_webui,comment,16856,,"It worked out. Now, I am using sqlite 3.42.0.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
3.42.0
```",2025-02-20T12:26:31Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671352257,"It worked out. Now, I am using sqlite 3.42.0.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
3.42.0
```",worked using sqlite venv martin martins mbp stable diffusion webui python c import sqlite print sqlite sqlite version
auto1111_webui,comment,16856,,"seems like it's confirmed to be an issue with sqlite 3.49.1

do you mind testing which version of sqlite works and which doesn't
> I only wrote version 3.42.0 above because my is using this version

also if possible can you write down the instructions on how to downgread on Mac
so that other people can follow your instructions",2025-02-20T12:39:53Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671381528,"seems like it's confirmed to be an issue with sqlite 3.49.1

do you mind testing which version of sqlite works and which doesn't
> I only wrote version 3.42.0 above because my is using this version

also if possible can you write down the instructions on how to downgread on Mac
so that other people can follow your instructions",seems like confirmed issue sqlite mind testing version sqlite works wrote version using version also possible write instructions downgread mac people follow instructions
auto1111_webui,comment,16856,,"I tried to reproduce my error and checked a few settings. 
**Conclusion: sqlite=3.49.1 was no problem, but python=3.12.9 seems to create some errors.** 

I am working with conda environments and use only the conda-forge channel.

The prompt will always be: ""Create an image of the sunrise in the Alpes with a lake in the foreground.""

## sqlite3-42-0
```
conda create --name sqlite3-42-0 python=3.10
conda activate sqlite3-42-0
conda install sqlite=3.42.0
>> 3.42.0 2023-05-16 12:36:15 831d0fb2836b71c9bc51067c49fee4b8f18047814f2ff22d817d25195cf350b0
```
*works fine!*

## sqlite3-43-0
```
conda create --name sqlite3-43-0 python=3.10
conda activate sqlite3-43-0
conda install sqlite=3.43.0
>> 3.43.0 2023-08-24 12:36:59 0f80b798b3f4b81a7bb4233c58294edd0f1156f36b6ecf5ab8e83631d468778c (64-bit)
```
*works fine!*

## sqlite3-44-0
```
conda create --name sqlite3-44-0 python=3.10
conda activate sqlite3-44-0
conda install sqlite=3.44.0
>> 3.44.0 2023-11-01 11:23:50 17129ba1ff7f0daf37100ee82d507aef7827cf38de1866e2633096ae6ad81301 (64-bit)
```
*works fine!

## sqlite3-45-0
```
conda create --name sqlite3-45-0 python=3.10
conda activate sqlite3-45-0
conda install sqlite=3.45
>> 3.45.3 2024-04-15 13:34:05 8653b758870e6ef0c98d46b3ace27849054af85da891eb121e9aaa537f1e8355 (64-bit)
```
*works fine!

## sqlite3-46-0
```
conda create --name sqlite3-46-0 python=3.10
conda activate sqlite3-46-0
conda install sqlite=3.46
>> 3.46.1 2024-08-13 09:16:08 c9c2ab54ba1f5f46360f1b4f35d849cd3f080e6fc2b6c60e91b16c63f69a1e33 (64-bit)
```
*works fine!

## sqlite3-47-0
```
conda create --name sqlite3-47-0 python=3.10
conda activate sqlite3-47-0
conda install sqlite=3.47
>> 3.47.2 2024-12-07 20:39:59 2aabe05e2e8cae4847a802ee2daddc1d7413d8fc560254d93ee3e72c14685b6c (64-bit)
```
*works fine!

## sqlite3-48-0
```
conda create --name sqlite3-48-0 python=3.10
conda activate sqlite3-48-0
conda install sqlite=3.48
>> 3.48.0 2025-01-14 11:05:00 d2fe6b05f38d9d7cd78c5d252e99ac59f1aea071d669830c1ffe4e8966e84010 (64-bit)
```
*works fine!

## sqlite3-49-0
```
conda create --name sqlite3-49-0 python=3.10
conda activate sqlite3-49-0
conda install sqlite=3.49
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!

**The sqlite seems not to be an error during this testing. So I upgraded python.**

## Python Version for sqlite 3-49-0
### Python 3.11
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.11.11
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!*

### Python 3.12
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.12.9
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```

This is what I get when I try to reinstall requirements with python==3.12.9
```
pip install -r requirements.txt
```
```
If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for tokenizers
Failed to build tokenizers
ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)
```


Maybe someone else can go through the different python versions. This is one of the created outputs - enjoy.

![Image](https://github.com/user-attachments/assets/16b1998f-b54f-4796-bf08-4f70dbcfccde)",2025-02-20T14:51:07Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671729533,"I tried to reproduce my error and checked a few settings. 
**Conclusion: sqlite=3.49.1 was no problem, but python=3.12.9 seems to create some errors.** 

I am working with conda environments and use only the conda-forge channel.

The prompt will always be: ""Create an image of the sunrise in the Alpes with a lake in the foreground.""

## sqlite3-42-0
```
conda create --name sqlite3-42-0 python=3.10
conda activate sqlite3-42-0
conda install sqlite=3.42.0
>> 3.42.0 2023-05-16 12:36:15 831d0fb2836b71c9bc51067c49fee4b8f18047814f2ff22d817d25195cf350b0
```
*works fine!*

## sqlite3-43-0
```
conda create --name sqlite3-43-0 python=3.10
conda activate sqlite3-43-0
conda install sqlite=3.43.0
>> 3.43.0 2023-08-24 12:36:59 0f80b798b3f4b81a7bb4233c58294edd0f1156f36b6ecf5ab8e83631d468778c (64-bit)
```
*works fine!*

## sqlite3-44-0
```
conda create --name sqlite3-44-0 python=3.10
conda activate sqlite3-44-0
conda install sqlite=3.44.0
>> 3.44.0 2023-11-01 11:23:50 17129ba1ff7f0daf37100ee82d507aef7827cf38de1866e2633096ae6ad81301 (64-bit)
```
*works fine!

## sqlite3-45-0
```
conda create --name sqlite3-45-0 python=3.10
conda activate sqlite3-45-0
conda install sqlite=3.45
>> 3.45.3 2024-04-15 13:34:05 8653b758870e6ef0c98d46b3ace27849054af85da891eb121e9aaa537f1e8355 (64-bit)
```
*works fine!

## sqlite3-46-0
```
conda create --name sqlite3-46-0 python=3.10
conda activate sqlite3-46-0
conda install sqlite=3.46
>> 3.46.1 2024-08-13 09:16:08 c9c2ab54ba1f5f46360f1b4f35d849cd3f080e6fc2b6c60e91b16c63f69a1e33 (64-bit)
```
*works fine!

## sqlite3-47-0
```
conda create --name sqlite3-47-0 python=3.10
conda activate sqlite3-47-0
conda install sqlite=3.47
>> 3.47.2 2024-12-07 20:39:59 2aabe05e2e8cae4847a802ee2daddc1d7413d8fc560254d93ee3e72c14685b6c (64-bit)
```
*works fine!

## sqlite3-48-0
```
conda create --name sqlite3-48-0 python=3.10
conda activate sqlite3-48-0
conda install sqlite=3.48
>> 3.48.0 2025-01-14 11:05:00 d2fe6b05f38d9d7cd78c5d252e99ac59f1aea071d669830c1ffe4e8966e84010 (64-bit)
```
*works fine!

## sqlite3-49-0
```
conda create --name sqlite3-49-0 python=3.10
conda activate sqlite3-49-0
conda install sqlite=3.49
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!

**The sqlite seems not to be an error during this testing. So I upgraded python.**

## Python Version for sqlite 3-49-0
### Python 3.11
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.11.11
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!*

### Python 3.12
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.12.9
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```

This is what I get when I try to reinstall requirements with python==3.12.9
```
pip install -r requirements.txt
```
```
If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for tokenizers
Failed to build tokenizers
ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)
```


Maybe someone else can go through the different python versions. This is one of the created outputs - enjoy.

![Image](https://github.com/user-attachments/assets/16b1998f-b54f-4796-bf08-4f70dbcfccde)",tried reproduce error checked settings conclusion sqlite problem python seems create errors working conda environments use conda forge channel prompt always create image sunrise alpes lake foreground sqlite conda create name sqlite python conda activate sqlite conda install sqlite fb b c bc c fee b f f ff cf b works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite f b b f b bb c edd f f b ecf ab e c bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite ba ff f daf ee aef cf de e ae ad bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite b e ef c b ace af da eb e aaa f e bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite c c ab ba f f f b f cd f e fc b c e b c f e bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite aabe e e cae ee daddc fc ee e c b c bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite fe b f cd c e ac f aea c ffe e e bit works fine sqlite conda create name sqlite python conda activate sqlite conda install sqlite e b ba c ab c cc c f e bit works fine sqlite seems error testing upgraded python python version sqlite python conda activate sqlite conda install python python e b ba c ab c cc c f e bit works fine python conda activate sqlite conda install python python e b ba c ab c cc c f e bit get try reinstall requirements python pip install r requirements txt intend build package source try installing rust compiler system package manager ensure path installation alternatively rustup available recommended way download update rust compiler toolchain end output note error originates subprocess likely problem pip error failed building wheel tokenizers failed build tokenizers error failed build installable wheels pyproject toml based projects tokenizers maybe someone else go different python versions one created outputs enjoy image
auto1111_webui,comment,16856,,"@m-balcewicz thanks for testing

for your info
according to https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2671431755 `@cocktailpeanut` seems to have found the root cause
but you said `3.4.91` works, so maybe they're are some factors at play, I'm not entirely sure at this point.
either way glad that you got it working

---

as for OP well I'm not sure he hasn't replied...
",2025-02-20T15:15:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671803877,"@m-balcewicz thanks for testing

for your info
according to https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2671431755 `@cocktailpeanut` seems to have found the root cause
but you said `3.4.91` works, so maybe they're are some factors at play, I'm not entirely sure at this point.
either way glad that you got it working

---

as for OP well I'm not sure he hasn't replied...",balcewicz thanks testing info according cocktailpeanut seems found root cause said works maybe factors play entirely sure point either way glad got working op well sure replied
auto1111_webui,comment,16856,,"I had the same issue, I was running sqlite 3.49.1 on python 3.10.16. Downgrading to 3.42.0 solved the issue:

```
The following packages will be DOWNGRADED:

  libsqlite                               3.49.1-h67fdade_1 --> 3.42.0-hcfcfb64_0
  python                         3.10.16-h37870fc_1_cpython --> 3.10.12-h4de0772_0_cpython

```

",2025-02-23T14:59:03Z,iolairus,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2676910082,"I had the same issue, I was running sqlite 3.49.1 on python 3.10.16. Downgrading to 3.42.0 solved the issue:

```
The following packages will be DOWNGRADED:

  libsqlite                               3.49.1-h67fdade_1 --> 3.42.0-hcfcfb64_0
  python                         3.10.16-h37870fc_1_cpython --> 3.10.12-h4de0772_0_cpython

```",issue running sqlite python downgrading solved issue following packages downgraded libsqlite h fdade hcfcfb python h fc cpython h de cpython
auto1111_webui,comment,16856,,"
Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need",2025-02-24T07:22:49Z,KazmaBlack,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2677606835,"Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need",hi im pretty new pinokio forgeui downgrade im using windows feel free ask whatever need
auto1111_webui,comment,16856,,"> Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need

I am using anaconda on windows 11. Within the environment I was using, I ran `conda install sqlite=3.42.0` which resulted in the above prompt, then on confirmation the package was downgraded.",2025-02-24T07:42:14Z,iolairus,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2677637940,"> Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need

I am using anaconda on windows 11. Within the environment I was using, I ran `conda install sqlite=3.42.0` which resulted in the above prompt, then on confirmation the package was downgraded.",hi im pretty new pinokio forgeui downgrade im using windows feel free ask whatever need using anaconda windows within environment using ran conda install sqlite resulted prompt confirmation package downgraded
auto1111_webui,comment,16856,,I ran into the same issue on a fresh install on Windows 10 when installing into a conda environment. Downgrading to 3.42.0 resolves the issue. Seems like the sqllite version needs to be fixed to that version until a PR formally upgrades it.,2025-03-09T18:37:38Z,Ddasch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2709008508,I ran into the same issue on a fresh install on Windows 10 when installing into a conda environment. Downgrading to 3.42.0 resolves the issue. Seems like the sqllite version needs to be fixed to that version until a PR formally upgrades it.,ran issue fresh install windows installing conda environment downgrading resolves issue seems like sqllite version needs fixed version pr formally upgrades
auto1111_webui,comment,16856,,"If you are here because of https://github.com/mateo-cogeanu/local-ai-mac-setup?tab=readme-ov-file instruction, trying to set up things on MacOS, then:

1. open conda shell
```
eval ""$(/Users/$(whoami)/miniforge3/bin/conda shell.zsh hook)""
```
2. switch to 'stable' venv
```
conda activate stable
```
3. install previous stable libsqlite version(NOTE: 3.49.0 is marked as broken and will not work, but 3.48.0 is ok)
```
 conda install libsqlite=3.48.0
```
4. run ```sh webui.sh``` as stated in the initial manual and enjoy",2025-03-10T22:33:44Z,kkulbatskiy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2711996376,"If you are here because of https://github.com/mateo-cogeanu/local-ai-mac-setup?tab=readme-ov-file instruction, trying to set up things on MacOS, then:

1. open conda shell
```
eval ""$(/Users/$(whoami)/miniforge3/bin/conda shell.zsh hook)""
```
2. switch to 'stable' venv
```
conda activate stable
```
3. install previous stable libsqlite version(NOTE: 3.49.0 is marked as broken and will not work, but 3.48.0 is ok)
```
 conda install libsqlite=3.48.0
```
4. run ```sh webui.sh``` as stated in the initial manual and enjoy",instruction trying set things macos open conda shell eval users whoami miniforge bin conda shell zsh hook switch stable venv conda activate stable install previous stable libsqlite version note marked broken work ok conda install libsqlite run sh webui sh stated initial manual enjoy
auto1111_webui,comment,16856,,"I received this error when using diskcache with plotly dash, downgrading sqlite fixed the problem.",2025-03-12T23:34:53Z,aeslaughter,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2719352342,"I received this error when using diskcache with plotly dash, downgrading sqlite fixed the problem.",received error using diskcache plotly dash downgrading sqlite fixed problem
auto1111_webui,comment,16856,,"ONLY for Chinese Users
对于使用绘世启动器，无法通过conda降级的情况，可以通过替换“绘世启动器_path\.ext\pkgs\libsqlite-3.49.1-h67fdade_1\Library\bin”下的dll文件解决

[sqlite3.zip](https://github.com/user-attachments/files/19219843/sqlite3.zip) 来自sqlite3 3.46版本",2025-03-13T01:09:38Z,yamosin,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2719486320,"ONLY for Chinese Users
对于使用绘世启动器，无法通过conda降级的情况，可以通过替换“绘世启动器_path\.ext\pkgs\libsqlite-3.49.1-h67fdade_1\Library\bin”下的dll文件解决

[sqlite3.zip](https://github.com/user-attachments/files/19219843/sqlite3.zip) 来自sqlite3 3.46版本",chinese users conda path ext pkgs libsqlite h fdade library bindll sqlite zip sqlite
auto1111_webui,comment,16856,,绘世启动器可以使用命令端 micromamba  install sqlite=3.42.0 ,2025-03-20T14:02:08Z,lemon123789,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2740565896,绘世启动器可以使用命令端 micromamba  install sqlite=3.42.0,micromamba install sqlite
auto1111_webui,comment,16856,,"在今天, 可以通过升级到 3.49.1 build hee588c1_2 修复, conda-forge团队似乎做了hotfix
As of today, it can be fixed by upgrading to `3.49.1 build hee588c1_2`, it seems conda-forge team fixed it by patch.

`conda install ""libsqlite>=3.49.1=hee588c1_2""`",2025-04-30T08:34:51Z,aploium,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2841229407,"在今天, 可以通过升级到 3.49.1 build hee588c1_2 修复, conda-forge团队似乎做了hotfix
As of today, it can be fixed by upgrading to `3.49.1 build hee588c1_2`, it seems conda-forge team fixed it by patch.

`conda install ""libsqlite>=3.49.1=hee588c1_2""`",build hee c conda forgehotfix today fixed upgrading build hee c seems conda forge team fixed patch conda install libsqlite hee c
auto1111_webui,issue,16854,[Bug]: Inpainting Mask does not support alpha-white pixels (over API),"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Hi guys,
I'm using Inpainting over the API and want to ask if it's possible to transmit a mask with semi-transparent pixels (alpha channel). This would be very useful for my workflow, and maybe it's just a small bug in Auto1111 that could be fixed easily.

A similar request was already made by Physeo, but it was closed without a solution: https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13089

Currently, if I pass a mask with a black background and pixels with an alpha value between 0 and 255, Automatic1111 does not process them correctly. Instead of interpreting semi-transparent areas as a soft mask, it seems to completely invert or overwrite the mask with solid white, affecting the entire image.

Thanks in advance for your answer! And of course, a huge thanks if this could be fixed :-)

### Steps to reproduce the problem

1. Send an image to the Img2Img Inpainting API.
2. Provide a mask with an alpha channel, where some pixels are semi-transparent.
3. Observe that Automatic1111 incorrectly fills or inverts the mask instead of using the alpha values properly.

### What should have happened?

If I pass a mask with a black background and semi-white pixels (Alpha > 0 && Alpha < 255), those pixels should influence the result less than fully opaque (Alpha = 255) areas. The inpainting process should respect the alpha transparency instead of converting the entire mask to solid white.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-02-18-20-45.json](https://github.com/user-attachments/files/18854281/sysinfo-2025-02-18-20-45.json)

### Console logs

```Shell
---
```

### Additional information

_No response_",2025-02-18T20:59:56Z,peterpernhofer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16854,"[Bug]: Inpainting Mask does not support alpha-white pixels (over API) ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Hi guys,
I'm using Inpainting over the API and want to ask if it's possible to transmit a mask with semi-transparent pixels (alpha channel). This would be very useful for my workflow, and maybe it's just a small bug in Auto1111 that could be fixed easily.

A similar request was already made by Physeo, but it was closed without a solution: https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13089

Currently, if I pass a mask with a black background and pixels with an alpha value between 0 and 255, Automatic1111 does not process them correctly. Instead of interpreting semi-transparent areas as a soft mask, it seems to completely invert or overwrite the mask with solid white, affecting the entire image.

Thanks in advance for your answer! And of course, a huge thanks if this could be fixed :-)

### Steps to reproduce the problem

1. Send an image to the Img2Img Inpainting API.
2. Provide a mask with an alpha channel, where some pixels are semi-transparent.
3. Observe that Automatic1111 incorrectly fills or inverts the mask instead of using the alpha values properly.

### What should have happened?

If I pass a mask with a black background and semi-white pixels (Alpha > 0 && Alpha < 255), those pixels should influence the result less than fully opaque (Alpha = 255) areas. The inpainting process should respect the alpha transparency instead of converting the entire mask to solid white.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-02-18-20-45.json](https://github.com/user-attachments/files/18854281/sysinfo-2025-02-18-20-45.json)

### Console logs

```Shell
---
```

### Additional information

_No response_",bug inpainting mask support alpha white pixels api checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently x issue reported fixed yet happened hi guys using inpainting api want ask possible transmit mask semi transparent pixels alpha channel would useful workflow maybe small bug auto could fixed easily similar request already made physeo closed without solution currently pass mask black background pixels alpha value automatic process correctly instead interpreting semi transparent areas soft mask seems completely invert overwrite mask solid white affecting entire image thanks advance answer course huge thanks could fixed steps reproduce problem send image img img inpainting api provide mask alpha channel pixels semi transparent observe automatic incorrectly fills inverts mask instead using alpha values properly happened pass mask black background semi white pixels alpha alpha pixels influence result less fully opaque alpha areas inpainting process respect alpha transparency instead converting entire mask solid white browsers use access ui response sysinfo sysinfo json console logs shell additional information response
auto1111_webui,issue,16850,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i can generate pictures, i have a clean instalattion

### Steps to reproduce the problem

1. I Write Prompt
2. Click on Generate

### What should have happened?

It should have created a picture

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-18-09-57.json](https://github.com/user-attachments/files/18842724/sysinfo-2025-02-18-09-57.json)

### Console logs

```Shell
Traceback (most recent call last):█████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.08it/s]
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1434, in process_api
    data = self.postprocess_data(fn_index, result[""prediction""], state)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1335, in postprocess_data
    prediction_value = block.postprocess(prediction_value)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\components\gallery.py"", line 197, in postprocess
    file_path = str(utils.abspath(file))
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\utils.py"", line 938, in abspath
    if is_symlink or path == path.resolve():  # in case path couldn't be resolved
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 1215, in resolve
    s = self._flavour.resolve(self, strict=strict)
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 215, in resolve
    s = self._ext_to_normal(_getfinalpathname(s))
OSError: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: 'outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917'
```

### Additional information

_No response_",2025-02-18T09:58:06Z,StreamHubHub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16850,"[Bug]: ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i can generate pictures, i have a clean instalattion

### Steps to reproduce the problem

1. I Write Prompt
2. Click on Generate

### What should have happened?

It should have created a picture

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-18-09-57.json](https://github.com/user-attachments/files/18842724/sysinfo-2025-02-18-09-57.json)

### Console logs

```Shell
Traceback (most recent call last):█████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.08it/s]
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1434, in process_api
    data = self.postprocess_data(fn_index, result[""prediction""], state)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1335, in postprocess_data
    prediction_value = block.postprocess(prediction_value)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\components\gallery.py"", line 197, in postprocess
    file_path = str(utils.abspath(file))
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\utils.py"", line 938, in abspath
    if is_symlink or path == path.resolve():  # in case path couldn't be resolved
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 1215, in resolve
    s = self._flavour.resolve(self, strict=strict)
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 215, in resolve
    s = self._ext_to_normal(_getfinalpathname(s))
OSError: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: 'outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917'
```

### Additional information

_No response_",bug checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened generate pictures clean instalattion steps reproduce problem write prompt click generate happened created picture browsers use access ui microsoft edge sysinfo sysinfo json console logs shell traceback recent call last file c users aleja downloads programs ia sd venv lib site packages gradio routes py line run predict output await app get blocks process api file c users aleja downloads programs ia sd venv lib site packages gradio blocks py line process api data self postprocess data fn index result prediction state file c users aleja downloads programs ia sd venv lib site packages gradio blocks py line postprocess data prediction value block postprocess prediction value file c users aleja downloads programs ia sd venv lib site packages gradio components gallery py line postprocess file path str utils abspath file file c users aleja downloads programs ia sd venv lib site packages gradio utils py line abspath symlink path path resolve case path resolved file c users aleja anaconda lib pathlib py line resolve self flavour resolve self strict strict file c users aleja anaconda lib pathlib py line resolve self ext normal getfinalpathname oserror winerror el nombre de archivo el nombre de directorio la sintaxis de la etiqueta del volumen son correctos outputs txt img images png additional information response
auto1111_webui,comment,16850,,"I believe the image is currently generated and saved to `outputs\txt2img-images\2025-02-18\00002-1888406001.png`
the issue occurs when it's trying to send the image to the browser

from what I can tell the cause is for some reason on your computer
```py
from pathlib import Path
Path('outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917').resolve()
```
this errors, as a result preventing it from being displayed in the browser
> this works on other computers I have tested

unfortunately I wasn't able to reproduce the issue even using python 3.9.13
I suspect there's something ""different"" at the low level on your computer but I'm not sure what's going on

I would suggest you try python 3.10
or try using our standalone package see [wiki Windows (method 1)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) ",2025-02-19T03:54:10Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16850#issuecomment-2667448136,"I believe the image is currently generated and saved to `outputs\txt2img-images\2025-02-18\00002-1888406001.png`
the issue occurs when it's trying to send the image to the browser

from what I can tell the cause is for some reason on your computer
```py
from pathlib import Path
Path('outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917').resolve()
```
this errors, as a result preventing it from being displayed in the browser
> this works on other computers I have tested

unfortunately I wasn't able to reproduce the issue even using python 3.9.13
I suspect there's something ""different"" at the low level on your computer but I'm not sure what's going on

I would suggest you try python 3.10
or try using our standalone package see [wiki Windows (method 1)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1)",believe image currently generated saved outputs txt img images png issue occurs trying send image browser tell cause reason computer py pathlib import path path outputs txt img images png resolve errors result preventing displayed browser works computers tested unfortunately able reproduce issue even using python suspect something different low level computer sure going would suggest try python try using standalone package see wiki windows method
auto1111_webui,issue,16847,[Bug]: ERROR: Could not find a version that satisfies the requirement torch==2.3.1 (from versions: 2.6.0),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

While trying to get webui working on my AMD Ryzen 9 7950x, I kept running into the same error everytime I tried to run the `webui-user.bat` that the install guide had as one of the steps. I saw the part that said

> If it looks like it is stuck when installing or running, press enter in the terminal and it should continue.

In my head though, it would be more of a frozen terminal which we've all seen plenty of times. Instead it filled the window with errors complaining about not being able to install torch. I tried everything to get the right version of torch installed, even tried 3 different python versions. Right as I was about to give up, I accidentally mistyped while the `webui-user.bat` window was focused, and it sprang back to life. 

I understand if this bug is hard to track down or something, I'm a dev myself, but the wording on the installation guide **needs** to be more descriptive/clear. At least put something mentioning that it ""freezing"" is actually it acting like it failed with errors.

![Image](https://github.com/user-attachments/assets/cd8b251a-41a1-410b-bb88-f373216f5065)

### Steps to reproduce the problem

1. Install Python 3.10.6
2. Clone the repo: `git clone https://github.com/lshqqytiger/stable-diffusion-webui-directml && cd stable-diffusion-webui-directml && git submodule init && git submodule update`
3. Run `webui-user.bat`
4. Assume installation has failed, because it indicated so

### What should have happened?

It should've just continued on with the installation process, after it provided the warnings and errors as opposed to just sitting there waiting on input.

### What browsers do you use to access the UI ?

Other

### Sysinfo

[sys.txt](https://github.com/user-attachments/files/18814926/sys.txt)

### Console logs

```Shell
webui-user.bat
```

### Additional information

_No response_",2025-02-16T14:09:28Z,lukecp5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16847,"[Bug]: ERROR: Could not find a version that satisfies the requirement torch==2.3.1 (from versions: 2.6.0) ### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

While trying to get webui working on my AMD Ryzen 9 7950x, I kept running into the same error everytime I tried to run the `webui-user.bat` that the install guide had as one of the steps. I saw the part that said

> If it looks like it is stuck when installing or running, press enter in the terminal and it should continue.

In my head though, it would be more of a frozen terminal which we've all seen plenty of times. Instead it filled the window with errors complaining about not being able to install torch. I tried everything to get the right version of torch installed, even tried 3 different python versions. Right as I was about to give up, I accidentally mistyped while the `webui-user.bat` window was focused, and it sprang back to life. 

I understand if this bug is hard to track down or something, I'm a dev myself, but the wording on the installation guide **needs** to be more descriptive/clear. At least put something mentioning that it ""freezing"" is actually it acting like it failed with errors.

![Image](https://github.com/user-attachments/assets/cd8b251a-41a1-410b-bb88-f373216f5065)

### Steps to reproduce the problem

1. Install Python 3.10.6
2. Clone the repo: `git clone https://github.com/lshqqytiger/stable-diffusion-webui-directml && cd stable-diffusion-webui-directml && git submodule init && git submodule update`
3. Run `webui-user.bat`
4. Assume installation has failed, because it indicated so

### What should have happened?

It should've just continued on with the installation process, after it provided the warnings and errors as opposed to just sitting there waiting on input.

### What browsers do you use to access the UI ?

Other

### Sysinfo

[sys.txt](https://github.com/user-attachments/files/18814926/sys.txt)

### Console logs

```Shell
webui-user.bat
```

### Additional information

_No response_",bug error could find version satisfies requirement torch versions checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui issue exists current version webui issue reported recently x issue reported fixed yet happened trying get webui working amd ryzen x kept running error everytime tried run webui user bat install guide one steps saw part said looks like stuck installing running press enter terminal continue head though would frozen terminal seen plenty times instead filled window errors complaining able install torch tried everything get right version torch installed even tried different python versions right give accidentally mistyped webui user bat window focused sprang back life understand bug hard track something dev wording installation guide needs descriptive clear least put something mentioning freezing actually acting like failed errors image steps reproduce problem install python clone repo git clone cd stable diffusion webui directml git submodule init git submodule update run webui user bat assume installation failed indicated happened continued installation process provided warnings errors opposed sitting waiting input browsers use access ui sysinfo sys txt console logs shell webui user bat additional information response
auto1111_webui,comment,16847,,"well you may have installed python 3.10
but because your also have python 3.13.1 installed and have it set as default
it will use the default unless told otherwise

to fix this you should
1. delete venv dir (in your webui root)
2. then edit `webui-user.bat` -> `set PYTHON=<path to your python 3.10 exe>`
3. run again


~~alternatively you could use [method 1 see wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) it comes with python instide, which means it doesn't care about whether or not you have install python on your system~~
this does not apply to you because you're on a AMD card
I don't know whether or not if the AMD fork has a standalone package similar to us

---

looks like your have a AMD Radeon RX 7800 XT
and your are using https://github.com/lshqqytiger/stable-diffusion-webui-directml
so if it still doesn't work after following the above instructions, you should report your issues to the fork
> I believe they have different installation instructions

---

okay I'm not entire show what's going on with your installation logs now
the first section which they error happens is on python 3.13
but it is Then followed by exception that I'm not sure has succeed or not using python 3.10

with an error of `it's not recognized as a internal or external command`

I'm going to take a guess did you edit `webui-user.bat while `webui-user.bat is being executed

don't quote me on this but if I understand things correct
windows batch script is is is read from storage line by line during runtime
which means if you edit the file while the file is being used some strange behaviors can occur
> different from most other languages that I'm aware of that reads the entire script into memory on load

this may be the cause of
>  it sprang back to life.


you can try this if you want, save this as a `.bat` and run it, edit the file well it is being used
```bat
echo 1 edit the line echo 2 and echo 3 and save, then press any key to continue
pause
echo 2 edit me while paused
pause
echo 3 edit me while paused
pause
```
",2025-02-16T14:55:49Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16847#issuecomment-2661468146,"well you may have installed python 3.10
but because your also have python 3.13.1 installed and have it set as default
it will use the default unless told otherwise

to fix this you should
1. delete venv dir (in your webui root)
2. then edit `webui-user.bat` -> `set PYTHON=<path to your python 3.10 exe>`
3. run again


~~alternatively you could use [method 1 see wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) it comes with python instide, which means it doesn't care about whether or not you have install python on your system~~
this does not apply to you because you're on a AMD card
I don't know whether or not if the AMD fork has a standalone package similar to us

---

looks like your have a AMD Radeon RX 7800 XT
and your are using https://github.com/lshqqytiger/stable-diffusion-webui-directml
so if it still doesn't work after following the above instructions, you should report your issues to the fork
> I believe they have different installation instructions

---

okay I'm not entire show what's going on with your installation logs now
the first section which they error happens is on python 3.13
but it is Then followed by exception that I'm not sure has succeed or not using python 3.10

with an error of `it's not recognized as a internal or external command`

I'm going to take a guess did you edit `webui-user.bat while `webui-user.bat is being executed

don't quote me on this but if I understand things correct
windows batch script is is is read from storage line by line during runtime
which means if you edit the file while the file is being used some strange behaviors can occur
> different from most other languages that I'm aware of that reads the entire script into memory on load

this may be the cause of
>  it sprang back to life.


you can try this if you want, save this as a `.bat` and run it, edit the file well it is being used
```bat
echo 1 edit the line echo 2 and echo 3 and save, then press any key to continue
pause
echo 2 edit me while paused
pause
echo 3 edit me while paused
pause
```",well may installed python also python installed set default use default unless told otherwise fix delete venv dir webui root edit webui user bat set python path python exe run alternatively could use method see wiki comes python instide means care whether install python system apply amd card know whether amd fork standalone package similar us looks like amd radeon rx xt using still work following instructions report issues fork believe different installation instructions okay entire show going installation logs first section error happens python followed exception sure succeed using python error recognized internal external command going take guess edit webui user bat webui user bat executed quote understand things correct windows batch script read storage line line runtime means edit file file used strange behaviors occur different languages aware reads entire script memory load may cause sprang back life try want save bat run edit file well used bat echo edit line echo echo save press key continue pause echo edit paused pause echo edit paused pause
auto1111_webui,issue,16843,[Bug]: stable diffusion not using gpu,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When using stable diffusion, the gpu of my rtx 3060 is not used, and when opening task manager, it does not appear when extracting images that it is being used ,, I want to use the gpu more since I have 12 GB of vram
Is there a solution to using the gpu so that I can appreciate the fastest image extraction process ؟

![Image](https://github.com/user-attachments/assets/3e7a7702-b414-4740-865e-0280eebb377f)

### Steps to reproduce the problem

1

### What should have happened?

1

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

1

### Console logs

```Shell
1
```

### Additional information

1",2025-02-14T23:45:26Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843,"[Bug]: stable diffusion not using gpu ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When using stable diffusion, the gpu of my rtx 3060 is not used, and when opening task manager, it does not appear when extracting images that it is being used ,, I want to use the gpu more since I have 12 GB of vram
Is there a solution to using the gpu so that I can appreciate the fastest image extraction process ؟

![Image](https://github.com/user-attachments/assets/3e7a7702-b414-4740-865e-0280eebb377f)

### Steps to reproduce the problem

1

### What should have happened?

1

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

1

### Console logs

```Shell
1
```

### Additional information

1",bug stable diffusion using gpu checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened using stable diffusion gpu rtx used opening task manager appear extracting images used want use gpu since gb vram solution using gpu appreciate fastest image extraction process image steps reproduce problem happened browsers use access ui response sysinfo console logs shell additional information
auto1111_webui,comment,16843,,"> when opening task manager, it does not appear when extracting images that it is being used

task manager not showing GPU 3D activity is could be normal
> seems to be related to the driver version

most likely it's using GPU but you just don't realize it

> assuming that the screenshot was taken immediately after the image generation finishes

if your instance is indeed NOT using GPU then it should be using CPU, but as you can see there is not spike in CPU activity, so it's most likely using GPU

your post does not contain any other information that would indicate whether or not it is using GPU
no sysinfo.json no logs no time takes to complet the job

if you wish someone to look into this further provide more information",2025-02-15T03:49:57Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2660703232,"> when opening task manager, it does not appear when extracting images that it is being used

task manager not showing GPU 3D activity is could be normal
> seems to be related to the driver version

most likely it's using GPU but you just don't realize it

> assuming that the screenshot was taken immediately after the image generation finishes

if your instance is indeed NOT using GPU then it should be using CPU, but as you can see there is not spike in CPU activity, so it's most likely using GPU

your post does not contain any other information that would indicate whether or not it is using GPU
no sysinfo.json no logs no time takes to complet the job

if you wish someone to look into this further provide more information",opening task manager appear extracting images used task manager showing gpu activity could normal seems related driver version likely using gpu realize assuming screenshot taken immediately image generation finishes instance indeed using gpu using cpu see spike cpu activity likely using gpu post contain information would indicate whether using gpu sysinfo json logs time takes complet job wish someone look provide information
auto1111_webui,comment,16843,,"
> your post does not contain any other information that would indicate whether or not it is using GPU no sysinfo.json no logs no time takes to complet the job
> 
> if you wish someone to look into this further provide more information

how could i contain the log ,, through terminal screen ? 
@w-e-w 

",2025-02-15T18:23:12Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661034407,"> your post does not contain any other information that would indicate whether or not it is using GPU no sysinfo.json no logs no time takes to complet the job
> 
> if you wish someone to look into this further provide more information

how could i contain the log ,, through terminal screen ? 
@w-e-w",post contain information would indicate whether using gpu sysinfo json logs time takes complet job wish someone look provide information could contain log terminal screen w e w
auto1111_webui,comment,16843,,"![Image](https://github.com/user-attachments/assets/b9d60fca-b2a2-46d0-beea-2e2d0f4596e7)
@w-e-w  
is this log ? ",2025-02-15T18:30:32Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661037453,"![Image](https://github.com/user-attachments/assets/b9d60fca-b2a2-46d0-beea-2e2d0f4596e7)
@w-e-w  
is this log ?",image w e w log
auto1111_webui,comment,16843,,"I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 
the speed is around 0.28 it/s

assuming that you're generating with similar settings
3.8 it/s is 13 times faster then 0.28 it/s

you are using GPU",2025-02-15T22:29:11Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661130257,"I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 
the speed is around 0.28 it/s

assuming that you're generating with similar settings
3.8 it/s is 13 times faster then 0.28 it/s

you are using GPU",k cpu use cpu generating x image sd speed around assuming generating similar settings times faster using gpu
auto1111_webui,comment,16843,,"> I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 the speed is around 0.28 it/s
> 
> assuming that you're generating with similar settings 3.8 it/s is 13 times faster then 0.28 it/s
> 
> you are using GPU


@w-e-w  but it's not show on my GPU in task manager ,, why ? ",2025-02-19T12:50:51Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2668564610,"> I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 the speed is around 0.28 it/s
> 
> assuming that you're generating with similar settings 3.8 it/s is 13 times faster then 0.28 it/s
> 
> you are using GPU


@w-e-w  but it's not show on my GPU in task manager ,, why ?",k cpu use cpu generating x image sd speed around assuming generating similar settings times faster using gpu w e w show gpu task manager
auto1111_webui,comment,16843,,"> but it's not show on my GPU in task manager ,, why ?

I don't know why GPU activity in task manager is broken
I have my guesses but I don't have any actual proof If those guesses are true
if you want a definitive answer you have to look somewhere else

---

my guess on why task manager does not show the acture load activity in 3D field is purely based on my observations and should not be taken as fact

I believe the 3D activity in task manager only shows when there is some accompanying graphical activity and not just CUDA

the reason of my speculation

my laptop with a discrete GPU (dGPU) GTX 1650, with a Intel internal GPU (iGPU)
the laptop display connect to the iGPU
so the main GPU is the iGPU which handles most of the light weight rendering tasks
the dGPU is only used for heavy tasks such as 3D applications such as games or for CUDA taks such as stable diffusion, the GPU is ""off"" most of the time

the task manager displays 3D activity, which most likely means that they will be some graphical output of some type
when running games it seems to work
but when running stable diffusion which doesn't have a graphical output so I think task manager decides to ignore it
> note by ""task manager"" I'm referring to itself and its dependencies on how it retrieves information such as drivers not just task manager alone

this hypothesis is strengthened by the testing on my main PC, which has a 3090 and iGPU
if I plug my monitors on the dGPU, the 3D activity inside task managner seems to correspond to stable diffusion
but if I plug my monitors on the iGPU (meaning that lightweight tasks suach as desktop rendering are performed by iGPU and dGPU is ""off"" most of the time), when running stable diffusion the task managner only spikes for a brief moment at the beginning of the job then drops to 0%, even though clearly that the dGPU is working

---

a long time ago (possibly 6~9 years ago) I recall there used to be a dedicated CUDA graph in task manager
I think it got removed either by driver update or something

---

I suggest you use HWiNFO if you want to see more reliable GPU activity ",2025-02-19T14:07:14Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2668761592,"> but it's not show on my GPU in task manager ,, why ?

I don't know why GPU activity in task manager is broken
I have my guesses but I don't have any actual proof If those guesses are true
if you want a definitive answer you have to look somewhere else

---

my guess on why task manager does not show the acture load activity in 3D field is purely based on my observations and should not be taken as fact

I believe the 3D activity in task manager only shows when there is some accompanying graphical activity and not just CUDA

the reason of my speculation

my laptop with a discrete GPU (dGPU) GTX 1650, with a Intel internal GPU (iGPU)
the laptop display connect to the iGPU
so the main GPU is the iGPU which handles most of the light weight rendering tasks
the dGPU is only used for heavy tasks such as 3D applications such as games or for CUDA taks such as stable diffusion, the GPU is ""off"" most of the time

the task manager displays 3D activity, which most likely means that they will be some graphical output of some type
when running games it seems to work
but when running stable diffusion which doesn't have a graphical output so I think task manager decides to ignore it
> note by ""task manager"" I'm referring to itself and its dependencies on how it retrieves information such as drivers not just task manager alone

this hypothesis is strengthened by the testing on my main PC, which has a 3090 and iGPU
if I plug my monitors on the dGPU, the 3D activity inside task managner seems to correspond to stable diffusion
but if I plug my monitors on the iGPU (meaning that lightweight tasks suach as desktop rendering are performed by iGPU and dGPU is ""off"" most of the time), when running stable diffusion the task managner only spikes for a brief moment at the beginning of the job then drops to 0%, even though clearly that the dGPU is working

---

a long time ago (possibly 6~9 years ago) I recall there used to be a dedicated CUDA graph in task manager
I think it got removed either by driver update or something

---

I suggest you use HWiNFO if you want to see more reliable GPU activity",show gpu task manager know gpu activity task manager broken guesses actual proof guesses true want definitive answer look somewhere else guess task manager show acture load activity field purely based observations taken fact believe activity task manager shows accompanying graphical activity cuda reason speculation laptop discrete gpu dgpu gtx intel internal gpu igpu laptop display connect igpu main gpu igpu handles light weight rendering tasks dgpu used heavy tasks applications games cuda taks stable diffusion gpu time task manager displays activity likely means graphical output type running games seems work running stable diffusion graphical output think task manager decides ignore note task manager referring dependencies retrieves information drivers task manager alone hypothesis strengthened testing main pc igpu plug monitors dgpu activity inside task managner seems correspond stable diffusion plug monitors igpu meaning lightweight tasks suach desktop rendering performed igpu dgpu time running stable diffusion task managner spikes brief moment beginning job drops even though clearly dgpu working long time ago possibly years ago recall used dedicated cuda graph task manager think got removed either driver update something suggest use hwinfo want see reliable gpu activity
auto1111_webui,comment,16843,,"
> 
> [@w-e-w](https://github.com/w-e-w) but it's not show on my GPU in task manager ,, why ?

Use the dropdown and pick cuda. You're welcome.

https://gyazo.com/5790f142cd4f10308043dab0604ac709",2025-02-21T08:41:42Z,TheVertexDoctor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2673924147,"> 
> [@w-e-w](https://github.com/w-e-w) but it's not show on my GPU in task manager ,, why ?

Use the dropdown and pick cuda. You're welcome.

https://gyazo.com/5790f142cd4f10308043dab0604ac709",w e w show gpu task manager use dropdown pick cuda welcome
auto1111_webui,comment,16843,,"> Use the dropdown and pick cuda. You're welcome.

well I did mention that there is CUDA in task manager but it's just not showing on lots of systems for some reason
this has been something that has been bothering me for lots of years

found one answer today that checks out on my system
https://answers.microsoft.com/en-us/windows/forum/all/cuda-not-in-task-manager/a65eed92-828f-4d92-b9c9-cb2666bdd87f

it turns out it's apparently has something to do with `Hardware-accelerated GPU scheduling (HAGS)` 

with HAGS on CUDA and lots of other graphs don't show
| On | Off |
|--------|--------|
| ![Image](https://github.com/user-attachments/assets/86f3e5ca-4380-4bc7-b43b-7b5dee976973) | ![Image](https://github.com/user-attachments/assets/0c44ed13-ce35-40c7-bde6-37d1ba43028a) | 

---

note 1: they could factors other then HAGS that enable of disable thoses graphs

note 2: this is not a recommendation to turn HAGS on or off
some claims that enabling it helps performance while others claim the contrary
",2025-02-21T10:53:31Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2674227716,"> Use the dropdown and pick cuda. You're welcome.

well I did mention that there is CUDA in task manager but it's just not showing on lots of systems for some reason
this has been something that has been bothering me for lots of years

found one answer today that checks out on my system
https://answers.microsoft.com/en-us/windows/forum/all/cuda-not-in-task-manager/a65eed92-828f-4d92-b9c9-cb2666bdd87f

it turns out it's apparently has something to do with `Hardware-accelerated GPU scheduling (HAGS)` 

with HAGS on CUDA and lots of other graphs don't show
| On | Off |
|--------|--------|
| ![Image](https://github.com/user-attachments/assets/86f3e5ca-4380-4bc7-b43b-7b5dee976973) | ![Image](https://github.com/user-attachments/assets/0c44ed13-ce35-40c7-bde6-37d1ba43028a) | 

---

note 1: they could factors other then HAGS that enable of disable thoses graphs

note 2: this is not a recommendation to turn HAGS on or off
some claims that enabling it helps performance while others claim the contrary",use dropdown pick cuda welcome well mention cuda task manager showing lots systems reason something bothering lots years found one answer today checks system turns apparently something hardware accelerated gpu scheduling hags hags cuda lots graphs show image image note could factors hags enable disable thoses graphs note recommendation turn hags claims enabling helps performance others claim contrary
auto1111_webui,comment,16843,,"AH I see. I have HAGS off, never felt i needed it as I have a 3090 and really haven't had any issues.
",2025-02-21T13:27:16Z,TheVertexDoctor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2674553509,"AH I see. I have HAGS off, never felt i needed it as I have a 3090 and really haven't had any issues.",ah see hags never felt needed really issues
auto1111_webui,issue,16810,[Bug]: I can't install xFormers,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i just want to install xformers for make faster images on StableDiffusion but i cant, no matter what i do i cant generate anything

### Steps to reproduce the problem

1. --xformers in webui-user.sh
2. generate a image

### What should have happened?

Xformers should be build for Cuda support

### What browsers do you use to access the UI ?

Other

### Sysinfo

RTX 3060TI
64gb ram

### Console logs

```Shell
raise NotImplementedError(msg)
    NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:
         query       : shape=(2, 1024, 10, 64) (torch.float32)
         key         : shape=(2, 1024, 10, 64) (torch.float32)
         value       : shape=(2, 1024, 10, 64) (torch.float32)
         attn_bias   : <class 'NoneType'>
         p           : 0.0
    `decoderF` is not supported because:
        xFormers wasn't build with CUDA support
        attn_bias type is <class 'NoneType'>
        operator wasn't built - see `python -m xformers.info` for more info
    `flshattF@0.0.0` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
    `tritonflashattF` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
        triton is not available
    `cutlassF` is not supported because:
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
    `smallkF` is not supported because:
        max(query.shape[-1] != value.shape[-1]) > 32
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
        unsupported embed per head: 64
```

### Additional information

NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs: query : shape=(2, 1024, 10, 64) (torch.float32) key : shape=(2, 1024, 10, 64) (torch.float32) value : shape=(2, 1024, 10, 64) (torch.float32) attn_bias : <class 'NoneType'> p : 0.0 `decoderF` is not supported because: xFormers wasn't build with CUDA support attn_bias type is <class 'NoneType'> operator wasn't built - see `python -m xformers.info` for more info `flshattF@0.0.0` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info `tritonflashattF` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info triton is not available `cutlassF` is not supported because: xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info `smallkF` is not supported because: max(query.shape[-1] != value.shape[-1]) > 32 xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info unsupported embed per head: 64

(Stable Diffusion)",2025-01-26T22:27:23Z,Franches13,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16810,"[Bug]: I can't install xFormers ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i just want to install xformers for make faster images on StableDiffusion but i cant, no matter what i do i cant generate anything

### Steps to reproduce the problem

1. --xformers in webui-user.sh
2. generate a image

### What should have happened?

Xformers should be build for Cuda support

### What browsers do you use to access the UI ?

Other

### Sysinfo

RTX 3060TI
64gb ram

### Console logs

```Shell
raise NotImplementedError(msg)
    NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:
         query       : shape=(2, 1024, 10, 64) (torch.float32)
         key         : shape=(2, 1024, 10, 64) (torch.float32)
         value       : shape=(2, 1024, 10, 64) (torch.float32)
         attn_bias   : <class 'NoneType'>
         p           : 0.0
    `decoderF` is not supported because:
        xFormers wasn't build with CUDA support
        attn_bias type is <class 'NoneType'>
        operator wasn't built - see `python -m xformers.info` for more info
    `flshattF@0.0.0` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
    `tritonflashattF` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
        triton is not available
    `cutlassF` is not supported because:
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
    `smallkF` is not supported because:
        max(query.shape[-1] != value.shape[-1]) > 32
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
        unsupported embed per head: 64
```

### Additional information

NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs: query : shape=(2, 1024, 10, 64) (torch.float32) key : shape=(2, 1024, 10, 64) (torch.float32) value : shape=(2, 1024, 10, 64) (torch.float32) attn_bias : <class 'NoneType'> p : 0.0 `decoderF` is not supported because: xFormers wasn't build with CUDA support attn_bias type is <class 'NoneType'> operator wasn't built - see `python -m xformers.info` for more info `flshattF@0.0.0` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info `tritonflashattF` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info triton is not available `cutlassF` is not supported because: xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info `smallkF` is not supported because: max(query.shape[-1] != value.shape[-1]) > 32 xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info unsupported embed per head: 64

(Stable Diffusion)",bug install xformers checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened want install xformers make faster images stablediffusion cant matter cant generate anything steps reproduce problem xformers webui user sh generate image happened xformers build cuda support browsers use access ui sysinfo rtx ti gb ram console logs shell raise notimplementederror msg notimplementederror operator found memory efficient attention forward inputs query shape torch float key shape torch float value shape torch float attn bias class nonetype p decoderf supported xformers build cuda support attn bias type class nonetype operator built see python xformers info info flshattf supported xformers build cuda support dtype torch float supported torch float torch bfloat operator built see python xformers info info tritonflashattf supported xformers build cuda support dtype torch float supported torch float torch bfloat operator built see python xformers info info triton available cutlassf supported xformers build cuda support operator built see python xformers info info smallkf supported max query shape value shape xformers build cuda support operator built see python xformers info info unsupported embed per head additional information notimplementederror operator found memory efficient attention forward inputs query shape torch float key shape torch float value shape torch float attn bias class nonetype p decoderf supported xformers build cuda support attn bias type class nonetype operator built see python xformers info info flshattf supported xformers build cuda support dtype torch float supported torch bfloat torch float operator built see python xformers info info tritonflashattf supported xformers build cuda support dtype torch float supported torch bfloat torch float operator built see python xformers info info triton available cutlassf supported xformers build cuda support operator built see python xformers info info smallkf supported max query shape value shape xformers build cuda support operator built see python xformers info info unsupported embed per head stable diffusion
auto1111_webui,comment,16810,,"> I can't install xFormers

I don't believe that's the case ""xformers wasn't build with CUDA support""
if it isn't installed then it will be a completely different error message
I believe it is installed just not correctly

I may have seen similar error messages cause by a a miss match of version between xformers and pytorch
if you want people to actually help you then you would want to provide your sysinfo
> sysinfo is a json file generated by web UI, not two lines, read the issue template instructions

---

because you did not provide sysinfo, the following is pure guesswork
my guess some distro of linux with python 3.12~ as default, irrc the default pytorch that the default version we use is not support on 3.12 and so you install a new version manually
then you use `--xformers` which by default installs a version of xformers meant for the old version of pytorch

if my guess is correct then I will try 
I will try installing xformers yourself manually, overriding what web UI does automatically
or install an old version of python, 3.11 or 3.10 then run web ui usin it",2025-02-04T17:57:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16810#issuecomment-2634687587,"> I can't install xFormers

I don't believe that's the case ""xformers wasn't build with CUDA support""
if it isn't installed then it will be a completely different error message
I believe it is installed just not correctly

I may have seen similar error messages cause by a a miss match of version between xformers and pytorch
if you want people to actually help you then you would want to provide your sysinfo
> sysinfo is a json file generated by web UI, not two lines, read the issue template instructions

---

because you did not provide sysinfo, the following is pure guesswork
my guess some distro of linux with python 3.12~ as default, irrc the default pytorch that the default version we use is not support on 3.12 and so you install a new version manually
then you use `--xformers` which by default installs a version of xformers meant for the old version of pytorch

if my guess is correct then I will try 
I will try installing xformers yourself manually, overriding what web UI does automatically
or install an old version of python, 3.11 or 3.10 then run web ui usin it",install xformers believe case xformers build cuda support installed completely different error message believe installed correctly may seen similar error messages cause miss match version xformers pytorch want people actually help would want provide sysinfo sysinfo json file generated web ui two lines read issue template instructions provide sysinfo following pure guesswork guess distro linux python default irrc default pytorch default version use support install new version manually use xformers default installs version xformers meant old version pytorch guess correct try try installing xformers manually overriding web ui automatically install old version python run web ui usin
auto1111_webui,issue,16809,"[Bug]: random crash with ""press any key to continue""","### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i get a random crash with no error other than ""Press any key to continue..."" popping up, it seems to happen regardless of extensions being active or not, it happens at completely random times (even with zero activity with the program) but much more often during startup or generation. 

### Steps to reproduce the problem

random

### What should have happened?

shoudnt crash

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-01-25-00-25.json](https://github.com/user-attachments/files/18544173/sysinfo-2025-01-25-00-25.json)

### Console logs

```Shell
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers --ckpt-dir 'J:\Ai\checkpoint' --embeddings-dir 'J:\Ai\embeddings' --autolaunch
*** ""Disable all extensions"" option was set, will only load built-in extensions ***
Press any key to continue . . .
```

### Additional information

_No response_",2025-01-25T00:26:22Z,cain666-4u,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809,"[Bug]: random crash with ""press any key to continue"" ### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i get a random crash with no error other than ""Press any key to continue..."" popping up, it seems to happen regardless of extensions being active or not, it happens at completely random times (even with zero activity with the program) but much more often during startup or generation. 

### Steps to reproduce the problem

random

### What should have happened?

shoudnt crash

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-01-25-00-25.json](https://github.com/user-attachments/files/18544173/sysinfo-2025-01-25-00-25.json)

### Console logs

```Shell
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers --ckpt-dir 'J:\Ai\checkpoint' --embeddings-dir 'J:\Ai\embeddings' --autolaunch
*** ""Disable all extensions"" option was set, will only load built-in extensions ***
Press any key to continue . . .
```

### Additional information

_No response_",bug random crash press key continue checklist x issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened get random crash error press key continue popping seems happen regardless extensions active happens completely random times even zero activity program much often startup generation steps reproduce problem random happened shoudnt crash browsers use access ui response sysinfo sysinfo json console logs shell venv j ai stable diffusion webui venv scripts python exe python tags v cc apr msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments xformers ckpt dir j ai checkpoint embeddings dir j ai embeddings autolaunch disable extensions option set load built extensions press key continue additional information response
auto1111_webui,comment,16809,,"i tried a fresh install of both auto1111 and python, and got this during install:

> Creating venv in directory J:\Ai\stable-diffusion-webui\venv using python ""C:\Users\cain6\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe""
Requirement already satisfied: pip in j:\ai\stable-diffusion-webui\venv\lib\site-packages (23.0.1)
Collecting pip
  Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.0.1
    Uninstalling pip-23.0.1:
      Successfully uninstalled pip-23.0.1
Successfully installed pip-24.3.1
WARNING: There was an error checking the latest version of pip.
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting numpy (from torchvision==0.16.2)
  Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Downloading filelock-3.17.0-py3-none-any.whl (16 kB)
Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)
Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl (12.9 MB)
   --------------------------- 12.9/12.9 MB 8.5 MB/s eta 0:00:00
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)
Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
ERROR: Error while checking for conflicts. Please file an issue on pip's issue tracker: https://github.com/pypa/pip/issues/new
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\commands\install.py"", line 584, in _determine_conflicts
    return check_install_conflicts(to_install)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 119, in check_install_conflicts
    would_be_installed = _simulate_installation_of(to_install, package_set)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 158, in _simulate_installation_of
    dist = abstract_dist.get_metadata_distribution()
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\distributions\wheel.py"", line 34, in get_metadata_distribution
    return get_wheel_distribution(wheel, canonicalize_name(self.req.name))
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\__init__.py"", line 106, in get_wheel_distribution
    return select_backend().Distribution.from_wheel(wheel, canonical_name)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\pkg_resources.py"", line 139, in from_wheel
    with wheel.as_zipfile() as zf:
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\base.py"", line 679, in as_zipfile
    return zipfile.ZipFile(self.location, allowZip64=True)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1269, in __init__
    self._RealGetContents()
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1391, in _RealGetContents
    x.date_time = ( (d>>9)+1980, (d>>5)&0xF, d&0x1F,
TypeError: unsupported operand type(s) for >>: 'ZipInfo' and 'int'
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2024.12.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
Installing clip
Installing open_clip
Cloning assets into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.98 MiB/s, done.
Cloning Stable Diffusion into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 2)
Receiving objects: 100% (580/580), 73.44 MiB | 8.33 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into J:\Ai\stable-diffusion-webui\repositories\generative-models...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (57/57), done.
remote: Compressing objects: 100% (29/29), done.
remote: Total 1064 (delta 35), reused 28 (delta 28), pack-reused 1007 (from 3)
Receiving objects: 100% (1064/1064), 53.61 MiB | 7.16 MiB/s, done.
Resolving deltas: 100% (544/544), done.
Cloning K-diffusion into J:\Ai\stable-diffusion-webui\repositories\k-diffusion...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (651/651), done.
remote: Compressing objects: 100% (87/87), done.
remote: Total 1350 (delta 608), reused 566 (delta 564), pack-reused 699 (from 1)
Receiving objects: 100% (1350/1350), 239.59 KiB | 2.75 MiB/s, done.
Resolving deltas: 100% (948/948), done.
Cloning BLIP into J:\Ai\stable-diffusion-webui\repositories\BLIP...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 7.50 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""J:\Ai\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 3221225477
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0-py3-none-any.whl
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.1-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5-py3-none-any.whl
Collecting numba (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Downloading numba-0.61.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)

Press any key to continue . . .",2025-01-26T04:32:34Z,cain666-4u,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2614207355,"i tried a fresh install of both auto1111 and python, and got this during install:

> Creating venv in directory J:\Ai\stable-diffusion-webui\venv using python ""C:\Users\cain6\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe""
Requirement already satisfied: pip in j:\ai\stable-diffusion-webui\venv\lib\site-packages (23.0.1)
Collecting pip
  Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.0.1
    Uninstalling pip-23.0.1:
      Successfully uninstalled pip-23.0.1
Successfully installed pip-24.3.1
WARNING: There was an error checking the latest version of pip.
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting numpy (from torchvision==0.16.2)
  Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Downloading filelock-3.17.0-py3-none-any.whl (16 kB)
Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)
Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl (12.9 MB)
   --------------------------- 12.9/12.9 MB 8.5 MB/s eta 0:00:00
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)
Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
ERROR: Error while checking for conflicts. Please file an issue on pip's issue tracker: https://github.com/pypa/pip/issues/new
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\commands\install.py"", line 584, in _determine_conflicts
    return check_install_conflicts(to_install)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 119, in check_install_conflicts
    would_be_installed = _simulate_installation_of(to_install, package_set)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 158, in _simulate_installation_of
    dist = abstract_dist.get_metadata_distribution()
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\distributions\wheel.py"", line 34, in get_metadata_distribution
    return get_wheel_distribution(wheel, canonicalize_name(self.req.name))
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\__init__.py"", line 106, in get_wheel_distribution
    return select_backend().Distribution.from_wheel(wheel, canonical_name)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\pkg_resources.py"", line 139, in from_wheel
    with wheel.as_zipfile() as zf:
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\base.py"", line 679, in as_zipfile
    return zipfile.ZipFile(self.location, allowZip64=True)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1269, in __init__
    self._RealGetContents()
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1391, in _RealGetContents
    x.date_time = ( (d>>9)+1980, (d>>5)&0xF, d&0x1F,
TypeError: unsupported operand type(s) for >>: 'ZipInfo' and 'int'
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2024.12.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
Installing clip
Installing open_clip
Cloning assets into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.98 MiB/s, done.
Cloning Stable Diffusion into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 2)
Receiving objects: 100% (580/580), 73.44 MiB | 8.33 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into J:\Ai\stable-diffusion-webui\repositories\generative-models...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (57/57), done.
remote: Compressing objects: 100% (29/29), done.
remote: Total 1064 (delta 35), reused 28 (delta 28), pack-reused 1007 (from 3)
Receiving objects: 100% (1064/1064), 53.61 MiB | 7.16 MiB/s, done.
Resolving deltas: 100% (544/544), done.
Cloning K-diffusion into J:\Ai\stable-diffusion-webui\repositories\k-diffusion...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (651/651), done.
remote: Compressing objects: 100% (87/87), done.
remote: Total 1350 (delta 608), reused 566 (delta 564), pack-reused 699 (from 1)
Receiving objects: 100% (1350/1350), 239.59 KiB | 2.75 MiB/s, done.
Resolving deltas: 100% (948/948), done.
Cloning BLIP into J:\Ai\stable-diffusion-webui\repositories\BLIP...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 7.50 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""J:\Ai\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 3221225477
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0-py3-none-any.whl
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.1-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5-py3-none-any.whl
Collecting numba (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Downloading numba-0.61.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)

Press any key to continue . . .",tried fresh install auto python got install creating venv directory j ai stable diffusion webui venv using python c users cain appdata local microsoft windowsapps pythonsoftwarefoundation python qbz n kfra p python exe requirement already satisfied pip j ai stable diffusion webui venv lib site packages collecting pip using cached pip py none whl mb installing collected packages pip attempting uninstall pip found existing installation pip uninstalling pip successfully uninstalled pip successfully installed pip warning error checking latest version pip venv j ai stable diffusion webui venv scripts python exe python tags v cc apr msc v bit amd version v commit hash c ae bd abdf eda b e installing torch torchvision looking indexes collecting torch using cached mb collecting torchvision using cached mb collecting filelock torch downloading filelock py none whl metadata kb collecting typing extensions torch using cached typing extensions py none whl metadata kb collecting sympy torch using cached sympy py none whl metadata kb collecting networkx torch using cached networkx py none whl metadata kb collecting jinja torch using cached jinja py none whl metadata kb collecting fsspec torch using cached fsspec py none whl metadata kb collecting numpy torchvision downloading numpy cp cp win amd whl metadata kb collecting requests torchvision using cached requests py none whl metadata kb collecting pillow torchvision using cached pillow cp cp win amd whl metadata kb collecting markupsafe jinja torch using cached markupsafe cp cp win amd whl metadata kb collecting charset normalizer requests torchvision using cached charset normalizer cp cp win amd whl metadata kb collecting idna requests torchvision using cached idna py none whl metadata kb collecting urllib requests torchvision using cached urllib py none whl metadata kb collecting certifi requests torchvision using cached certifi py none whl metadata kb collecting mpmath sympy torch using cached kb using cached pillow cp cp win amd whl mb downloading filelock py none whl kb using cached fsspec py none whl kb using cached jinja py none whl kb using cached networkx py none whl mb downloading numpy cp cp win amd whl mb mb mb eta using cached requests py none whl kb using cached sympy py none whl mb using cached typing extensions py none whl kb using cached certifi py none whl kb using cached charset normalizer cp cp win amd whl kb using cached idna py none whl kb using cached markupsafe cp cp win amd whl kb using cached urllib py none whl kb error error checking conflicts please file issue pip issue tracker traceback recent call last file j ai stable diffusion webui venv lib site packages pip internal commands install py line determine conflicts return check install conflicts install file j ai stable diffusion webui venv lib site packages pip internal operations check py line check install conflicts would installed simulate installation install package set file j ai stable diffusion webui venv lib site packages pip internal operations check py line simulate installation dist abstract dist get metadata distribution file j ai stable diffusion webui venv lib site packages pip internal distributions wheel py line get metadata distribution return get wheel distribution wheel canonicalize name self req name file j ai stable diffusion webui venv lib site packages pip internal metadata init py line get wheel distribution return select backend distribution wheel wheel canonical name file j ai stable diffusion webui venv lib site packages pip internal metadata pkg resources py line wheel wheel zipfile zf file j ai stable diffusion webui venv lib site packages pip internal metadata base py line zipfile return zipfile zipfile self location allowzip true file c program files windowsapps pythonsoftwarefoundation python x qbz n kfra p lib zipfile py line init self realgetcontents file c program files windowsapps pythonsoftwarefoundation python x qbz n kfra p lib zipfile py line realgetcontents x date time xf x f typeerror unsupported operand type zipinfo int installing collected packages mpmath urllib typing extensions sympy pillow numpy networkx markupsafe idna fsspec filelock charset normalizer certifi requests jinja torch torchvision successfully installed markupsafe certifi charset normalizer filelock fsspec idna jinja mpmath networkx numpy pillow requests sympy torch cu torchvision cu typing extensions urllib installing clip installing open clip cloning assets j ai stable diffusion webui repositories stable diffusion webui assets cloning j ai stable diffusion webui repositories stable diffusion webui assets remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done cloning stable diffusion j ai stable diffusion webui repositories stable diffusion stability ai cloning j ai stable diffusion webui repositories stable diffusion stability ai remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done cloning stable diffusion xl j ai stable diffusion webui repositories generative models cloning j ai stable diffusion webui repositories generative models remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done cloning k diffusion j ai stable diffusion webui repositories k diffusion cloning j ai stable diffusion webui repositories k diffusion remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects kib mib done resolving deltas done cloning blip j ai stable diffusion webui repositories blip cloning j ai stable diffusion webui repositories blip remote enumerating objects done remote counting objects done remote compressing objects done remote total delta reused delta pack reused receiving objects mib mib done resolving deltas done installing requirements traceback recent call last file j ai stable diffusion webui launch py line module main file j ai stable diffusion webui launch py line main prepare environment file j ai stable diffusion webui modules launch utils py line prepare environment run pip f install r requirements file requirements file j ai stable diffusion webui modules launch utils py line run pip return run f python pip command prefer binary index url line desc f installing desc errdesc f install desc live live file j ai stable diffusion webui modules launch utils py line run raise runtimeerror n join error bits runtimeerror install requirements command j ai stable diffusion webui venv scripts python exe pip install r requirements versions txt prefer binary error code stdout collecting setuptools r requirements versions txt line using cached setuptools py none whl metadata kb collecting gitpython r requirements versions txt line using cached gitpython py none whl metadata kb collecting pillow r requirements versions txt line using cached pillow cp cp win amd whl metadata kb collecting accelerate r requirements versions txt line using cached accelerate py none whl metadata kb collecting blendmodes r requirements versions txt line using cached blendmodes py none whl metadata kb collecting clean fid r requirements versions txt line using cached clean fid py none whl metadata kb collecting diskcache r requirements versions txt line using cached diskcache py none whl metadata kb collecting einops r requirements versions txt line using cached einops py none whl metadata kb collecting facexlib r requirements versions txt line using cached facexlib py none whl metadata kb collecting fastapi r requirements versions txt line using cached fastapi py none whl metadata kb collecting gradio r requirements versions txt line using cached gradio py none whl metadata kb collecting r requirements versions txt line using cached kb collecting inflection r requirements versions txt line using cached inflection py py none whl metadata kb collecting jsonmerge r requirements versions txt line using cached jsonmerge py none whl collecting kornia r requirements versions txt line using cached kornia py py none whl metadata kb collecting lark r requirements versions txt line using cached lark py py none whl metadata kb collecting numpy r requirements versions txt line using cached numpy cp cp win amd whl metadata kb collecting omegaconf r requirements versions txt line using cached omegaconf py none whl metadata kb collecting open clip torch r requirements versions txt line using cached open clip torch py none whl metadata kb collecting piexif r requirements versions txt line using cached piexif py py none whl metadata kb requirement already satisfied protobuf j ai stable diffusion webui venv lib site packages r requirements versions txt line collecting psutil r requirements versions txt line using cached psutil cp abi win amd whl metadata kb collecting pytorch lightning r requirements versions txt line using cached pytorch lightning py none whl metadata kb collecting resize right r requirements versions txt line using cached resize right py none whl metadata bytes collecting safetensors r requirements versions txt line using cached safetensors cp none win amd whl metadata kb collecting scikit image r requirements versions txt line using cached scikit image cp cp win amd whl metadata kb collecting spandrel r requirements versions txt line using cached spandrel py none whl metadata kb collecting spandrel extra arches r requirements versions txt line using cached spandrel extra arches py none whl metadata kb collecting tomesd r requirements versions txt line using cached tomesd py none whl metadata kb requirement already satisfied torch j ai stable diffusion webui venv lib site packages r requirements versions txt line cu collecting torchdiffeq r requirements versions txt line using cached torchdiffeq py none whl metadata bytes collecting torchsde r requirements versions txt line using cached torchsde py none whl metadata kb collecting transformers r requirements versions txt line using cached transformers py none whl metadata kb collecting r requirements versions txt line using cached kb collecting pillow avif plugin r requirements versions txt line using cached pillow avif plugin cp cp win amd whl metadata kb collecting gitdb gitpython r requirements versions txt line using cached gitdb py none whl metadata kb requirement already satisfied packaging j ai stable diffusion webui venv lib site packages accelerate r requirements versions txt line requirement already satisfied pyyaml j ai stable diffusion webui venv lib site packages accelerate r requirements versions txt line collecting aenum blendmodes r requirements versions txt line using cached aenum py none whl metadata kb collecting deprecation blendmodes r requirements versions txt line using cached deprecation py py none whl metadata kb requirement already satisfied torchvision j ai stable diffusion webui venv lib site packages clean fid r requirements versions txt line cu collecting scipy clean fid r requirements versions txt line using cached scipy cp cp win amd whl metadata kb requirement already satisfied tqdm j ai stable diffusion webui venv lib site packages clean fid r requirements versions txt line requirement already satisfied requests j ai stable diffusion webui venv lib site packages clean fid r requirements versions txt line collecting filterpy facexlib r requirements versions txt line using cached filterpy py none whl collecting numba facexlib r requirements versions txt line downloading numba cp cp win amd whl metadata kb press key continue
auto1111_webui,comment,16809,,"I get these a lot when generating with hires fix, and since it mostly happens with many other programs open at the same time, I suspect this is caused by out of RAM",2025-02-04T10:22:38Z,Zueuk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2633470853,"I get these a lot when generating with hires fix, and since it mostly happens with many other programs open at the same time, I suspect this is caused by out of RAM",get lot generating hires fix since mostly happens many programs open time suspect caused ram
auto1111_webui,comment,16809,,Have you tried this in other browsers because often enough cached information and tabs from your browser can take up memory on your computer over time. I would uninstall all extensions unless you know what extension is corrupt and clear the cache if it persists. This is if your browser is crashing.,2025-02-09T11:08:31Z,Jman3755,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2646179635,Have you tried this in other browsers because often enough cached information and tabs from your browser can take up memory on your computer over time. I would uninstall all extensions unless you know what extension is corrupt and clear the cache if it persists. This is if your browser is crashing.,tried browsers often enough cached information tabs browser take memory computer time would uninstall extensions unless know extension corrupt clear cache persists browser crashing
auto1111_webui,comment,16809,,"See [this](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1474)

**TL;DR:** You're running out of RAM. Try increasing your System Swap.",2025-02-14T08:48:21Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2658634067,"See [this](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1474)

**TL;DR:** You're running out of RAM. Try increasing your System Swap.",see tl dr running ram try increasing system swap
auto1111_webui,issue,16807,[Bug]: Updated installation instructions for installing Stable Diffusion using ROCm (Linux) (Documentation and webui.sh needs updating),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Run the same instructions as the documentation says for the first part.
(Debian): `sudo apt install git python3.10-venv -y`
(Fedora): `sudo dnf install python-3.10`
`git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui`
`python3.10 -m venv venv`

Then update line 156 in webui.sh
`pip install torch torchvision --index-url https://download.pytorch.org/whl/nightly/rocm5.7` --> `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2`

Run webui.sh with this command
`HSA_OVERRIDE_GFX_VERSION=11.0.0 HIP_VISIBLE_DEVICES=0 ./webui.sh --precision full --no-half`

VERSION=11.0.0 is specific to the 7900XTX, version number may change depending on GPU model so check ROCm documentation just in case. If you have a 7900XTX, follow instructions exactly.



### Steps to reproduce the problem

1. Follow the official documentation

### What should have happened?

Documentation and ROCm in webui.sh needs updating to make webui.sh work error free.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

Not needed as the program is running with all features when instructions above is followed.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec  4 2024, 00:00:00) [GCC 14.2.1 20240912 (Red Hat 14.2.1-3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --precision full --no-half
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: /home/user/AI/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-01-21 14:56:37,167 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [a31be20e08] from /home/user/AI/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
2025-01-21 14:56:37,546 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/AI/stable-diffusion-webui/configs/v1-inference.yaml
Startup time: 12.6s (prepare environment: 7.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 1.6s, other imports: 0.3s, load scripts: 0.6s, create ui: 0.4s, gradio launch: 0.3s).
```

### Additional information

_No response_",2025-01-21T20:02:02Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807,"[Bug]: Updated installation instructions for installing Stable Diffusion using ROCm (Linux) (Documentation and webui.sh needs updating) ### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Run the same instructions as the documentation says for the first part.
(Debian): `sudo apt install git python3.10-venv -y`
(Fedora): `sudo dnf install python-3.10`
`git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui`
`python3.10 -m venv venv`

Then update line 156 in webui.sh
`pip install torch torchvision --index-url https://download.pytorch.org/whl/nightly/rocm5.7` --> `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2`

Run webui.sh with this command
`HSA_OVERRIDE_GFX_VERSION=11.0.0 HIP_VISIBLE_DEVICES=0 ./webui.sh --precision full --no-half`

VERSION=11.0.0 is specific to the 7900XTX, version number may change depending on GPU model so check ROCm documentation just in case. If you have a 7900XTX, follow instructions exactly.



### Steps to reproduce the problem

1. Follow the official documentation

### What should have happened?

Documentation and ROCm in webui.sh needs updating to make webui.sh work error free.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

Not needed as the program is running with all features when instructions above is followed.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec  4 2024, 00:00:00) [GCC 14.2.1 20240912 (Red Hat 14.2.1-3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --precision full --no-half
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: /home/user/AI/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-01-21 14:56:37,167 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [a31be20e08] from /home/user/AI/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
2025-01-21 14:56:37,546 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/AI/stable-diffusion-webui/configs/v1-inference.yaml
Startup time: 12.6s (prepare environment: 7.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 1.6s, other imports: 0.3s, load scripts: 0.6s, create ui: 0.4s, gradio launch: 0.3s).
```

### Additional information

_No response_",bug updated installation instructions installing stable diffusion using rocm linux documentation webui sh needs updating checklist issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened run instructions documentation says first part debian sudo apt install git python venv fedora sudo dnf install python git clone cd stable diffusion webui python venv venv update line webui sh pip install torch torchvision index url pip install torch torchvision torchaudio index url run webui sh command hsa override gfx version hip visible devices webui sh precision full half version specific xtx version number may change depending gpu model check rocm documentation case xtx follow instructions exactly steps reproduce problem follow official documentation happened documentation rocm webui sh needs updating make webui sh work error free browsers use access ui brave sysinfo needed program running features instructions followed console logs shell install script stable diffusion web ui tested debian bullseye fedora opensuse leap newer running user user repo already cloned using install directory create activate python venv launching launch py glibc version check tcmalloc libtcmalloc minimal libtcmalloc minimal linked libc execute ld preload lib libtcmalloc minimal python main dec gcc red hat version v commit hash c ae bd abdf eda b e controlnet init warning unable install insightface automatically please try run pip install insightface manually launching web ui arguments precision full half module xformers processing without module xformers processing without module xformers proceeding without controlnet preprocessor location home user ai stable diffusion webui extensions sd webui controlnet annotator downloads controlnet info controlnet v loading weights e home user ai stable diffusion webui models stable diffusion v pruned emaonly safetensors controlnet info controlnet ui callback registered running local url create public link set share true launch creating model config home user ai stable diffusion webui configs v inference yaml startup time prepare environment import torch import gradio setup paths imports load scripts create ui gradio launch additional information response
auto1111_webui,comment,16807,,"You might be better off using this fork that is made to support AMD GPU's and ROCm:

https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu-forge

I'm using it with RX 6700 and some user compiled ROCm libs etc. It works well for me.",2025-02-19T09:00:21Z,the-real-vortex-v,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2667967277,"You might be better off using this fork that is made to support AMD GPU's and ROCm:

https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu-forge

I'm using it with RX 6700 and some user compiled ROCm libs etc. It works well for me.",might better using fork made support amd gpu rocm using rx user compiled rocm libs etc works well
auto1111_webui,comment,16807,,"I second this with an AMD 7800XT.  The rom5.7 nightly is not currently available anyway (403 error) and even installing rocm5.7 stable into the venv manually with pip doesn't work.  For me, launch.py (and by extension webui.sh) will launch assuming there is a CUDA card involved, even with the HSA_GFX_OVERRIDE.  Skipping the cuda check just causes more errors and the webui won't launch.  Using pip to install torch and torchvision using the --index-url https://download.pytorch.org/whl/rocm6.2 argument was the only thing that worked.  After installing those versions, I can launch using ./webui.sh without any arguments and image generation works.

As for @the-real-vortex-v recommendation to using stable-diffusion-webui-amdgpu-forge, I tried it and it doesn't work. Following the automatic installation instructions still yields the same issue where it assumes I have a CUDA card unless I install rocm6.2.4 manually. I believe this issue is specific to the RX7800 / Navi 3x series cards.  I had a 6700xt and had no issues with webui. Everything went wrong when I upgraded my card to the 7800xt.

",2025-02-22T16:47:06Z,hapwizard,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2676300015,"I second this with an AMD 7800XT.  The rom5.7 nightly is not currently available anyway (403 error) and even installing rocm5.7 stable into the venv manually with pip doesn't work.  For me, launch.py (and by extension webui.sh) will launch assuming there is a CUDA card involved, even with the HSA_GFX_OVERRIDE.  Skipping the cuda check just causes more errors and the webui won't launch.  Using pip to install torch and torchvision using the --index-url https://download.pytorch.org/whl/rocm6.2 argument was the only thing that worked.  After installing those versions, I can launch using ./webui.sh without any arguments and image generation works.

As for @the-real-vortex-v recommendation to using stable-diffusion-webui-amdgpu-forge, I tried it and it doesn't work. Following the automatic installation instructions still yields the same issue where it assumes I have a CUDA card unless I install rocm6.2.4 manually. I believe this issue is specific to the RX7800 / Navi 3x series cards.  I had a 6700xt and had no issues with webui. Everything went wrong when I upgraded my card to the 7800xt.",second amd xt rom nightly currently available anyway error even installing rocm stable venv manually pip work launch py extension webui sh launch assuming cuda card involved even hsa gfx override skipping cuda check causes errors webui launch using pip install torch torchvision using index url argument thing worked installing versions launch using webui sh without arguments image generation works real vortex v recommendation using stable diffusion webui amdgpu forge tried work following automatic installation instructions still yields issue assumes cuda card unless install rocm manually believe issue specific rx navi x series cards xt issues webui everything went wrong upgraded card xt
auto1111_webui,comment,16807,,"Thank you for finding a solution for this, I haven't started Webui for a few months and suddenly i got an error when launching the webui.sh script: `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`

Trying a new installation of webui failed too with a 403 error when downloading the rocm5.7 torch version.

Then I found your post and got my installation working again:

I changed the script from rocm5.7 to 6.2, manually uninstalled torch, torchvision and  torchaudio with pip in the venv and manually installed the 6.2 version. The manuall part was probably unnecessary and changing the script and launching it would have been enough, but it's working again and I'm happy.

Hopefully this will be updated soon.",2025-03-01T10:32:52Z,hanspetzer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2692130153,"Thank you for finding a solution for this, I haven't started Webui for a few months and suddenly i got an error when launching the webui.sh script: `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`

Trying a new installation of webui failed too with a 403 error when downloading the rocm5.7 torch version.

Then I found your post and got my installation working again:

I changed the script from rocm5.7 to 6.2, manually uninstalled torch, torchvision and  torchaudio with pip in the venv and manually installed the 6.2 version. The manuall part was probably unnecessary and changing the script and launching it would have been enough, but it's working again and I'm happy.

Hopefully this will be updated soon.",thank finding solution started webui months suddenly got error launching webui sh script torch able use gpu add skip torch cuda test commandline args variable disable check trying new installation webui failed error downloading rocm torch version found post got installation working changed script rocm manually uninstalled torch torchvision torchaudio pip venv manually installed version manuall part probably unnecessary changing script launching would enough working happy hopefully updated soon
auto1111_webui,comment,16807,,"Same issue with : version: [v1.10.1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2)  •  python: 3.10.12  •  torch: 2.6.0+rocm6.2.4  •  xformers: 0.0.29.post3  •  gradio: 3.41.2  •  checkpoint: 6ce0161689
[dockerlog.txt](https://github.com/user-attachments/files/19496272/dockerlog.txt)

Dockerfile :
```dockerfile
FROM rocm/dev-ubuntu-22.04

RUN apt update && apt install libgoogle-perftools-dev libgl1 git python3 python3-pip python3-venv libglib2.0-0 --no-install-recommends -y
ENV LD_PRELOAD=libtcmalloc.so

RUN adduser app --uid 1000

USER app:app
WORKDIR /app
RUN git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git /app
ENV TORCH_COMMAND=""pip install torch torchvision --index-url https://download.pytorch.org/whl/rocm6.2.4""
ENV XFORMERS_PACKAGE=""xformers --index-url https://download.pytorch.org/whl/rocm6.2.4""
RUN --mount=type=cache,target=/home/app/.cache/pip,uid=1000,gid=1000 /app/webui.sh --skip-torch-cuda-test --exit

EXPOSE 7860/tcp
ENTRYPOINT [ ""/app/webui.sh"", ""--enable-insecure-extension-access"",""--listen"", ""--data-dir=/data"" ]
```

docker-compose.yml
```yml
name: stablediffusionwebui-test
services:
  sdwui:
    build: .
    image: dockerstablediffusionwebui:test
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.0
    devices:
      - /dev/dri
      - /dev/kfd
    group_add:
      - video
      - 110 #render
    user: 1000:1000
    ports:
      - 7861:7860
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    ipc: host
    command: --api --disable-console-progressbars --xformers
    # entrypoint: bash
    # tty: true
    # stdin_open: true
    volumes:
      - ./data-test:/data
```",2025-03-28T00:51:19Z,AR2000AR,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2759904208,"Same issue with : version: [v1.10.1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2)  •  python: 3.10.12  •  torch: 2.6.0+rocm6.2.4  •  xformers: 0.0.29.post3  •  gradio: 3.41.2  •  checkpoint: 6ce0161689
[dockerlog.txt](https://github.com/user-attachments/files/19496272/dockerlog.txt)

Dockerfile :
```dockerfile
FROM rocm/dev-ubuntu-22.04

RUN apt update && apt install libgoogle-perftools-dev libgl1 git python3 python3-pip python3-venv libglib2.0-0 --no-install-recommends -y
ENV LD_PRELOAD=libtcmalloc.so

RUN adduser app --uid 1000

USER app:app
WORKDIR /app
RUN git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git /app
ENV TORCH_COMMAND=""pip install torch torchvision --index-url https://download.pytorch.org/whl/rocm6.2.4""
ENV XFORMERS_PACKAGE=""xformers --index-url https://download.pytorch.org/whl/rocm6.2.4""
RUN --mount=type=cache,target=/home/app/.cache/pip,uid=1000,gid=1000 /app/webui.sh --skip-torch-cuda-test --exit

EXPOSE 7860/tcp
ENTRYPOINT [ ""/app/webui.sh"", ""--enable-insecure-extension-access"",""--listen"", ""--data-dir=/data"" ]
```

docker-compose.yml
```yml
name: stablediffusionwebui-test
services:
  sdwui:
    build: .
    image: dockerstablediffusionwebui:test
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.0
    devices:
      - /dev/dri
      - /dev/kfd
    group_add:
      - video
      - 110 #render
    user: 1000:1000
    ports:
      - 7861:7860
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    ipc: host
    command: --api --disable-console-progressbars --xformers
    # entrypoint: bash
    # tty: true
    # stdin_open: true
    volumes:
      - ./data-test:/data
```",issue version v python torch rocm xformers post gradio checkpoint ce dockerlog txt dockerfile dockerfile rocm dev ubuntu run apt update apt install libgoogle perftools dev libgl git python python pip python venv libglib install recommends env ld preload libtcmalloc run adduser app uid user app app workdir app run git clone app env torch command pip install torch torchvision index url env xformers package xformers index url run mount type cache target home app cache pip uid gid app webui sh skip torch cuda test exit expose tcp entrypoint app webui sh enable insecure extension access listen data dir data docker compose yml yml name stablediffusionwebui test services sdwui build image dockerstablediffusionwebui test environment hsa override gfx version devices dev dri dev kfd group add video render user ports security opt seccomp unconfined cap add sys ptrace ipc host command api disable console progressbars xformers entrypoint bash tty true stdin open true volumes data test data
auto1111_webui,comment,16807,,"I just edited the webui.sh script to fetch rocm7.0 instead as rocm5.7 does not exist.

Not really the devs fault but would be good, if the latest, was just called latest instead of a version number, or called nightly, as this will be an ongoing issue, version numbers are constantly changing, including Python, instructions say install Python 3 which will allways be the latest, but it tells use we need 3.10.6, but directly under that, its telling me to install 3.11, all a little ""fly by the seat of my pants"" or lets ""yolo it"" :)",2025-11-03T23:45:00Z,NexGen-3D-Printing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483045766,"I just edited the webui.sh script to fetch rocm7.0 instead as rocm5.7 does not exist.

Not really the devs fault but would be good, if the latest, was just called latest instead of a version number, or called nightly, as this will be an ongoing issue, version numbers are constantly changing, including Python, instructions say install Python 3 which will allways be the latest, but it tells use we need 3.10.6, but directly under that, its telling me to install 3.11, all a little ""fly by the seat of my pants"" or lets ""yolo it"" :)",edited webui sh script fetch rocm instead rocm exist really devs fault would good latest called latest instead version number called nightly ongoing issue version numbers constantly changing including python instructions say install python allways latest tells use need directly telling install little fly seat pants lets yolo
auto1111_webui,comment,16807,,"Rocm versions are tied to the python version you are running. The old 5.7 (Python 3.10) can't handle some newer model so thus the tutorial. I can't remember off the top of my head which Python version you need to run to make the above work but I assume I was using 3.12 or 3.13 at the time. The newer Rocm 7+ requires the lastest Python version to work. If you are trying to get this to work on the new Strix Halo chips, use a different repo. I am pretty sure TheRock has a Docker image that makes A1111 work with Strix Halo in his repos.",2025-11-04T00:21:34Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483171301,"Rocm versions are tied to the python version you are running. The old 5.7 (Python 3.10) can't handle some newer model so thus the tutorial. I can't remember off the top of my head which Python version you need to run to make the above work but I assume I was using 3.12 or 3.13 at the time. The newer Rocm 7+ requires the lastest Python version to work. If you are trying to get this to work on the new Strix Halo chips, use a different repo. I am pretty sure TheRock has a Docker image that makes A1111 work with Strix Halo in his repos.",rocm versions tied python version running old python handle newer model thus tutorial remember top head python version need run make work assume using time newer rocm requires lastest python version work trying get work new strix halo chips use different repo pretty sure therock docker image makes work strix halo repos
auto1111_webui,comment,16807,,Update: I was using 3.10. I guess Rocm 5.7 must be for an even earlier version of Python.,2025-11-04T00:24:08Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483180306,Update: I was using 3.10. I guess Rocm 5.7 must be for an even earlier version of Python.,update using guess rocm must even earlier version python
auto1111_webui,comment,16807,,"Im using a 7900 GRE, I seen there is some special experimental builds currently for the 7000 series, RDNA 3.5 and 4, all seperate branches of ROCM, in my opinion, its a bit of dogs breakfast, no wonder all these tools are so touchy, its quite scattered, probably why everyone just goes with nVidia, as Cuda is a little more universal.

I just wanted to test some ROCM workloads to see if its worth my time using some MI50 cards, but it looks quite futile, I have RDNA 2, 3 and 4 at my disposal, so I might have to do some testing on the other cards as well to see what is going to work before I purchase anything more, just trying to avoid nVidia, and Intel Arc if I can.",2025-11-04T01:15:53Z,NexGen-3D-Printing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483287105,"Im using a 7900 GRE, I seen there is some special experimental builds currently for the 7000 series, RDNA 3.5 and 4, all seperate branches of ROCM, in my opinion, its a bit of dogs breakfast, no wonder all these tools are so touchy, its quite scattered, probably why everyone just goes with nVidia, as Cuda is a little more universal.

I just wanted to test some ROCM workloads to see if its worth my time using some MI50 cards, but it looks quite futile, I have RDNA 2, 3 and 4 at my disposal, so I might have to do some testing on the other cards as well to see what is going to work before I purchase anything more, just trying to avoid nVidia, and Intel Arc if I can.",im using gre seen special experimental builds currently series rdna seperate branches rocm opinion bit dogs breakfast wonder tools touchy quite scattered probably everyone goes nvidia cuda little universal wanted test rocm workloads see worth time using mi cards looks quite futile rdna disposal might testing cards well see going work purchase anything trying avoid nvidia intel arc
auto1111_webui,issue,16806,[Feature Request]: Hide specific directory buttons when viewing extra networks in Dirs view style,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I would like there to be a setting that lets you select available directories in your extra networks tab to hide individually.

I like to keep my LoRAs organized in folders by their supported checkpoints and categories. For instance, my checkpoints are SDXL, Pony, and Illustrious. Then within those folders I have Characters (Male, Female, Non-Human), Styles, and Concepts. Then I have even more specific folders within those.

The result is I get every possible directory as a button I can click to filter the cards. There's the feature that hides folders and models from being shown if the folder starts with a period, but it hides _all_ the subfolders and models within that folder.

I know I could simply have fewer folders to reduce the amount of directory buttons, but I think the ability to hide specific ones to have a personalized list would be a good feature overall.

Alongside this, I think being able to save presets of hidden buttons would be great when going between different checkpoint versions.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-01-21T07:45:51Z,DecodeTalker1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806,"[Feature Request]: Hide specific directory buttons when viewing extra networks in Dirs view style ### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I would like there to be a setting that lets you select available directories in your extra networks tab to hide individually.

I like to keep my LoRAs organized in folders by their supported checkpoints and categories. For instance, my checkpoints are SDXL, Pony, and Illustrious. Then within those folders I have Characters (Male, Female, Non-Human), Styles, and Concepts. Then I have even more specific folders within those.

The result is I get every possible directory as a button I can click to filter the cards. There's the feature that hides folders and models from being shown if the folder starts with a period, but it hides _all_ the subfolders and models within that folder.

I know I could simply have fewer folders to reduce the amount of directory buttons, but I think the ability to hide specific ones to have a personalized list would be a good feature overall.

Alongside this, I think being able to save presets of hidden buttons would be great when going between different checkpoint versions.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",feature request hide specific directory buttons viewing extra networks dirs view style existing issue x searched existing issues checked recent builds commits would feature would like setting lets select available directories extra networks tab hide individually like keep loras organized folders supported checkpoints categories instance checkpoints sdxl pony illustrious within folders characters male female non human styles concepts even specific folders within result get every possible directory button click filter cards feature hides folders models shown folder starts period hides subfolders models within folder know could simply fewer folders reduce amount directory buttons think ability hide specific ones personalized list would good feature overall alongside think able save presets hidden buttons would great going different checkpoint versions proposed workflow go press additional information response
auto1111_webui,comment,16806,,"switch to tree view?
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16803#discussioncomment-11890409",2025-01-22T03:06:18Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806#issuecomment-2606189108,"switch to tree view?
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16803#discussioncomment-11890409",switch tree view
auto1111_webui,comment,16806,,I like the filters being on the top. I gave the tree view a try but it feels too clunky having to navigate to each folder I want to quickly view. I was hoping for a solution with the directory buttons,2025-01-23T04:20:15Z,DecodeTalker1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806#issuecomment-2608821519,I like the filters being on the top. I gave the tree view a try but it feels too clunky having to navigate to each folder I want to quickly view. I was hoping for a solution with the directory buttons,like filters top gave tree view try feels clunky navigate folder want quickly view hoping solution directory buttons
auto1111_webui,issue,16802,[Bug]: Installing K diffusion,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Tried to install k diffusion but gives me an error, it used to have many errors now am stuck with is one (RROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion')

### Steps to reproduce the problem

Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.

### What should have happened?

It should have installed k diffusion 

### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

IDK?

### Console logs

```Shell
(base) PS C:\WINDOWS\system32> cd C:\1111\stable-diffusion-cpuonly
(base) PS C:\1111\stable-diffusion-cpuonly> git clone git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.
```

### Additional information

_No response_",2025-01-17T12:42:50Z,the2unix,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16802,"[Bug]: Installing K diffusion ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Tried to install k diffusion but gives me an error, it used to have many errors now am stuck with is one (RROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion')

### Steps to reproduce the problem

Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.

### What should have happened?

It should have installed k diffusion 

### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

IDK?

### Console logs

```Shell
(base) PS C:\WINDOWS\system32> cd C:\1111\stable-diffusion-cpuonly
(base) PS C:\1111\stable-diffusion-cpuonly> git clone git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.
```

### Additional information

_No response_",bug installing k diffusion checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui issue exists current version webui issue reported recently x issue reported fixed yet happened tried install k diffusion gives error used many errors stuck one rror command errored exit status git clone q c stable diffusion cpuonly src k diffusion steps reproduce problem obtaining k diffusion git cloning c stable diffusion cpuonly src k diffusion error command errored exit status git clone q c stable diffusion cpuonly src k diffusion check logs full command output file copied file copied happened installed k diffusion browsers use access ui google chrome microsoft edge sysinfo idk console logs shell base ps c windows system cd c stable diffusion cpuonly base ps c stable diffusion cpuonly git clone git obtaining k diffusion git cloning c stable diffusion cpuonly src k diffusion error command errored exit status git clone q c stable diffusion cpuonly src k diffusion check logs full command output file copied file copied additional information response
auto1111_webui,comment,16802,,"I'm not sure what instructions are you following but I'm pretty sure you're not using https://github.com/AUTOMATIC1111/stable-diffusion-webui
if you're trying to get whatever you're currently using to work then you're asking in the wrong place
if you're trying to install AUTOMATIC1111/stable-diffusion-webui then read https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs

---

also this https://github.com/hlky/k-diffusion-sd leads to a 404 page
whatever it was before it was deleted",2025-01-18T03:21:55Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16802#issuecomment-2599496838,"I'm not sure what instructions are you following but I'm pretty sure you're not using https://github.com/AUTOMATIC1111/stable-diffusion-webui
if you're trying to get whatever you're currently using to work then you're asking in the wrong place
if you're trying to install AUTOMATIC1111/stable-diffusion-webui then read https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs

---

also this https://github.com/hlky/k-diffusion-sd leads to a 404 page
whatever it was before it was deleted",sure instructions following pretty sure using trying get whatever currently using work asking wrong place trying install automatic stable diffusion webui read also leads page whatever deleted
auto1111_webui,issue,16797,[Bug]: Bad API auth with certain passwords,"### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

```
Jan 14 13:14:03 roxanne.dragonfear stable-diffusion-webui[1682746]: ValueError: too many values to unpack (expected 2)
```
The routine in api.py is using auth.split("":"")

It should be using auth.partition("":"") to avoid double-splits.

### Steps to reproduce the problem

Just run the thing with an API password that contains colons.

### What should have happened?

Should start normally.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Doesn't matter.  It's a code bug.

### Console logs

```Shell
Above.
```


### Additional information

_No response_",2025-01-14T13:15:50Z,Rudd-O,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797,"[Bug]: Bad API auth with certain passwords ### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

```
Jan 14 13:14:03 roxanne.dragonfear stable-diffusion-webui[1682746]: ValueError: too many values to unpack (expected 2)
```
The routine in api.py is using auth.split("":"")

It should be using auth.partition("":"") to avoid double-splits.

### Steps to reproduce the problem

Just run the thing with an API password that contains colons.

### What should have happened?

Should start normally.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Doesn't matter.  It's a code bug.

### Console logs

```Shell
Above.
```


### Additional information

_No response_",bug bad api auth certain passwords checklist x issue exists disabling extensions x issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently issue reported fixed yet happened jan roxanne dragonfear stable diffusion webui valueerror many values unpack expected routine api py using auth split using auth partition avoid double splits steps reproduce problem run thing api password contains colons happened start normally browsers use access ui response sysinfo matter code bug console logs shell additional information response
auto1111_webui,comment,16797,,"> It should be using auth.partition("":"") to avoid double-splits.

sure, `partition` or `str.split(':', maxsplit=1)`
but maybe it's better to just not use the second colon in your password",2025-01-17T06:43:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2597544730,"> It should be using auth.partition("":"") to avoid double-splits.

sure, `partition` or `str.split(':', maxsplit=1)`
but maybe it's better to just not use the second colon in your password",using auth partition avoid double splits sure partition str split maxsplit maybe better use second colon password
auto1111_webui,comment,16797,,"Design Request Summary for BeautyPlus:

Text:

English only (BeautyPlus or B+).
Promotional phrases:
""Discover the best salons and spas.""
""Book appointments and find offers.""
""Contact us for details.""
Images:

App interface screenshots.
Simple visuals like hair or nails.
Icons: 3 only (Search, Home, Account).

Contact Information:

Email: info@beautyplusapp.com
WhatsApp: 0561688990
Colors:

Background: #899F93 (green-gray).
Text: White.
Sizes:

1080x1080 px.
400x400 px.
350x420 px.
Presentation:

Show design within an iPhone mockup.",2025-01-17T12:49:03Z,manea19,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2598297100,"Design Request Summary for BeautyPlus:

Text:

English only (BeautyPlus or B+).
Promotional phrases:
""Discover the best salons and spas.""
""Book appointments and find offers.""
""Contact us for details.""
Images:

App interface screenshots.
Simple visuals like hair or nails.
Icons: 3 only (Search, Home, Account).

Contact Information:

Email: info@beautyplusapp.com
WhatsApp: 0561688990
Colors:

Background: #899F93 (green-gray).
Text: White.
Sizes:

1080x1080 px.
400x400 px.
350x420 px.
Presentation:

Show design within an iPhone mockup.",design request summary beautyplus text english beautyplus b promotional phrases discover best salons spas book appointments find offers contact us details images app interface screenshots simple visuals like hair nails icons search home account contact information email info beautyplusapp com whatsapp colors background f green gray text white sizes x px x px x px presentation show design within iphone mockup
auto1111_webui,comment,16797,,"I worked around by changing the password, but this is a basic bug that should be fixed and might even have security implications.",2025-01-18T22:34:24Z,Rudd-O,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2600217958,"I worked around by changing the password, but this is a basic bug that should be fixed and might even have security implications.",worked around changing password basic bug fixed might even security implications
auto1111_webui,issue,16781,[Bug]: Dreambooth installed but tab is not viewed on UI,"### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [X] The issue has been reported before but has not been fixed yet

### What happened?

No Dreambooth Tab

### Steps to reproduce the problem

just install the extension and fully restart UI

### What should have happened?

it should show the tab

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

I do know how to do it


### Console logs

```Shell
https://pastebin.com/acPkiMTZ
```


### Additional information

nothing",2025-01-10T22:02:04Z,Hi1603,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16781,"[Bug]: Dreambooth installed but tab is not viewed on UI ### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [X] The issue has been reported before but has not been fixed yet

### What happened?

No Dreambooth Tab

### Steps to reproduce the problem

just install the extension and fully restart UI

### What should have happened?

it should show the tab

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

I do know how to do it


### Console logs

```Shell
https://pastebin.com/acPkiMTZ
```


### Additional information

nothing",bug dreambooth installed tab viewed ui checklist x issue exists disabling extensions x issue exists clean installation webui x issue caused extension believe caused bug webui x issue exists current version webui x issue reported recently x issue reported fixed yet happened dreambooth tab steps reproduce problem install extension fully restart ui happened show tab browsers use access ui microsoft edge sysinfo know console logs shell additional information nothing
auto1111_webui,comment,16781,,Just use [kohya_ss](https://github.com/bmaltais/kohya_ss) or [OneTrainer](https://github.com/Nerogar/OneTrainer),2025-01-13T05:55:25Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16781#issuecomment-2586222604,Just use [kohya_ss](https://github.com/bmaltais/kohya_ss) or [OneTrainer](https://github.com/Nerogar/OneTrainer),use kohya ss onetrainer
auto1111_webui,issue,16762,[Feature Request]: prepare host for specific gpu (needed for containers) without starting api/ui,"### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have some option to initializen the current installation for a specific gpu
right now I exploit the script to ""simulate"" my amd gpu

```
root@ollama:~/ollama# cat Dockerfile.automatic1111
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (exploits webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    sed 's/start()/# start()/g' launch.py >_init.py \
 && bash -ec ""function lspci { echo '03:00.0 VGA compatible controller: Advanced Micro Devices, Inc. [AMD/ATI] XXXXXX'; } \
 && export -f lspci \
 && LAUNCH_SCRIPT=_init.py ./webui.sh -f --data-dir /data --skip-torch-cuda-test"" \
 && rm -rf /data/* _init.py

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"" ]
```

### Proposed workflow

maybe a separate script or argument would be nice

### Additional information
if someome is interessted this is my docker-compose.yml
```
services:
  ollama:
    image: ollama/ollama:rocm
    ports:
      - ""11434:11434""
    volumes:
      #- ./ollama:/root/.ollama
      - /usr/share/ollama/.ollama:/root/.ollama
    restart: unless-stopped
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - 44
      - 993

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    volumes:
      - ./open-webui:/app/backend/data
    ports:
      - ""8080:8080""
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      AUTOMATIC1111_BASE_URL: http://automatic1111:7860
      ENABLE_OLLAMA_API: true
      ENABLE_OPENAI_API: false
      YOUTUBE_LOADER_LANGUAGE: de
      ENABLE_RAG_WEB_SEARCH: true
      RAG_WEB_SEARCH_ENGINE: duckduckgo
      ENABLE_IMAGE_GENERATION: true
      IMAGE_GENERATION_ENGINE: automatic1111
      IMAGE_GENERATION_MODEL: v1-5-pruned-emaonly.safetensors [6ce0161689]
      SCARF_NO_ANALYTICS: true
      DO_NOT_TRACK: true
      ANONYMIZED_TELEMETRY: false

  automatic1111:
    build:
      context: .
      dockerfile: Dockerfile.automatic1111
    volumes:
      - ./automatic1111:/data
    restart: unless-stopped
    ports:
      - ""7860:7860""
    group_add:
      - 44
      - 993
    devices:
      - /dev/kfd
      - /dev/dri
```",2024-12-30T01:12:12Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762,"[Feature Request]: prepare host for specific gpu (needed for containers) without starting api/ui ### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have some option to initializen the current installation for a specific gpu
right now I exploit the script to ""simulate"" my amd gpu

```
root@ollama:~/ollama# cat Dockerfile.automatic1111
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (exploits webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    sed 's/start()/# start()/g' launch.py >_init.py \
 && bash -ec ""function lspci { echo '03:00.0 VGA compatible controller: Advanced Micro Devices, Inc. [AMD/ATI] XXXXXX'; } \
 && export -f lspci \
 && LAUNCH_SCRIPT=_init.py ./webui.sh -f --data-dir /data --skip-torch-cuda-test"" \
 && rm -rf /data/* _init.py

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"" ]
```

### Proposed workflow

maybe a separate script or argument would be nice

### Additional information
if someome is interessted this is my docker-compose.yml
```
services:
  ollama:
    image: ollama/ollama:rocm
    ports:
      - ""11434:11434""
    volumes:
      #- ./ollama:/root/.ollama
      - /usr/share/ollama/.ollama:/root/.ollama
    restart: unless-stopped
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - 44
      - 993

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    volumes:
      - ./open-webui:/app/backend/data
    ports:
      - ""8080:8080""
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      AUTOMATIC1111_BASE_URL: http://automatic1111:7860
      ENABLE_OLLAMA_API: true
      ENABLE_OPENAI_API: false
      YOUTUBE_LOADER_LANGUAGE: de
      ENABLE_RAG_WEB_SEARCH: true
      RAG_WEB_SEARCH_ENGINE: duckduckgo
      ENABLE_IMAGE_GENERATION: true
      IMAGE_GENERATION_ENGINE: automatic1111
      IMAGE_GENERATION_MODEL: v1-5-pruned-emaonly.safetensors [6ce0161689]
      SCARF_NO_ANALYTICS: true
      DO_NOT_TRACK: true
      ANONYMIZED_TELEMETRY: false

  automatic1111:
    build:
      context: .
      dockerfile: Dockerfile.automatic1111
    volumes:
      - ./automatic1111:/data
    restart: unless-stopped
    ports:
      - ""7860:7860""
    group_add:
      - 44
      - 993
    devices:
      - /dev/kfd
      - /dev/dri
```",feature request prepare host specific gpu needed containers without starting api ui existing issue x searched existing issues checked recent builds commits would feature would nice option initializen current installation specific gpu right exploit script simulate amd gpu root ollama ollama cat dockerfile automatic rocm pytorch rocm ubuntu py pytorch release workdir automatic install packages run apt update apt install google perftools bc install recommends apt clean clone repo run mkdir p data git clone prepare environment exploits webui sh run mount type cache target root cache pip sed start start g launch py init py bash ec function lspci echo vga compatible controller advanced micro devices inc amd ati xxxxxx export f lspci launch script init py webui sh f data dir data skip torch cuda test rm rf data init py expose volume data cmd automatic webui sh f api listen skip prepare environment data dir data precision full half proposed workflow maybe separate script argument would nice additional information someome interessted docker compose yml services ollama image ollama ollama rocm ports volumes ollama root ollama usr share ollama ollama root ollama restart unless stopped devices dev kfd dev dri group add open webui image ghcr io open webui open webui main restart unless stopped volumes open webui app backend data ports environment ollama base url automatic base url enable ollama api true enable openai api false youtube loader language de enable rag web search true rag web search engine duckduckgo enable image generation true image generation engine automatic image generation model v pruned emaonly safetensors ce scarf analytics true track true anonymized telemetry false automatic build context dockerfile dockerfile automatic volumes automatic data restart unless stopped ports group add devices dev kfd dev dri
auto1111_webui,comment,16762,,"I think what you asking is already supported
> I don't use AMD GPU so I'm not exactly familiar with the situation but from my understanding

there should be no need to simulate a GPU
unless there is something that I'm not aware the difference is the different GPU is what version of torch that it installs

the environment variable `TORCH_COMMAND` is the actual thing that defines what version of torch that we installed
so you should just set the appropriate command for your desired platform without the heck simulation stuff
if the user already defines `TORCH_COMMAND` then auto platform detection is disabled
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/webui.sh#L130-L152

alternatively you could always manually install torch, if torch is already installed webui won't auto install a different version for you (unless you pass `--reinstall-torch`) in whitch case it will try to install what's defined by `TORCH_COMMAND`

---

also there is no need to modify launch.py to prevent webui from starting
just pass `--exit` and it will exit after installing requirements
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/modules/launch_utils.py#L442-L444

---

wiki

https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings",2024-12-30T04:29:59Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565014551,"I think what you asking is already supported
> I don't use AMD GPU so I'm not exactly familiar with the situation but from my understanding

there should be no need to simulate a GPU
unless there is something that I'm not aware the difference is the different GPU is what version of torch that it installs

the environment variable `TORCH_COMMAND` is the actual thing that defines what version of torch that we installed
so you should just set the appropriate command for your desired platform without the heck simulation stuff
if the user already defines `TORCH_COMMAND` then auto platform detection is disabled
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/webui.sh#L130-L152

alternatively you could always manually install torch, if torch is already installed webui won't auto install a different version for you (unless you pass `--reinstall-torch`) in whitch case it will try to install what's defined by `TORCH_COMMAND`

---

also there is no need to modify launch.py to prevent webui from starting
just pass `--exit` and it will exit after installing requirements
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/modules/launch_utils.py#L442-L444

---

wiki

https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings",think asking already supported use amd gpu exactly familiar situation understanding need simulate gpu unless something aware difference different gpu version torch installs environment variable torch command actual thing defines version torch installed set appropriate command desired platform without heck simulation stuff user already defines torch command auto platform detection disabled alternatively could always manually install torch torch already installed webui auto install different version unless pass reinstall torch whitch case try install defined torch command also need modify launch py prevent webui starting pass exit exit installing requirements wiki
auto1111_webui,comment,16762,,"`--exit` seems to work - II completely overlooked it.

Also setting the `TORCH_COMMAND` works - I already spotted this but in this case I need to know the correct packages, versions and urls.
My goal was to use the ""suggested"" settings from webui.sh
e.g. in my case `export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7""` is the command to use but if you change the rocm version, add a package or set a specific version I would have to do the same in the Dockerfile.

it would be nice to have an option or environment variable to define the gpu type which results in the ""correct"" TORCH_COMMAMD

this is my current docker-file
```
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone --depth 1 https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (TORCH_COMMAND from webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7"" \
 && bash -e ./webui.sh -f --data-dir /data --skip-torch-cuda-test --exit \
 && rm -rf /data/*

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"", ""--medvram"" ]
```",2024-12-30T13:33:51Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565492097,"`--exit` seems to work - II completely overlooked it.

Also setting the `TORCH_COMMAND` works - I already spotted this but in this case I need to know the correct packages, versions and urls.
My goal was to use the ""suggested"" settings from webui.sh
e.g. in my case `export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7""` is the command to use but if you change the rocm version, add a package or set a specific version I would have to do the same in the Dockerfile.

it would be nice to have an option or environment variable to define the gpu type which results in the ""correct"" TORCH_COMMAMD

this is my current docker-file
```
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone --depth 1 https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (TORCH_COMMAND from webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7"" \
 && bash -e ./webui.sh -f --data-dir /data --skip-torch-cuda-test --exit \
 && rm -rf /data/*

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"", ""--medvram"" ]
```",exit seems work ii completely overlooked also setting torch command works already spotted case need know correct packages versions urls goal use suggested settings webui sh e g case export torch command pip install torch torchvision torchaudio index url command use change rocm version add package set specific version would dockerfile would nice option environment variable define gpu type results correct torch commamd current docker file rocm pytorch rocm ubuntu py pytorch release workdir automatic install packages run apt update apt install google perftools bc install recommends apt clean clone repo run mkdir p data git clone depth prepare environment torch command webui sh run mount type cache target root cache pip export torch command pip install torch torchvision torchaudio index url bash e webui sh f data dir data skip torch cuda test exit rm rf data expose volume data cmd automatic webui sh f api listen skip prepare environment data dir data precision full half medvram
auto1111_webui,comment,16762,,"so are you asking for something like
if `gpu_info` is pre defined
then don't run the gpu test like `lspci 2>/dev/null | grep -E ""VGA|Display""` ` grep -q ""NVIDIA""` ` grep -q ""AMD""`
but still sets `TORCH_COMMAND` base on the pre defined value of `gpu_info`",2024-12-30T22:22:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565968020,"so are you asking for something like
if `gpu_info` is pre defined
then don't run the gpu test like `lspci 2>/dev/null | grep -E ""VGA|Display""` ` grep -q ""NVIDIA""` ` grep -q ""AMD""`
but still sets `TORCH_COMMAND` base on the pre defined value of `gpu_info`",asking something like gpu info pre defined run gpu test like lspci dev null grep e vga display grep q nvidia grep q amd still sets torch command base pre defined value gpu info
auto1111_webui,comment,16762,,"something like this would be nice.
or maybe a new variable or arguments like --amd-gpu and --nvidia-gpu (maybe more depending on the count of TORCH_COMMAND)",2024-12-30T23:07:26Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565995771,"something like this would be nice.
or maybe a new variable or arguments like --amd-gpu and --nvidia-gpu (maybe more depending on the count of TORCH_COMMAND)",something like would nice maybe new variable arguments like amd gpu nvidia gpu maybe depending count torch command
auto1111_webui,comment,16762,,"if you really have a clear idea of what you want
then it's better that you make a PR and see if others agree with your addition",2024-12-30T23:49:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2566014634,"if you really have a clear idea of what you want
then it's better that you make a PR and see if others agree with your addition",really clear idea want better make pr see others agree addition
auto1111_webui,comment,16762,,"I think the easiest change would be something like this
```
if [[ -z ""${TORCH_GPU}"" ]]
then
    gpu_info=$(lspci 2>/dev/null | grep -E ""VGA|Display"")
else
    gpu_info=$TORCH_GPU
fi
```",2024-12-31T00:24:44Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2566031879,"I think the easiest change would be something like this
```
if [[ -z ""${TORCH_GPU}"" ]]
then
    gpu_info=$(lspci 2>/dev/null | grep -E ""VGA|Display"")
else
    gpu_info=$TORCH_GPU
fi
```",think easiest change would something like z torch gpu gpu info lspci dev null grep e vga display else gpu info torch gpu fi
auto1111_webui,issue,16760,[Bug]: LORAs installed does not show up at Lora tab ,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

LORAs installed does not show up at Lora tab 
![Lora didnt show up](https://github.com/user-attachments/assets/86796bf9-3c27-4da5-bdbd-3cab74e02649)


### Steps to reproduce the problem

I have installed some LORAs but not idea why it won't show up at Lora Tab. Please help.

### What should have happened?

Under Lora tab should display all the Lora I have installed.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2024-12-29-13-11.json](https://github.com/user-attachments/files/18269696/sysinfo-2024-12-29-13-11.json)


### Console logs

```Shell
venv ""C:\Auto1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 13:09:10.222780: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 13:09:10.947711: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 13:09:16,846 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 13:09:16,948 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 13:09:18,551 - ControlNet - INFO - ControlNet v1.1.448
13:09:19 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 13:09:21,984 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
AnimateDiffScript init
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 42.9s (prepare environment: 23.5s, import torch: 4.1s, import gradio: 1.1s, setup paths: 3.4s, initialize shared: 0.3s, other imports: 0.7s, setup codeformer: 0.2s, load scripts: 7.1s, create ui: 1.6s, gradio launch: 0.7s).
Applying attention optimization: Doggettx... done.
Model loaded in 11.8s (load weights from disk: 1.5s, create model: 0.9s, apply weights to model: 7.8s, apply half(): 0.1s, move model to device: 0.4s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.8s).
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 20:56:32.029570: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 20:56:32.754525: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 20:56:40,169 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 20:56:40,173 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 20:56:40,174 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 20:56:40,322 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 20:56:43,388 - ControlNet - INFO - ControlNet v1.1.448
20:56:45 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 20:56:49,154 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
AnimateDiffScript init
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 61.0s (prepare environment: 36.6s, import torch: 4.1s, import gradio: 1.0s, setup paths: 3.2s, initialize shared: 0.3s, other imports: 1.6s, setup codeformer: 0.2s, load scripts: 11.6s, create ui: 2.0s, gradio launch: 0.6s).
Applying attention optimization: Doggettx... done.
activating extra network lora: TypeError
Traceback (most recent call last):
  File ""C:\Auto1111\stable-diffusion-webui\modules\extra_networks.py"", line 145, in activate
    extra_network.activate(p, [])
  File ""C:\Auto1111\stable-diffusion-webui\extensions-builtin\Lora\extra_networks_lora.py"", line 18, in activate
    p.all_prompts = [x + f""<lora:{additional}:{shared.opts.extra_networks_default_multiplier}>"" for x in p.all_prompts]
TypeError: 'NoneType' object is not iterable

Model loaded in 15.2s (load weights from disk: 1.6s, create model: 1.1s, apply weights to model: 11.1s, apply half(): 0.1s, move model to device: 0.4s, calculate empty prompt: 0.8s).
```


### Additional information

_No response_",2024-12-29T13:13:10Z,fion0412,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760,"[Bug]: LORAs installed does not show up at Lora tab  ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

LORAs installed does not show up at Lora tab 
![Lora didnt show up](https://github.com/user-attachments/assets/86796bf9-3c27-4da5-bdbd-3cab74e02649)


### Steps to reproduce the problem

I have installed some LORAs but not idea why it won't show up at Lora Tab. Please help.

### What should have happened?

Under Lora tab should display all the Lora I have installed.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2024-12-29-13-11.json](https://github.com/user-attachments/files/18269696/sysinfo-2024-12-29-13-11.json)


### Console logs

```Shell
venv ""C:\Auto1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 13:09:10.222780: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 13:09:10.947711: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 13:09:16,846 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 13:09:16,948 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 13:09:18,551 - ControlNet - INFO - ControlNet v1.1.448
13:09:19 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 13:09:21,984 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
AnimateDiffScript init
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 42.9s (prepare environment: 23.5s, import torch: 4.1s, import gradio: 1.1s, setup paths: 3.4s, initialize shared: 0.3s, other imports: 0.7s, setup codeformer: 0.2s, load scripts: 7.1s, create ui: 1.6s, gradio launch: 0.7s).
Applying attention optimization: Doggettx... done.
Model loaded in 11.8s (load weights from disk: 1.5s, create model: 0.9s, apply weights to model: 7.8s, apply half(): 0.1s, move model to device: 0.4s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.8s).
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 20:56:32.029570: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 20:56:32.754525: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 20:56:40,169 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 20:56:40,173 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 20:56:40,174 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 20:56:40,322 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 20:56:43,388 - ControlNet - INFO - ControlNet v1.1.448
20:56:45 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 20:56:49,154 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
AnimateDiffScript init
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 61.0s (prepare environment: 36.6s, import torch: 4.1s, import gradio: 1.0s, setup paths: 3.2s, initialize shared: 0.3s, other imports: 1.6s, setup codeformer: 0.2s, load scripts: 11.6s, create ui: 2.0s, gradio launch: 0.6s).
Applying attention optimization: Doggettx... done.
activating extra network lora: TypeError
Traceback (most recent call last):
  File ""C:\Auto1111\stable-diffusion-webui\modules\extra_networks.py"", line 145, in activate
    extra_network.activate(p, [])
  File ""C:\Auto1111\stable-diffusion-webui\extensions-builtin\Lora\extra_networks_lora.py"", line 18, in activate
    p.all_prompts = [x + f""<lora:{additional}:{shared.opts.extra_networks_default_multiplier}>"" for x in p.all_prompts]
TypeError: 'NoneType' object is not iterable

Model loaded in 15.2s (load weights from disk: 1.6s, create model: 1.1s, apply weights to model: 11.1s, apply half(): 0.1s, move model to device: 0.4s, calculate empty prompt: 0.8s).
```


### Additional information

_No response_",bug loras installed show lora tab checklist issue exists disabling extensions issue exists clean installation webui issue caused extension believe caused bug webui x issue exists current version webui issue reported recently issue reported fixed yet happened loras installed show lora tab lora didnt show steps reproduce problem installed loras idea show lora tab please help happened lora tab display lora installed browsers use access ui google chrome sysinfo sysinfo json console logs shell venv c auto stable diffusion webui venv scripts python exe python tags v c b bd aug msc v bit amd version v commit hash cf fab af da e e acdca f e module xformers processing without module xformers processing without module xformers proceeding without installing requirements face editor installed check tensorflow cpu failed spec none installing requirements easyphoto webui installing requirements tensorflow cuda launching web ui arguments tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts module xformers processing without module xformers processing without module xformers proceeding without extension sd webui replacer requires sd webui segment anything installed modelscope info pytorch version cu found modelscope info tensorflow version found modelscope info loading ast index c users fion cache modelscope ast indexer modelscope info loading done current index file version md e cc f ebf b f total number components indexed controlnet preprocessor location c auto stable diffusion webui extensions sd webui controlnet annotator downloads controlnet info controlnet v reactor status running v b device cuda error loading script replacer main ui py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer main ui py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location error loading script replacer script py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer script py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location loading weights b fd c auto stable diffusion webui models stable diffusion sdxlyamersanime stageanima safetensors animatediffscript init animatediffscript init controlnet info controlnet ui callback registered facefusion core ffmpeg installed animatediffscript init creating model config c auto stable diffusion webui repositories generative models configs inference sd xl base yaml running local url create public link set share true launch error executing callback app started callback c auto stable diffusion webui extensions sd webui replacer scripts replacer api py traceback recent call last file c auto stable diffusion webui modules script callbacks py line app started callback c callback demo app file c auto stable diffusion webui extensions sd webui replacer scripts replacer api py line replacer api scripts sam import sam model list modulenotfounderror module named scripts sam startup time prepare environment import torch import gradio setup paths initialize shared imports setup codeformer load scripts create ui gradio launch applying attention optimization doggettx done model loaded load weights disk create model apply weights model apply half move model device load textual inversion embeddings calculate empty prompt python tags v c b bd aug msc v bit amd version v commit hash cf fab af da e e acdca f e module xformers processing without module xformers processing without module xformers proceeding without installing requirements face editor installed check tensorflow cpu failed spec none installing requirements easyphoto webui installing requirements tensorflow cuda launching web ui arguments tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts tensorflow core util port cc onednn custom operations may see slightly different numerical results due floating point round errors different computation orders turn set environment variable tf enable onednn opts module xformers processing without module xformers processing without module xformers proceeding without extension sd webui replacer requires sd webui segment anything installed modelscope info pytorch version cu found modelscope info tensorflow version found modelscope info loading ast index c users fion cache modelscope ast indexer modelscope info loading done current index file version md e cc f ebf b f total number components indexed controlnet preprocessor location c auto stable diffusion webui extensions sd webui controlnet annotator downloads controlnet info controlnet v reactor status running v b device cuda error loading script replacer main ui py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer main ui py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location error loading script replacer script py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer script py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location loading weights b fd c auto stable diffusion webui models stable diffusion sdxlyamersanime stageanima safetensors animatediffscript init animatediffscript init controlnet info controlnet ui callback registered facefusion core ffmpeg installed creating model config c auto stable diffusion webui repositories generative models configs inference sd xl base yaml animatediffscript init running local url create public link set share true launch error executing callback app started callback c auto stable diffusion webui extensions sd webui replacer scripts replacer api py traceback recent call last file c auto stable diffusion webui modules script callbacks py line app started callback c callback demo app file c auto stable diffusion webui extensions sd webui replacer scripts replacer api py line replacer api scripts sam import sam model list modulenotfounderror module named scripts sam startup time prepare environment import torch import gradio setup paths initialize shared imports setup codeformer load scripts create ui gradio launch applying attention optimization doggettx done activating extra network lora typeerror traceback recent call last file c auto stable diffusion webui modules extra networks py line activate extra network activate p file c auto stable diffusion webui extensions builtin lora extra networks lora py line activate p prompts x f lora additional shared opts extra networks default multiplier x p prompts typeerror nonetype object iterable model loaded load weights disk create model apply weights model apply half move model device calculate empty prompt additional information response
auto1111_webui,comment,16760,,"By default, it'll only display LORAs compatible with the loaded checkpoint. Make sure you have SDXL LORAs.

Other than that, not all of the files you have in there are LORAs.
`cuteCartoon_v10.safetensors` is a checkpoint. Put it in `models/Stable-diffusion`.
`canny-modified.safetensors` is a controlnet model. It goes in `models/ControlNet`.

```
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)
```
This one is due to your webui version being too old. Update with `git pull`

```json
{
    ""name"": ""stable-diffusion-webui"",
    ""path"": ""C:\\Auto1111\\stable-diffusion-webui\\extensions\\stable-diffusion-webui"",
    ""version"": ""1c0a0c4c"",
    ""branch"": ""master"",
    ""remote"": ""https://github.com/AUTOMATIC1111/stable-diffusion-webui""
},
```
How did that happen? Delete `C:\Auto1111\stable-diffusion-webui\extensions\stable-diffusion-webui`

You might also try it without extensions. You can do that with the `--disable-all-extensions` argument.",2024-12-30T01:37:50Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2564939931,"By default, it'll only display LORAs compatible with the loaded checkpoint. Make sure you have SDXL LORAs.

Other than that, not all of the files you have in there are LORAs.
`cuteCartoon_v10.safetensors` is a checkpoint. Put it in `models/Stable-diffusion`.
`canny-modified.safetensors` is a controlnet model. It goes in `models/ControlNet`.

```
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)
```
This one is due to your webui version being too old. Update with `git pull`

```json
{
    ""name"": ""stable-diffusion-webui"",
    ""path"": ""C:\\Auto1111\\stable-diffusion-webui\\extensions\\stable-diffusion-webui"",
    ""version"": ""1c0a0c4c"",
    ""branch"": ""master"",
    ""remote"": ""https://github.com/AUTOMATIC1111/stable-diffusion-webui""
},
```
How did that happen? Delete `C:\Auto1111\stable-diffusion-webui\extensions\stable-diffusion-webui`

You might also try it without extensions. You can do that with the `--disable-all-extensions` argument.",default display loras compatible loaded checkpoint make sure sdxl loras files loras cutecartoon v safetensors checkpoint put models stable diffusion canny modified safetensors controlnet model goes models controlnet error loading script replacer main ui py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer main ui py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location error loading script replacer script py traceback recent call last file c auto stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c auto stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c auto stable diffusion webui extensions sd webui replacer scripts replacer script py line module replacer ui import replacer tab ui file c auto stable diffusion webui extensions sd webui replacer replacer ui replacer tab ui py line module modules import shared ui settings errors infotext utils importerror cannot import name infotext utils modules unknown location one due webui version old update git pull json name stable diffusion webui path c auto stable diffusion webui extensions stable diffusion webui version c c c branch master remote happen delete c auto stable diffusion webui extensions stable diffusion webui might also try without extensions disable extensions argument
auto1111_webui,comment,16760,,Let me try first git pull and see whether can appear all installed LORA in my LORA tab,2024-12-31T05:45:52Z,fion0412,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2566152281,Let me try first git pull and see whether can appear all installed LORA in my LORA tab,let try first git pull see whether appear installed lora lora tab
auto1111_webui,comment,16760,,I've encountered the same situation; has this been resolved?,2025-01-02T14:02:44Z,ropz12138,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2567822563,I've encountered the same situation; has this been resolved?,encountered situation resolved
auto1111_webui,comment,16760,,"I've encountered the same issue, I'm using Norton 365, wondering if that may have had something to do with it???
I've uninstalled, re-installed: Python 3.10.6, SD1.5, A1111, Even loaded it on a non-system drive, still no fix. 
This happened suddenly, on New Years Eve.  All Loras were working and suddenly, nothing. They just disapeared from the UI, but were still in the Lora folder when examined in file explorer.

Error Message when I refresh:
Nothing here. Add some content to the following directories:
E:\stable-diffusion-webui\models\Lora
E:\stable-diffusion-webui\models\LyCORIS
",2025-01-02T16:26:51Z,turkeelurkee,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2568039359,"I've encountered the same issue, I'm using Norton 365, wondering if that may have had something to do with it???
I've uninstalled, re-installed: Python 3.10.6, SD1.5, A1111, Even loaded it on a non-system drive, still no fix. 
This happened suddenly, on New Years Eve.  All Loras were working and suddenly, nothing. They just disapeared from the UI, but were still in the Lora folder when examined in file explorer.

Error Message when I refresh:
Nothing here. Add some content to the following directories:
E:\stable-diffusion-webui\models\Lora
E:\stable-diffusion-webui\models\LyCORIS",encountered issue using norton wondering may something uninstalled installed python sd even loaded non system drive still fix happened suddenly new years eve loras working suddenly nothing disapeared ui still lora folder examined file explorer error message refresh nothing add content following directories e stable diffusion webui models lora e stable diffusion webui models lycoris
auto1111_webui,comment,16760,,"Found what got my Loras back from another forum:

Hello! If you are using Stable Diffusion 1111 — All you need to do is:

**1 — Go to the ""Settings"" menu.
2 — Click on the sub-menu ""Extra Networks"".
3 — Scroll down and click on the option ""Always show all networks on the Lora page"".
4 — Click on the ""Apply Settings"" button (at the top of the page).
5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**

ALL your Loras appear or are back!",2025-01-02T18:37:10Z,turkeelurkee,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2568202959,"Found what got my Loras back from another forum:

Hello! If you are using Stable Diffusion 1111 — All you need to do is:

**1 — Go to the ""Settings"" menu.
2 — Click on the sub-menu ""Extra Networks"".
3 — Scroll down and click on the option ""Always show all networks on the Lora page"".
4 — Click on the ""Apply Settings"" button (at the top of the page).
5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**

ALL your Loras appear or are back!",found got loras back another forum hello using stable diffusion need go settings menu click sub menu extra networks scroll click option always show networks lora page click apply settings button top page go extra network tab click refresh button ta daaa works loras appear back
auto1111_webui,comment,16760,,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 — All you need to do is:
> 
> **1 — Go to the ""Settings"" menu. 2 — Click on the sub-menu ""Extra Networks"". 3 — Scroll down and click on the option ""Always show all networks on the Lora page"". 4 — Click on the ""Apply Settings"" button (at the top of the page). 5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works!",2025-03-26T21:11:30Z,Eeoneguy356,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2755757187,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 — All you need to do is:
> 
> **1 — Go to the ""Settings"" menu. 2 — Click on the sub-menu ""Extra Networks"". 3 — Scroll down and click on the option ""Always show all networks on the Lora page"". 4 — Click on the ""Apply Settings"" button (at the top of the page). 5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works!",found got loras back another forum hello using stable diffusion need go settings menu click sub menu extra networks scroll click option always show networks lora page click apply settings button top page go extra network tab click refresh button ta daaa works loras appear back thanks works
auto1111_webui,comment,16760,,I met same problem,2025-05-28T19:48:22Z,fan9704,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2917439725,I met same problem,met problem
auto1111_webui,comment,16760,,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 — All you need to do is:
> 
> **1 — Go to the ""Settings"" menu. 2 — Click on the sub-menu ""Extra Networks"". 3 — Scroll down and click on the option ""Always show all networks on the Lora page"". 4 — Click on the ""Apply Settings"" button (at the top of the page). 5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works for me!",2025-05-28T19:50:01Z,fan9704,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2917442958,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 — All you need to do is:
> 
> **1 — Go to the ""Settings"" menu. 2 — Click on the sub-menu ""Extra Networks"". 3 — Scroll down and click on the option ""Always show all networks on the Lora page"". 4 — Click on the ""Apply Settings"" button (at the top of the page). 5 — Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works for me!",found got loras back another forum hello using stable diffusion need go settings menu click sub menu extra networks scroll click option always show networks lora page click apply settings button top page go extra network tab click refresh button ta daaa works loras appear back thanks works
auto1111_webui,issue,16759,[Bug]: Error loading script: main.py,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when started webui-user.bat, I got this error message:

*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

When I try to send to txt2img the openpose s pose , nothing happened, when I manually set up the pose pictures, the picture isnt posed with the pose I setup....

Sorry I am a bit lost, If someone can help me I would be gratefull

### Steps to reproduce the problem

1.l auch webui-user.bat

2. get the error:

Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

3. 3dopenpose doesnt want to send the pose and other controlnet such as depht for example to the txt2img or img2img.

4. after setting up the pose pictuer into controlnet parameter and setting up the options. it doesnt follow the pose...

### What should have happened?

1. No error on startting webui-user.bat

2. Openpose can send the picures to img2img or txt2img

3. I got the result with a picture with the pose I set up

### What browsers do you use to access the UI ?

Mozilla Firefox, Google Chrome

### Sysinfo

[sysinfo-2024-12-28-17-43.json](https://github.com/user-attachments/files/18267048/sysinfo-2024-12-28-17-43.json)


### Console logs

```Shell
off ""C:\Users\netwo\AppData\Local\Programs\Python\Python310\python.exe

C:\Users\netwo\stable-diffusion-webui>set PYTHON=

C:\Users\netwo\stable-diffusion-webui>set GIT=

C:\Users\netwo\stable-diffusion-webui>set VENV_DIR=

C:\Users\netwo\stable-diffusion-webui>set COMMANDLINE_ARGS= ""--xformers""

C:\Users\netwo\stable-diffusion-webui>call webui.bat
venv ""C:\Users\netwo\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

---
ControlNet preprocessor location: C:\Users\netwo\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-28 18:45:35,296 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [d803b444ed] from C:\Users\netwo\stable-diffusion-webui\models\Stable-diffusion\disneyrealcartoonmix_v10.safetensors
2024-12-28 18:45:36,849 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: C:\Users\netwo\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Startup time: 21.3s (prepare environment: 9.4s, import torch: 4.1s, import gradio: 1.6s, setup paths: 0.8s, import ldm: 0.1s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 3.2s, create ui: 0.7s, gradio launch: 0.6s).
```


### Additional information

_No response_",2024-12-28T17:46:16Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16759,"[Bug]: Error loading script: main.py ### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when started webui-user.bat, I got this error message:

*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

When I try to send to txt2img the openpose s pose , nothing happened, when I manually set up the pose pictures, the picture isnt posed with the pose I setup....

Sorry I am a bit lost, If someone can help me I would be gratefull

### Steps to reproduce the problem

1.l auch webui-user.bat

2. get the error:

Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

3. 3dopenpose doesnt want to send the pose and other controlnet such as depht for example to the txt2img or img2img.

4. after setting up the pose pictuer into controlnet parameter and setting up the options. it doesnt follow the pose...

### What should have happened?

1. No error on startting webui-user.bat

2. Openpose can send the picures to img2img or txt2img

3. I got the result with a picture with the pose I set up

### What browsers do you use to access the UI ?

Mozilla Firefox, Google Chrome

### Sysinfo

[sysinfo-2024-12-28-17-43.json](https://github.com/user-attachments/files/18267048/sysinfo-2024-12-28-17-43.json)


### Console logs

```Shell
off ""C:\Users\netwo\AppData\Local\Programs\Python\Python310\python.exe

C:\Users\netwo\stable-diffusion-webui>set PYTHON=

C:\Users\netwo\stable-diffusion-webui>set GIT=

C:\Users\netwo\stable-diffusion-webui>set VENV_DIR=

C:\Users\netwo\stable-diffusion-webui>set COMMANDLINE_ARGS= ""--xformers""

C:\Users\netwo\stable-diffusion-webui>call webui.bat
venv ""C:\Users\netwo\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

---
ControlNet preprocessor location: C:\Users\netwo\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-28 18:45:35,296 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [d803b444ed] from C:\Users\netwo\stable-diffusion-webui\models\Stable-diffusion\disneyrealcartoonmix_v10.safetensors
2024-12-28 18:45:36,849 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: C:\Users\netwo\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Startup time: 21.3s (prepare environment: 9.4s, import torch: 4.1s, import gradio: 1.6s, setup paths: 0.8s, import ldm: 0.1s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 3.2s, create ui: 0.7s, gradio launch: 0.6s).
```


### Additional information

_No response_",bug error loading script main py checklist issue exists disabling extensions issue exists clean installation webui x issue caused extension believe caused bug webui issue exists current version webui issue reported recently issue reported fixed yet happened started webui user bat got error message error loading script main py traceback recent call last file c users netwo stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c users netwo stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c users netwo stable diffusion webui extensions openpose editor scripts main py line module basicsr utils download util import load file url modulenotfounderror module named basicsr try send txt img openpose pose nothing happened manually set pose pictures picture isnt posed pose setup sorry bit lost someone help would gratefull steps reproduce problem l auch webui user bat get error launching web ui arguments xformers error loading script main py traceback recent call last file c users netwo stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c users netwo stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c users netwo stable diffusion webui extensions openpose editor scripts main py line module basicsr utils download util import load file url modulenotfounderror module named basicsr dopenpose doesnt want send pose controlnet depht example txt img img img setting pose pictuer controlnet parameter setting options doesnt follow pose happened error startting webui user bat openpose send picures img img txt img got result picture pose set browsers use access ui mozilla firefox google chrome sysinfo sysinfo json console logs shell c users netwo appdata local programs python python python exe c users netwo stable diffusion webui set python c users netwo stable diffusion webui set git c users netwo stable diffusion webui set venv dir c users netwo stable diffusion webui set commandline args xformers c users netwo stable diffusion webui call webui bat venv c users netwo stable diffusion webui venv scripts python exe python tags v cc apr msc v bit amd version v commit hash c ae bd abdf eda b e launching web ui arguments xformers error loading script main py traceback recent call last file c users netwo stable diffusion webui modules scripts py line load scripts script module script loading load module scriptfile path file c users netwo stable diffusion webui modules script loading py line load module module spec loader exec module module file frozen importlib bootstrap external line exec module file frozen importlib bootstrap line call frames removed file c users netwo stable diffusion webui extensions openpose editor scripts main py line module basicsr utils download util import load file url modulenotfounderror module named basicsr controlnet preprocessor location c users netwo stable diffusion webui extensions sd webui controlnet annotator downloads controlnet info controlnet v loading weights b ed c users netwo stable diffusion webui models stable diffusion disneyrealcartoonmix v safetensors controlnet info controlnet ui callback registered running local url create public link set share true launch creating model config c users netwo stable diffusion webui repositories generative models configs inference sd xl base yaml startup time prepare environment import torch import gradio setup paths import ldm initialize shared imports load scripts create ui gradio launch additional information response
auto1111_webui,comment,16759,,"
Thaanks I fixed the issue by uploading ... install packages

but no I have no more message error, but 3dopenpose seems not working
",2024-12-29T13:21:25Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16759#issuecomment-2564724201,"Thaanks I fixed the issue by uploading ... install packages

but no I have no more message error, but 3dopenpose seems not working",thaanks fixed issue uploading install packages message error dopenpose seems working
auto1111_webui,issue,16750,[Feature Request]: 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！,"### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！

### Proposed workflow

请问下，webui是放弃更新了吗？感觉已经好久没有更新了！

### Additional information

 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！",2024-12-25T07:35:32Z,BannyLon,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16750,"[Feature Request]: 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！ ### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！

### Proposed workflow

请问下，webui是放弃更新了吗？感觉已经好久没有更新了！

### Additional information

 请问下，webui是放弃更新了吗？感觉已经好久没有更新了！",feature request webui existing issue x searched existing issues checked recent builds commits would feature webui proposed workflow webui additional information webui
auto1111_webui,comment,16750,,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/pulse
people are working in the background",2024-12-31T01:31:27Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16750#issuecomment-2566058703,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/pulse
people are working in the background",people working background
