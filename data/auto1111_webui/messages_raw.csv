repo_slug,type,issue_number,title,body,created_at,user,url
auto1111_webui,issue,17255,[Bug]: RuntimeError: Couldn't clone Stable Diffusion.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The ""auto-install"" can't find the repository for stablediffusion: Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

I checked they repository and they not moved. They deleted the repository. Looks like this is dead now?

### Steps to reproduce the problem

Just try to install

### What should have happened?

Clean install

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no need for the problem

### Console logs

```Shell
Creating venv in directory D:\Auto\stable-diffusion-webui\venv using python ""C:\Program Files\Python310\python.exe""
Requirement already satisfied: pip in d:\auto\stable-diffusion-webui\venv\lib\site-packages (22.2.1)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.2.1
    Uninstalling pip-22.2.1:
      Successfully uninstalled pip-22.2.1
Successfully installed pip-25.3
venv ""D:\Auto\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.1.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.3-py3-none-any.whl (16 kB)
Using cached fsspec-2026.1.0-py3-none-any.whl (201 kB)
Using cached https://d21usjoq99fcb9.cloudfront.net/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)
Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2026.1.4 charset_normalizer-3.4.4 filelock-3.20.3 fsspec-2026.1.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.1.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.3
Installing clip
Installing open_clip
Cloning assets into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.47 MiB/s, done.
Cloning Stable Diffusion into D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\Auto\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\Auto\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\Auto\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Press any key to continue . . .
```

### Additional information

Alternative: Forge or ComfyUI",2026-01-19T20:59:37Z,KaityTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255
auto1111_webui,comment,17255,,"open modules/launch_utils.pyï¼Œ edit 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")
to 
stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")",2026-01-20T01:47:27Z,zhangchang725,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3770666470
auto1111_webui,comment,17255,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2026-01-20T05:51:25Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3771156482
auto1111_webui,comment,17255,,switch to dev branch,2026-01-31T18:09:51Z,AlexPetrusca,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3828950541
auto1111_webui,comment,17255,,"Having a similar issue. Im having some issues in the same code lines as yours, but some are also different. After install and clicking webui-user.bat It looks like this on the log 

venv ""C:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Fetching updates for Stable Diffusion...
info: please complete authentication in your browser...
Traceback (most recent call last):
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 160, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""C:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""C:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch
Error code: 128
stderr: remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Press any key to continue . . .",2026-02-01T03:07:55Z,ForgottenLogic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3830195522
auto1111_webui,comment,17255,,Using this as a core reference for my startup. Pushed some useful extensions to my profile if anyone needs them.,2026-02-05T17:28:39Z,oil666oil,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3855092828
auto1111_webui,comment,17255,,"Same issue, install on main doesn't work. Can you please fix so main be working?",2026-02-08T23:57:13Z,Ignalion,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3868592841
auto1111_webui,comment,17255,,"Got it! The error youâ€™re seeing is explained in the log itself:
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found

Your WebUI is trying to clone/fetch the old repository https://github.com/Stability-AI/stablediffusion.git,
which no longer exists. This is a common issue with newer versions of
SD WebUI if the STABLE_DIFFUSION_REPO is set incorrectly.

You mentioned in your webui-user.bat:

set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

Thatâ€™s correct for the w-e-w version. However, your WebUI is still trying to use the old Stability-AI/stablediffusion repo. This usually happens if the variable wasnâ€™t picked up correctly or an old repository already exists.

**Step-by-Step Fix**

**_Delete the old repository_**

Go to:
C:\AI\stable-diffusion-webui\repositories\

- Delete the folder stable-diffusion-stability-ai.
- This prevents WebUI from trying to fetch the old repo.

**_Make sure the environment variable is correct_**

In webui-user.bat, it should be:
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

- Make sure there are no typos or extra spaces.

Restart WebUI
- Run webui.bat again.
- It should now clone/fetch the w-e-w repository.

Optional: test cloning manually

cd C:\AI\stable-diffusion-webui\repositories
git clone https://github.com/w-e-w/stablediffusion.git stable-diffusion-stability-a


ViolÃ !",2026-02-09T20:19:26Z,sageliebi-maker,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17255#issuecomment-3873635028
auto1111_webui,issue,17251,[Bug]: Error while executing run.bat,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

Download the sd.webui.zip > run update.bat and execute run.bat

### What should have happened?

The webUI should be oppened on localhost:7860

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

None

### Console logs

```Shell
stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\alvar\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",2026-01-17T01:18:39Z,alvvos,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251
auto1111_webui,comment,17251,,I am facing the same issue.,2026-02-01T13:24:28Z,TheDamnedScientist,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251#issuecomment-3831041657
auto1111_webui,comment,17251,,"I am also facing the same issue

<img width=""1702"" height=""1025"" alt=""Image"" src=""https://github.com/user-attachments/assets/139eabf4-364a-4caa-b0f2-9432929ef970"" />",2026-02-06T07:37:13Z,vaemsdev,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17251#issuecomment-3858546960
auto1111_webui,issue,17245,[Feature Request]:Some sort of Options in the Settings for Automating Various Things if Possible,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature/Enhancement Request:
Could we Possibly Get some sort of Options in the Settings of the Webui to Automate These because its getting a Bit Tiresome to Find the Right ones for these every time 

<img width=""1222"" height=""64"" alt=""Image"" src=""https://github.com/user-attachments/assets/5d147f1b-6010-44fb-bca2-0583b93cf40d"" />
<img width=""937"" height=""97"" alt=""Image"" src=""https://github.com/user-attachments/assets/687ee083-e821-47a5-8abf-022bb8c1b7c1"" />
<img width=""1231"" height=""45"" alt=""Image"" src=""https://github.com/user-attachments/assets/8ccc3784-2b4e-4274-a50e-d046bf5e1869"" />

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2026-01-09T16:31:41Z,LadyFlames,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17245
auto1111_webui,comment,17245,,"this might be what you're looking for https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/User-Interface-Customizations
specifically section on `UI item order`
you can customize the orders of the options to a certain degree
",2026-01-12T07:20:28Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17245#issuecomment-3737187907
auto1111_webui,issue,17244,[Feature Request]: appimage,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

stable-diffusion-webui in appimage???????????????

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2026-01-09T00:48:43Z,kmnnmk212-source,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17244
auto1111_webui,comment,17244,,Okay what the hell?how would an appimage even work with stabel diffusion? it can but its very stupid idea since appimages have prebuild dependencys in it but the files still have to cloned somewhere the only thing different is just running an appimage and what reason you need an appimage.(Im not the developer or helper of the project just a guy giving an opinion and the confusion of the feature enhancement),2026-01-19T19:52:18Z,FemBoyGamerTechGuy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17244#issuecomment-3769900390
auto1111_webui,issue,17236,[Bug]:  AssertionError: Torch not compiled with CUDA enabled,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when starting web-ui.bat it shows error:
`RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`
when adding argument to variable its not generating and shows error:
`AssertionError: Torch not compiled with CUDA enabled`

### Steps to reproduce the problem

1. get runtimeerror above
2. add --skip-torch-cuda-test to COMMANDLINE_ARGS var
3. generate img2img

### What should have happened?

work

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2026-01-04-08-13.json](https://github.com/user-attachments/files/24420699/sysinfo-2026-01-04-08-13.json)

### Console logs

```Shell
venv ""C:\Users\elmar_86\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [cc6cb27103] from C:\Users\elmar_86\stable-diffusion-webui\models\Stable-diffusion\v1-5-pruned-emaonly.ckpt
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.3s (prepare environment: 0.4s, import torch: 2.6s, import gradio: 0.6s, setup paths: 0.4s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.3s).
Creating model from config: C:\Users\elmar_86\stable-diffusion-webui\configs\v1-inference.yaml
C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: AssertionError
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
    _lazy_init()
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
    raise AssertionError(""Torch not compiled with CUDA enabled"")
AssertionError: Torch not compiled with CUDA enabled


Stable diffusion model failed to load
Exception in thread Thread-16 (load_model):
Traceback (most recent call last):
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\elmar_86\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\initialize.py"", line 154, in load_model
    devices.first_time_calculation()
  File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 277, in first_time_calculation
    linear(x)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File ""C:\Users\elmar_86\stable-diffusion-webui\extensions-builtin\Lora\networks.py"", line 584, in network_Linear_forward
    return originals.Linear_forward(self, input)
  File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: ""addmm_impl_cpu_"" not implemented for 'Half'
Using already loaded model v1-5-pruned-emaonly.ckpt [cc6cb27103]: done in 0.0s
*** Error completing request
*** Arguments: ('task(iba2sr0ecdrv7hs)', <gradio.routes.Request object at 0x0000020525B6FC40>, 0, 'improve quality', 'sketch art, worse quality', [], <PIL.Image.Image image mode=RGBA size=423x525 at 0x20525B6FBE0>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 512, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""C:\Users\elmar_86\stable-diffusion-webui\modules\devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 769, in current_device
        _lazy_init()
      File ""C:\Users\elmar_86\stable-diffusion-webui\venv\lib\site-packages\torch\cuda\__init__.py"", line 289, in _lazy_init
        raise AssertionError(""Torch not compiled with CUDA enabled"")
    AssertionError: Torch not compiled with CUDA enabled

---
```

### Additional information

_No response_",2026-01-04T08:16:38Z,WhO2022,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17236
auto1111_webui,issue,17235,https://github.com/Stability-AI/stablediffusion.git is 404,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/82a973c04367123ae98bd9abdf80d9eda9b910e2/modules/launch_utils.py#L349C70-L349C121,2026-01-04T07:35:04Z,emit991,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235
auto1111_webui,comment,17235,,"This is a known issue with downloading the zip folder. A fix has been merged into the dev branch, which updates webui to clone from a working fork. 
Be sure to clone the repository, and not download the zip file. 
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
#17213 ",2026-01-04T08:17:51Z,grilledpanini,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3707856241
auto1111_webui,comment,17235,,"Thanks a lot! This is super helpful! Would it be possible to add this important information to the repoâ€™s homepage? I think a lot of people would benefit from it.

<img width=""1061"" height=""278"" alt=""Image"" src=""https://github.com/user-attachments/assets/7b4aff98-39e2-4d7c-97fa-93a27e28d3a5"" />",2026-01-15T14:57:05Z,crawlingsnail9,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3755268912
auto1111_webui,comment,17235,,"Thank you for this issue, i got a lot of error but now it works!",2026-01-17T18:09:40Z,DaniNotFound702,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3764172511
auto1111_webui,comment,17235,,"> git pull

It seems that the dev version Pytorch version has become 2.7.0ï¼Œand doesn't support my V100 GPU any more

RuntimeError: CUDA error: no kernel image is available for execution on the device

Iâ€˜m using Ubuntu and Tesla V100",2026-01-19T17:00:48Z,Cryghast,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17235#issuecomment-3769378299
auto1111_webui,issue,17227,[Bug]: Installation fails due to missing Git submodule https://github.com/Stability-AI/stablediffusion.git,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installation fails immediately because the launcher tries to clone a GitHub repository that no longer exists (https://github.com/Stability-AI/stablediffusion.git). This causes a fatal Git error and prevents the WebUI from starting, even with a correct Python setup or when using the release ZIP. This blocks new users from installing the software.

### Steps to reproduce the problem


Download the latest official release ZIP of stable-diffusion-webui from the AUTOMATIC1111 GitHub.
Extract the ZIP on Windows.
Run webui-user.bat.
During startup, the launcher attempts to clone https://github.com/Stability-AI/stablediffusion.git.
The repository does not exist, causing a Git error (Error 128).
The WebUI stops and does not launch.

### What should have happened?

The WebUI should launch successfully without Git errors, complete setup automatically, and open the user interface in the browser.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Sysinfo unavailable:
WebUI cannot be started due to a fatal Git clone error during initial launch (Stability-AI/stablediffusion.git repository not found). The installation folder was removed after repeated failed attempts, so a sysinfo file could not be generated.

### Console logs

```Shell
Console logs unavailable:
The WebUI fails during initial startup before the interface or logging system initializes. The process stops with a fatal Git error while attempting to clone https://github.com/Stability-AI/stablediffusion.git (repository not found). Because the UI never successfully starts and the installation folder was removed after repeated failures, full console logs cannot be provided.
```

### Additional information

This issue occurs on a clean setup following the official installation instructions, with no local modifications. The failure happens consistently on first launch and appears to be caused by a hard-coded reference to a deleted GitHub repository, not by environment configuration.",2025-12-29T06:00:36Z,nellappli-nell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227
auto1111_webui,comment,17227,,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17213

This worked for me.",2025-12-29T10:15:25Z,Arcxsun,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696072020
auto1111_webui,comment,17227,,"It appears that all new fixes go to the dev branch now, not master.",2025-12-29T10:41:57Z,nick-morhun,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696135080
auto1111_webui,comment,17227,,"Thanks for the clarification.
This confirms the issue: the default install still targets master, which is currently broken, while fixes only exist on dev.
This causes fresh installs to fail before the UI can start. Either master needs to be fixed, or the installer/docs should explicitly default to dev to prevent broken first-time installs.",2025-12-29T14:22:31Z,nellappli-nell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3696664541
auto1111_webui,comment,17227,,it's 404 too  - https://github.com/wew/stablediffusion,2025-12-29T19:16:19Z,johnxrist702-cmd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3697303705
auto1111_webui,comment,17227,,"You've provided excellent documentation of this issue. This is indeed the same Stability-AI repository problem affecting many users today.

The repository https://github.com/Stability-AI/stablediffusion.git has been taken down (404), breaking all new installations.

Since you mentioned this affects even the official release ZIP, the issue is in the hardcoded repository URL in the codebase. The maintainers need to update this to point to an alternative repository.

For now, there's no clean workaround for new installations. Keep watching the repo for an official fix - this is a critical blocker affecting everyone trying to install.",2025-12-30T00:48:14Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3697937491
auto1111_webui,comment,17227,,duplicate from [https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204),2025-12-30T13:05:33Z,xoxefdp,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3699304399
auto1111_webui,comment,17227,,"@nellappli-nell  You can try add on `webui.bat`, it works for me

```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```",2026-01-01T15:17:23Z,yassershahofficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3703816303
auto1111_webui,comment,17227,,"> it's 404 too - https://github.com/wew/stablediffusion

https://github.com/w-e-w/stablediffusion",2026-01-01T15:56:06Z,nick-morhun,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3703846891
auto1111_webui,comment,17227,,"I updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) so the fix is included by default
uses who use that package (assuming that package works for them) don't need to add the add
```bat
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```
if they launch using `run.bat`

---

for people manually cloning and installing the master branch there's nothing much we can do
AUTOMATIC1111 is the only one with the privileges to update the master branch and he's gone silent
me and one other collaborator only have access to the dev branch, and we have fixed dev branch
I have pinned a guide on how to fix ths issue, but people don't read it
",2026-01-05T21:49:31Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3712204689
auto1111_webui,comment,17227,,"There no way to install ? always have a error and open a window of login git hub, ",2026-01-07T13:54:56Z,ZIGAIBNX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3719006593
auto1111_webui,comment,17227,,"> [@nellappli-nell](https://github.com/nellappli-nell) You can try add on `webui.bat`, it works for me
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```

yes this worked for me thx :)",2026-01-17T05:21:03Z,god-sriji,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3762685158
auto1111_webui,comment,17227,,"**æˆ‘çš„æŠ¥é”™ï¼š**
stderr: fatal: unable to access 'https://github.com/Stability-AI/stablediffusion.git/': Recv failure: Connection was reset
[Exited, code 1 (0x00000001)]

**è§£å†³æ–¹æ³•ï¼š**

æ­¥éª¤ 1ï¼šæ‰¾åˆ°ç›®æ ‡æ–‡ä»¶
æ‰“å¼€è·¯å¾„ï¼š...\sd-webui-aki-v4.11.1-cu128\modules\launch_utils.py
æ­¥éª¤ 2ï¼šæ›¿æ¢ git_clone å‡½æ•°ä»£ç 
å°†æ–‡ä»¶ä¸­åŸå§‹çš„ git_clone å‡½æ•°å…¨éƒ¨åˆ é™¤ï¼Œæ›¿æ¢ä¸ºä»¥ä¸‹ä¿®æ”¹åçš„ä»£ç ï¼ˆå·²æ³¨é‡Šæ‰€æœ‰ç½‘ç»œæ“ä½œï¼Œä¿ç•™æœ¬åœ°æ–‡ä»¶å¤¹åˆ¤æ–­ï¼‰ï¼š
`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful
    # æ ¸å¿ƒä¿®æ”¹ï¼šæœ¬åœ°æ–‡ä»¶å¤¹å­˜åœ¨åˆ™ç›´æ¥è¿”å›ï¼Œè·³è¿‡æ‰€æœ‰ç½‘ç»œæ“ä½œï¼ˆfetch/checkout/remoteï¼‰
    if os.path.exists(dir):
        print(f""æœ¬åœ°å·²å­˜åœ¨{name}ä»“åº“ï¼Œè·³è¿‡æ‰€æœ‰Gitç½‘ç»œæ“ä½œï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶"")
        return

    # ä»…å½“æœ¬åœ°æ— æ–‡ä»¶å¤¹æ—¶ï¼Œæ‰æ‰§è¡Œå…‹éš†ï¼ˆå¯é€‰ï¼šæ³¨é‡Šæ‰å…‹éš†ï¼Œå½»åº•ç¦ç”¨ç½‘ç»œï¼‰
    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    # æ³¨é‡Šæ‰å“ˆå¸Œæ ¡éªŒï¼Œé¿å…åç»­ç½‘ç»œè¯·æ±‚
    # if commithash is not None:
    #     run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, f""Couldn't checkout {name}'s hash: {commithash}"")
`

æ­¥éª¤ 3ï¼šç¡®ä¿æœ¬åœ°æœ‰å®Œæ•´çš„ä»“åº“æ–‡ä»¶å¤¹
ç¡®è®¤repositoriesä¸‹æœ‰å®Œæ•´çš„stable-diffusion-stability-aiæ–‡ä»¶å¤¹ï¼ˆè‹¥æ²¡æœ‰ï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼è·å–ï¼‰ï¼š
    ä¸‹è½½å›½å†…é•œåƒåŒ…ï¼šhttps://github.com/w-e-w/stablediffusion/archive/refs/heads/main.zip
    è§£å‹åå°†æ–‡ä»¶å¤¹é‡å‘½åä¸ºstable-diffusion-stability-ai
    æ”¾åˆ°è·¯å¾„ï¼š...\sd-webui-aki-v4.11.1-cu128\repositories\

æ­¥éª¤ 4ï¼šä¿å­˜æ–‡ä»¶å¹¶å¯åŠ¨
    ä¿å­˜launch_utils.pyï¼ˆè‹¥æç¤ºæƒé™ä¸è¶³ï¼Œå³é”®æ–‡ä»¶â†’å±æ€§â†’å®‰å…¨ï¼Œç»™å½“å‰ç”¨æˆ·æ·»åŠ å†™å…¥æƒé™ï¼‰
    åŒå‡» SD-WebUI å¯åŠ¨å™¨ï¼Œæ­¤æ—¶ä¼šç›´æ¥è·³è¿‡ Git ç½‘ç»œæ“ä½œï¼Œæ— æŠ¥é”™å¯åŠ¨ã€‚


é™„ï¼š
è¢«æ›¿æ¢çš„é‚£æ®µåŸä»£ç ï¼š

`def git_clone(url, dir, name, commithash=None):
    # TODO clone into temporary dir and move if successful

    if os.path.exists(dir):
        if commithash is None:
            return

        current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
        if current_hash == commithash:
            return

        if run_git(dir, name, 'config --get remote.origin.url', None, f""Couldn't determine {name}'s origin URL"", live=False).strip() != url:
            run_git(dir, name, f'remote set-url origin ""{url}""', None, f""Failed to set {name}'s origin URL"", live=False)

        run_git(dir, name, 'fetch', f""Fetching updates for {name}..."", f""Couldn't fetch {name}"", autofix=False)

        run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)

        return

    try:
        run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
    except RuntimeError:
        shutil.rmtree(dir, ignore_errors=True)
        raise

    if commithash is not None:
        run(f'""{git}"" -C ""{dir}"" checkout {commithash}', None, ""Couldn't checkout {name}'s hash: {commithash}"")
`",2026-02-07T04:16:19Z,renxingblack,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17227#issuecomment-3863540453
auto1111_webui,issue,17225,[Bug]: RuntimeError: Couldn't clone assets.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Cloning assets into /root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
æ­£å…‹éš†åˆ° '/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
fatal: æ— æ³•è®¿é—® 'https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git/'ï¼šFailed to connect to github.com port 443 after 133654 ms: è¿æ¥è¶…æ—¶
Traceback (most recent call last):
  File ""/root/stable-diffusion-webui/launch.py"", line 53, in <module>
    main()
  File ""/root/stable-diffusion-webui/launch.py"", line 44, in main
    prepare_environment()
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 443, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 190, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/root/stable-diffusion-webui/modules/launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone assets.
Command: ""git"" clone --config core.filemode=false ""https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git"" ""/root/stable-diffusion-webui/repositories/stable-diffusion-webui-assets""
Error code: 128

### Steps to reproduce the problem

An error was reported when starting the project

### What should have happened?

The project was successfully launched.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

-

### Console logs

```Shell
-
```

### Additional information

_No response_",2025-12-27T14:17:32Z,Kysen121,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17225
auto1111_webui,comment,17225,,"Thanks for opening this issue! I'm interested in contributing to this. ğŸ‘‹

## ğŸ¤” Understanding the Requirements

To provide the best solution, I'd like to understand:

**Context:**
- What's the current behavior?
- What's the expected/desired behavior?
- What's the impact or use case?

**Scope:**
- Are there any specific requirements or constraints?
- Any preferences for implementation approach?
- Related issues or PRs?

**Success Criteria:**
- What would ""done"" look like for this issue?
- Any specific metrics or tests needed?

## ğŸ’ª How I Can Help

I have experience with AUTOMATIC1111 projects and can contribute:

- ğŸ” **Investigation**: Research and propose solutions
- ğŸ’» **Implementation**: Write clean, tested code
- âœ… **Testing**: Comprehensive test coverage
- ğŸ“š **Documentation**: Clear docs and examples
- ğŸ‘€ **Review**: Iterate based on feedback

## ğŸš€ My Approach

1. Understand requirements thoroughly
2. Research best practices and similar solutions
3. Design before implementing
4. Write tests first (TDD)
5. Implement incrementally
6. Document clearly
7. Iterate based on review

Let me know if this is still open and how I can help! I'm excited to contribute. ğŸ¯

**My relevant experience:**
- Similar projects and features
- Modern development practices
- Open source contribution
- Production system experience

Feel free to assign this to me if you'd like me to work on it! ğŸ™Œ",2025-12-30T00:48:23Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17225#issuecomment-3697937639
auto1111_webui,issue,17218,[Bug]: RuntimeError: Couldn't clone Stable Diffusion.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Can't find Repository 

### Steps to reproduce the problem

just start webui-user.bat

### What should have happened?

start webui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't get to WebUI

### Console logs

```Shell
:\AI\stable-diffusion-webui>git pull
Already up to date.
venv ""D:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\AI\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""D:\AI\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""D:\AI\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Ğ»ÑĞ±ÑƒÑ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆÑƒ . . .
```

### Additional information

_No response_",2025-12-21T17:30:23Z,FireTheHedge,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218
auto1111_webui,comment,17218,,Same.  The repository has been deleted.,2025-12-21T23:07:14Z,TorvaldUtne,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3679661710
auto1111_webui,comment,17218,,"404 not found, any ideas?
",2025-12-22T07:57:17Z,Lizuardi612,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3680908953
auto1111_webui,comment,17218,,Where can I get these swap files now?,2025-12-22T08:17:36Z,Desync-Using,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3680975423
auto1111_webui,comment,17218,,"> Same. The repository has been deleted.

gave upï¼Œ plan to use comfyui",2025-12-22T12:01:22Z,903345072,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3681773815
auto1111_webui,comment,17218,,"Read this discussion, there is a way to fix it https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212",2025-12-22T16:26:58Z,Laura7277,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3682812080
auto1111_webui,comment,17218,,"Modify the contents of webui-user.bat

@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=
set STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git

call webui.bat",2025-12-23T08:12:10Z,akunone,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3685657243
auto1111_webui,comment,17218,,"Switch to the ```dev``` branch, or do this:

Delete the ```repositories``` folder.

Open modules>launch_utils.py

Change Line 349 from

 ```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")```

to

```stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/w-e-w/stablediffusion.git"")```

Launch webui-user.bat again.


",2025-12-23T12:36:47Z,kavyamali,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3686500416
auto1111_webui,comment,17218,,"For Mac users:
in `webui-user.sh` file add this line: 
```bash
export STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
```",2025-12-24T22:18:05Z,zjor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3690560549
auto1111_webui,comment,17218,,"Me, too!
æˆ‘ä¿®æ”¹åˆ°äº†devåˆ†æ”¯ï¼š
cd /d C:\Users\Administrator\Desktop\Projects\stable-diffusion-webui
git switch dev
git pull",2025-12-26T01:36:06Z,zhhehe8,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3691899786
auto1111_webui,comment,17218,,"Another user hit by the Stability-AI repo being down. This is the main issue affecting fresh installs today.

Error 128 indicates git failed to clone because the repository at https://github.com/Stability-AI/stablediffusion.git no longer exists (404).

This needs to be fixed at the project level - the repo URL needs to be updated to a working alternative. Keep checking the main repo for updates from the maintainers.",2025-12-30T00:48:33Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3697937780
auto1111_webui,comment,17218,,Same issue. Please fix it.,2026-01-17T16:48:08Z,tianxuanliu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17218#issuecomment-3764096436
auto1111_webui,issue,17217,[Bug]: Cannot import 'setuptools.build_meta',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

It's sayed I need Cannot import 'setuptools.build_meta'

### Steps to reproduce the problem

use run.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't go in it

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 2
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\fires\appdata\local\temp\pip-req-build-4j1bd_oe
  Resolved https://github.com/TencentARC/GFPGAN.git to commit 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\fires\AppData\Local\Temp\pip-req-build-4j1bd_oe'
  Running command git rev-parse -q --verify 'sha^8d2447a2d918f8eba5a4a01463fd48e45126a379'
  Running command git fetch -q https://github.com/TencentARC/GFPGAN.git 8d2447a2d918f8eba5a4a01463fd48e45126a379
  Running command git checkout -q 8d2447a2d918f8eba5a4a01463fd48e45126a379
ERROR: Exception:
Traceback (most recent call last):
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\Programs\Windows\Tools\Python\AI\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'


Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Ğ»ÑĞ±ÑƒÑ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆÑƒ . . .
```

### Additional information

_No response_",2025-12-21T16:11:15Z,FireTheHedge,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217
auto1111_webui,comment,17217,,Duplicate of #17162 ,2025-12-25T05:59:42Z,4piu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3690975975
auto1111_webui,comment,17217,,"This is a different issue from the repository 404 errors others are experiencing. Your error is about setuptools.

The issue is that pip can't import 'setuptools.build_meta' when trying to install GFPGAN. This typically happens when setuptools is outdated or corrupted.

Try this fix:
1. Navigate to your webui directory
2. Run: 
3. Then try running webui-user.bat again

If that doesn't work, you might need to delete the venv folder and let it rebuild from scratch.",2025-12-30T00:48:42Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3697937922
auto1111_webui,comment,17217,,"Maybe Python is just not installed on that OS installation ? 
I know it is my case, with the same error message. ",2026-01-18T01:05:45Z,Baraz-Siriel,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17217#issuecomment-3764555160
auto1111_webui,issue,17216,[Bug]: Repository not found.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when I run webui-user.bat, I get an error saying that there is no such repository! I tried to fix it using chatGPT, but it didn't work...

<img width=""983"" height=""860"" alt=""Image"" src=""https://github.com/user-attachments/assets/3aa51a46-dfc8-4716-9298-66f20e19e80f"" />

### Steps to reproduce the problem

clone the repository and open webui-user.bat

### What should have happened?

localhost and neural network will be launched

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

.

### Console logs

```Shell
Creating venv in directory E:\!2\stable-diffusion-webui\venv using python ""C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe""
Requirement already satisfied: pip in e:\!2\stable-diffusion-webui\venv\lib\site-packages (22.0.4)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.0.4
    Uninstalling pip-22.0.4:
      Successfully uninstalled pip-22.0.4
Successfully installed pip-25.3
venv ""E:\!2\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from torchvision==0.16.2)
  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)
Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Using cached pillow-12.0.0-cp310-cp310-win_amd64.whl (7.0 MB)
Using cached filelock-3.20.1-py3-none-any.whl (16 kB)
Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)
Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.3 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.1 fsspec-2025.12.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.0.0 requests-2.32.5 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.15.0 urllib3-2.6.2
Installing clip
Installing open_clip
Installing xformers
Cloning Stable Diffusion into E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\!2\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""E:\!2\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""E:\!2\stable-diffusion-webui\repositories\stable-diffusion-stability-ai""
Error code: 128
Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Ğ»ÑĞ±ÑƒÑ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆÑƒ . . .
```

### Additional information

webui-user.bat :
@echo off
set PYTHON=C:\Users\harin\AppData\Local\Programs\Python\Python310\python.exe
set COMMANDLINE_ARGS=--medvram --xformers --listen
call webui.bat
",2025-12-21T09:21:18Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216
auto1111_webui,comment,17216,,"I'm sorry, I don't know what to write in ""Sysinfo""",2025-12-21T09:22:19Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3678629683
auto1111_webui,comment,17216,,"<img width=""1218"" height=""670"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b16e864-059c-45fa-ad34-5cf207333c7a"" />",2025-12-21T09:22:50Z,Beelzebub-Hell,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3678629985
auto1111_webui,comment,17216,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2025-12-23T10:58:50Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3686182444
auto1111_webui,comment,17216,,"Looking at the screenshot, the error shows git is failing to find a repository, which typically happens when there's a network/proxy issue or the stable-diffusion-webui-assets repo is being blocked. The path `E:\!2\stable-diffusion-webui` with the exclamation mark could also be causing issues since special characters in paths sometimes break scripts. Try moving your installation to a simpler path like `E:\sd-webui` without special characters. If that doesn't help, check if you can manually run `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-assets.git` from command line to see the actual error message, which would tell us if it's a network or authentication problem.",2025-12-30T01:11:01Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17216#issuecomment-3697977733
auto1111_webui,issue,17214,[Bug]: RuntimeError: Couldn't fetch Stable Diffusion.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

What should I do?



### Steps to reproduce the problem

/

### What should have happened?

Can't open web UI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

/

### Console logs

```Shell
venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
```

### Additional information

_No response_",2025-12-20T15:19:37Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214
auto1111_webui,comment,17214,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2025-12-20T16:56:34Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3677956643
auto1111_webui,comment,17214,,"I'm still getting the error.

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 176, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 164, in run_git
    git_fix_workspace(dir, name)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 151, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""D:\StableDiffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128

",2025-12-23T14:53:24Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3686918979
auto1111_webui,comment,17214,,"my bad, you have this line in the logs
```sh
Couldn't determine Stable Diffusion's hash: cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf, attempting autofix...
```
basically webui thinks there is something wrong with your currently downloaded
`stable-diffusion-webui\repositories\stable-diffusion-stability-ai`
so it's calling to GitHub to the original repository to fix it

the fix I provide only works if the for new installs, because when trying to `autofix` the updated url is ignored

in this case the simplest thing to do is to just delete the existing folder `stable-diffusion-webui\repositories\stable-diffusion-stability-ai` then try again, and it will re-clone it
> deleting the folder basically bring you to the same state as a new install",2025-12-23T15:42:44Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687084974
auto1111_webui,comment,17214,,"Thank you! I was able to install it successfully, but I can't generate images.

RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.",2025-12-23T17:49:23Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687475087
auto1111_webui,comment,17214,,"you're really not giving me much information to work with other than ""most likely it's not working because of GPU related issue"" 
I can't help you unless you give me more information upload sysinfo
what GPU do you have",2025-12-23T19:54:09Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3687817910
auto1111_webui,comment,17214,,I'm using a GeForce RTX 5080.,2025-12-23T23:29:01Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3688205043
auto1111_webui,comment,17214,,"> I'm using a GeForce RTX 5080.

pretty sure you are in the same situation as this person
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199#issuecomment-3687812778

without your assist info I can only guess at your situation
my guess is that currently the torch version installed is on compatible with older gpus

I would try delete venv and try again

base on your log
```
Version: v1.10.1-93-gfd68e0c3
```
you're on dev branch
so it should install the correct version of torch",2025-12-24T07:34:06Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3688946657
auto1111_webui,comment,17214,,"I deleted the stable diffusion venv folder and ran it again, but this time I got a different error.
Is there any other information I need?

venv ""D:\StableDiffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-93-gfd68e0c3
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 53, in <module>
    main()
  File ""D:\StableDiffusion\stable-diffusion-webui\launch.py"", line 49, in main
    start()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\launch_utils.py"", line 497, in start
    import webui
  File ""D:\StableDiffusion\stable-diffusion-webui\webui.py"", line 13, in <module>
    initialize.imports()
  File ""D:\StableDiffusion\stable-diffusion-webui\modules\initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'",2025-12-24T19:39:24Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3690422253
auto1111_webui,comment,17214,,I restarted it and it worked fine! Thank you for your support so far.,2025-12-24T21:44:58Z,ao2reina3-alt,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3690534342
auto1111_webui,comment,17214,,I'm facing the same problem; please tell me how you were able to solve it.,2025-12-25T18:12:33Z,rafee1997,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3691648720
auto1111_webui,comment,17214,,"Same issue here - the Stability-AI repository is down. You're getting error 128 because git can't clone from a non-existent repo.

This is affecting multiple users today (see #17205, #17208, #17218). The core problem is https://github.com/Stability-AI/stablediffusion.git returning 404.

Until there's an official fix, your options are limited. The project maintainers will need to update the repository URL in the codebase. Watch for updates in the main repo.",2025-12-30T00:48:59Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3697938204
auto1111_webui,comment,17214,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:36:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17214#issuecomment-3700286508
auto1111_webui,issue,17208,[Bug]: The StableDiffusion Repository is offline.,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The StableDiffision Repository is offline, so I cannot use Automatic1111 anymore.

### Steps to reproduce the problem

Run the webui-user.bat and the install breaks when it tries to clone the StableDiffusion git.

### What should have happened?

Automatic1111 should just installed fine.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Not needed

### Console logs

```Shell
Not needed
```

### Additional information

_No response_",2025-12-18T15:21:22Z,RichieRich1891,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208
auto1111_webui,comment,17208,,Same problem,2025-12-19T04:11:27Z,LifeCheckpoint,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3673404975
auto1111_webui,comment,17208,,"Please see this link
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3669833420",2025-12-19T12:20:41Z,alles,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3674876261
auto1111_webui,comment,17208,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2025-12-20T09:00:26Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3677623547
auto1111_webui,comment,17208,,"The Stability-AI repository being offline is affecting everyone right now. This is the root cause preventing new installations.

The immediate issue is that https://github.com/Stability-AI/stablediffusion.git returns 404. This affects all fresh installs and anyone trying to update.

For now, you might want to:
- Use an existing installation if you have one
- Wait for the maintainers to update to a new repository URL
- Or manually modify the launch scripts to skip or use an alternative repo

This seems to be the same issue affecting #17205, #17214, #17218 and others today.",2025-12-30T00:49:08Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3697938339
auto1111_webui,comment,17208,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:34:38Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17208#issuecomment-3700281878
auto1111_webui,issue,17205,"[Bug]: Repository not found, error 128","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I run a1111 in the terminal, I see error 128. I tried a clean reinstall of stable diffusion, it didn't help

### Steps to reproduce the problem

1. Launch webui-user.bat
2. You will see GitHub login window
3. Login
4. See error 128

### What should have happened?

You will get this error

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cant lauch webui to produce Sysinfo

### Console logs

```Shell
venv ""E:\Python\stable_diffusion\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't determine Stable Diffusion's hash: f16630a927e00098b524d687640719e4eb469b76, attempting autofix...
Fetching all contents for Stable Diffusion
info: please complete authentication in your browser...
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""E:\Python\stable_diffusion\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch Stable Diffusion.
Command: ""git"" -C ""E:\Python\stable_diffusion\stable-diffusion-webui\repositories\stable-diffusion-stability-ai"" fetch --refetch --no-auto-gc
Error code: 128
Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Ğ»ÑĞ±ÑƒÑ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆÑƒ . . .
```

### Additional information

https://github.com/Stability-AI/stablediffusion - 404 page not found",2025-12-17T10:41:11Z,shyameli,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205
auto1111_webui,comment,17205,,"I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private",2025-12-17T15:26:31Z,khaledadrani,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3665862775
auto1111_webui,comment,17205,,Same here...,2025-12-18T07:41:54Z,yohanesc1987,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3668823550
auto1111_webui,comment,17205,,"if anyone is looking for a fork, I have a fork under my account
https://github.com/w-e-w/stablediffusion.git

I also made a pr to update it on the dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/17207
",2025-12-18T11:27:25Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3669833420
auto1111_webui,comment,17205,,![Image](https://github.com/user-attachments/assets/c87a5c89-79cd-4cf8-b94b-3e6a543943da),2025-12-18T15:16:13Z,bilalaliyu3892-rgb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3670802993
auto1111_webui,comment,17205,,"Solution:

1. go to stable_diffusion\stable-diffusion-webui\repositories\
2. remove folder stable-diffusion-stability-ai
3. use git bash in repositories\ - git clone https://github.com/Stability-AI/generative-models.git stable-diffusion-stability-ai
4. run webui-user.bat",2025-12-19T03:29:57Z,shyameli,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3673335848
auto1111_webui,comment,17205,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2025-12-20T09:00:53Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3677624170
auto1111_webui,comment,17205,,"> I think what needs to be done, is to change the url for the latest stable ""fork"" of the original repository, it looks like it went private

how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one
",2025-12-21T06:18:31Z,ritz33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3678506194
auto1111_webui,comment,17205,,"> how to change url im new to this shi and am troubleshooting this entirely without any knowledge can you guide me how to change url to new one

@ritz33 
I believe you have read
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

what part are you having trouble understanding

---

if you have already figured out is there anything I can add to the post I made to make it more clearer",2025-12-21T08:46:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3678603767
auto1111_webui,comment,17205,,"I see you're hitting error 128 with the missing Stability-AI repository. This is a widespread issue right now - the original repo appears to be down (404).

The error happens because webui tries to clone https://github.com/Stability-AI/stablediffusion.git/ which no longer exists.

As a quick workaround, you can:
1. Edit  around line 412
2. Change the repo URL to point to a fork or mirror
3. Or comment out the git_clone line for stable-diffusion-stability-ai temporarily

The maintainers will likely need to update the default repo URL. Keep an eye on the repo for an official fix\!",2025-12-30T00:49:17Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3697938481
auto1111_webui,comment,17205,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:34:02Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17205#issuecomment-3700280265
auto1111_webui,issue,17204,[Bug]: Repository not found: Stability-AI/stablediffusion (public clone fails),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When trying to install Stable Diffusion WebUI on Ubuntu 24.04, the installation script fails with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".
This happens even when using a GitHub Personal Access Token. The installation cannot proceed because the required repository is not accessible.

```
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': *****
Password for 'https://*****': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
```


### Steps to reproduce the problem

Install dependencies:
```
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
```

Install Python 3.11:

```
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11
```
Create a new directory and download the webui.sh script:

```
mkdir stable-diffusion
cd stable-diffusion
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
chmod +x webui.sh
```

Run the installation script:
```
./webui.sh
```
`The script will attempt to clone the repository https://github.com/Stability-AI/stablediffusion.git, but it will fail with the error:
""remote: Repository not found. fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found"".

### What should have happened?


The installation script should have successfully cloned the required Stable Diffusion repository and continued with the setup. 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Unable to generate sysinfo file because WebUI fails to start due to repository not found error. If needed, I can provide system details manually (Ubuntu 24.04, Python 3.11, RTX 5070 Ti).

### Console logs

```Shell
aleksei@ubusteam:~/stable-diffusion$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on aleksei user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.11.14 (main, Oct 10 2025, 08:54:04) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Cloning Stable Diffusion into /home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
Username for 'https://github.com': ****
Password for 'https://****github.com': 
remote: Repository not found.
fatal: repository 'https://github.com/Stability-AI/stablediffusion.git/' not found
Traceback (most recent call last):
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""/home/aleksei/stable-diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""/home/aleksei/stable-diffusion/stable-diffusion-webui/repositories/stable-diffusion-stability-ai""
Error code: 128
aleksei@ubusteam:~/stable-diffusion$
```

### Additional information

_No response_",2025-12-16T20:50:33Z,AlexeyMRX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204
auto1111_webui,comment,17204,,"Same issue here, the repository does not seem to exist on github anymore:
https://github.com/Stability-AI/stablediffusion.git
Delivers a 404 page not found error
",2025-12-16T21:23:30Z,bauerwer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662434500
auto1111_webui,comment,17204,,"It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result

As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py

Exact lines are 349 and 355

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`

Change to 

`stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")`
`stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`

**This is in no way a permanent solution. I don't know the dev behind that repository.**

_**DO THIS AT YOUR OWN RISK !!!!**_

",2025-12-16T22:42:03Z,BlackCharon142,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662743174
auto1111_webui,comment,17204,,"> It seems to have been just changed to private or closed since every search engine i try comes up with the repository as the number 1 result
> 
> As a temporary solution I changed the url and hash of the repo to a fork that was made quite recently, the file to edit is in the `modules` folder and the file to edit is launch_utils.py
> 
> Exact lines are 349 and 355
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Stability-AI/stablediffusion.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf"")`
> 
> Change to
> 
> `stable_diffusion_repo = os.environ.get('STABLE_DIFFUSION_REPO', ""https://github.com/Kantyadoram/stable-diffusion-stability-ai.git"")` `stable_diffusion_commit_hash = os.environ.get('STABLE_DIFFUSION_COMMIT_HASH', ""7435a5be1050962a936a4ef624b43814ee8824a8"")`
> 
> **This is in no way a permanent solution. I don't know the dev behind that repository.**
> 
> _**DO THIS AT YOUR OWN RISK !!!!**_

it's safer replacing it in the ~~webui.sh~~ (correction: there are multiple files for this purpose already, suggested is webui-user.sh) or wrap the sh with another sh file setting the envs",2025-12-16T23:21:30Z,marco-porru,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3662854834
auto1111_webui,comment,17204,,"I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):

https://github.com/joypaul162/Stability-AI-stablediffusion

Commit hash: `f16630a927e00098b524d687640719e4eb469b76`

So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.",2025-12-17T01:38:50Z,thenickdude,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663211808
auto1111_webui,comment,17204,,"Thanks Nick, that modification in modules/launch_utils.py fixed the issue for me.",2025-12-17T03:26:42Z,Galvinox,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663471355
auto1111_webui,comment,17204,,"Thanks Nick, worked for me too

> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, worked for me too",2025-12-17T03:43:35Z,Edderou,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663507706
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks, I added the following to `webui-user.bat`:
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and ran `run.bat` again. This fixed the issue for me.",2025-12-17T03:53:46Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3663524626
auto1111_webui,comment,17204,,"I am alos running Stable Diffusion WebUI (but on Windows 11), and I am facing the same problem with the ""stable-diffusion-stability-ai"" repository not being found. Hopefully, the official team can make improvements. QAQ",2025-12-17T10:28:53Z,wateryuen,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3664697139
auto1111_webui,comment,17204,,"This is from a reddit post from a month ago and could be related to the repositories here and on huggingface going down:


> StableITAdmin posted the following message a day after the platform was brought down:
> 
> ""...it looks like our team has decided to deprecate SD 2.0 and 2.1. We were told this official statement:
> 
> 'We have officially deprecated Stable Diffusion 2.0 and 2.1. This is part of our effort to clean up and consolidate our model offering and to get ahead of upcoming compliance requirements for the EU AI Act in 2026. These models have been outpaced by newer architectures that offer far stronger performance, safety, and alignment, and continuing to maintain them does not fit our long-term roadmap.
> 
> 'If you currently rely on SD 2.0 or 2.1 for an active business use case, please reach out and share your workflow and requirements. While these models will no longer be part of our public lineup, we want to make sure that any legitimate business dependencies are surfaced so we can explore the right path forward with you.' ",2025-12-17T12:41:45Z,azolash,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3665175573
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

I also just forked if anyone needs a backup option, same commit hash.

https://github.com/glens/Stability-AI-stablediffusion.git",2025-12-18T07:40:40Z,glens,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3668819570
auto1111_webui,comment,17204,,"- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/17207
",2025-12-18T11:30:15Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3669844132
auto1111_webui,comment,17204,,"i changed the git url the commit hash, nothing is happening, not able to run this, please anyone help",2025-12-19T03:18:28Z,zsyborg,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3673316896
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

Thanks bro, it helps",2025-12-20T06:58:43Z,crowthek4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3677489800
auto1111_webui,comment,17204,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212,2025-12-20T09:02:15Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3677625965
auto1111_webui,comment,17204,," File ""D:\stable-diffusion-portable-main\venv\lib\site-packages\torch\_meta_registrations.py"", line 5351, in zeros_like
        res.fill_(0)
    torch.AcceleratorError: CUDA error: no kernel image is available for execution on the device
    Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
    CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
    For debugging consider passing CUDA_LAUNCH_BLOCKING=1
    Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


It gave me this error, but it ran in the browser. Images aren't generated.",2025-12-21T11:55:05Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3678727081
auto1111_webui,comment,17204,,"I think SD2 has long been used in both AIGC community and AI research community. I hope even if stabilityai take it down, the community is going to maintain an official repo of SD2 including checkpoints, codes etc. (also I want SD1.4 SD1.5 back)

I have both sd2-1-base and sd1-5-base checkpoints locally , contact me if any need it.",2025-12-22T09:08:44Z,Bili-Sakura,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3681130624
auto1111_webui,comment,17204,,"Hello,
is it neccessarry to download that Repo if I downloaded my own model from Huggingface? Could I just completely disable cloning it?",2025-12-22T10:52:53Z,axoking,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3681554788
auto1111_webui,comment,17204,,"AcceleratorError: CUDA error: no kernel image is available for execution on the device Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information. CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Can you suggest what to do about this?",2025-12-25T15:16:25Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3691532265
auto1111_webui,comment,17204,,"
Fix Windows:
```bash
clear;
cd /d stable-diffusion-webui\modules

powershell -Command ""(Get-Content launch_utils.py) -replace 'https://github.com/Stability-AI/stablediffusion.git', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui.git' | Set-Content launch_utils.py""

powershell -Command ""(Get-Content launch_utils.py) -replace 'cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf', '82a973c04367123ae98bd9abdf80d9eda9b910e2' | Set-Content launch_utils.py""
```

Fix Linux (not tested)
```bash
clear;
cd stable-diffusion-webui/modules
sed -i -e ""s/https\:\/\/github.com\/Stability\-AI\/stablediffusion\.git/https\:\/\/github.com\/AUTOMATIC1111\/stable\-diffusion\-webui\.git/g"" launch_utils.py 
sed -i -e ""s/cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf/82a973c04367123ae98bd9abdf80d9eda9b910e2/g""  launch_utils.py
```",2025-12-25T16:49:29Z,dexter74,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3691596954
auto1111_webui,comment,17204,,"From https://github.com/AUTOMATIC1111/stable-diffusion-webui
 * branch              dev        -> FETCH_HEAD
Already up to date.
venv ""venv\Scripts\Python.exe""
fatal: No names found, cannot describe anything.
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Version: 1.10.1
Commit hash: fd68e0c3846b07c637c3d57b0c38f06c8485a753
Fetching updates for Stable Diffusion...
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion, attempting autofix...
Fetching all contents for Stable Diffusion
remote: Enumerating objects: 586, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 586 (delta 2), reused 0 (delta 0), pack-reused 581 (from 1)
Receiving objects:  99% (581/586), 72.44 MiB | 5.59 MiB/s
Receiving objects: 100% (586/586), 73.45 MiB | 5.56 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Pruning Stable Diffusion
Enumerating objects: 592, done.
Counting objects: 100% (592/592), done.
Delta compression using up to 12 threads
Compressing objects: 100% (571/571), done.
Writing objects: 100% (592/592), done.
Total 592 (delta 309), reused 283 (delta 0), pack-reused 0
Checking out commit for Stable Diffusion with hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2...
fatal: reference is not a tree: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""D:\stable-diffusion-portable-main\launch.py"", line 53, in <module>
    main()
  File ""D:\stable-diffusion-portable-main\launch.py"", line 44, in main
    prepare_environment()
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 444, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 185, in git_clone
    run_git(dir, name, f'checkout {commithash}', f""Checking out commit for {name} with hash: {commithash}..."", f""Couldn't checkout commit {commithash} for {name}"", live=True)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 166, in run_git
    return run(f'""{git}"" -C ""{dir}"" {command}', desc=desc, errdesc=errdesc, custom_env=custom_env, live=live)
  File ""D:\stable-diffusion-portable-main\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't checkout commit 82a973c04367123ae98bd9abdf80d9eda9b910e2 for Stable Diffusion.
Command: ""git\cmd\git.exe"" -C ""D:\stable-diffusion-portable-main\repositories\stable-diffusion-stability-ai"" checkout 82a973c04367123ae98bd9abdf80d9eda9b910e2
Error code: 128


New error",2025-12-27T12:32:05Z,asnmsi77-glitch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3693948552
auto1111_webui,comment,17204,,"> > I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> > https://github.com/joypaul162/Stability-AI-stablediffusion
> > Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> > So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.
> 
> Thanks, I added the following to `webui-user.bat`:
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> and ran `run.bat` again. This fixed the issue for me.


well u guys right! just add these command into webui.user.bat: 
```
set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
```
and it fix !",2025-12-28T13:53:33Z,meokinh000,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3694763842
auto1111_webui,comment,17204,,"> I found a fork that has a commit that matches [the last hash from the official repo](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/):
> 
> https://github.com/joypaul162/Stability-AI-stablediffusion
> 
> Commit hash: `f16630a927e00098b524d687640719e4eb469b76`
> 
> So this one is an exact match for the original, you should be able to change only the URL to `https://github.com/joypaul162/Stability-AI-stablediffusion.git` and leave the commit hash as it was.

thank you lifesaver!",2025-12-28T15:46:40Z,crisricc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3694839706
auto1111_webui,comment,17204,,"This isn't a bug in the webui itself - the upstream Stability-AI/stablediffusion repository has been removed or made private by Stability AI, so no amount of authentication will help here. This is affecting all new installations that depend on that repo. The maintainers will need to either mirror the required code somewhere else, bundle it directly, or point to an alternative source. As a temporary workaround, you might be able to manually clone from a community mirror or fork into the expected path before running the installer, though I'd wait to see if there's an official fix coming since this is likely impacting a lot of users right now.",2025-12-30T01:11:31Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3697978211
auto1111_webui,comment,17204,,"> > > æˆ‘æ‰¾åˆ°ä¸€ä¸ªåˆ†æ”¯ï¼Œæäº¤çš„å“ˆ[å¸Œå€¼å’Œå®˜æ–¹ä»“åº“çš„æœ€åä¸€ä¸ªå“ˆå¸Œ](https://web.archive.org/web/20251010224917/https://github.com/Stability-AI/stablediffusion/)ä¸€è‡´ï¼šhttps://github.com/joypaul162/Stability-AI-stablediffusion æäº¤å“ˆå¸Œï¼šè¿™ä¸ªå’ŒåŸæ¥å®Œå…¨åŒ¹é…ï¼Œä½ åº”è¯¥åªæŠŠURLæ”¹æˆï¼Œæäº¤å“ˆå¸Œä¿æŒåŸæ ·ã€‚`f16630a927e00098b524d687640719e4eb469b76``https://github.com/joypaul162/Stability-AI-stablediffusion.git`
> > 
> > 
> > è°¢è°¢ï¼Œæˆ‘è¡¥å……äº†ä»¥ä¸‹å†…å®¹ï¼š`webui-user.bat`
> > ```
> > set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> > set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> > ```
> > 
> > 
> >     
> >       
> >     
> > 
> >       
> >     
> > 
> >     
> >   
> > ç„¶ååˆè·‘äº†ä¸€æ¬¡ã€‚è¿™è§£å†³äº†æˆ‘çš„é—®é¢˜ã€‚`run.bat`
> 
> ä½ ä»¬è¯´å¾—å¯¹ï¼åªéœ€åœ¨ webui.user.bat ä¸­æ·»åŠ ä»¥ä¸‹å‘½ä»¤ï¼š
> 
> ```
> set STABLE_DIFFUSION_REPO=https://github.com/joypaul162/Stability-AI-stablediffusion.git
> set STABLE_DIFFUSION_COMMIT_HASH=f16630a927e00098b524d687640719e4eb469b76
> ```
> 
> è€Œä¸”å®ƒä¿®å¥½äº†ï¼

<img width=""2394"" height=""66"" alt=""Image"" src=""https://github.com/user-attachments/assets/e4ed17fc-0808-4559-817f-126f2409ca33"" />  , also directly modify the launch_utils.py file.",2025-12-30T16:23:19Z,zhugeshenren,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3699862614
auto1111_webui,comment,17204,,"this essentially is a solved issue
I have written a detailed explanation on how to fix it
- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/17212

if you have issues or questions please make your comment over on that post",2025-12-30T19:31:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17204#issuecomment-3700272985
auto1111_webui,issue,17201,[Bug]: Couldn't Install Clip,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I used the NVidia Automatic for Windows method with the sd.webui.zip. 
When attempting to set up using the ""run.bat"" file, it eventually gets to the point where it attempts to install ""clip"". After that it will give me a ""Press and key to continue..."" which will close the Command Window and nothing else will happen.

I've seen others bring this issue up before, however their error codes are different than mine. I'm not very well versed in python to know exactly what is going on here. I've seen some solutions mention running a script in the ""venv"" folder, but I don't even have that, just a ""tmp"" folder.

I have done two clean installs, as well installing in fresh locations, however the same issue arises. I also ran the ""update.bat"" before running ""run.bat"".

### Steps to reproduce the problem

1. Double click ""run.bat""
2. Get error saying it cannot install clip.

### What should have happened?

Install clip and open the WebUI I guess.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

I cannot even get to the WebUI.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash:
Installing clip
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 48, in
main()
File ""M:\AI\Stable Diffusion\sd.webui\webui\launch.py"", line 39, in main
prepare_environment()
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
run_pip(f""install {clip_package}"", ""clip"")
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
File ""M:\AI\Stable Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""M:\AI\Stable Diffusion\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
Installing build dependencies: started
Installing build dependencies: finished with status 'done'
Getting requirements to build wheel: started
Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 107, in _run_wrapper
status = _inner_run()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\base_command.py"", line 98, in _inner_run
return self.run(options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\cli\req_command.py"", line 85, in wrapper
return func(self, options, args)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\commands\install.py"", line 388, in run
requirement_set = resolver.resolve(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
collected = self.factory.collect_root_requirements(root_reqs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
reqs = list(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
cand = self._make_base_candidate_from_link(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
self._link_candidate_cache[link] = LinkCandidate(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 318, in init
super().init(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 161, in init
self.dist = self._prepare()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
dist = self._prepare_distribution()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
return self._prepare_linked_requirement(req, parallel_builds)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
dist = _get_prepared_distribution(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
abstract_dist.prepare_distribution_metadata(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
self._install_build_reqs(build_env_installer)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 132, in _install_build_reqs
build_reqs = self._get_build_requires_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
return backend.get_requires_for_build_wheel()
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
return super().get_requires_for_build_wheel(config_settings=cs)
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 196, in get_requires_for_build_wheel
return self._call_hook(
File ""M:\AI\Stable Diffusion\sd.webui\system\python\lib\site-packages\pip_vendor\pyproject_hooks_impl.py"", line 402, in _call_hook
raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

I have a newer version of Python, but am using pyenv-win to downgrade from 3.12.4 to 3.10.6. Both the Command Prompt from run.bat as well as PowerShell recognize 3.10.6 as the version.

Using an RTX 3090 if that makes any difference.",2025-12-13T05:58:13Z,ZurokSlayer7X9,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201
auto1111_webui,comment,17201,,"å®‰è£… OpenAI CLIPï¼š D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation ""git+ https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1#egg=clip"" 


å®‰è£… OpenCLIPï¼š D:\proj\sd.webui\system\python\python.exe -m pip install --no-build-isolation  https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip",2025-12-15T02:26:57Z,jarvonH,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3652638081
auto1111_webui,comment,17201,,"Looking at this issue, the problem is almost certainly network-related or a Python environment issue rather than a clip-specific bug. The fact that you don't have a venv folder yet suggests the installation is failing very early, before the virtual environment is even fully created. Can you try running run.bat from an administrator command prompt and paste the full console output here? The ""Press any key to continue"" message appears when there's a fatal error, but we need to see what comes before it. Also check if you have Python 3.10.x installed system-wide and that it's in your PATH - the webui requires a specific Python version range and will fail silently if it can't find a compatible interpreter.",2025-12-30T01:11:52Z,tysoncung,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3697978592
auto1111_webui,comment,17201,,"i have the same issue and when i run run.bat from an administrator command prompt this is appears 

INCOMPATIBLE PYTHON VERSION

This program is tested with 3.10.6 Python, but you have 3.14.2.
If you encounter an error with ""RuntimeError: Couldn't install torch."" message,
or any other error regarding unsuccessful package (library) installation,
please downgrade (or upgrade) to the latest version of 3.10 Python
and delete current Python and ""venv"" folder in WebUI's directory.

You can download 3.10 Python from here: https://www.python.org/downloads/release/python-3106/

Alternatively, use a binary release of WebUI: https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre

Use --skip-python-version-check to suppress this warning.
=============================================================================================================================
Python 3.14.2 (tags/v3.14.2:df79316, Dec  5 2025, 17:18:21) [MSC v.1944 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu128
ERROR: Could not find a version that satisfies the requirement torch==2.7.0 (from versions: 2.9.0, 2.9.0+cu128, 2.9.1, 2.9.1+cu128)
ERROR: No matching distribution found for torch==2.7.0
Traceback (most recent call last):
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 53, in <module>
    main()
    ~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\launch.py"", line 44, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 413, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\modules\launch_utils.py"", line 114, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\PERSONAL\OneDrive\Desktop\A1111\webui\venv\Scripts\python.exe"" -m pip install torch==2.7.0 torchvision==0.22.0 --extra-index-url https://download.pytorch.org/whl/cu128
Error code: 1",2026-01-01T13:13:15Z,muhsandi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3703679767
auto1111_webui,comment,17201,,It absolutely is a wrong version of Python issue. Just had to fix my own. I had to track it down in appdata local and just delete the old files then manually install just the 3.10.6 once I got it and installed + added to path it's working fine. ,2026-01-08T20:39:06Z,OmegaVenus32,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3725693079
auto1111_webui,comment,17201,,"1. Clone the Repository

Note: The main branch was last updated two years ago (2024), while the dev branch was last updated on December 18, 2025. According to feedback from issues #17213 and #17235, the dev branch works correctly, so we'll use it.

Option 1: Clone then switch to dev branch
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
git pull
```
Option 2: Directly clone dev branch
```
git clone -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
```
2. Python Environment (Choose One Option)

Option A: Use Conda (Recommended for environment isolation)
```
conda create -n sd_webui python=3.10.6 -y
conda activate sd_webui
```
Option B: Directly install Python 3.10.6
- Download: https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe
- Important: During installation, check ""Add Python to PATH""

3. Run the Installation Script

This process will create a venv virtual environment.

Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```
4. Fix CLIP Installation Failure (If Encountered)

If you encounter CLIP installation errors like:

- Couldn't Install Clip

- ERROR: Failed to build 'https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip'

First repair the build tools in the venv environment, then install CLIP:

Windows:
```
.\venv\Scripts\python.exe -m pip install wheel
.\venv\Scripts\Python.exe -m pip install ""setuptools<70""
.\venv\Scripts\python.exe -m pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
```
Linux/Mac:
```
source venv/bin/activate
pip install wheel
pip install ""setuptools<70""
pip install --no-build-isolation git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1
deactivate
```
5. Continue Running the Installation Script

After fixing CLIP, run the installation script again:
Windows:
```
.\webui-user.bat
```
Linux/Mac:
```
./webui.sh
```

PS: Linux/Mac steps have not been tested personally.
",2026-02-11T04:10:59Z,WhizZest,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17201#issuecomment-3882017097
auto1111_webui,issue,17199,[Bug]: RuntimeError: CUDA error,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello. I need some advice. When I try to generate an image, I get this error.
RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1 Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

### Steps to reproduce the problem

 When I try to generate an image

### What should have happened?

<img width=""898"" height=""155"" alt=""Image"" src=""https://github.com/user-attachments/assets/dc86e89c-a6ee-4807-91fc-b2d495b30f2e"" />

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://pastebin.com/clone/up4rC9L1

### Console logs

https://pastebin.com/rh4vKdGV

### Additional information

_No response_",2025-12-07T09:33:20Z,Jakewh,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199
auto1111_webui,comment,17199,,"you have from sysinfo

""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
you need to use new PyTorch 2.7.0 +
use `dev` branch and tell it to `--reinstall-torch` or reinstall everything by deleting `venv` dir
or manually install compatible torch version

- see https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818",2025-12-23T19:51:50Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17199#issuecomment-3687812778
auto1111_webui,issue,17197,[Feature Request]: How to support multi-GPU parallel computing.,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

How to support multi-GPU parallel computing.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-12-05T09:08:42Z,wanglujun86,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17197
auto1111_webui,issue,17194,[Feature Request]:  zimage_turbo support?,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Runing [Z-Image-Turbo](https://hf-mirror.com/Tongyi-MAI/Z-Image-Turbo) on webui.

### Proposed workflow

User download model and run it.

### Additional information

_No response_",2025-12-02T01:25:29Z,NaughtDZ,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17194
auto1111_webui,issue,17184,[Bug]: GFPAN Error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Getting an error even though I installed it correctly.

### Steps to reproduce the problem

1. Install sd.webui.zip
2. Update
3. Run

### What should have happened?

it should work after those steps.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

I can't launch webui

### Console logs

```Shell
I just installed this on a new PC but I am not sure what the error is and I am stuck trying to fix it.

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing gfpgan
Traceback (most recent call last):
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 324, in <module>
    prepare_environment()
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 239, in prepare_environment
    run_pip(f""install {gfpgan_package}"", ""gfpgan"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 106, in run_pip
    return run(f'""{python}"" -m pip {args} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"")
  File ""C:\Users\HOME\Desktop\sd.webui\webui\launch.py"", line 74, in run
    raise RuntimeError(message)
RuntimeError: Couldn't install gfpgan.
Command: ""C:\Users\HOME\Desktop\sd.webui\system\python\python.exe"" -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary
Error code: 1
stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379
  Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s

stderr:   Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s'
  remote: Internal Server Error
  fatal: unable to access 'https://github.com/TencentARC/GFPGAN.git/': The requested URL returned error: 500
  error: subprocess-exited-with-error

  git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git 'C:\Users\HOME\AppData\Local\Temp\pip-req-build-kf84lt_s' did not run successfully.
  exit code: 128

  No available output.

  note: This error originates from a subprocess, and is likely not a problem with pip.
ERROR: Failed to build 'git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379' when git clone --filter=blob:none --quiet https://github.com/tencentarc/gfpgan.git 'c:\users\home\appdata\local\temp\pip-req-build-kf84lt_s'
```

### Additional information

_No response_",2025-11-18T21:09:01Z,TeraTyrantShadic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17184
auto1111_webui,issue,17180,[Bug]: ModuleNotFoundError: No module named '_lzma',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

After following the Apple Silicon installation instructions at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon, I have run into an error that I cannot seem to resolve. It is looking for a module `_lzma` and not finding it.

The only deviation in the instructions is that I installed `python 3.10` via `pyenv` instead of homebrew. I'm currently running 3.10.10 to try and run the web ui.

I found another discussion on this issue that suggested installing the `xz` libraries via homebrew, and then re-installing (rebuilding) the python being used. I have tried this but it did not resolve the error.

Any advice on how to fix this error and get up and running with the web ui?


Thanks for your time.

### Steps to reproduce the problem

1. Git clone repository for `stable-diffusion-webui`
2. Install `pyenv` and install python 3.10 (3.10.10) with pyenv using `pyenv install 3.10.10 && pyenv global 3.10.10`
3. Run web ui script from project root directory: `./webui.sh`
4. Observe the error trying and failing to import module `_lzma`

### What should have happened?

The `webui.sh` script should have completed successfully and the application be visible in a browser.

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

Unable to load web ui and thus unable to load system info as requested.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on wagnar user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.11.8 (main, Sep 11 2025, 17:27:21) [Clang 17.0.0 (clang-1700.0.13.5)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/wagnar/projects/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Users/wagnar/projects/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Users/wagnar/projects/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/__init__.py"", line 35, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/batch_size_finder.py"", line 24, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/types.py"", line 27, in <module>
    from torchmetrics import Metric
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/__init__.py"", line 37, in <module>
    from torchmetrics import functional  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/__init__.py"", line 56, in <module>
    from torchmetrics.functional.image._deprecated import (
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/__init__.py"", line 14, in <module>
    from torchmetrics.functional.image.arniqa import arniqa
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchmetrics/functional/image/arniqa.py"", line 31, in <module>
    from torchvision import transforms
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/__init__.py"", line 6, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/__init__.py"", line 1, in <module>
    from ._optical_flow import FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/_optical_flow.py"", line 13, in <module>
    from .utils import _read_pfm, verify_str_arg
  File ""/Users/wagnar/projects/stable-diffusion-webui/venv/lib/python3.11/site-packages/torchvision/datasets/utils.py"", line 4, in <module>
    import lzma
  File ""/Users/wagnar/.pyenv/versions/3.11.8/lib/python3.11/lzma.py"", line 27, in <module>
    from _lzma import *
ModuleNotFoundError: No module named '_lzma'
```

### Additional information

Issue occurred on a clean clone/install of `stable-diffusion-webui`.",2025-11-15T02:23:05Z,sotekllc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180
auto1111_webui,comment,17180,,"I managed to fix the issue by following up on the reinstallation and deleting the `venv` folder and re-installing. Here are the steps I used to resolve this issue:

1. `brew reinstall xz`
2. deleted the `venv/` folder from the project root directory
3. `pyenv uninstall 3.10.10 && pyenv install 3.10.10 && pyenv global 3.10.10`
4. from the project root directory: `./webui.sh`",2025-11-15T02:29:26Z,sotekllc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3535428778
auto1111_webui,comment,17180,,"`pyenv uninstall 3.10.10` and `pyenv global 3.10.10` aren't necessary. Deleting the venv folder and uninstalling the pyenv do the same thing. Setting the global pyenv binary isn't necessary unless you actually want this. If you don't want this, this will actually break your venv for other venvs you use. 

Next time this happens, install the module rather than deleting the venv. It'll not only save you time, but help you understand what is wrong and help you read the error as a useful, constructive helpline. 

Packages are installed using either `pip` or `uv`, with `pip` being the more usual but slower option, albeit still more popular nonetheless. `Pip` is also easier to get started with, as it's more native to Python itself than the external tool `uv`, needing manual installation from an external source.",2025-11-17T11:52:33Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3541414842
auto1111_webui,comment,17180,,"Humble deer, could you please clarify what are the necessary steps to fix this issue? A detailed step by step instruction would help me resolve this issue.",2025-11-18T20:56:01Z,TeraTyrantShadic,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3549513389
auto1111_webui,comment,17180,,"I can't provide an exact resolution step by step, because as of right now I have no reason to believe this is a systematic failure that others will experience. 

However, I can elaborate on my suggestions:

- `pyenv uninstall 3.10.10` being unnecessary:
  Deleting the venv folder did that already, short of any specific cache outside of the folder -- they don't impact anything.
  **Suggested resolution** with my comment: use the command or the deleting of the folder; the command is ""the right way"".
- `pyenv global 3.10.10` being unnecessary:
  This sets your global standard for which python version to use. The reason this is unnecessary is twofold:
  - Your venv will have its own local version of python installed inside the `.venv` folder
  - It sets the default for the entire system, which may inadvertently break other improperly installed Python-based programs by breaking their code or dependencies. Furthermore, for the purpose of rebuilding your venv, it doesn't do anything.
  - It does not play a role in your venv creation -- it is and can be kept entirely separated from your global versions, dependencies, and programs. 
- In fact, keeping the venv (virtual environment) separate from the global python version and its installed packages is the entire purpose for why virtual environments are used. That's their primary nigh only reason why they're used. ",2025-11-20T16:49:17Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17180#issuecomment-3559058963
auto1111_webui,issue,17173,[Feature Request]: Questions about downloading PyTorch resources,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I have an Nvidia RTX Pro 1000 graphics card. After manually installing CUDA 13 and the corresponding version of PyTorch, running ""webui.sh"" in the project's root directory still installs a version of PyTorch with CUDA 12, and the project reports an error after starting.
In addition, this graphics card belongs to the Blackwell architecture like the RTX 5000 series. I saw some repair issues related to the RTX 5000 series graphics cards, and I can't determine whether it is my operational error or some other issue.

### Proposed workflow

When Pytorch is detected, skip the download step

### Additional information

_No response_",2025-11-08T09:48:06Z,mjzde17,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173
auto1111_webui,comment,17173,,"After installing your sd-webui and custom versions of Torch, pass the `--skip-prepare-environment` and `--skip-install` arguments. You can add these in the .bat/.sh file of your choosing â€” whichever you usually use.

Optionally, `--skip-python-version-check` and `--skip-torch-cuda-test` could be added too. The former stops version checks, the latter stops torch cuda presence test and its subsequent errors if it doesn't detect what it expects. These can clean up the terminal output, but might also hide issues if you end up with a screwed up venv. 

I'd hope it goes without saying, but: if you're installing the new PyTorch version outside of your venv, it's entirely expected for it to not be inside your venv. That's... the entire point of the venv. 

The default checks and installation is there to aid users that might not be trying to tinker and/or just want it to ""just work"". It installs the versions of packages specified in the requirements as those are the ones known to work well for the majority of people as well as being intercompatible with each other. ",2025-11-17T13:10:23Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173#issuecomment-3541757178
auto1111_webui,comment,17173,,"Nvidia RTX Pro 1000 I belibe that this has the same requirements as othre blackwell/50 series GPU
if you are using the `dev` branch pytorch version that works with it
so you shouldn't have to do anything special

---

if you do need something custom

and if pytorch is the only thing you need to change then setting the environment variables `TORCH_COMMAND` and `INDEX_URL` allows you to controls what pytorch webui tries to auto install
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

by default webui use a python venv ([python's virtual environments](https://docs.python.org/3/library/venv.html)), simply put if you system pytorch on your system environment webui it's not going to use it because it is using its own virtual environment, 
webui also installs only if it doesn't ""find"" that pytorch is installed
if for some reason you could always enter the venv and modify (install different version of pytorch)

---

> After manually installing CUDA 13 

if I'm reading this correctly I'm guessing that you are installing CUDA tool kit, 
the official binaries should come with CUDA dependencies package inside
so you shouldn't need to install your own CUDA toolkit in the system environment
",2025-11-21T10:08:24Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17173#issuecomment-3562313106
auto1111_webui,issue,17170,[Feature Request]: Vulnerability Disclosure Contact,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello,

We have discovered a vulnerability in Stable Diffusion WebUI and we would like to disclose it responsibly to you. Please provide a private/secure channel where we can submit the report confidentially.

If we are unable to contact you after 15 days, we reserve the right to publish this vulnerability in accordance with our Disclosure Policy, which you can read here: https://www.zerodayinitiative.com/advisories/disclosure_policy/

Thank you and best regards,
Zero Day Initiative
Trend Micro
ZDI-DISCLOSURES@trendmicro.com

### Proposed workflow

a private/secure channel where we can submit the report confidentially.

### Additional information

_No response_",2025-11-06T16:50:16Z,zdi-disclosures,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17170
auto1111_webui,comment,17170,,"Hi I'm one of the main collaborators of these repo

AUTOMATIC1111 is basically radio silent quite a long time, and he is the only person that has rights to push master branch of this repo
we only only have the rights to push to the dev branch, so honestly I'm not too sure what can be done if there is a vulnerability

---

there's two ways to make contact

there's a Discord server invitation link on the wikihttps://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing
there we can talk privately via direct message

ou can also contact via email
you could contact me at wewgithub@gmail.com

if you want to try and contact AUTOMATIC1111 directly you can potentially try the email address that is listed in the get log
but my guess is like like that he won't answer



",2025-11-21T10:33:49Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17170#issuecomment-3562410098
auto1111_webui,issue,17165,"[Bug]:  '(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded","### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when i run ./webui.sh

it goes wrong. how can I put the download files to the right directory.
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Steps to reproduce the problem

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What should have happened?

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].


### Console logs

```Shell
(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3eff10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: cbe46719-276a-430e-b7e8-1df759b2f6db)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 2s [Retry 2/5].
WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef1c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 60485d4f-a14a-4c58-af5f-d5d683858fc2)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 4s [Retry 3/5].
WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f3ef340>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: f0419891-2a54-4beb-a2f4-f407e09e2a76)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 4/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e8f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 58c6eedd-b0f2-44ac-9806-24be1cf9f0bf)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
Retrying in 8s [Retry 5/5].
WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2e9810>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: bc43639a-29e7-4721-b736-0f71fff21e3d)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json
--------- /home/justin/.cache/huggingface/hub/models--openai--clip-vit-large-patch14
'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
WARNING:huggingface_hub.utils._http:'(MaxRetryError(""HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/merges.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc30f2ea230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))""), '(Request ID: 5f7287e5-2203-46b5-9dcf-e03db5035a99)')' thrown while requesting HEAD https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
Retrying in 1s [Retry 1/5].
WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].
```

### Additional information

_No response_",2025-11-01T08:49:56Z,Xbotgo-Justin1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17165
auto1111_webui,issue,17162,[Bug]: pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

`run.bat` fails while installing Clip with message `pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'`. Fresh install of webui.

### Steps to reproduce the problem

Download webui, run `update.bat`, then `run.bat`

### What should have happened?

It should run

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2


### Console logs

```Shell
Installing clip
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\josep\Downloads\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 394, in prepare_environment
    run_pip(f""install {clip_package}"", ""clip"")
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\josep\Downloads\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install clip.
Command: ""C:\Users\josep\Downloads\sd.webui\system\python\python.exe"" -m pip install https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary
Error code: 2
stdout: Collecting https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip
  Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 107, in _run_wrapper
    status = _inner_run()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 98, in _inner_run
    return self.run(options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 85, in wrapper
    return func(self, options, args)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 388, in run
    requirement_set = resolver.resolve(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 79, in resolve
    collected = self.factory.collect_root_requirements(root_reqs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 538, in collect_root_requirements
    reqs = list(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 494, in _make_requirements_from_install_req
    cand = self._make_base_candidate_from_link(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 226, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 318, in __init__
    super().__init__(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 161, in __init__
    self.dist = self._prepare()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 238, in _prepare
    dist = self._prepare_distribution()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 329, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 543, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 658, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 77, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 55, in prepare_distribution_metadata
    self._install_build_reqs(build_env_installer)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 132, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 107, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 694, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""C:\Users\josep\Downloads\sd.webui\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

### Additional information

_No response_",2025-10-27T03:44:09Z,royaldark,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162
auto1111_webui,comment,17162,,"EDIT: These steps work fine for me on a clean installation:

1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
2. Run `run.bat` until it throws the error.

3. After that, go to the folder `sd.webui\system\python` and run these commands:
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
4. Finally, run `run.bat` again.",2025-10-28T03:26:39Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3454376026
auto1111_webui,comment,17162,,"> After you get the error message, try going to `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> Then try again.

Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.",2025-10-29T16:17:22Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462533435
auto1111_webui,comment,17162,,I am also facing the same issue,2025-10-29T16:49:08Z,ryker-uptycs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462661691
auto1111_webui,comment,17162,,"> > After you get the error message, try going to `sd.webui\system\python` and run these commands:
> > ```
> > python.exe -m pip install clip-anytorch
> > python.exe -m pip install open-clip-torch
> > ```
> > 
> > 
> >     
> >   
> > Then try again.
> 
> Thank you, but even though I was able to instal both within the respective folder, it did not fix the issue on the rerun. I got the exact same error.

Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.",2025-10-29T17:13:27Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3462743304
auto1111_webui,comment,17162,,"
> Well, actually my installation has a few extra steps because of the GPU I used. Indeed, just running those commands alone didn't work for me either, so I'll edit my answer to include them as well.

Thanks for the attempted update, but the update didn't work for me either.  From the looks of it, it looks like you're trying to pre-install CLiP.  You, too, are also using xformers.  The pre-installation of the CLiP library didn't help me.  The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.

I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files.  I'm not sure, but I that is an educated guess.

Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update.  That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.",2025-10-30T14:19:42Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3468264596
auto1111_webui,comment,17162,,"> Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> 
> I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> 
> Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.

I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
```
clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
```
to
```
clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
```
But in later tests, I didnâ€™t need to do this anymore.

And that's all I did. I hope it can be of some use to you.",2025-10-30T17:27:43Z,ferrique,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3469184718
auto1111_webui,comment,17162,,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didnâ€™t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Excellent. I'll try to give this a change later and report back with my results.
",2025-10-30T17:53:48Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3469328449
auto1111_webui,comment,17162,,"> > Thanks for the attempted update, but the update didn't work for me either. From the looks of it, it looks like you're trying to pre-install CLiP. You, too, are also using xformers. The pre-installation of the CLiP library didn't help me. The installs in the python folder did complete, however, the application still tries to install that specific zip of the CLiP library.
> > I've not had time to dig into the code (I'm a dev, but not a python dev) but looking at the errors, it seems like the issue is that there's a hard-dependency on a version of CLiP that no longer exists., After some basic research, I think CLiP has has some major updates and they may have removed the old dependency files. I'm not sure, but I that is an educated guess.
> > Anyway, if you can think of anything else you might have changed (did you remove that forced dependency version in a config somewhere?) then I'd appreciate one more update. That said, I'm not expecting you to solve the problem, but thanks for trying and sharing.
> 
> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didnâ€™t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Unfortunately didn't work.",2025-10-31T10:52:41Z,BerBerOnGithub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472493779
auto1111_webui,comment,17162,,"Try running this command:

**`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**

Worked for me.
",2025-10-31T12:52:40Z,BerBerOnGithub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472973242
auto1111_webui,comment,17162,,"Yeah, the second suggestion didn't work for me either, but I also don't have much time to troubleshoot this. Yes, the application tries to put stuff in the `system\python` folder but I think I might personally have some other dependency issues.

I've been quite busy and I've only been able to mess with this for 5-10 minutes here and there, but if I can get any serious time to look into this, I'll try to diagnose and fix a patch.  Alternatively, someone might have a fork of this and they've updated the related code. It might be worth trying to look into that. I would but, again, that takes time I don't have at the moment.",2025-10-31T12:54:23Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3472978302
auto1111_webui,comment,17162,,"> I've got Windows 11 and RTX 5070. Outside of the WebUI Python, I have Python 3.10.6 installed manually (with the environment variable added to the PATH). I edited `sd.webui\webui\webui-user.bat` to have `set COMMANDLINE_ARGS=--xformers`. Also, when I first had the issue, I fixed it by editing `sd.webui\webui\modules\launch_utils.py` at lines 377-378:
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""https://github.com/mlfoundations/open_clip/archive/bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b.zip"")
> ```
> 
> to
> 
> ```
> clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"")
> openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
> ```
> 
> But in later tests, I didnâ€™t need to do this anymore.
> 
> And that's all I did. I hope it can be of some use to you.

Thanks for the help, unfortunately it doesn't change the error, which is (at the end of the trace):

```
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'
```

I also tried some `pip` commands to force upgrade and purge, but to no avail.",2025-10-31T18:18:34Z,rkyoku,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3474299992
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Yeah, the ""--no-build-isolation"" is the key. THX",2025-11-02T22:10:47Z,I-m-PhD,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478415041
auto1111_webui,comment,17162,,"Win11, NVIDIA 4060 LAPTOP GPU, the problem was that i had multiple versions of python installed on my pc and SD somehow picks the latest version. 

I fixed it by following this steps.



update.bat switch-branch-toole.bat  option 3, update.bat (just in case)

""**run.bat**"", after it says ""**creating venv**""  press ""**ctrl+c**"" and go to ""**webui\venv**"" and edit ""**pyvenv.cfg**"" file (replace with your installed location)

<img width=""1083"" height=""125"" alt=""Image"" src=""https://github.com/user-attachments/assets/5b9ec391-369c-4751-96ac-ec8b4e6a486e"" />


if it still fails try:

 if you have any vpn services disable it, disable any dns blockers or rewrites, disable any DPI-Bypassers, disable any proxies. After those check if its fixed ",2025-11-02T22:20:53Z,mahmutozerg,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478429562
auto1111_webui,comment,17162,,same issue,2025-11-02T22:49:50Z,kubinka0505,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478451046
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

```
F:\sd.webui\system\python>""python.exe"" -m pip install --no-build-isolation -r ""F:\sd.webui\webui\requirements_versions.txt""
F:\sd.webui\system\python\python.exe: No module named pip
```",2025-11-02T22:50:57Z,kubinka0505,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3478451872
auto1111_webui,comment,17162,,"I first tried
```
""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
```
and it didn't work. But I then tried
```
python.exe -m pip install clip-anytorch
python.exe -m pip install open-clip-torch
```
and it got past the issue.",2025-11-06T19:24:26Z,Draaloff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3499040595
auto1111_webui,comment,17162,,"> I first tried
> 
> ```
> ""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""
> ```
> 
> and it didn't work. But I then tried
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> and it got past the issue.

I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?",2025-11-06T19:59:17Z,rhartness,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3499175736
auto1111_webui,comment,17162,,"
> I could never get variations of this to work for me. If you don't mind me asking, what's your set? Type of PC, version of python installed, etc?

It also did not solve it for me, despite the commands running and outputting (I guess it used system python, which is not what you need as far as I understand) but then I tried the following, which solved it for me:

 Open an elevated CMD prompt (**not** powershell), cd into: [YOUR_PATH]/webui/system/python,

Then running the following command:
`python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`

After this, the run.bat finally started working. :) ",2025-11-11T20:43:13Z,pushhyeah,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3518666742
auto1111_webui,comment,17162,,"It seems like the problem also affect CLIP
`RuntimeError: Couldn't install clip.`
So I ran your command @pushhyeah and then ran in ""[YOUR PATH HERE]\sd.webui\system\python>""
`python.exe -m pip install --no-build-isolation https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary`

It allowed the UI to launch but then I faced a failed download from the stable diffusion model.
In addition I got a bit to brave and tried installing the DeOldify extension but had to install manually the missing dependency via your trick.
On a second launch, downloading the stable diffusion model worked just fine. But I am actually stuck in an endless loop of conflicting dependency. 

",2025-11-11T23:40:18Z,TSS-22,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3519192723
auto1111_webui,comment,17162,,"> pip install open-clip-torch

This full code helped 
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python .exe"" -m pip install clip-anytorch`
`& ""C:\StableDiffusionInstall\stable-diffusion\system\python\python.exe"" -m pip install open-clip-torch`
Change the disk for yourself.",2025-11-14T22:16:10Z,alukardua1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3534866619
auto1111_webui,comment,17162,,"after I come to python in the sd.webui files, where do I go then, because there is just more files",2025-11-18T10:25:26Z,Kirsipasta,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3546749433
auto1111_webui,comment,17162,,"I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors.  I only found the final fix after reading the stack trace:

Add a `--no-build-isolation` here:

https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142

Result:

```python
    return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
```",2025-11-24T23:39:09Z,YunJD,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3573168981
auto1111_webui,comment,17162,,"> I have a 5090 GPU, and previous comments to install clip-anytorch and open-clip-torch were helpful to pass those errors. I only found the final fix after reading the stack trace:
> 
> Add a `--no-build-isolation` here:
> 
> [stable-diffusion-webui/modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/6685e532dfb40deee3287ef62a66bf4465728517/modules/launch_utils.py#L142)
> 
> Line 142 in [6685e53](/AUTOMATIC1111/stable-diffusion-webui/commit/6685e532dfb40deee3287ef62a66bf4465728517)
> 
>  return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live) 
> Result:
> 
>     return run(f'""{python}"" -m pip {command} --no-build-isolation --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)

Adding `--no-build-isolation` and modding the `launch_utils.py` to use name refs for packages vs commit hash refs at least lets me launch the web UI. I am now getting errors about no CUDA kernel image failing the load of Stable diffusion model. So... progress I guess.",2025-11-29T21:38:36Z,Naphier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3591955624
auto1111_webui,comment,17162,,"Following steps worked for me (I used Git bash as my terminal):
- Uninstall all other versions of Python, keep only 3.10.6
- Open git bash, activate virtual environment inside webui directory: `source /sd.webui/webui/venv/Scripts/activate`
- `pip install -r /sd.webui/webui/requirements_versions.txt`

After this, `run.bat` should work fine.",2025-12-01T21:59:10Z,lakshadeep91,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3599140909
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

Worked for me, too. Thank you!",2025-12-02T13:42:04Z,foreveryoung82,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3602139264
auto1111_webui,comment,17162,,"Steps I took to get it running
System: Windows 11, Intel 285k, RTX 5090

- Ensure ONLY Python 3.10.6 is installed (had issues till I removed the others)
- Run switch-branch-toole.bat (it also updates automatically) and choose 3. dev
- (From PowerShell) Run run.bat so it throws errors
- cd to system\python and run
- python.exe -m pip install clip-anytorch
- python.exe -m pip install open-clip-torch
- Edit webui\modules\launch_utils.py
- LINE 142 Add --no-build-isolation before the --prefer-binary
- LINE 377 Change to clip_package = os.environ.get('CLIP_PACKAGE', ""clip-anytorch"") 
- LINE 378 Change to openclip_package = os.environ.get('OPENCLIP_PACKAGE', ""open-clip-torch"")
- Edit webui\webui-user.bat
- LINE 6 Change to set COMMANDLINE_ARGS=--xformers

At that point it ran and was able to generate a simple test image to be sure it was working 

<img width=""2055"" height=""1147"" alt=""Image"" src=""https://github.com/user-attachments/assets/6ba5a603-7aa2-4693-90dc-b7c62fc04124"" />

Hope this helps anyone else with a 50 series getting this error ",2025-12-30T19:47:39Z,AlyxSharkBite,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3700313904
auto1111_webui,comment,17162,,"@AlyxSharkBite thank you, your steps helped
for me I need to add `.\` begin of bellow commands to make sure that it uses python.exe in  `\sd.webui.zip\system\python\`

like this:

```
.\python.exe -m pip install clip-anytorch
.\python.exe -m pip install open-clip-torch
```",2026-01-04T21:48:15Z,minhhungit,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3708455202
auto1111_webui,comment,17162,,"> Try running this command:
> 
> **`""python.exe"" -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\sd.webui\webui\requirements_versions.txt""`**
> 
> Worked for me.

OMG THANK YOU SO MUCH",2026-01-16T20:47:43Z,kod0ku,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3761761194
auto1111_webui,comment,17162,,"So you need to correctly install packages for local python installation (that's located in `./system/python` subfolder).
What's worked for me:
1. Run `run.bat`. It fails, you get `setuptools.build_meta` error.
2. Run cmd and go to the aforementioned folder.
3. Run `python.exe -m pip install --no-build-isolation -r ""[YOUR PATH HERE]\webui\requirements_versions.txt""`. Double check the path -> `webui` folder is in the root of the `sd.webui.zip` archive; consider it when unarchiving and setting the path in the command.
4. In the same folder run `python.exe -m pip install clip-anytorch`
5. Then `python.exe -m pip install open-clip-torch`
6. Run `run.bat` again.",2026-01-24T13:57:33Z,astepforward,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3794687387
auto1111_webui,comment,17162,,"Hey I'm quite new to using Python and I've run into this same issue, but I don't know where to begin troubleshooting. I cant follow the first instruction you give. 

> EDIT: These steps work fine for me on a clean installation:
> 
> 1. Run `switch-branch-toole.bat` (it also updates automatically) and choose `3. dev`.
> 2. Run `run.bat` until it throws the error.
> 3. After that, go to the folder `sd.webui\system\python` and run these commands:
> 
> ```
> python.exe -m pip install clip-anytorch
> python.exe -m pip install open-clip-torch
> ```
> 
> 4. Finally, run `run.bat` again.

I go to the folder you state but... where am I running these commands? In the python application in that folder? When I copy the test as-is it throws up a syntax error. I haven't Installed anything else but this application following the steps provided. ",2026-01-28T22:08:54Z,AkioDude,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162#issuecomment-3814182819
auto1111_webui,issue,17161,[Security Alert]: Not all endpoints require authentication even when explicitly enabled,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Some manually added endpoints such as `/internal/sysinfo` can still be called even when authentication is meant to be enforced by Gradio.



### Steps to reproduce the problem

1. Enable Gradio based authentication
2. Open http://127.0.0.1/internal/sysinfo in an incognito browser window
3. Notice how it still returns system information even when authentication is enabled.

### What should have happened?

It should have required the user to be signed in to return that information.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-00-00-00-00.json](https://github.com/user-attachments/files/23155260/sysinfo-2025-00-00-00-00.json)

### Console logs

```Shell
N/A
```

### Additional information

_No response_",2025-10-27T02:01:37Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17161
auto1111_webui,comment,17161,,"for `/internal/sysinfo` I have a PR
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16755

personally I don't like exposed `/internal/sysinfo` that's why I decided to make the pr

but as the authentication password should be stripped from `/internal/sysinfo` response (if you're no using a old version)
I believe AUTOMATIC1111 thinks it ok to be exposed and easier to implement at the time

note that endpoints added by extension they will have to enable authentication when adding the route on the extension side",2025-10-29T19:45:47Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17161#issuecomment-3463565283
auto1111_webui,issue,17150,[Feature Request]: Run on Jetson Thor,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

For Jetson orin,there is a jetson-container to help us run this project easily.However, I was trying to run this on Jetson thor and failed.I hope it could provide a convenient way to run on Jetson Thor.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-10-16T06:46:01Z,ckdavid233,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17150
auto1111_webui,issue,17146,[Bug]: Doesn't run in newer python versions (ex. python v3.13.5.),"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

### Steps to reproduce the problem

Try to open program with python version newer than 1.10

### What should have happened?

update if possible, so it work with latest python versions

### What browsers do you use to access the UI ?

Brave

### Sysinfo

[sysinfo.py](https://github.com/user-attachments/files/22881841/sysinfo.py)

### Console logs

```Shell
This program is tested with 3.10.6 Python, but you have 3.13.5.

ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: none)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
    ~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Download\Programs\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""D:\Download\Programs\stable-diffusion-webui-master\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",2025-10-13T09:55:01Z,Rein-42,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146
auto1111_webui,comment,17146,,"You can install multiple python versions at once.

Set python 3.10 in [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L3) and delete the venv folder.
```batch
set PYTHON=python3.10.exe
```",2025-10-17T22:12:09Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3417393896
auto1111_webui,comment,17146,,As @missionfloyd said but be sure to set the exe path in quotes as well,2025-11-06T21:28:34Z,ngrosso1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3499457866
auto1111_webui,comment,17146,,"I'm having the same issue, and I wrote a [Discussion post yesterday](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues) about this that hasn't gotten any views yet.

In my case, on Linux Mint, README.md says nothing about editing a .bat file, though there is one present. Is the .bat file used on Mint too or just Windows?

Instead, it instructs to edit the `webui.sh` launch script, which as I mention in the post, conflicts with the file's comment instructing **not** to edit it, but to edit `webui-user.sh` instead.

So I edit `webui-user.sh` and it has no effect. And now that I discovered this bug thread, I tried editing the `webui-user.bat` file instead, and it still it does not work. I still get the same error message as the OP, but in a GNU accent.

```
Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0, 2.2.0+cu121, 2.2.1, 2.2.1+cu121, 2.2.2, 2.2.2+cu121, 2.3.0, 2.3.0+cu121, 2.3.1, 2.3.1+cu121, 2.4.0, 2.4.0+cu121, 2.4.1, 2.4.1+cu121, 2.5.0, 2.5.0+cu121, 2.5.1, 2.5.1+cu121, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)
ERROR: No matching distribution found for torch==2.1.2
Traceback (most recent call last):
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/user/apps/0_ai/stable-diffusion-webui/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1

```
I should note that the instructions for GNU systems instruct to install Python 3.11â€”not Python 3.10, and links a ppa repository.  Is this information correct?

The team may want to look into revising the README.md to address all these issues! Documentation is important!",2025-11-23T20:55:53Z,Ratspeed,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3568327656
auto1111_webui,comment,17146,,"Currently, with minor dependency changes, there's no problem keeping Automatic1111 updated to Python 3.12 + PyTorch 2.9.1 + CU130 + xformers: 0.0.34+, using a good number of installed extensions, and it works perfectly.

With Python 3.13, I haven't finished resolving some indirect problems specifically caused by ControlNet, since it requires at least pydantic 1.10.20, which breaks several parts of Automatic1111 that I'm currently working on.

Some other extensions also have problems because they don't yet have dependencies compatible with Python 3.13 (obviously, these are the ones I use).",2025-11-26T03:08:59Z,Theliel,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17146#issuecomment-3578769763
auto1111_webui,issue,17126,[Bug]: SDXL Models Fail After WebUI Restart Due to VAE Error Recovery Not Persisting,"### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SDXL models generate properly on fresh WebUI installation but consistently fail after any WebUI restart, producing corrupted output (""color splashes"" or grey boxes). SD 1.5 models remain unaffected. The issue appears to be related to WebUI's automatic VAE error recovery mechanism not initializing properly on restart for SDXL models.

WebUI Version: v1.10.1 (Commit: 82a973c04367123ae98bd9abdf80d9eda9b910e2)
Hardware: NVIDIA GeForce RTX 3050 (6GB VRAM)
CUDA: 12.9
PyTorch: 2.1.2+cu121
Python: 3.10.6
OS: Windows

### Steps to reproduce the problem

Reproduction Steps
Consistent Reproduction:

Fresh WebUI installation
Load any SDXL model
Generate image â†’ Works perfectly
Close WebUI terminal completely
Restart WebUI (one or two times before the failure happens)
Load same SDXL model
Generate image â†’ Produces corrupted output (color splashes/grey boxes)

Key Observations:

SD 1.5 models continue working normally after restart
Some specific SDXL models remain stable across restarts (model-dependent)
Loading certain SD 1.5 models can ""fix"" SDXL generation but contaminates output with SD 1.5 model's characteristics
Issue persists across different SDXL checkpoints

### What should have happened?

SDXL models should generate consistently after WebUI restarts, with the same automatic VAE error recovery that occurs on fresh installation.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-09-14-09-57.json](https://github.com/user-attachments/files/22319280/sysinfo-2025-09-14-09-57.json)

### Console logs

```Shell
C:\webui_fresh>webui-user.bat
venv ""C:\webui_fresh\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
C:\webui_fresh\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [3343bb16c2] from C:\webui_fresh\models\Stable-diffusion\SDXL_madejanss.safetensors
Creating model from config: C:\webui_fresh\configs\v1-inference.yaml
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
C:\webui_fresh\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 12.5s (prepare environment: 3.7s, import torch: 4.3s, import gradio: 1.1s, setup paths: 0.8s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 0.9s, create ui: 0.4s, gradio launch: 0.5s).
Applying attention optimization: xformers... done.
Model loaded in 2.0s (create model: 1.3s, apply weights to model: 0.2s, calculate empty prompt: 0.3s).
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.50it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.87it/s]
```

### Additional information

VAE Error Recovery Pattern: The key indicator of working vs failing state is the presence of these console messages:

Working State (Fresh Install):
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.

Failing State (After Restart):
Above VAE error messages do NOT appear
SDXL models fail to generate properly
Corruption occurs during generation process

Hypothesis
WebUI's automatic VAE error recovery mechanism that converts VAE to 32-bit floats is not initializing properly on restart for SDXL models. This protective conversion that prevents VAE corruption works on fresh install but fails to trigger on subsequent sessions.
Attempted Solutions (All Failed)

--no-half-vae flag
--medvram with various memory optimizations
NumPy downgrade to <2.0
Clearing model cache and pycache directories
PyTorch reinstallation with specific CUDA versions
Various precision flags (--no-half, --upcast-sampling, etc.)
Model configuration resets

Additional Context
Model-Specific Behavior:

Some SDXL models maintain stability across restarts
Others fail immediately after any model switching
The corruption appears when WebUI stops automatically handling VAE NaN errors

SD 1.5 Model ""Fixing"" Pattern:

Loading specific SD 1.5 models can restore SDXL functionality
However, SDXL output becomes contaminated with characteristics of the SD 1.5 model
This suggests model state cross-contamination during loading",2025-09-14T10:04:34Z,mlworks90,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17126
auto1111_webui,issue,17122,[Feature Request]: Multi full prompt batch automation in series,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Feature would allow for automatically processing additional generations from previous prompts from a list of generated image png file paths.

### Proposed workflow

1. Load text file with full png file paths, one file path per line
2. For each file path, load its metadata in the png tab, and automatically parse and transfer metadata to txt2img
3. Override certain generation parameters through fields or sliders to be applied to the entire batch of prompts (e.g. random seed, batch size, number of batches)
4. Run the prompt for the specified batch size, number of batches, and seed
5. Repeat for next png file path in input text file until all are complete


### Additional information

Often times I explore many different prompts in quick succession, and then I want to go back later to generate a larger number of images from past prompts, for greater variety, or to achieve greater quality from the set.  This feature would help with that!  Having to do this manually takes a lot of manual intervention, and switching prompts and pressing 'generate' cannot be done while sleeping or away from the computer.

I already tried developing a Python script to carry out this behavior, but I ran into issues with parsing the metadata tuple from each png file into the fields needed to run txt2img.  Internally the webui clearly has this functionality, as seen by the features of the PNG tab, but I could not find publicly available modules to mimic this behavior.

Ideally, the feature would work within the webui, such that loaded png files and previews of generated images are still displayed, and such that all generated images would be saved as normal according to the webui's user settings.

This feature request differs from the prompt matrix script or using the '|' character because I don't want to do multiple combinations of small changes within the same prompt, I want to load up completely distinct prompts for every run.  And ideally, the input file may have hundreds of different distinct prompts, in which case, I would want to leave the full batch running for days or weeks at a time until everything is complete.",2025-09-07T05:10:02Z,colin-heberling,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17122
auto1111_webui,comment,17122,,"[sd_batch_from_pngs.py](https://github.com/user-attachments/files/22226496/sd_batch_from_pngs.py)

I figured out a working solution using scripts, but would still be nice to have an inbuilt webui feature for this.  I wrote a custom function for parsing parameters from png metadata.",2025-09-09T05:01:49Z,colin-heberling,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17122#issuecomment-3268877500
auto1111_webui,issue,17119,[Bug]: Runtime error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

every time I start up the run.bat file, it shows this message over and over again. I have a powerful pc and I have no idea whtas going on

<img width=""626"" height=""87"" alt=""Image"" src=""https://github.com/user-attachments/assets/baa327d1-0ef3-4a68-b5d6-1044f765f0a5"" />

### Steps to reproduce the problem

run the run.bat file, thats it

### What should have happened?

it shouldve ran it with no issues like the past times ive run this without an issue on this pc

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

i couldnt find anything that this is asking

### Console logs

```Shell
again, i couldnt figure out how to do this and im short for time
```

### Additional information

_No response_",2025-09-01T19:17:23Z,Marshy111,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17119
auto1111_webui,comment,17119,,"## Report to the creator of the project

As your issue is happening on a **fork** of this project, please _report it to them_ instead: https://github.com/lllyasviel/stable-diffusion-webui-forge

---

### Additional tip to ensure you get the support you need

> Sysinfo
> i couldnt find anything that this is asking

Follow the instructions given by the template. They are there for a reason. You can collect the sysinfo without needing the webui to start up completely. 

> again, i couldnt figure out how to do this and im short for time

Copy the entire text output rather than taking a screenshot of a tiny section of it. If you're able to take a screenshot, there's no excuse to not just copy the text instead.

",2025-11-17T13:21:26Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17119#issuecomment-3541811456
auto1111_webui,issue,17117,[Bug]: win10å®‰è£…å¡åœ¨Installing requirementsæ²¡ååº”,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

<img width=""1091"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/b7e00c0c-cde4-46bc-a91b-259180aa4070"" />

### Steps to reproduce the problem

æŒ‰windowsæ­¥éª¤éƒ¨ç½²

### What should have happened?

å¸Œæœ›æ­£å¸¸éƒ¨ç½²

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements


### Console logs

```Shell
venv ""F:\AI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
```

### Additional information

_No response_",2025-08-28T09:07:26Z,Qiqi-Cici,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117
auto1111_webui,comment,17117,,"è¿™ä¸ªé—®é¢˜æˆ‘ä¹‹å‰é—®chatgptï¼ŒæŒ‰å®ƒè¯´çš„è§£å†³äº†ï¼Œäº§ç”Ÿè¿™ä¸ªé—®é¢˜çš„åŸå› æ˜¯è¿˜æœ‰ä¸€äº›æ–‡ä»¶éœ€è¦ä¸‹è½½ï¼Œä½†æ˜¯æŒ‚æ¢¯å­éƒ½ä¸å¥½ä½¿ï¼Œè¦åœ¨é•œåƒç½‘ç«™ä¸‹ï¼Œ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
å¦‚æœæˆ‘æ²¡è®°é”™æ˜¯è¿™ä¸ªï¼Œå¦å¤–å¯ä»¥æ£€æŸ¥ä¸€ä¸‹ä½ çš„pipæ˜¯ä¸æ˜¯æœ€æ–°ç‰ˆ",2025-09-13T04:49:03Z,finally12345,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3287555065
auto1111_webui,comment,17117,,"åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰“å¼€ç»ˆç«¯ï¼š
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
D:\stable-diffusion-webui-master\venv\Scripts\activate

# å‡çº§ pip
python -m pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…å¿…éœ€ä¾èµ–
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£… xformersï¼ˆå¯é€‰ï¼ŒåŠ é€Ÿï¼‰
pip install xformers -i https://pypi.tuna.tsinghua.edu.cn/simple
",2025-09-13T04:51:39Z,finally12345,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3287557305
auto1111_webui,comment,17117,,"æˆ‘åœ¨è¿è¡Œpip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simpleçš„æ—¶å€™ï¼Œå‡ºç°äº†è¿™ä¸ªï¼š
Fatal error in launcher: Unable to create process using ...
è¯·é—®æ€ä¹ˆè§£å†³å‘€ï¼Ÿ @finally12345 ",2025-10-26T16:07:52Z,YII266,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17117#issuecomment-3448659819
auto1111_webui,issue,17112,# Update 20250501,"# Update 20250501
Official PyTorch 2.7.0 wheels with Blackwell 50 series support and xFormers have been released

Pull Request have been merged into dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16972

## Updated instructions on how to install for 50 series (also work for non 50 series)
### For casual windows users
follow the instructions of [Install-and-Run-on-NVidia-GPUs#windows-method-1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) 
the newly updated [sd.webui.zip](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip) includes a new `switch-branch-toole.bat` that can simplify switching branch
use `switch-branch-toole.bat` to switch to `dev` branch

### Advance users
For new install clone the webui branch `dev`
```sh
git clone --filter=blob:none -b dev https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
```
> `-b dev` to clones the desired a branch directly
> `--filter=blob:none` save around 30MB of disk space

or if you prefer you can do it in separate steps
```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
git switch dev
```

---

For existing installations you can switch to `dev` branch without re-cloneing
> may have to run `git pull` after `git switch dev`
```
cd stable-diffusion-webui
git switch dev
git pull
```
> if you're already on the `dev` branch then just `git pull` should work

after switching launch webui with `COMMANDLINE_ARGS` `--reinstall-torch` to tell it to reinstall PyTorch
> also launch with `--reinstall-xformers` if you are using `xFormers`
> remember to remove `--reinstall-torch` `--reinstall-xformers` afterwards

---

revelant wiki [How-to-switch-to-different-versions-of-WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

---

<details><summary>Outdated info</summary>
<p>

As PyTorch have not yet released a compatible builds for Blackwell GPUs
we have been allowed to publish Early Access PyTorch wheels by Nvidia 

---

There are several methods to run on Blackwell 50XX GPUs

## Method 1: use the a new standalone release
Recommended for new install or for those not familiar with terminals / commands)

we have prepared a standalone release for Windows which can be downloaded here [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z) (1.8GB)

1. Download [sd.webui-1.10.1-blackwell.7z](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.10.0/sd.webui-1.10.1-blackwell.7z)
2. Extract using [7z](https://www.7-zip.org)
> Windows 11 seems to have it added native 7z support

3. Click `run.bat` to launch webui

~~note: do not enable `--xformers`, currently it is not compatible~~ [xformers v0.0.29.post2](https://github.com/facebookresearch/xformers/releases/tag/v0.0.29.post2) is released, see below for instructions

## Method 2: use the latest `dev` branch
Recommended for those who are migrating from existing installation and for those who are familiar with commands and terminals

- As of https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16817 the dev branch have been update with auto detection of blackwell GPUs, when detected it will automatically install the appropriate PyTorch which version

1. Follow the guide on how to switch branches see [wiki How to switch to different versions of WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/How-to-switch-to-different-versions-of-WebUI)

> instead of the `release_candidate` in the example substituted with `dev` to switch to dev branch

2. Add `--reinstall-torch` to `COMMANDLINE_ARGS` to tell webui to reinstall PyTorch
3. Launch webui

> remember to remove`--reinstall-torch` from `COMMANDLINE_ARGS` after it's done reinstalling PyTorch

## Method 3: manual upgrade
Meant for developers
The PyTorch wheels are provided at https://huggingface.co/w-e-w/torch-2.6.0-cu128.nv
This should be all the info you need

## xformers (may not work)
to use xformers
you need you need to set the environment variable `XFORMERS_PACKAGE` to `xformers==0.0.29.post2`
on windows this can be done by adding the following line to to `webui-user.bat` before `call webui.bat`
```bat
set XFORMERS_PACKAGE=xformers==0.0.29.post2
```

<details><summary>the <code>webui-user.bat</code> should look like something this (click to expand)

</summary>
<p>

```bat
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS=--xformers
set XFORMERS_PACKAGE=xformers==0.0.29.post2

call webui.bat
```

</p>
</details> 

note: if you have previously used `--xformers` then you will need to add `--reinstall-xformers` to tell webui to reinstall xformers
> similer to `--reinstall-torch`, remeber to remove `--reinstall-xformers` after it's done


</p>
</details>

_Originally posted by @w-e-w in https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818_",2025-08-26T18:26:47Z,cjhScotland,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112
auto1111_webui,comment,17112,,"Hi, I have tried to install AutomaticIIII following the instructions in Windows Method 1. I have an Nvidia RTX 5080 and so followed the instructions and ran swich-branch-toole.bat with option 3, dev.

Q. I ran the switch-branch-toole.bat file AFTER update.bat. Is this correct?

run.bat aappeared to run correctly and displayed the UI at the end. However, when I click 'Generate' two grey buttons appear then immediately disappear. No image is created.

can someone please help me. Screendumps of the CMD screens follow (on a subsequent run of run.bat). Windows is up to date and I have downloaded the latest Nvidia drivers.

THanks (hopefully!) in advance

Chris

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/038e0345-2a9e-40f8-b0d8-3f6b57a0f99a"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/69252029-0b9a-442e-99d8-dc9e222fbb20"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/955e59c6-3076-48e4-8853-1f1d2b2f8470"" />

<img width=""1734"" height=""927"" alt=""Image"" src=""https://github.com/user-attachments/assets/8e293c69-3b56-4d3f-9fc5-bc1ae68507f1"" />",2025-08-26T18:38:50Z,cjhScotland,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112#issuecomment-3225297721
auto1111_webui,comment,17112,,"I followed this video and it worked for me

https://youtu.be/gVQD2OqX0ZU",2025-09-12T07:46:06Z,pocketpoetry,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17112#issuecomment-3284158330
auto1111_webui,issue,17111,[Bug]:  Any error happening after 'commit hash : XXXX' is not related to the launcher,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Any error happening after 'commit hash : XXXX' is not related to the launcher

### Steps to reproduce the problem

open the luncher 

### What should have happened?

no opened 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no opened

### Console logs

```Shell
no opened
```

### Additional information

no opened",2025-08-25T21:26:13Z,elsepulin,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17111
auto1111_webui,comment,17111,,"Without any additional information, there's absolutely no way for anyone to know what you're referring to unless they have themselves gone through the extensive efforts to try and replicate your issue on purpose. 

I can't reproduce any bugs related to ""commit hash: "" and your report is sufficiently unclear enough to confuse me as to what it pertains to.

**Please include the requested diagnostic information.** 

Given you're talking about a console output, ""no opened"" is not only not a valid response to any question, but also simply false in its implied meaning. You cannot have a reported issue or bug regarding console output, only to then claim your console never opened. Those are mutually exclusive, friend.",2025-11-17T13:18:12Z,HumbleDeer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17111#issuecomment-3541794634
auto1111_webui,issue,17102,[Bug]: Missing xformers (on linux at least),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Both dev branch and master branch (1.10.1)

xformers does not show up as an available option under ""Cross attention optimization"" even though launch option has been set
`Launching Web UI with arguments: --xformers`

<img width=""473"" height=""247"" alt=""Image"" src=""https://github.com/user-attachments/assets/929af83c-d0c7-4d7c-860c-1f7b469d9b8f"" />

### Steps to reproduce the problem

1. fresh install on linux
2. add argument for xformers
3. run
4. check settings
--> missing option for xformers

### What should have happened?

xformers should show up as an available option

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-08-19-19-26.json](https://github.com/user-attachments/files/21865900/sysinfo-2025-08-19-19-26.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.9 (main, Jun  2 2025, 19:48:19) [GCC 13.3.0]
Version: v1.10.1-89-g2174ce5a
Commit hash: 2174ce5afea90ca489d222f539988dcef59f1027
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --xformers
[-] ADetailer initialized. version: 25.3.0, num models: 10
ControlNet preprocessor location: /home/user/venvs/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-08-19 21:29:18,516 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [9687bd2559] from /home/user/venvs/stable-diffusion-webui/models/Stable-diffusion/ricecakeRemix.safetensors
2025-08-19 21:29:19,121 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/venvs/stable-diffusion-webui/configs/v1-inference.yaml
/home/user/venvs/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 9.0s (prepare environment: 1.7s, import torch: 2.8s, import gradio: 0.5s, setup paths: 1.0s, initialize shared: 0.2s, other imports: 0.2s, load scripts: 1.5s, create ui: 0.7s, gradio launch: 0.4s).
Loading VAE weights specified in settings: /home/user/venvs/stable-diffusion-webui/models/VAE/SD1.5.safetensors
Disabling attention optimization
Model loaded in 3.6s (load weights from disk: 1.0s, create model: 0.4s, apply weights to model: 1.7s, load VAE: 0.2s, calculate empty prompt: 0.2s).
Disabling attention optimization
```

### Additional information

_No response_",2025-08-19T20:17:38Z,TeKett,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102
auto1111_webui,comment,17102,,"Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**

Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.

",2025-09-02T13:50:39Z,Nate82,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102#issuecomment-3245440383
auto1111_webui,comment,17102,,"> Try adding **--xformers --force-enable-xformers** to your webui-user.bat file, so it should read **set COMMANDLINE_ARGS= --xformers --force-enable-xformers**
> 
> Previously I had mine with this just --xformers and it was using Doggettx and xformers wasn't showing up in the Optimization tab. Now it does.

hes on linux so its web-user.sh which then it should look like (export COMMANDLINE_ARGS="" --xformers --force-enable-xformers"") its a bit different but mostly the same cant really confirm since im on archlinux and i don't use xformers despite having an nvidia card 
",2025-12-18T00:52:04Z,FemBoyGamerTechGuy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17102#issuecomment-3667761449
auto1111_webui,issue,17081,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControleNet via the interface, the program terminated without further possibility to open it

### Steps to reproduce the problem

1. Install ControlNet
2. Update interface

### What should have happened?

Adding a ControlNet Option

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

It is not possible due to the inability to open the interface

### Console logs

```Shell
C:\HUI\stable-diffusion-webui>git pull
Already up to date.
venv ""C:\HUI\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --autolaunch
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-cn-in-extras-tab"" requires ""sd-webui-controlnet"" which is not installed.
Loading weights [b8616b3a8f] from C:\HUI\stable-diffusion-webui\models\Stable-diffusion\pasanctuarySDXL_v50.safetensors
Creating model from config: C:\HUI\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\HUI\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 5.1s (load weights from disk: 0.2s, create model: 0.4s, apply weights to model: 4.1s, move model to device: 0.1s, calculate empty prompt: 0.2s).
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\HUI\stable-diffusion-webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
calling C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py/ui: ImportError
Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 103, in wrap_call
    res = func(*args, **kwargs)
  File ""C:\HUI\stable-diffusion-webui\extensions\sd-webui-cn-in-extras-tab\scripts\cn_in_extras_tab.py"", line 108, in ui
    from scripts import global_state
ImportError: cannot import name 'global_state' from 'scripts' (unknown location)

Traceback (most recent call last):
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\HUI\stable-diffusion-webui\launch.py"", line 44, in main
    start()
  File ""C:\HUI\stable-diffusion-webui\modules\launch_utils.py"", line 469, in start
    webui.webui()
  File ""C:\HUI\stable-diffusion-webui\webui.py"", line 64, in webui
    shared.demo = ui.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui.py"", line 872, in create_ui
    ui_postprocessing.create_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\ui_postprocessing.py"", line 25, in create_ui
    script_inputs = scripts.scripts_postproc.setup_ui()
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 165, in setup_ui
    self.create_script_ui(script, inputs)
  File ""C:\HUI\stable-diffusion-webui\modules\scripts_postprocessing.py"", line 134, in create_script_ui
    for control in script.controls.values():
AttributeError: 'NoneType' object has no attribute 'values'
```

### Additional information

_No response_",2025-08-03T13:19:57Z,superdonz-crypto,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17081
auto1111_webui,comment,17081,,"it is highly likely that this is caused by `sd-webui-cn-in-extras-tab`
I was able to produce similar errors usnign an old version of `sd-webui-cn-in-extras-tab`

I suggest you first try removeing `sd-webui-cn-in-extras-tab` by deleting `extensions\sd-webui-cn-in-extras-tab` dir
then launching webui
it is likely that this will get you back and running

if you still want to use `sd-webui-cn-in-extras-tab` install it again from the extensions tab, this will install the latest version

---

Sysinfo
> It is not possible due to the inability to open the interface

as written in the issue template
it is likely that you will be able to dump the sysinfo by adding `--dump-sysinfo` to command line args
<img width=""602"" height=""243"" alt=""Image"" src=""https://github.com/user-attachments/assets/98ea0021-b474-4a19-b414-f3b5b5f579e8"" />


",2025-08-07T19:05:35Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17081#issuecomment-3165398516
auto1111_webui,issue,17067,[Bug]: Issue Running V-Pred Model on A1111 Dev Branch: Black Output After Fixing NaNs Error,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

I'm trying to run a V-pred model:
https://files.catbox.moe/vciz3c.pdf

I followed the instructions to use the dev branch of Automatic1111 to make it work. However, after a clean install, I encountered this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion, or use the --no-half command line argument to fix this. Use --disable-nan-check to disable this check.

After I added the --no-half and --disable-nan-check arguments, the error disappeared â€” but the model only generates black images.

Is there any additional step required to get this model working correctly?

My Specs : 
NVIDIA GeForce RTX 3090 (24GB VRAM), 64GB RAM, Intel Core i5-9600K

Iâ€™ve also uploaded my full system information file generated by the WebUI below.



### Steps to reproduce the problem

I performed a clean install of the WebUI using the dev branch of Automatic1111, following the instructions provided in this document:
https://files.catbox.moe/vciz3c.pdf

Then, I tried generating an image using the V-Pred model mentioned in the guide.



### What should have happened?

its generate an image of Model Sdxl V-Pred

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-24-19-57.json](https://github.com/user-attachments/files/21418368/sysinfo-2025-07-24-19-57.json)

### Console logs

```Shell
Here is the full Console : 

Running on local URL:  http://127.0.0.1:7861

To create a public link, set `share=True` in `launch()`.
Creating model from config: D:\stable-diffusion-webui-dev\configs\sd_xl_v.yaml
D:\stable-diffusion-webui-dev\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 14.9s (prepare environment: 3.0s, import torch: 6.0s, import gradio: 1.3s, setup paths: 1.7s, initialize shared: 0.3s, other imports: 0.4s, load scripts: 0.8s, create ui: 0.7s, gradio launch: 0.6s).
Applying attention optimization: xformers... done.
Model loaded in 12.1s (load weights from disk: 1.0s, create model: 0.5s, apply weights to model: 9.8s, apply half(): 0.1s, apply dtype to VAE: 0.2s, move model to device: 0.1s, calculate empty prompt: 0.2s).
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                 | 12/30 [00:03<00:05,  3.48it/s]D:\stable-diffusion-webui-dev\modules\sd_samplers_common.py:68: RuntimeWarning: invalid value encountered in cast54it/s]
  x_sample = x_sample.astype(np.uint8)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.44it/s]
*** Error completing requestâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.46it/s]
*** Arguments: ('task(0zf4yw7wrdpmybr)', <gradio.routes.Request object at 0x000001805EA70FA0>, 'masterpiece, best quality, newest, absurdres, highres, nsfw, anime screencap, ayase seiko, dandadan, 1girl, mature female, red eyes,  glasses, beehive hairdo, long hair, white hair, grey hair, ponytail, large breasts, cleavage, thighs, hoop earrings, baseball bat, cigarette, mature female,', 'sfw, worst quality, old, early, low quality, lowres, signature, username, logo, bad hands, mutated hands, mammal, anthro, furry, ambiguous form, feral, semi-anthro, 3d, realistic,', [], 1, 1, 7, 1216, 864, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['Downcast alphas_cumprod: True', 'Clip skip: 2'], 0, 30, 'Euler a', 'Automatic', False, '', 0.8, 696349519, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\stable-diffusion-webui-dev\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""D:\stable-diffusion-webui-dev\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""D:\stable-diffusion-webui-dev\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.
```

### Additional information

_No response_",2025-07-24T20:03:32Z,xura-xa,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067
auto1111_webui,comment,17067,,"Same problem, sdxl model",2025-07-28T01:59:53Z,Roywhite,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067#issuecomment-3124989192
auto1111_webui,comment,17067,,"I get this error if I have `Clip Skip SDXL` Enabled and `Clip Skip` set to `1`
I don't have `--no-half` or `--disable-nan-check` arguments enabled
I don't get this error if I set `Clip Skip` to `2` while `Clip Skip SDXL` is enabled, or I disable `Clip Skip SDXL`
Be sure to restart the UI after turning on/off `Clip Skip SDXL`",2025-08-01T06:09:40Z,FriedGenera,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17067#issuecomment-3142608655
auto1111_webui,issue,17064,[Bug]: AttributeError: 'NoneType' object has no attribute 'get',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

the issue happened when i train hypernetwork

<img width=""1764"" height=""1028"" alt=""Image"" src=""https://github.com/user-attachments/assets/70b7641f-5ae6-4492-b457-d586465a6254"" />

### Steps to reproduce the problem

preprocess the image
train the hypernetwork model
then the issue happend

### What should have happened?

start training the issue

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-23-08-32.txt](https://github.com/user-attachments/files/21383763/sysinfo-2025-07-23-08-32.txt)

### Console logs

```Shell
*** Error verifying pickled file from D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt
*** The file may be malicious, so the program is not going to read it.
*** You can skip this check with --disable-safe-unpickle commandline argument.
***
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 137, in load_with_extra
        check_pt(filename, extra_handler)
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 84, in check_pt
        check_zip_filenames(filename, z.namelist())
      File ""D:\code\sd-webui-aki-v4.10\modules\safe.py"", line 76, in check_zip_filenames
        raise Exception(f""bad file inside {filename}: {name}"")
    Exception: bad file inside D:\code\sd-webui-aki-v4.10\models\hypernetworks\mural-restore.pt: archive/.format_version

---
Applying attention optimization: sdp... done.
*** Error completing request
*** Arguments: ('task(2gmsdezwnvylszq)', 'mural-restore', '0.00001', 1, 1, 'D:\\code\\sdfile\\sd_processed', 'textual_inversion', 512, 512, False, 100000, 'disabled', '0.1', False, 0, 'once', False, 500, 500, 'style_filewords.txt', False, '', '', 20, 'DPM++ 2M Karras', 7, -1, 512, 512) {}
    Traceback (most recent call last):
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 57, in f
        res = list(func(*args, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\call_queue.py"", line 36, in f
        res = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\ui.py"", line 25, in train_hypernetwork
        hypernetwork, filename = modules.hypernetworks.hypernetwork.train_hypernetwork(*args)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 482, in train_hypernetwork
        hypernetwork.load(path)
      File ""D:\code\sd-webui-aki-v4.10\modules\hypernetworks\hypernetwork.py"", line 249, in load
        self.layer_structure = state_dict.get('layer_structure', [1, 2, 1])
                               ^^^^^^^^^^^^^^
    AttributeError: 'NoneType' object has no attribute 'get'
```

### Additional information

_No response_",2025-07-23T08:32:52Z,war-nightmare,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17064
auto1111_webui,issue,17063,[Bug]: ModuleNotFoundError: No module named 'numpy.exceptions',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Automatic1111 Google Collab, yesterday it launched fine, 

https://github.com/TheLastBen/fast-stable-diffusion

today I got error : 



### Steps to reproduce the problem

Launch Automatic1111 https://github.com/TheLastBen/fast-stable-diffusion

### What should have happened?

It should launch 

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

no access to UI due to error

### Console logs

```Shell
Traceback (most recent call last):
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/__init__.py"", line 34, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/__init__.py"", line 14, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/callback.py"", line 25, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File ""/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/types.py"", line 28, in <module>
    from torchmetrics import Metric
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/__init__.py"", line 52, in <module>
    from torchmetrics.image import (  # noqa: E402
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/__init__.py"", line 26, in <module>
    from torchmetrics.image.fid import FrechetInceptionDistance  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/torchmetrics/image/fid.py"", line 28, in <module>
    from torch_fidelity.feature_extractor_inceptionv3 import FeatureExtractorInceptionV3
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/__init__.py"", line 6, in <module>
    from torch_fidelity.metric_fid import KEY_METRIC_FID
  File ""/usr/local/lib/python3.11/dist-packages/torch_fidelity/metric_fid.py"", line 6, in <module>
    import scipy.linalg
  File ""/usr/local/lib/python3.11/dist-packages/scipy/linalg/__init__.py"", line 204, in <module>
    from ._cythonized_array_utils import *
  File ""scipy/linalg/_cythonized_array_utils.pyx"", line 11, in init scipy.linalg._cythonized_array_utils
  File ""/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py"", line 20, in <module>
    from numpy.exceptions import AxisError
ModuleNotFoundError: No module named 'numpy.exceptions'
```

### Additional information

_No response_",2025-07-23T00:09:12Z,Limmweb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063
auto1111_webui,comment,17063,,"Update: solved issue by adding this command 

`!pip install numpy==1.26.4 scipy==1.11.4 --force-reinstall
`

after **Connect Google Drive** and before **Install/Update AUTOMATIC1111 repo** modules in Google Collab",2025-07-23T00:32:41Z,Limmweb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3105241421
auto1111_webui,comment,17063,,"Thank you so much for sharing this! 
I tried running the script after mounting Google Drive, but ran into the following issue:

```Collecting numpy==1.26.4
  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.0/61.0 kB 4.7 MB/s eta 0:00:00
Collecting scipy==1.11.4
  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 60.4/60.4 kB 5.9 MB/s eta 0:00:00
Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.3/18.3 MB 92.1 MB/s eta 0:00:00
Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 36.4/36.4 MB 24.6 MB/s eta 0:00:00
Installing collected packages: numpy, scipy
  Attempting uninstall: numpy
    Found existing installation: numpy 2.0.2
    Uninstalling numpy-2.0.2:
      Successfully uninstalled numpy-2.0.2
  Attempting uninstall: scipy
    Found existing installation: scipy 1.16.0
    Uninstalling scipy-1.16.0:
      Successfully uninstalled scipy-1.16.0
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
Successfully installed numpy-1.26.4 scipy-1.11.4
WARNING: The following packages were previously imported in this runtime:
  [numpy]
You must restart the runtime in order to use newly installed versions.
```

However, even after restarting the session, the same warning keeps appearing.
I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?


",2025-07-26T03:35:55Z,rororoSSS,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3121126859
auto1111_webui,comment,17063,,"> Thank you so much for sharing this! I tried running the script after mounting Google Drive, but ran into the following issue:
> 
> ```
>   Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
>      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.0/61.0 kB 4.7 MB/s eta 0:00:00
> Collecting scipy==1.11.4
>   Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
>      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 60.4/60.4 kB 5.9 MB/s eta 0:00:00
> Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
>    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.3/18.3 MB 92.1 MB/s eta 0:00:00
> Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)
>    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 36.4/36.4 MB 24.6 MB/s eta 0:00:00
> Installing collected packages: numpy, scipy
>   Attempting uninstall: numpy
>     Found existing installation: numpy 2.0.2
>     Uninstalling numpy-2.0.2:
>       Successfully uninstalled numpy-2.0.2
>   Attempting uninstall: scipy
>     Found existing installation: scipy 1.16.0
>     Uninstalling scipy-1.16.0:
>       Successfully uninstalled scipy-1.16.0
> ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
> opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= ""3.10"", but you have scipy 1.11.4 which is incompatible.
> opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
> opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= ""3.9"", but you have numpy 1.26.4 which is incompatible.
> Successfully installed numpy-1.26.4 scipy-1.11.4
> WARNING: The following packages were previously imported in this runtime:
>   [numpy]
> You must restart the runtime in order to use newly installed versions.
> ```
> 
> However, even after restarting the session, the same warning keeps appearing. I was wondering if you've encountered this issue as well? Or is there something I might be missing in the setup?

After restarting the runtime, you skip this module and run everything as usual. I have the same error, but it doesn't cause any problems with startup.",2025-07-26T10:50:29Z,lRyzzl,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3121611474
auto1111_webui,comment,17063,,"It's working, thank you so much for the help!",2025-07-27T02:19:26Z,rororoSSS,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17063#issuecomment-3123780214
auto1111_webui,issue,17062,[Feature Request]: AVIF Lossless Support,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Stable Diffusion Webui already supports avif, but there is no setting to make it lossless like webp.

Also of note, if I pass an avif image through an upscaler in extras, the resulting avif's colorspace, color primaries and color transfer settings will be changed (to bt601,bt709 and srgb)

The whole idea here is to use AVIF to extract frames losslessly (or near losslessly I guess) from a video, upscale those frames in sdwebui's extras tab and saving them as an AVIF with the same paramaters as the AVIF that was loaded in.

### Proposed workflow

1. A lossless setting for avif next to the 'Use lossless compression for webp images' setting. 
2. The setting should ideally try to account for colorspace, color primaries, and color transfer of the original image. (Otherwise it cannot be called lossless as the colors will change from the conversion of those attributes to different ones)

### Additional information

You can extract a frame from any video as avif with ffmpeg as avif using this command:

    ffmpeg -i <input_video> -ss <timestamp> -cpu-used 4 -c:v libaom-av1 -aom-params lossless=1 -frames:v 1 <output_image>.avif


Alternatively below is an example avif image.

I had to rename the extension to png because github said so. 

Simply download it and rename it's extension to .avif.

![Image](https://github.com/user-attachments/assets/6fbf77c3-8ccf-4b5d-8543-01e8e91a4957)

",2025-07-15T05:03:40Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062
auto1111_webui,comment,17062,,"you sure we don't support losses AVIF?
 
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/15610

<img width=""341"" height=""94"" alt=""Image"" src=""https://github.com/user-attachments/assets/8a6584e6-bce7-439b-ab5a-7f8edd65774f"" />

",2025-07-19T02:38:53Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062#issuecomment-3091427111
auto1111_webui,comment,17062,,"> you sure we don't support losses AVIF?

Setting avif quality to 100%, like with jpeg, does not make it lossless, it would need to be a separate tickable setting like with the webp. And the lossless compression for webp setting does not make avif lossless, I've checked that.

A lossless parameter needs to be set, this remains true for all av1 libraries I tested except for rav1e which doesn't support lossless av1 at all.
 
For example with ffmpeg to create lossless avif one of the below combinations of settings is required, there's also a quality setting but as I said, setting it to 100 is not the same as lossless.
```
#svtav1
 -c:v libsvtav1 -svtav1-params lossless=1
#libaom-av1
 -c:v libaom-av1 -aom-params lossless=1
```

The pixel format and colorspace conversions would also still be a rather big issue.",2025-07-21T11:12:14Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17062#issuecomment-3096245082
auto1111_webui,issue,17061,[Bug]: AttributeError: 'BertLMHeadModel' object has no attribute 'generate',"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I tried to run BLIP image caption for data preprocess
but I cannot run it successfully.

### Steps to reproduce the problem

1. Select the tab `Extras` > `Batch from directory`.
2. fill in input dir & output dir.
3. Select Caption > BLIP.

### What should have happened?

In `repositories/BLIP/models/blip.py` there's no function called `generate` in `Class BertLMHeadModel` indeed, but this method called by `modules/interrogate.py` at line 181.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

{
    ""Platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
    ""Python"": ""3.10.18"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""ä½æ–¼åˆ†æ”¯ master\næ‚¨çš„åˆ†æ”¯èˆ‡ä¸Šæ¸¸åˆ†æ”¯ 'origin/master' ä¸€è‡´ã€‚\n\nå°šæœªæš«å­˜ä»¥å‚™æäº¤çš„è®Šæ›´ï¼š\n  ï¼ˆä½¿ç”¨ \""git add <æª”æ¡ˆ>...\"" æ›´æ–°è¦æäº¤çš„å…§å®¹ï¼‰\n  ï¼ˆä½¿ç”¨ \""git restore <æª”æ¡ˆ>...\"" æ¨æ£„å·¥ä½œå€çš„æ”¹å‹•ï¼‰\n\tä¿®æ”¹ï¼š     modules/launch_utils.py\n\tä¿®æ”¹ï¼š     webui-user.sh\n\tä¿®æ”¹ï¼š     webui.sh\n\næœªè¿½è¹¤çš„æª”æ¡ˆ:\n  ï¼ˆä½¿ç”¨ \""git add <æª”æ¡ˆ>...\"" ä»¥åŒ…å«è¦æäº¤çš„å…§å®¹ï¼‰\n\tdata/\n\nä¿®æ”¹å°šæœªåŠ å…¥æäº¤ï¼ˆä½¿ç”¨ \""git add\"" å’Œ/æˆ– \""git commit -a\""ï¼‰"",
    ""Script path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Data path"": ""/home/matt/Documents/stable-diffusion-webui"",
    ""Extensions dir"": ""/home/matt/Documents/stable-diffusion-webui/extensions"",
    ""Checksum"": ""4e7bff3f3cfe0f27f5e47b1af1d0d720b5211dbd577cace58e87aa151cb03fd9"",
    ""Commandline"": [
        ""launch.py"",
        ""--disable-safe-unpickle""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.9.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.9"",
        ""gcc_version"": ""(Ubuntu 14.2.0-4ubuntu2~24.04) 14.2.0"",
        ""clang_version"": null,
        ""cmake_version"": ""version 3.28.3"",
        ""os"": ""Ubuntu 24.04.2 LTS (x86_64)"",
        ""libc_version"": ""glibc-2.39"",
        ""python_version"": ""3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0] (64-bit runtime)"",
        ""python_platform"": ""Linux-6.15.0-061500-generic-x86_64-with-glibc2.39"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""575.57.08"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5090"",
        ""cudnn_version"": [
            ""Probably one of the following:"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.8/targets/x86_64-linux/lib/libcudnn_ops_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_adv_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8"",
            ""/usr/local/cuda-12.9/targets/x86_64-linux/lib/libcudnn_ops_train.so.8""
        ],
        ""is_xpu_available"": ""False"",
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""nvidia-cublas-cu12==12.9.1.4"",
            ""nvidia-cuda-cupti-cu12==12.9.79"",
            ""nvidia-cuda-nvrtc-cu12==12.9.86"",
            ""nvidia-cuda-runtime-cu12==12.9.79"",
            ""nvidia-cudnn-cu12==9.10.2.21"",
            ""nvidia-cufft-cu12==11.4.1.4"",
            ""nvidia-curand-cu12==10.3.10.19"",
            ""nvidia-cusolver-cu12==11.7.5.82"",
            ""nvidia-cusparse-cu12==12.5.10.65"",
            ""nvidia-cusparselt-cu12==0.7.1"",
            ""nvidia-nccl-cu12==2.27.5"",
            ""nvidia-nvjitlink-cu12==12.9.86"",
            ""nvidia-nvtx-cu12==12.9.79"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""pytorch_optimizer==3.4.0"",
            ""pytorch-triton==3.4.0+gitae848267"",
            ""torch==2.9.0.dev20250712+cu129"",
            ""torchaudio==2.8.0.dev20250713+cu129"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.24.0.dev20250713+cu129"",
            ""triton==3.3.1""
        ],
        ""conda_packages"": [
            ""numpy                        1.26.2                    pypi_0           pypi"",
            ""nvidia-cublas-cu12           12.9.1.4                  pypi_0           pypi"",
            ""nvidia-cuda-cupti-cu12       12.9.79                   pypi_0           pypi"",
            ""nvidia-cuda-nvrtc-cu12       12.9.86                   pypi_0           pypi"",
            ""nvidia-cuda-runtime-cu12     12.9.79                   pypi_0           pypi"",
            ""nvidia-cudnn-cu12            9.10.2.21                 pypi_0           pypi"",
            ""nvidia-cufft-cu12            11.4.1.4                  pypi_0           pypi"",
            ""nvidia-curand-cu12           10.3.10.19                pypi_0           pypi"",
            ""nvidia-cusolver-cu12         11.7.5.82                 pypi_0           pypi"",
            ""nvidia-cusparse-cu12         12.5.10.65                pypi_0           pypi"",
            ""nvidia-cusparselt-cu12       0.7.1                     pypi_0           pypi"",
            ""nvidia-nccl-cu12             2.27.5                    pypi_0           pypi"",
            ""nvidia-nvjitlink-cu12        12.9.86                   pypi_0           pypi"",
            ""nvidia-nvtx-cu12             12.9.79                   pypi_0           pypi"",
            ""open-clip-torch              2.20.0                    pypi_0           pypi"",
            ""pytorch-lightning            1.9.4                     pypi_0           pypi"",
            ""pytorch-optimizer            3.4.0                     pypi_0           pypi"",
            ""pytorch-triton               3.4.0+gitae848267         pypi_0           pypi"",
            ""torch                        2.9.0.dev20250712+cu129   pypi_0           pypi"",
            ""torchaudio                   2.8.0.dev20250713+cu129   pypi_0           pypi"",
            ""torchdiffeq                  0.2.3                     pypi_0           pypi"",
            ""torchmetrics                 1.7.4                     pypi_0           pypi"",
            ""torchsde                     0.2.6                     pypi_0           pypi"",
            ""torchvision                  0.24.0.dev20250713+cu129  pypi_0           pypi"",
            ""triton                       3.3.1                     pypi_0           pypi""
        ],
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""æ¶æ§‹ï¼š                                   x86_64"",
            ""CPU ä½œæ¥­æ¨¡å¼ï¼š                           32-bit, 64-bit"",
            ""Address sizes:                           46 bits physical, 48 bits virtual"",
            ""Byte Order:                              Little Endian"",
            ""CPU(s):                                  24"",
            ""On-line CPU(s) list:                     0-23"",
            ""ä¾›æ‡‰å•†è­˜åˆ¥è™Ÿï¼š                           GenuineIntel"",
            ""Model name:                              Intel(R) Core(TM) Ultra 9 285K"",
            ""CPU å®¶æ—ï¼š                               6"",
            ""å‹è™Ÿï¼š                                   198"",
            ""æ¯æ ¸å¿ƒåŸ·è¡Œç·’æ•¸ï¼š                         1"",
            ""æ¯é€šè¨Šç«¯æ ¸å¿ƒæ•¸ï¼š                         24"",
            ""Socket(s):                               1"",
            ""è£½ç¨‹ï¼š                                   2"",
            ""CPU(s) scaling MHz:                      70%"",
            ""CPU max MHz:                             6500.0000"",
            ""CPU min MHz:                             800.0000"",
            ""BogoMIPS:                                7372.80"",
            ""Flags:                                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect user_shstk avx_vnni lam wbnoinvd dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid bus_lock_detect movdiri movdir64b fsrm md_clear serialize arch_lbr ibt flush_l1d arch_capabilities"",
            ""è™›æ“¬ï¼š                                   VT-x"",
            ""L1d å¿«å–ï¼š                               768 KiB (20 instances)"",
            ""L1i å¿«å–ï¼š                               1.3 MiB (20 instances)"",
            ""L2 å¿«å–ï¼š                                40 MiB (12 instances)"",
            ""L3 å¿«å–ï¼š                                36 MiB (1 instance)"",
            ""NUMA ç¯€é»ï¼š                              1"",
            ""NUMA node0 CPU(s)ï¼š                      0-23"",
            ""Vulnerability Gather data sampling:      Not affected"",
            ""Vulnerability Ghostwrite:                Not affected"",
            ""Vulnerability Indirect target selection: Not affected"",
            ""Vulnerability Itlb multihit:             Not affected"",
            ""Vulnerability L1tf:                      Not affected"",
            ""Vulnerability Mds:                       Not affected"",
            ""Vulnerability Meltdown:                  Not affected"",
            ""Vulnerability Mmio stale data:           Not affected"",
            ""Vulnerability Reg file data sampling:    Not affected"",
            ""Vulnerability Retbleed:                  Not affected"",
            ""Vulnerability Spec rstack overflow:      Not affected"",
            ""Vulnerability Spec store bypass:         Mitigation; Speculative Store Bypass disabled via prctl"",
            ""Vulnerability Spectre v1:                Mitigation; usercopy/swapgs barriers and __user pointer sanitization"",
            ""Vulnerability Spectre v2:                Mitigation; Enhanced / Automatic IBRS; IBPB conditional; PBRSB-eIBRS Not affected; BHI BHI_DIS_S"",
            ""Vulnerability Srbds:                     Not affected"",
            ""Vulnerability Tsx async abort:           Not affected""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        },
        {
            ""exception"": ""'BertLMHeadModel' object has no attribute 'generate'"",
            ""traceback"": [
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 194, interrogate"",
                    ""caption = self.generate_caption(pil_image)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py, line 181, generate_caption"",
                    ""caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)""
                ],
                [
                    ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py, line 156, generate"",
                    ""outputs = self.text_decoder.generate(input_ids=input_ids,""
                ],
                [
                    ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py, line 1962, __getattr__"",
                    ""raise AttributeError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""x86_64"",
        ""count logical"": 24,
        ""count physical"": 24
    },
    ""RAM"": {
        ""total"": ""62GB"",
        ""used"": ""13GB"",
        ""free"": ""4GB"",
        ""active"": ""11GB"",
        ""inactive"": ""43GB"",
        ""buffers"": ""736MB"",
        ""cached"": ""44GB"",
        ""shared"": ""1GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd_dreambooth_extension"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd_dreambooth_extension"",
            ""commit"": ""bae1e87c9b0fe3bb0d261d6851ceffab6f99dfb6"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/d8ahazard/sd_dreambooth_extension.git""
        }
    ],
    ""Inactive extensions"": [
        {
            ""name"": ""sd-webui-blip2"",
            ""path"": ""/home/matt/Documents/stable-diffusion-webui/extensions/sd-webui-blip2"",
            ""commit"": ""6ca77c3ac9f522fc288f302d73e6e1e3edd1c0f4"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Tps-F/sd-webui-blip2.git""
        }
    ],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--disable-safe-unpickle"",
        ""GIT"": ""git"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v1-5-pruned-emaonly.safetensors [6ce0161689]"",
        ""sd_checkpoint_hash"": ""6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa"",
        ""disabled_extensions"": [
            ""sd-webui-blip2""
        ],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 54.858973026275635,
        ""records"": {
            ""initial startup"": 0.006804466247558594,
            ""prepare environment/checks"": 4.76837158203125e-05,
            ""prepare environment/git version info"": 0.0056149959564208984,
            ""prepare environment/install torch"": 38.455273389816284,
            ""prepare environment/torch GPU test"": 1.2488372325897217,
            ""prepare environment/clone repositores"": 0.021414518356323242,
            ""prepare environment/install requirements"": 3.1076724529266357,
            ""prepare environment/run extensions installers/sd_dreambooth_extension"": 7.6595964431762695,
            ""prepare environment/run extensions installers"": 7.659667015075684,
            ""prepare environment"": 50.49855923652649,
            ""launcher"": 0.0026547908782958984,
            ""import torch"": 1.9291045665740967,
            ""import gradio"": 0.3491065502166748,
            ""setup paths"": 0.6249384880065918,
            ""import ldm"": 0.0012063980102539062,
            ""import sgm"": 1.9073486328125e-06,
            ""initialize shared"": 0.11213350296020508,
            ""other imports"": 0.21344661712646484,
            ""opts onchange"": 0.00021076202392578125,
            ""setup SD model"": 2.5987625122070312e-05,
            ""setup codeformer"": 0.0003218650817871094,
            ""setup gfpgan"": 0.01207423210144043,
            ""set samplers"": 1.6927719116210938e-05,
            ""list extensions"": 0.0004096031188964844,
            ""restore config state file"": 4.5299530029296875e-06,
            ""list SD models"": 0.01157999038696289,
            ""list localizations"": 8.106231689453125e-05,
            ""load scripts/custom_code.py"": 0.0005917549133300781,
            ""load scripts/img2imgalt.py"": 0.00019502639770507812,
            ""load scripts/loopback.py"": 0.00010895729064941406,
            ""load scripts/outpainting_mk_2.py"": 0.00012350082397460938,
            ""load scripts/poor_mans_outpainting.py"": 8.249282836914062e-05,
            ""load scripts/postprocessing_codeformer.py"": 7.224082946777344e-05,
            ""load scripts/postprocessing_gfpgan.py"": 6.318092346191406e-05,
            ""load scripts/postprocessing_upscale.py"": 0.00011491775512695312,
            ""load scripts/prompt_matrix.py"": 8.20159912109375e-05,
            ""load scripts/prompts_from_file.py"": 0.0001304149627685547,
            ""load scripts/sd_upscale.py"": 7.557868957519531e-05,
            ""load scripts/xyz_grid.py"": 0.0006914138793945312,
            ""load scripts/ldsr_model.py"": 0.021519184112548828,
            ""load scripts/lora_script.py"": 0.05590462684631348,
            ""load scripts/scunet_model.py"": 0.00992441177368164,
            ""load scripts/swinir_model.py"": 0.008924245834350586,
            ""load scripts/hotkey_config.py"": 0.0006728172302246094,
            ""load scripts/extra_options_section.py"": 0.0006744861602783203,
            ""load scripts/hypertile_script.py"": 0.017293930053710938,
            ""load scripts/postprocessing_autosized_crop.py"": 0.00045418739318847656,
            ""load scripts/postprocessing_caption.py"": 0.00043702125549316406,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.00041174888610839844,
            ""load scripts/postprocessing_focal_crop.py"": 0.0007452964782714844,
            ""load scripts/postprocessing_split_oversized.py"": 0.0003840923309326172,
            ""load scripts/soft_inpainting.py"": 0.00027942657470703125,
            ""load scripts/__init__.py"": 0.00014495849609375,
            ""load scripts/api.py"": 0.2062222957611084,
            ""load scripts/main.py"": 0.02004265785217285,
            ""load scripts/comments.py"": 0.008637189865112305,
            ""load scripts/refiner.py"": 0.00034928321838378906,
            ""load scripts/sampler.py"": 0.0004024505615234375,
            ""load scripts/seed.py"": 0.00018310546875,
            ""load scripts"": 0.3559587001800537,
            ""load upscalers"": 0.0018105506896972656,
            ""refresh VAE"": 0.00035762786865234375,
            ""refresh textual inversion templates"": 2.1696090698242188e-05,
            ""scripts list_optimizers"": 0.00014162063598632812,
            ""scripts list_unets"": 7.867813110351562e-06,
            ""reload hypernetworks"": 0.0006139278411865234,
            ""initialize extra networks"": 0.011160135269165039,
            ""scripts before_ui_callback"": 0.0008454322814941406,
            ""create ui"": 0.35759758949279785,
            ""gradio launch"": 0.3304779529571533,
            ""add APIs"": 0.037171363830566406,
            ""app_started_callback/lora_script.py"": 0.0001723766326904297,
            ""app_started_callback"": 0.0001742839813232422
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""altair==5.5.0"",
        ""annotated-types==0.7.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""bitsandbytes==0.46.1"",
        ""blendmodes==2022"",
        ""certifi==2025.7.14"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""dadaptation==3.2"",
        ""deprecation==2.1.0"",
        ""diffusers==0.34.0"",
        ""discord-webhook==1.3.1"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""hf-xet==1.1.5"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""kornia_rs==0.1.9"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""nvidia-cublas-cu12==12.9.1.4"",
        ""nvidia-cuda-cupti-cu12==12.9.79"",
        ""nvidia-cuda-nvrtc-cu12==12.9.86"",
        ""nvidia-cuda-runtime-cu12==12.9.79"",
        ""nvidia-cudnn-cu12==9.10.2.21"",
        ""nvidia-cufft-cu12==11.4.1.4"",
        ""nvidia-cufile-cu12==1.14.1.1"",
        ""nvidia-curand-cu12==10.3.10.19"",
        ""nvidia-cusolver-cu12==11.7.5.82"",
        ""nvidia-cusparse-cu12==12.5.10.65"",
        ""nvidia-cusparselt-cu12==0.7.1"",
        ""nvidia-nccl-cu12==2.27.5"",
        ""nvidia-nvjitlink-cu12==12.9.86"",
        ""nvidia-nvshmem-cu12==3.3.9"",
        ""nvidia-nvtx-cu12==12.9.79"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip @ file:///croot/pip_1746204010231/work"",
        ""propcache==0.3.2"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydantic_core==2.33.2"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytorch-triton==3.4.0+gitae848267"",
        ""pytorch_optimizer==3.4.0"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.26.0"",
        ""safetensors==0.5.3"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.17"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""torch==2.9.0.dev20250712+cu129"",
        ""torchaudio==2.8.0.dev20250713+cu129"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.24.0.dev20250713+cu129"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.53.2"",
        ""triton==3.3.1"",
        ""typing-inspection==0.4.1"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""xformers==0.0.31.post1"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
Here's the full log about this issue


*** Error interrogating
    Traceback (most recent call last):
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 194, in interrogate
        caption = self.generate_caption(pil_image)
      File ""/home/matt/Documents/stable-diffusion-webui/modules/interrogate.py"", line 181, in generate_caption
        caption = self.blip_model.generate(gpu_image, sample=False, num_beams=shared.opts.interrogate_clip_num_beams, min_length=shared.opts.interrogate_clip_min_length, max_length=shared.opts.interrogate_clip_max_length)
      File ""/home/matt/Documents/stable-diffusion-webui/repositories/BLIP/models/blip.py"", line 156, in generate
        outputs = self.text_decoder.generate(input_ids=input_ids,
      File ""/home/matt/miniconda3/envs/webui/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1962, in __getattr__
        raise AttributeError(
    AttributeError: 'BertLMHeadModel' object has no attribute 'generate'
```

### Additional information

_No response_",2025-07-14T08:18:13Z,hanasay,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17061
auto1111_webui,comment,17061,,"same here 
```
from caption import caption
caption(imgpth,batch_size=50)
```

It nags you about this first before proceeding to crap the bed with the error posted by OP:
```
BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
```",2025-09-05T01:01:05Z,openSourcerer9000,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17061#issuecomment-3256640049
auto1111_webui,issue,17060,[Bug]: SDXL Hires. fix Fails with OOM (Out Of Memory) on Intel Arc (DirectML),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When generating SDXL images with Hires. fix on an Intel Arc A770 (DirectML) GPU, the generation frequently stops mid-process, usually at the Hires. fix stage (around 50-70% progress). This happens even with `--lowvram` and `--no-half-vae` enabled, and at relatively low base resolutions like 512x512. The VRAM usage shown by Task Manager often indicates around 3GB used when it stops, while the console shows Out Of Memory (OOM) errors (e.g., ""Could not allocate tensor..."") or sometimes a NaN error with automatic 32-bit VAE retry. The issue is inconsistent; sometimes a generation succeeds, but subsequent attempts often fail.

### Steps to reproduce the problem

1.  **Hardware:** Intel Arc A770 16GB VRAM, Windows 11.
2.  **Web UI Setup:**
    * Using Automatic1111 stable-diffusion-webui (latest `git pull`).
    * `webui-user.bat` includes: `--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae`
    * Python 3.10.9, Torch 2.0.0+cpu (as shown in startup log, despite `--reinstall-torch` attempts).
3.  **Model:** Use an SDXL 1.0 base model (e.g., `novaOrangeXL_reV10.safetensors` or `waiNSFWIllustrious_v140.safetensors`).
4.  **Steps:**
    a.  Launch Web UI using `webui-user.bat`.
    b.  Go to the `txt2img` tab.
    c.  Enter a simple prompt (e.g., ""masterpiece, best quality, beautiful girl, clear eyes"").
    d.  Set image dimensions to **Width: 512, Height: 512**.
    e.  Enable **Hires. fix**.
    f.  Set **Upscale by: 2**.
    g.  Set **Hires steps: 24** (or similar, default often used).
    h.  Set **Denoising strength: 0.7** (or similar).
    i.  Set **Sampler: Euler a** (or any other, issue persists).
    j.  Click **""Generate""**.
5.  **Observe:** The generation often stops at around 50-70% progress (Hires. fix stage). The console shows `RuntimeError: Could not allocate tensor...` or sometimes prints ""A tensor with all NaNs was produced in VAE."" before converting to float32 and then potentially still failing with OOM.
6.  **Inconsistency:** If the first generation succeeds, attempting a second generation immediately after often results in a failure with the same errors. Restarting the Web UI process (closing and relaunching `webui-user.bat`) usually allows for one successful generation again.

### What should have happened?

The image generation, including the Hires. fix stage, should complete successfully without encountering Out Of Memory errors or NaN issues. The process should be stable, allowing for continuous image generation without requiring a Web UI restart after each successful image. Given the 16GB VRAM on the Intel Arc A770, it should be capable of consistently handling SDXL Hires. fix up to 1024x1024 (or at least 896x896) without crashing or inconsistent behavior, especially with `--lowvram` and `--no-half-vae` enabled.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.26100-SP0"",
    ""Python"": ""3.10.9"",
    ""Version"": ""v1.10.1-amd-39-g6d85a7df"",
    ""Commit"": ""6d85a7dfa4977ae4eece9cbbab4725123833be14"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   launch.py\n\tmodified:   webui-user.bat\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""D:\\sd_directml"",
    ""Data path"": ""D:\\sd_directml"",
    ""Extensions dir"": ""D:\\sd_directml\\extensions"",
    ""Checksum"": ""ba7a852b3fbd4f24b5aad10e0a0c032445127e2e79154b9925ee223e4c5c4b70"",
    ""Commandline"": [
        ""launch.py"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae"",
        ""--autolaunch"",
        ""--precision"",
        ""full"",
        ""--skip-torch-cuda-test"",
        ""--opt-sdp-attention"",
        ""--use-directml"",
        ""--lowvram"",
        ""--no-half-vae""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.0.0+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": null,
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Home"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.26100-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.0.0"",
            ""torch-directml==0.2.0.dev230426"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.4"",
            ""torchsde==0.2.6"",
            ""torchvision==0.15.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=2592"",
            ""DeviceID=CPU0"",
            ""Family=205"",
            ""L2CacheSize=3072"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=2592"",
            ""Name=11th Gen Intel(R) Core(TM) i5-11400 @ 2.60GHz"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": """",
            ""traceback"": [
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 849, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""D:\\sd_directml\\extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py, line 59, processing_process_images_hijack"",
                    ""return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1083, process_images_inner"",
                    ""samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1457, sample"",
                    ""return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)""
                ],
                [
                    ""D:\\sd_directml\\modules\\processing.py, line 1549, sample_hr_pass"",
                    ""samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, sample_img2img"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_common.py, line 272, launch_sampling"",
                    ""return func()""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_kdiffusion.py, line 187, <lambda>"",
                    ""samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py, line 115, decorate_context"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\sampling.py, line 145, sample_euler_ancestral"",
                    ""denoised = model(x, sigmas[i] * s_in, **extra_args)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_samplers_cfg_denoiser.py, line 268, forward"",
                    ""x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 112, forward"",
                    ""eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\k-diffusion\\k_diffusion\\external.py, line 138, get_eps"",
                    ""return self.inner_model.apply_model(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_models_xl.py, line 43, apply_model"",
                    ""return self.model(x, t, cond)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 22, <lambda>"",
                    ""setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_utils.py, line 34, __call__"",
                    ""return self.__sub_func(self.__orig_func, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_unet.py, line 50, apply_model"",
                    ""result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\wrappers.py, line 28, forward"",
                    ""return self.diffusion_model(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_unet.py, line 91, UNetModel_forward"",
                    ""return original_forward(self, x, timesteps, context, *args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 993, forward"",
                    ""h = module(h, emb, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1538, _call_impl"",
                    ""result = forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py, line 100, forward"",
                    ""x = layer(x, context)""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 627, forward"",
                    ""x = block(x, context=context[i])""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 459, forward"",
                    ""return checkpoint(""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\diffusionmodules\\util.py, line 167, checkpoint"",
                    ""return func(*inputs)""
                ],
                [
                    ""D:\\sd_directml\\repositories\\generative-models\\sgm\\modules\\attention.py, line 467, _forward"",
                    ""self.attn1(""
                ],
                [
                    ""D:\\sd_directml\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py, line 1501, _call_impl"",
                    ""return forward_call(*args, **kwargs)""
                ],
                [
                    ""D:\\sd_directml\\modules\\sd_hijack_optimizations.py, line 547, scaled_dot_product_attention_forward"",
                    ""hidden_states = torch.nn.functional.scaled_dot_product_attention(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 167 Stepping 1, GenuineIntel"",
        ""count logical"": 12,
        ""count physical"": 6
    },
    ""RAM"": {
        ""total"": ""16GB"",
        ""used"": ""10GB"",
        ""free"": ""6GB""
    },
    ""Extensions"": [
        {
            ""name"": ""sd-webui-animatediff"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-animatediff"",
            ""commit"": ""a88e88912bcbae0531caccfc50fd639f6ea83fd0"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/continue-revolution/sd-webui-animatediff""
        },
        {
            ""name"": ""sd-webui-controlnet"",
            ""path"": ""D:\\sd_directml\\extensions\\sd-webui-controlnet"",
            ""commit"": ""56cec5b2958edf3b1807b7e7b2b1b5186dbd2f81"",
            ""branch"": ""main"",
            ""remote"": ""https://github.com/Mikubill/sd-webui-controlnet""
        },
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""D:\\sd_directml\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""http://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae"",
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""novaOrangeXL_reV10.safetensors [2e13269995]"",
        ""sd_checkpoint_hash"": ""2e13269995e4c3e1e1edb7d45e815dc311f770558ee5a31f248807f5d598e964"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""onnx_cached_models_path"": ""D:\\sd_directml\\models\\ONNX\\cache"",
        ""onnx_temp_dir"": ""D:\\sd_directml\\models\\ONNX\\temp"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""onnx_enable"": false,
        ""diffusers_pipeline"": ""ONNX Stable Diffusion"",
        ""diffusers_vae_upcast"": ""default"",
        ""onnx_execution_provider"": ""CUDAExecutionProvider"",
        ""onnx_cache_converted"": true,
        ""olive_enable"": false,
        ""olive_submodels"": [],
        ""olive_float16"": true,
        ""olive_vae_encoder_float32"": false,
        ""olive_static_dims"": true,
        ""olive_cache_optimized"": true,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""directml_memory_provider"": ""Performance Counter"",
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""sdxlVAE_sdxlVAE.safetensors"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""animatediff_model_path"": """",
        ""animatediff_default_save_formats"": [
            ""GIF"",
            ""PNG""
        ],
        ""animatediff_save_to_custom"": true,
        ""animatediff_frame_extract_path"": """",
        ""animatediff_frame_extract_remove"": false,
        ""animatediff_default_frame_extract_method"": ""ffmpeg"",
        ""animatediff_optimize_gif_palette"": false,
        ""animatediff_optimize_gif_gifsicle"": false,
        ""animatediff_mp4_crf"": 23,
        ""animatediff_mp4_preset"": """",
        ""animatediff_mp4_tune"": """",
        ""animatediff_webp_quality"": 80,
        ""animatediff_webp_lossless"": false,
        ""animatediff_s3_enable"": false,
        ""animatediff_s3_host"": """",
        ""animatediff_s3_port"": """",
        ""animatediff_s3_access_key"": """",
        ""animatediff_s3_secret_key"": """",
        ""animatediff_s3_storge_bucket"": """",
        ""control_net_detectedmap_dir"": ""detected_maps"",
        ""control_net_models_path"": """",
        ""control_net_modules_path"": """",
        ""control_net_unit_count"": 3,
        ""control_net_model_cache_size"": 2,
        ""control_net_inpaint_blur_sigma"": 7,
        ""control_net_no_detectmap"": false,
        ""control_net_detectmap_autosaving"": false,
        ""control_net_allow_script_control"": false,
        ""control_net_sync_field_args"": true,
        ""controlnet_show_batch_images_in_ui"": false,
        ""controlnet_increment_seed_during_batch"": false,
        ""controlnet_disable_openpose_edit"": false,
        ""controlnet_disable_photopea_edit"": false,
        ""controlnet_photopea_warning"": true,
        ""controlnet_ignore_noninpaint_mask"": false,
        ""controlnet_clip_detector_on_cpu"": false,
        ""controlnet_control_type_dropdown"": false,
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""D:\\sd_directml\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": [],
        ""prioritized_callbacks_cfg_denoiser"": [],
        ""prioritized_callbacks_after_component"": [],
        ""prioritized_callbacks_on_reload"": [],
        ""prioritized_callbacks_script_before_process_batch"": [],
        ""prioritized_callbacks_script_postprocess"": [],
        ""prioritized_callbacks_script_postprocess_batch"": [],
        ""prioritized_callbacks_script_postprocess_batch_list"": [],
        ""prioritized_callbacks_script_postprocess_image"": []
    },
    ""Startup"": {
        ""total"": 117.79217195510864,
        ""records"": {
            ""launcher"": 35.03606104850769,
            ""import torch"": 21.190768241882324,
            ""import gradio"": 1.6846561431884766,
            ""setup paths"": 12.206217765808105,
            ""import ldm"": 0.007937192916870117,
            ""import sgm"": 0.0,
            ""initialize shared"": 2.566276788711548,
            ""other imports"": 0.046120643615722656,
            ""opts onchange"": 0.0010085105895996094,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.002558469772338867,
            ""setup gfpgan"": 0.0189664363861084,
            ""set samplers"": 0.00102996826171875,
            ""list extensions"": 0.0015044212341308594,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.07561135292053223,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.013432025909423828,
            ""load scripts/img2imgalt.py"": 0.0015058517456054688,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0010120868682861328,
            ""load scripts/poor_mans_outpainting.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0010037422180175781,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0017118453979492188,
            ""load scripts/prompts_from_file.py"": 0.0011334419250488281,
            ""load scripts/sd_upscale.py"": 0.0010564327239990234,
            ""load scripts/xyz_grid.py"": 0.001165151596069336,
            ""load scripts/ldsr_model.py"": 1.1645009517669678,
            ""load scripts/lora_script.py"": 0.2477409839630127,
            ""load scripts/scunet_model.py"": 0.041359901428222656,
            ""load scripts/swinir_model.py"": 0.040180206298828125,
            ""load scripts/hotkey_config.py"": 0.0017354488372802734,
            ""load scripts/extra_options_section.py"": 0.0014653205871582031,
            ""load scripts/hypertile_script.py"": 0.08105015754699707,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0012936592102050781,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0015063285827636719,
            ""load scripts/postprocessing_focal_crop.py"": 0.002042531967163086,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009915828704833984,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/animatediff.py"": 0.19388294219970703,
            ""load scripts/animatediff_freeinit.py"": 0.0010075569152832031,
            ""load scripts/animatediff_i2ibatch.py"": 0.0010106563568115234,
            ""load scripts/animatediff_infotext.py"": 0.0,
            ""load scripts/animatediff_infv2v.py"": 0.0011479854583740234,
            ""load scripts/animatediff_latent.py"": 0.0,
            ""load scripts/animatediff_logger.py"": 0.0012199878692626953,
            ""load scripts/animatediff_mm.py"": 0.0,
            ""load scripts/animatediff_output.py"": 0.0,
            ""load scripts/animatediff_prompt.py"": 0.0015058517456054688,
            ""load scripts/animatediff_settings.py"": 0.0,
            ""load scripts/animatediff_ui.py"": 0.0,
            ""load scripts/animatediff_utils.py"": 0.0015609264373779297,
            ""load scripts/animatediff_xyz.py"": 0.0,
            ""load scripts/adapter.py"": 0.002076864242553711,
            ""load scripts/api.py"": 0.3266606330871582,
            ""load scripts/batch_hijack.py"": 0.0015680789947509766,
            ""load scripts/cldm.py"": 0.0026121139526367188,
            ""load scripts/controlnet.py"": 1.2729477882385254,
            ""load scripts/controlnet_diffusers.py"": 0.0010955333709716797,
            ""load scripts/controlnet_lllite.py"": 0.0,
            ""load scripts/controlnet_lora.py"": 0.0,
            ""load scripts/controlnet_model_guess.py"": 0.0015072822570800781,
            ""load scripts/controlnet_sparsectrl.py"": 0.0,
            ""load scripts/controlnet_version.py"": 0.0,
            ""load scripts/enums.py"": 0.0015232563018798828,
            ""load scripts/external_code.py"": 0.0010516643524169922,
            ""load scripts/global_state.py"": 0.0,
            ""load scripts/hook.py"": 0.0010027885437011719,
            ""load scripts/infotext.py"": 0.0,
            ""load scripts/logging.py"": 0.0010135173797607422,
            ""load scripts/lvminthin.py"": 0.0,
            ""load scripts/movie2movie.py"": 0.0,
            ""load scripts/supported_preprocessor.py"": 0.001506805419921875,
            ""load scripts/utils.py"": 0.0011930465698242188,
            ""load scripts/xyz_grid_support.py"": 0.0,
            ""load scripts/tagger.py"": 0.14598941802978516,
            ""load scripts/comments.py"": 0.044586181640625,
            ""load scripts/refiner.py"": 0.0010988712310791016,
            ""load scripts/sampler.py"": 0.0009937286376953125,
            ""load scripts/seed.py"": 0.0015211105346679688,
            ""load scripts"": 3.618171453475952,
            ""load upscalers"": 0.004336118698120117,
            ""refresh VAE"": 0.0010046958923339844,
            ""refresh textual inversion templates"": 0.0010097026824951172,
            ""scripts list_optimizers"": 0.0010306835174560547,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009660720825195312,
            ""initialize extra networks"": 0.0998542308807373,
            ""scripts before_ui_callback"": 0.01022028923034668,
            ""create ui"": 40.41819214820862,
            ""gradio launch"": 0.772036075592041,
            ""add APIs"": 0.019764184951782227,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/api.py"": 0.003812551498413086,
            ""app_started_callback/tagger.py"": 0.003056764602661133,
            ""app_started_callback"": 0.006869316101074219
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""addict==2.4.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.14"",
        ""aiosignal==1.4.0"",
        ""albumentations==1.4.3"",
        ""alembic==1.16.4"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""basicsr==1.4.2"",
        ""beautifulsoup4==4.13.4"",
        ""blendmodes==2022"",
        ""certifi==2025.7.9"",
        ""cffi==1.17.1"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""controlnet_aux==0.0.10"",
        ""cssselect2==0.8.0"",
        ""cycler==0.12.1"",
        ""Cython==3.1.2"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""depth_anything @ https://github.com/huchenlei/Depth-Anything/releases/download/v1.0.0/depth_anything-2024.1.22.0-py2.py3-none-any.whl#sha256=26c1d38b8c3c306b4a2197d725a4b989ff65f7ebcf4fb5a96a1b6db7fbd56780"",
        ""depth_anything_v2 @ https://github.com/MackinationsAi/UDAV2-ControlNet/releases/download/v1.0.0/depth_anything_v2-2024.7.1.0-py2.py3-none-any.whl#sha256=6848128867d1f7c7519d88df0f88bfab89100dc5225259c4d7cb90325c308c9f"",
        ""diffusers==0.30.2"",
        ""diskcache==5.6.3"",
        ""dsine @ https://github.com/sdbds/DSINE/releases/download/1.0.2/dsine-2024.3.23-py3-none-any.whl#sha256=b9ea3bacce09f9b3f7fb4fa12471da7e465b2f9a60412711105a9238db280442"",
        ""easydict==1.13"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.5"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""future==1.0.0"",
        ""fvcore==0.1.5.post20221221"",
        ""gast==0.6.0"",
        ""gdown==5.2.0"",
        ""geffnet==1.0.2"",
        ""gfpgan @ git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""glob2==0.5"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.3"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""handrefinerportable @ https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl#sha256=1e6c702905919f4c49bcb2db7b20d334e8458a7555cd57630600584ec38ca6a9"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.4"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.7.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""insightface @ https://github.com/Gourieff/Assets/raw/main/Insightface/insightface-0.7.3-cp310-cp310-win_amd64.whl#sha256=47aa0571b2aadd8545d4bc7615dfbc374c10180c283b7ac65058fcb41ed4df86"",
        ""iopath==0.1.9"",
        ""jax==0.6.2"",
        ""jaxlib==0.6.2"",
        ""Jinja2==3.1.6"",
        ""joblib==1.5.1"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""lmdb==1.7.2"",
        ""lpips==0.1.4"",
        ""lxml==6.0.0"",
        ""Mako==1.3.10"",
        ""manifold3d==3.1.1"",
        ""mapbox_earcut==1.0.3"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""mediapipe==0.10.21"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.6.3"",
        ""namex==0.1.0"",
        ""narwhals==1.46.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""olive-ai==0.9.1"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnx-ir==0.1.4"",
        ""onnxruntime==1.22.1"",
        ""onnxscript==0.3.2"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optimum==1.26.1"",
        ""optree==0.16.0"",
        ""optuna==4.4.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.1"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""platformdirs==4.3.8"",
        ""portalocker==3.2.0"",
        ""prettytable==3.16.0"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pycollada==0.9.2"",
        ""pycparser==2.22"",
        ""pydantic==1.10.17"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""PySocks==1.7.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""pywin32==310"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""reportlab==4.4.2"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.26.0"",
        ""rtree==1.4.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.25.2"",
        ""scikit-learn==1.7.0"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""shapely==2.1.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""sounddevice==0.5.2"",
        ""soupsieve==2.7"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.41"",
        ""starlette==0.26.1"",
        ""svg.path==7.0"",
        ""svglib==1.5.1"",
        ""sympy==1.14.0"",
        ""tabulate==0.9.0"",
        ""tb-nightly==2.20.0a20250711"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.5.10"",
        ""timm==0.9.5"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.2"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.0.0"",
        ""torch-directml==0.2.0.dev230426"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.4"",
        ""torchsde==0.2.6"",
        ""torchvision==0.15.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.7.0"",
        ""typing_extensions==4.14.1"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.35.0"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.1"",
        ""zipp==3.23.0""
    ]
}

### Console logs

```Shell
venv ""D:\sd_directml\venv\Scripts\Python.exe""
Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
Commit hash: 6d85a7dfa4977ae4eece9cbbab4725123833be14
Installing requirements

loading WD14-tagger reqs from D:\sd_directml\extensions\stable-diffusion-webui-wd14-tagger\requirements.txt
Checking WD14-tagger requirements.

Launching Web UI with arguments: --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae --autolaunch --precision full --skip-torch-cuda-test --opt-sdp-attention --use-directml --lowvram --no-half-vae
2025-07-13 11:08:42.939440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-13 11:08:45.640065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ONNX failed to initialize: Failed to import optimum.onnxruntime.modeling_diffusion because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
==============================================================================
You are running torch 2.0.0+cpu.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
ControlNet preprocessor location: D:\sd_directml\extensions\sd-webui-controlnet\annotator\downloads
2025-07-13 11:08:56,379 - ControlNet - INFO - ControlNet v1.1.455
== WD14 tagger /gpu:0, uname_result(system='Windows', node='DESKTOP-GBPLTQV', release='10', version='10.0.26100', machine='AMD64') ==
Loading weights [2e13269995] from D:\sd_directml\models\Stable-diffusion\novaOrangeXL_reV10.safetensors
Creating model from config: D:\sd_directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
Model loaded in 36.5s (load weights from disk: 0.6s, create model: 0.9s, apply weights to model: 25.6s, apply half(): 0.3s, apply dtype to VAE: 0.1s, load VAE: 3.2s, load weights from state dict: 0.2s, move model to device: 0.3s, hijack: 1.0s, load textual inversion embeddings: 1.9s, calculate empty prompt: 2.3s).
2025-07-13 11:09:36,520 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 117.8s (launcher: 35.0s, import torch: 21.2s, import gradio: 1.7s, setup paths: 12.2s, initialize shared: 2.6s, load scripts: 3.6s, create ui: 40.4s, gradio launch: 0.8s).
Couldn't find VAE named sdxl_vae.safetensors; using None instead
Restoring base VAE
Applying attention optimization: sdp... done.
VAE weights loaded.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [07:00<00:00, 15.56s/it]
  0%|                                                                                           | 0/27 [00:00<?, ?it/s]
Loading VAE weights specified in settings: D:\sd_directml\models\VAE\sdxlVAE_sdxlVAE.safetensors
Applying attention optimization: sdp... done.
VAE weights loaded.
*** Error completing request
*** Arguments: ('task(tblrxw7xt728m2a)', <gradio.routes.Request object at 0x00000142C4CDE1D0>, 'beautiful girl, masterpiece, best quality, ultra-detailed face,beautiful eyes,Well-arranged eyes,\nshort layered bob haircut,purple eyes, slightly upturned nose,(smile:0.5),small nose,\ndeep violet hair with mint green gradient tips, smooth shiny hair, slightly tousled, detailed hair strands, natural skin texture,\nslim yet curvy body, slender waist, wide hips, hourglass figure, youthful proportions,\nnatural-looking large breasts, C-cup, smooth cleavage,\nlong legs, plump thighs, soft skin, firm hips, well-defined back curve, shapely arms, elegant neck,\nrealistic yet anime-inspired body proportions,height around 165cm,\nwhite dress shirt, glossy slightly,sleeves casually rolled up to elbows,\ntop buttons undone, teal necktie, loosely tied, natural drape,\nshort pleated skirt, (beige and brown plaid pattern), uniform style, folded waistband,\nthick fabric with sharp pleats, natural shadows, realistic light reflection,\nschool uniform inspired but casually worn,\n,on the train, train interior, front view of front seat,(looking away:1.4) ,\n(sitting:1.3),(skirt:1.3), show off panties, light blue panties,\nasakura toru, <lora:Asakura_Toru:1.2>', 'bad anatomy, poorly drawn face, asymmetrical eyes, extra hair strands, blurry face, lowres, jpeg artifacts,\nwrong hair color, wrong hairstyle, deformed, monochrome, sketch, photo\n', [], 1, 1, 5, 1056, 904, True, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', ['VAE: sdxl_vae.safetensors'], 0, 27, 'Euler a', 'Karras', False, '', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x00000142C4DFBC40>, ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, None, None, False, None, None, False, None, None, False, 50) {}
    Traceback (most recent call last):
      File ""D:\sd_directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""D:\sd_directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""D:\sd_directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""D:\sd_directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""D:\sd_directml\extensions\sd-webui-controlnet\scripts\batch_hijack.py"", line 59, in processing_process_images_hijack
        return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)
      File ""D:\sd_directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1457, in sample
        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)
      File ""D:\sd_directml\modules\processing.py"", line 1549, in sample_hr_pass
        samples = self.sampler.sample_img2img(self, samples, noise, self.hr_c, self.hr_uc, steps=self.hr_second_pass_steps or self.steps, image_conditioning=image_conditioning)
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""D:\sd_directml\modules\sd_samplers_kdiffusion.py"", line 187, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""D:\sd_directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 145, in sample_euler_ancestral
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_samplers_cfg_denoiser.py"", line 268, in forward
        x_out[a:b] = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""D:\sd_directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""D:\sd_directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1538, in _call_impl
        result = forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 100, in forward
        x = layer(x, context)
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 627, in forward
        x = block(x, context=context[i])
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 459, in forward
        return checkpoint(
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""D:\sd_directml\repositories\generative-models\sgm\modules\attention.py"", line 467, in _forward
        self.attn1(
      File ""D:\sd_directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""D:\sd_directml\modules\sd_hijack_optimizations.py"", line 547, in scaled_dot_product_attention_forward
        hidden_states = torch.nn.functional.scaled_dot_product_attention(
    RuntimeError

---
```

### Additional information

Operating System: Windows 11 Insider Preview (Build 26100). I am aware this is a pre-release build and might be a contributing factor to the instability.

GPU Driver: Intel Graphics Driver version 32.0.101.6913. I regularly update my drivers to the latest available.

Problem Summary: The issue consistently occurs during the Highres. fix step of image generation (specifically with SDXL models), leading to a RuntimeError. This happens when upscaling with a Denoising strength of 0.7 or higher, even at relatively low base resolutions 

VRAM Management: I have confirmed that the ""VRAM usage polls per second"" setting was at 8 and will change it to 0 as suggested.

Commandline Args: I've identified that my webui-user.bat file contains duplicate COMMANDLINE_ARGS entries and will correct this.

PyTorch-DirectML Version: My torch-directml version is 0.2.0.dev230426, which seems to be an older development version. I plan to attempt to update it.

Extensions: While the provided log was generated with extensions active, the issue has also persisted when --disable-all-extensions was enabled (I will re-test if needed).

System RAM: My system has 16GB of RAM, with approximately 12GB typically in use before starting the WebUI. I make an effort to close other applications to free up RAM during image generation.",2025-07-13T02:48:38Z,RUTO1920,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17060
auto1111_webui,issue,17056,[Bug]: Fails to self-correct after failing to create Python venv,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh script fails to activate the Python virtual environment, reporting ""ERROR: Cannot activate python venv, aborting..."". This often occurs after an initial failure due to a missing dependency like python3.10-venv. Even after installing the dependency, subsequent attempts fail.


This happens because an initial run, without the necessary python3.10-venv or if interrupted, can create an incomplete or corrupted venv directory. The webui.sh script's logic checks for an existing venv directory. If it finds one, it doesn't attempt to recreate it, assuming it's valid. However, if this existing venv is corrupted (e.g., missing the activate script), the script then fails to find the activate script, leading to the ""Cannot activate python venv, aborting..."" error. This creates a persistent loop where the script never fixes the broken environment.

Resolution:

Manually remove the corrupted venv directory. This forces webui.sh to treat it as a fresh run and recreate the virtual environment correctly.

Steps to resolve:


1. Ensure all necessary system dependencies (e.g., python3.10-venv) are installed.
2. Navigate to the root directory of the stable-diffusion-webui project.
3. Remove the existing virtual environment directory:

1     rm -rf venv

4. Run the webui.sh script again. It should now successfully create and activate the virtual environment.

### Steps to reproduce the problem

./webui.sh

### What should have happened?

It should check if you have the ability to install a venv before creating the directory, install the dependency rather than failing, and remove a corrupted one if it fails to activate.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-07-09-04-13.json](https://github.com/user-attachments/files/21134594/sysinfo-2025-07-09-04-13.json)

### Console logs

```Shell
$ ./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on <redacted> user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
ERROR: Cannot activate python venv, aborting...
################################################################
$
```

### Additional information

This is first run without Python 3.10-venv installed. After installing, it still doesn't work because of the now broken, existing, venv. The script tells you to install the dependency, but doesn't clean up the failed creation, and then fails to start, because the venv is broken.",2025-07-09T04:21:15Z,Mechputer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17056
auto1111_webui,comment,17056,,"I am confused.

How did you get broken venv if you did not have python3-venv installed?

If you do not have `python3-venv` installed, you should see this message: `ERROR: python3-venv is not installed, aborting...` before even git clone was executed.

If you have `python3-venv` installed, after cloning the repo, script will create venv folder if it does not exist.

What you describe can only happen if empty venv folder was manually created, or if script was manually aborted during creation of a venv folder. In any other scenario, this should not happen.

I might do some minor improvements when I find some time.

Easiest would be to delete venv if it cannot be activated, before printing this message: `ERROR: Cannot activate python venv, aborting...` After next launch it will be recreated.

To be honest, if this was my repo I would rewrite the whole scipt from scratch. But, since I am just a user who contribute some minor patches from time to time, I will try to keep my changes to minimum.",2025-08-15T20:55:57Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17056#issuecomment-3192732716
auto1111_webui,issue,17054,[Bug]: AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize',"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

when trying to generate X/Y/Z plot at the end I get AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'

### Steps to reproduce the problem

I start generation with X/Y/Z plot enabled with several checkpoints

### What should have happened?

--

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-89-g2174ce5a"",
    ""Commit"": ""2174ce5afea90ca489d222f539988dcef59f1027"",
    ""Git status"": ""On branch dev\nYour branch is up to date with 'origin/dev'.\n\nChanges not staged for commit:\n  (use \""git add/rm <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tdeleted:    models/Stable-diffusion/Put Stable Diffusion checkpoints here.txt\n\tmodified:   modules/images.py\n\tmodified:   webui-user.bat\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\tconfigs/anything_v3.yaml\n\tconfigs/v1-inference_clip_skip_2.yaml\n\tconfigs/v1-inference_clip_skip_2_fp16.yaml\n\tconfigs/v1-inference_fp16.yaml\n\tconfigs/v2-inference-v.yaml\n\tconfigs/v2-inference-v_fp32.yaml\n\tconfigs/v2-inference.yaml\n\tconfigs/v2-inference_fp32.yaml\n\tconfigs/v2-inpainting-inference.yaml\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Data path"": ""C:\\ai_web\\sd.webui\\webui"",
    ""Extensions dir"": ""C:\\ai_web\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""e650cac89c923089b0558a9bf4646232f85a6b848bc8ca6abf0d011d6fd0e96d"",
    ""Commandline"": [
        ""launch.py"",
        ""--theme"",
        ""dark"",
        ""--autolaunch""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0+cu128"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""ĞœĞ°Ğ¹ĞºÑ€Ğ¾ÑĞ¾Ñ„Ñ‚ Windows 10 Pro (10.0.19045 64-Ñ€Ğ°Ğ·Ñ€ÑĞ´Ğ½Ğ°Ñ)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": ""12.9.86\r"",
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""576.80"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5060 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.4"",
            ""onnxruntime-gpu==1.22.0"",
            ""open-clip-torch==2.20.0"",
            ""optree==0.16.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.3"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": ""garbage_collection_threshold:0.9,max_split_size_mb:768"",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz"",
            ""Manufacturer: GenuineIntel"",
            ""Family: 179"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 2401"",
            ""MaxClockSpeed: 2401"",
            ""L2CacheSize: 3584"",
            ""L2CacheSpeed: None"",
            ""Revision: 20225""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in VAE. This could be because there's not enough precision to represent the picture. Try adding --no-half-vae commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\processing.py, line 637, decode_latent_batch"",
                    ""devices.test_for_nans(sample, \""vae\"")""
                ],
                [
                    ""C:\\ai_web\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 79 Stepping 1, GenuineIntel"",
        ""count logical"": 28,
        ""count physical"": 14
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""25GB"",
        ""free"": ""39GB""
    },
    ""Extensions"": [
        {
            ""name"": ""stable-diffusion-webui-wd14-tagger"",
            ""path"": ""C:\\ai_web\\sd.webui\\webui\\extensions\\stable-diffusion-webui-wd14-tagger"",
            ""commit"": ""e72d984bdbed832ba83e2a443238c3851b9088ae"",
            ""branch"": ""master"",
            ""remote"": ""https://github.com/picobyte/stable-diffusion-webui-wd14-tagger.git""
        }
    ],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""COMMANDLINE_ARGS"": ""--theme dark --autolaunch "",
        ""GRADIO_ANALYTICS_ENABLED"": ""False"",
        ""XFORMERS_PACKAGE"": ""xformers==0.0.30.dev1005""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]"",
        ""sd_checkpoint_hash"": ""9278fc3affba7a41c9a17c29795ae9cb9d5a7f601af22c2817039de5323e901f"",
        ""outdir_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_txt2img_samples"": ""H:\\ai_created_my\\outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""H:\\ai_created_my\\outputs\\img2img-images"",
        ""outdir_extras_samples"": ""H:\\ai_created_my\\outputs\\extras-images"",
        ""outdir_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_txt2img_grids"": ""H:\\ai_created_my\\outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""H:\\ai_created_my\\outputs\\img2img-grids"",
        ""outdir_save"": ""H:\\ai_created_my\\log\\images"",
        ""outdir_init_images"": ""H:\\ai_created_my\\outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""textual_inversion_image_embedding_data_cache"": false,
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""sub-quadratic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 31337,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 2,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""webp"",
        ""show_progress_grid"": false,
        ""show_progress_every_n_steps"": 4,
        ""show_progress_type"": ""TAESD"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": true,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint"",
            ""CLIP_stop_at_last_layers"",
            ""sd_vae"",
            ""face_restoration"",
            ""interrogate_deepbooru_score_threshold""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""concurrent_git_fetch_limit"": 16,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.19,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": ""censored, yaoi, futa, mosaic censoring, censoring, pubic hair, ugly, x-ray ,furry,, 2boys, 3boys, ugly man, bar censor, animal ears, fat man, food,"",
        ""upscaler_for_img2img"": ""R-ESRGAN 4x+"",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none"",
        ""tagger_out_filename_fmt"": ""[name].[output_extension]"",
        ""tagger_count_threshold"": 100.0,
        ""tagger_batch_recursive"": true,
        ""tagger_auto_serde_json"": true,
        ""tagger_store_images"": false,
        ""tagger_weighted_tags_files"": false,
        ""tagger_verbose"": false,
        ""tagger_repl_us"": true,
        ""tagger_repl_us_excl"": ""0_0, (o)_(o), +_+, +_-, ._., <o>_<o>, <|>_<|>, =_=, >_<, 3_3, 6_9, >_o, @_@, ^_^, o_o, u_u, x_x, |_|, ||_||"",
        ""tagger_escape"": false,
        ""tagger_batch_size"": 1024,
        ""tagger_hf_cache_dir"": ""C:\\ai_web\\sd.webui\\webui\\models\\interrogators"",
        ""prioritized_callbacks_ui_tabs"": []
    },
    ""Startup"": {
        ""total"": 1.3822298049926758,
        ""records"": {
            ""app reload callback"": 0.0,
            ""scripts unloaded callback"": 0.0,
            ""set samplers"": 0.0,
            ""list extensions"": 0.003998756408691406,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.015995025634765625,
            ""list localizations"": 0.0019996166229248047,
            ""load scripts/custom_code.py"": 0.006997108459472656,
            ""load scripts/img2imgalt.py"": 0.0009996891021728516,
            ""load scripts/loopback.py"": 0.0,
            ""load scripts/outpainting_mk_2.py"": 0.0009999275207519531,
            ""load scripts/poor_mans_outpainting.py"": 0.0,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0010001659393310547,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009989738464355469,
            ""load scripts/xyz_grid.py"": 0.00099945068359375,
            ""load scripts/ldsr_model.py"": 0.06201457977294922,
            ""load scripts/lora_script.py"": 0.23192191123962402,
            ""load scripts/scunet_model.py"": 0.034992218017578125,
            ""load scripts/swinir_model.py"": 0.03499341011047363,
            ""load scripts/hotkey_config.py"": 0.0,
            ""load scripts/extra_options_section.py"": 0.0009694099426269531,
            ""load scripts/hypertile_script.py"": 0.07700014114379883,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0010044574737548828,
            ""load scripts/postprocessing_caption.py"": 0.0,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0009696483612060547,
            ""load scripts/postprocessing_focal_crop.py"": 0.0,
            ""load scripts/postprocessing_split_oversized.py"": 0.001026153564453125,
            ""load scripts/soft_inpainting.py"": 0.000997781753540039,
            ""load scripts/tagger.py"": 0.11196684837341309,
            ""load scripts/comments.py"": 0.038991689682006836,
            ""load scripts/refiner.py"": 0.0010004043579101562,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.000997304916381836,
            ""load scripts"": 0.6118409633636475,
            ""load upscalers"": 0.002003192901611328,
            ""refresh VAE"": 0.001993894577026367,
            ""refresh textual inversion templates"": 0.0010035037994384766,
            ""scripts list_optimizers"": 0.0019981861114501953,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009989738464355469,
            ""initialize extra networks"": 0.0040018558502197266,
            ""scripts before_ui_callback"": 0.0019953250885009766,
            ""create ui"": 0.5678255558013916,
            ""gradio launch"": 0.15555405616760254,
            ""add APIs"": 0.0070226192474365234,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback/tagger.py"": 0.003998279571533203,
            ""app_started_callback"": 0.003998279571533203
        }
    },
    ""Packages"": [
        ""absl-py==2.3.1"",
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.12.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""astunparse==1.6.3"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.6.15"",
        ""charset-normalizer==3.4.2"",
        ""clean-fid==0.1.35"",
        ""click==8.2.1"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deepdanbooru==1.0.4"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.3.0"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.6.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.58.4"",
        ""frozenlist==1.7.0"",
        ""fsspec==2025.5.1"",
        ""ftfy==6.3.1"",
        ""gast==0.6.0"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""google-pasta==0.2.0"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""grpcio==1.73.1"",
        ""h11==0.12.0"",
        ""h5py==3.14.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.33.0"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.24.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""keras==3.10.0"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""libclang==18.1.1"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Markdown==3.8.2"",
        ""markdown-it-py==3.0.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.3"",
        ""mdurl==0.1.2"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.5.0"",
        ""namex==0.1.0"",
        ""narwhals==1.43.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.4"",
        ""omegaconf==2.2.3"",
        ""onnxruntime-gpu==1.22.0"",
        ""open-clip-torch==2.20.0"",
        ""opencv-contrib-python==4.11.0.86"",
        ""opencv-python==4.11.0.86"",
        ""opencv-python-headless==4.11.0.86"",
        ""opt_einsum==3.4.0"",
        ""optree==0.16.0"",
        ""orjson==3.10.18"",
        ""packaging==25.0"",
        ""pandas==2.3.0"",
        ""piexif==1.1.3"",
        ""pillow==10.4.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1.1"",
        ""propcache==0.3.2"",
        ""protobuf==5.29.5"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""Pygments==2.19.2"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.4"",
        ""resize-right==0.0.2"",
        ""rich==14.0.0"",
        ""rpds-py==0.25.1"",
        ""safetensors==0.4.5"",
        ""scikit-image==0.25.2"",
        ""scipy==1.15.3"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.14.0"",
        ""tensorboard==2.19.0"",
        ""tensorboard-data-server==0.7.2"",
        ""tensorflow==2.19.0"",
        ""tensorflow-io-gcs-filesystem==0.31.0"",
        ""termcolor==3.1.0"",
        ""tifffile==2025.5.10"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.3"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.14.0"",
        ""tzdata==2025.2"",
        ""urllib3==2.5.0"",
        ""uvicorn==0.34.3"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""Werkzeug==3.1.3"",
        ""wheel==0.45.1"",
        ""wrapt==1.17.2"",
        ""yarl==1.20.1""
    ]
}

### Console logs

```Shell
*** Error completing request
*** Arguments: ('task(ja4jazzpwfefl4b)', <gradio.routes.Request object at 0x000001D11E24D810>,*//*, [], 1, 1, 7, 1024, 1384, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 3, 30, 'Euler a', 'Automatic', False, '', 0.8, 2144633961, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 0, '', [], 11, '', ['NAI_novaAnimeXL_ilV5b.safetensors [bb9b24719f]', 'NAI_oneObsessionNoob_v30NoobVpredrouwei.safetensors [9278fc3aff]', 'NoobAI-XL-v1.1.safetensors [6681e8e4b1]', 'nova3DCGXL_illustriousV10.safetensors [6316d41b68]', 'PONY_animusmixV10_v10.safetensors [a2ba3c02a1]', 'PONY_SDXL_autismmixSDXL_autismmixPony.safetensors [821aa5537f]', 'waiNsfwBranchRouwei_ePred1_0.7e.safetensors [dd25aa81fe]', 'waiNSFWIllustrious_v140.safetensors [bdb59bac77]'], 0, '', [], True, False, False, False, False, False, False, 0, False, True) {}
    Traceback (most recent call last):
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\ai_web\sd.webui\webui\modules\txt2img.py"", line 106, in txt2img
        processed = modules.scripts.scripts_txt2img.run(p, *p.script_args)
      File ""C:\ai_web\sd.webui\webui\modules\scripts.py"", line 780, in run
        processed = script.run(p, *script_args)
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 773, in run
        processed = draw_xyz_grid(
      File ""C:\ai_web\sd.webui\webui\scripts\xyz_grid.py"", line 382, in draw_xyz_grid
        grid = images.draw_grid_annotations(grid, grid_max_w, grid_max_h, hor_texts, ver_texts, margin_size)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 228, in draw_grid_annotations
        draw_texts(d, x, y, hor_texts[col], fnt, fontsize)
      File ""C:\ai_web\sd.webui\webui\modules\images.py"", line 171, in draw_texts
        while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
    AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize'
```

### Additional information

we need to replace multiline_textsize with the new textbbox method.
Steps:
Open the file:
\stable-diffusion-webui\modules\images.py
Find the line (around line 171):
while drawing.multiline_textsize(line.text, font=fnt)[0] > line.allowed_width and fontsize > 0:
Replace it with:
while drawing.textbbox((0, 0), line.text, font=fnt)[2] > line.allowed_width and fontsize > 0:
Save the file and restart WebUI.",2025-07-08T13:19:09Z,MSCAs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054
auto1111_webui,comment,17054,,"i ask deepseek about it. And he tell me that this problem is related to ""The error AttributeError: 'ImageDraw' object has no attribute 'multiline_textsize' occurs because the multiline_textsize method has been removed in the new version of the Pillow Library (PIL).""",2025-07-08T13:21:52Z,MSCAs,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054#issuecomment-3048953294
auto1111_webui,comment,17054,,"You may try to use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which is currently well-maintained and has built-in support for both OpenVINO and IPEX.",2025-07-10T06:45:56Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17054#issuecomment-3055864510
auto1111_webui,issue,17051,[Bug]: ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello,
I'm try to install automatic1111 on my arch linux, I followed the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs but when I try to run the final script I've the following error
`./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
`
Can someone help me to figure out what to do? Looking in the open issue I'm not able to find someone that have the invalid argument as error, what should I check? If needed rocm is on version 6.4.1-1 Thanks!

### Steps to reproduce the problem

Follow the guide at https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs and run with ./webui.sh --skip-torch-cuda-test

### What should have happened?

Webui should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

the  --dump-sysinfo return the same error as mentioned 
    ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument


### Console logs

```Shell
./webui.sh --skip-torch-cuda-test

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on [] user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /[]/[]/[]/stable-diffusion-webui/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
Python 3.10.18 (main, Jul  5 2025, 09:14:32) [GCC 15.1.1 20250425]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test
Traceback (most recent call last):
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bestbug/Documents/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/home/bestbug/Documents/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/home/bestbug/Documents/stable-diffusion-webui/modules/initialize.py"", line 15, in imports
    import torch  # noqa: F401
  File ""/home/bestbug/Documents/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/__init__.py"", line 239, in <module>
    from torch._C import *  # noqa: F403
ImportError: libamdhip64.so: cannot enable executable stack as shared object requires: Invalid argument
```

### Additional information

_No response_",2025-07-05T10:12:28Z,bestbug456,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051
auto1111_webui,comment,17051,,"I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.",2025-07-12T04:07:39Z,dlm21,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3064631280
auto1111_webui,comment,17051,,"> I fixed this by using `patchelf --clear-execstack libamdhip64.so` (and on libhiprtc.so too), after that it loaded and worked. hth.

This worked great. For anyone else running into this issue later: you can run the following one liner from the projects directory to fix the problem.
```bash
find . \( -name ""libhiprtc.so"" -o -name ""libamdhip64.so"" \) -exec patchelf --clear-execstack {} \;
```",2025-08-14T05:52:48Z,Lethja,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3187055652
auto1111_webui,comment,17051,,It's such a great auto-setup script...,2025-09-09T00:29:05Z,Hatsune-Cthulhu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17051#issuecomment-3268444547
auto1111_webui,issue,17047,"[Bug]: Intel Arc GPU (XPU) not detected with PyTorch builds integrating XPU support (e.g., 2.7.1+XPU)","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When attempting to run Stable Diffusion WebUI (Automatic1111) on a Linux system equipped with an Intel Arc A770 GPU and a PyTorch version that natively integrates XPU (Intel GPU) support (such as PyTorch 2.7.1+XPU), the WebUI consistently fails to detect and utilize the Intel Arc GPU. Instead, it defaults to performing image generation on the CPU, even when the `--use-ipex` command-line argument is explicitly provided in `webui-user.sh`.

### Steps to reproduce the problem

1. **System Setup:** Configure a Linux system with an Intel Arc A770 GPU.
2. **Driver Installation:** Ensure the latest Intel GPU drivers for Linux are installed and correctly loaded (e.g., i915 kernel module, level-zero, firmware, etc.).
3. **PyTorch Installation:** Install a PyTorch build with integrated XPU support (e.g., PyTorch 2.7.1+XPU). A relevant community guide for this setup can be found [here](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821).
- **Verification:** Confirm that PyTorch correctly recognizes the XPU by executing `python -c ""import torch; print(torch.xpu.is_available());""` within your PyTorch environment. This command should return `True`.
4. **Stable Diffusion WebUI Setup:** Clone and set up the Automatic1111 Stable Diffusion WebUI.
5. **Configure WebUI Launch:** In your `webui-user.sh` file, ensure `COMMANDLINE_ARGS` includes `--use-ipex`. Example: `export COMMANDLINE_ARGS=""--use-ipex --precision full --no-half ""`.
6. **Launch WebUI:** Start Stable Diffusion WebUI using `./webui.sh`.
7. **Observe Behavior:** Initiate an image generation task. The WebUI will incorrectly utilize the CPU instead of the Intel Arc GPU (XPU).

### What should have happened?

When the `--use-ipex` command-line argument is provided and a PyTorch build with native XPU support (like `PyTorch 2.7.1+XPU`) is correctly installed and `torch.xpu.is_available()` returns `True`, Stable Diffusion WebUI should correctly detect and automatically utilize the Intel Arc GPU (XPU) for accelerated image generation.

### What browsers do you use to access the UI ?

Other

### Sysinfo

not applicable but anyway

[sysinfo-2025-06-28-05-33.json](https://github.com/user-attachments/files/20958988/sysinfo-2025-06-28-05-33.json)

### Console logs

```Shell
not applicable
```

### Additional information

- **GPU Model:** Intel Arc A770
- **Operating System:** Linux (tested on PikaOS; issue likely affects other Linux distributions as well)
- **PyTorch Version:** 2.7.1+XPU (XPU support is integrated into the core PyTorch package, making a separate `intel_extension_for_pytorch` module unnecessary for functionality).

**Root Cause Analysis:**
- The problem lies in the XPU device detection logic within the Stable Diffusion WebUI, specifically in files like `modules/xpu_specific.py`.
- The relevant code snippet for XPU detection (`has_ipex variable`, which translates to `xpu_specific.has_xpu` in `modules/devices.py`) relies on a `try...except` block attempting to import `intel_extension_for_pytorch`.
- Since `PyTorch 2.7.1+XPU` integrates the functionality of `intel_extension_for_pytorch` directly, the standalone `intel_extension_for_pytorch` module is often not installed separately (and is not needed for `torch.xpu.is_available()` to be true).
- Consequently, the `import intel_extension_for_pytorch` call fails within `xpu_specific.py`, causing the detection flag (`has_ipex` / `xpu_specific.has_xpu`) to remain `False`.
- This leads `modules/devices.py`'s `get_optimal_device_name()` function to incorrectly fall back to the CPU, despite the GPU being fully functional and available via `torch.xpu`.

**Temporary Workaround (User's Solution):**
A temporary workaround that resolves the issue is to directly force the XPU backend by manually changing the last line within the `def get_optimal_device_name():` function in `modules/devices.py` from `return ""cpu""` to `return ""xpu""`. This bypasses the flawed detection logic, and the WebUI then successfully uses the Intel Arc GPU.

**Proposed Clean Solution (for `xpu_specific.py`):**
To provide a more robust and future-proof detection mechanism, the XPU availability check in `xpu_specific.py` should be modified to directly query `torch.xpu.is_available()`. This would eliminate the dependency on the presence of the separate `intel_extension_for_pytorch` module for detection.
Example modification within `xpu_specific.py`:

```python
import torch
# ... other necessary imports ...

has_xpu_device_natively_available = False
try:
    if hasattr(torch, 'xpu') and torch.xpu.is_available():
        has_xpu_device_natively_available = True
except Exception:
    # Log error if needed, but ensure has_xpu_device_natively_available remains False
    pass

# This variable should be the one accessed by modules/devices.py
# If it was originally named 'has_ipex', retain that name for compatibility.
has_ipex = has_xpu_device_natively_available

# Ensure get_xpu_device_string() also uses torch.xpu methods directly if present.
```",2025-06-28T05:35:58Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047
auto1111_webui,comment,17047,,"Hi all
pls see also here: 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/14461
may be I found a workaround on this, but is in testing actually.
.. see my comment @end.

Regards,
Roger",2025-06-30T08:57:23Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3018345308
auto1111_webui,comment,17047,,"or also in webui-user.sh for simpler method, to be tested:
try that:
# install command for torch
#export TORCH_COMMAND=""pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113""
.. and set u'r appropriate version here for INTEL?
Regards,
Roger",2025-06-30T09:07:41Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3018378315
auto1111_webui,comment,17047,,"I believe my issue in #17047 is slightly different. PyTorch itself correctly detects the XPU (as `torch.xpu.is_available()` returns `True`). The core problem is that the Stable Diffusion WebUI application fails to detect the XPU and falls back to CPU. This happens because it still attempts to import `intel_extension_for_pytorch`, which is no longer separately necessary with newer PyTorch versions (like 2.7.1+XPU) that integrate this functionality directly.

My proposed solution aims to update the detection logic in `modules/xpu_specific.py` to directly query `torch.xpu.is_available()`, removing the dependency on the separate extension module.

Hope this clarifies the distinction. Thanks!",2025-06-30T14:47:42Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3019456144
auto1111_webui,comment,17047,,"@DrThodt2021 
Well, ok, sorry for this misunderstanding.
So, just to get u right, since I still always have to fiddle around with the correct packages on Torch and Pytorch4ARC GPU:
Is it right that u say that latest packages from python on torch will suffice?
And that those packages from Intel's repos are still no longer necessary?
Thanks for clearing up to me.
Regards,
Roger",2025-06-30T16:13:11Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3019811071
auto1111_webui,comment,17047,,"I don't know if 2.7.1+XPU is the latest package; I just followed [this guide](https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821) for installation. After that, it should **technically** work, but it doesn't, because of how Automatic1111 tries to recognize the XPU capability of the hardware.

As described, Automatic checks if `--use-ipex` is set **AND** if `intel_extension_for_pytorch` is installed. With PyTorch 2.7.1+XPU already installed and working, the **additional** `Intel_extension_for_pytorch module` is not needed, which causes this check to fail. Consequently, Automatic1111 uses the CPU instead of the GPU.

I forced Automatic1111 to use the GPU by changing a default value in `modules/devices.py`. While this workaround functions in my setup, it's not a safe or proper long-term solution. That's why I provided a concept for a better mechanism to recognize the XPU capability.",2025-06-30T19:44:57Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3020487996
auto1111_webui,comment,17047,,"@DrThodt2021:
Hmm, u'r right; I just now ran in to the same issue like u did, BUT trying to setup SDNext with '--use-ipex'. Also installed my own venv, not via using webui.sh, than:
'pip install torch==2.7.1+xpu torchvision==0.22.1+xpu torchaudio==2.7.1+xpu intel-cmplr-lib-rt intel-cmplr-lib-ur intel-cmplr-lic-rt intel-sycl-rt ' like in u'r link,
and when starting/running/first booting with 'python launch.py --debug --use-ipex' I get:
RuntimeError: No XPU devices are available.
So, I will try to also noe additionally to install Intel's extensions for pytorch an report back.
Regards,
Roger",2025-07-01T16:03:42Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3024642967
auto1111_webui,comment,17047,,"BTW: may u tell me which entry u added in modules/devices.py?
Roger",2025-07-01T16:04:25Z,RogerWeihrauch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3024645570
auto1111_webui,comment,17047,,"Sure. Search for `def get_optimal_device_name():` (approx. at line 50):

```Python
 if torch.cuda.is_available():
        return get_cuda_device_string()

    if has_mps():
        return ""mps""

    if has_xpu():
        return xpu_specific.get_xpu_device_string()

    if npu_specific.has_npu:
        return npu_specific.get_npu_device_string()

    return ""cpu""
```

The last line `return ""cpu""` determine the ""default"" state, which ist used if the above checks (cuda, mps, xpu, npu) fails. I just changed this to `return ""xpu""`. This forces Automatic1111 to use xpu as default (even if the check before failed) and will probably fail if you don't have a propper set up XPU device. So this may work, but it's not recommended, exept you're absolutly sure you have a propper set up XPU GPU.",2025-07-01T19:11:35Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3025217693
auto1111_webui,comment,17047,,You may try [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) which is currently maintained and support OpenVINO and IPEX im my opinion. ,2025-07-10T06:05:29Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3055723298
auto1111_webui,comment,17047,,"I would agree, if you can explan me how to overcome the 75 token limit in SD.Next",2025-07-10T14:35:25Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17047#issuecomment-3057714722
auto1111_webui,issue,17046,[Bug]: error code 128,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

new to install, when running webui-user.bat, this happened..

### Steps to reproduce the problem

open webui-user.bat

### What should have happened?

run ui

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

is this necessary to this problem? tell me if it is i'll re-edit that

### Console logs

```Shell
venv ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.10.1
Commit hash: <none>
Couldn't determine assets's hash: 6f7db241d2f8ba7457bac5ca9753331f0c266917, attempting autofix...
Fetching all contents for assets
fatal: detected dubious ownership in repository at 'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets'
'D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets' is on a file system that does not record ownership
To add an exception for this directory, call:

        git config --global --add safe.directory D:/sdui/stable-diffusion-webui-master/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets
Traceback (most recent call last):
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 411, in prepare_environment
    git_clone(assets_repo, repo_dir('stable-diffusion-webui-assets'), ""assets"", assets_commit_hash)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 178, in git_clone
    current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 166, in run_git
    git_fix_workspace(dir, name)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 153, in git_fix_workspace
    run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)
  File ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't fetch assets.
Command: ""git"" -C ""D:\sdui\stable-diffusion-webui-master\stable-diffusion-webui-master\repositories\stable-diffusion-webui-assets"" fetch --refetch --no-auto-gc
Error code: 128
è¯·æŒ‰ä»»æ„é”®ç»§ç»­. . .
```

### Additional information

i don't actually know what's going on, i have seen others reported about error code 128 and still not fixed yet...",2025-06-27T22:33:06Z,emai24volts,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17046
auto1111_webui,comment,17046,,"to reinstall using windows-method-1 on teh wiki
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1",2025-06-27T23:06:05Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17046#issuecomment-3014589842
auto1111_webui,issue,17041,[Bug]: Cannot do inpainting,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Nothing happens.

### Steps to reproduce the problem

Try to do inpainting on blackwell gpu (setup with torch 2.7.0+cu128 and xformers 0.0.30)

### What should have happened?

Inpainting should work.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-24-02-04.json](https://github.com/user-attachments/files/20874601/sysinfo-2025-06-24-02-04.json)

### Console logs

```Shell
Traceback (most recent call last):â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:13<00:00,  2.14it/s]
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 270, in preprocess
    assert isinstance(x, dict)
           ^^^^^^^^^^^^^^^^^^^
AssertionError
```

Sometimes I get this instead:

```
Traceback (most recent call last):
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1429, in process_api
    inputs = self.preprocess_data(fn_index, inputs, state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/blocks.py"", line 1239, in preprocess_data
    processed_input.append(block.preprocess(inputs[i]))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/components/image.py"", line 290, in preprocess
    mask_im = processing_utils.decode_base64_to_image(mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 58, in decode_base64_to_image
    image_encoded = extract_base64_data(encoding)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/sdwebui/venv/lib/python3.11/site-packages/gradio/processing_utils.py"", line 49, in extract_base64_data
    return x.rsplit("","", 1)[-1]
           ^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'rsplit'
```

### Additional information

_No response_",2025-06-24T02:04:40Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041
auto1111_webui,comment,17041,,"coming from we believe that this has to do with your 5080 GPU
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussioncomment-13563587

but looking at the logs you provided it does not seem to me that this has anything to do with pytorch or your GPU 5080

from what I can tell for some reason the user interface / webpage is broken

I cannot be certain this case but this seems similar to what would happen sometimes when you have multiple tabs of web UI (webpage) open in browser, then you install / update / enable / disable an extension, after clicking apply to applying and restarting the server, you then use another webui tab that was open before the restart to generated an image, then you might see similar error

this is because when changing extension configurations it might also cause some UI elements to change, and when you try to communicate on our old web page that sends the old configurations to the server things don't line up properly and cause things to break

> I remember some one say that this might also happen just by restarting the server but me personally have not experienced this

---

I guess by this point you have already tried restarting your server and reloading the web page
if restart and reload didn't fix it then I would suggest a clean installation
> If you do so also I recommend you use `git` and switch to `dev` branch
",2025-06-25T12:59:46Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041#issuecomment-3004684998
auto1111_webui,comment,17041,,"> I guess by this point you have already tried restarting your server and reloading the web page if restart and reload didn't fix it then I would suggest a clean installation
> 
> > If you do so also I recommend you use `git` and switch to `dev` branch

Yes, and I already tried doing a clean installation, it already kinda is a clean installation; but I have not tried the dev branch. If you say it seems the webui is broken maybe using another browser would work ğŸ¤” 

Yup, I didn't have another browser on hand, but I tried running it in electron, and it worked fine there.

My browser is ungoogled chromium, installed from the cachyos official package.

I believe the binary for my current version comes from here: https://github.com/ungoogled-software/ungoogled-chromium/archive/137.0.7151.119-1.tar.gz

seems like it's happening with default settings.",2025-06-25T22:14:44Z,Rabcor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17041#issuecomment-3006396191
auto1111_webui,issue,17037,[Bug]: å›¾åƒç¼©æ”¾åä½ç½®å‡ºé”™,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

ä½¿ç”¨ shift å’Œ wheel æ”¾å¤§ img2img canvusï¼Œå½“å›¾åƒå†æ¬¡å‡ºç°æ—¶ä¸åœ¨æ­£ç¡®çš„ä½ç½®ã€‚åªèƒ½ä½¿ç”¨ CTRL+æ»šè½®è¿›è¡Œ Edge Web æµè§ˆå™¨é¡µé¢ç¼©æ”¾ï¼Œå°†å…¶æ”¾å›æ­£ç¡®çš„ä½ç½®ã€‚å¤§éƒ¨åˆ†æ—¶é—´éƒ½æœ‰æ•ˆï¼Œä½†æœ‰æ—¶å‡ºé”™ï¼Œä¸å¾—ä¸å†åšä¸€æ¬¡

### Steps to reproduce the problem

å°†å›¾ç‰‡å¯¼å…¥ img2imgï¼Œä½¿ç”¨ Shift å’Œé¼ æ ‡æ»šè½®æ”¾å¤§ï¼Œç„¶åç¼©å°ï¼Œå›¾ç‰‡ä¸ä¼šå±…ä¸­ï¼Œå¦‚æœä½¿ç”¨ CRTL + é¼ æ ‡æ»šè½®ï¼Œå®ƒä¼šæ”¹å˜ Web æµè§ˆå™¨çš„ç¼©æ”¾ï¼Œæ‰èƒ½ä½¿å›¾ç‰‡æ”¾å›å®ƒåº”è¯¥åœ¨çš„ä½ç½®ã€‚ç„¶è€Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå›¾åƒæ¶ˆå¤±äº†ã€‚ä¹‹åå®ƒä»ç„¶ä¼šç”Ÿæˆï¼Œä½†ä¹‹åä¸èƒ½å†è¿›è¡Œä»»ä½•ä¿®å¤ã€‚ï¼ˆéœ€è¦å¤šæ¬¡æ“ä½œæ‰å¯èƒ½è§¦å‘æ­¤bug)

### What should have happened?

é¡µé¢ç¼©æ”¾åº”å°†å›¾åƒæ”¾å›æ­£ç¡®çš„ä½ç½®

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now

### Console logs

```Shell
Nothing in logs other than image generations I was doing
```

### Additional information

_No response_",2025-06-19T14:29:39Z,SUN-myriad,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17037
auto1111_webui,issue,17035,[Bug]: images corrupting on last step with euler / euler a,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

in txt2img when i generate an image, its fine during generation but corrupts at the last second when specifically using euler / euler a

### Steps to reproduce the problem

1. use img2img
2. select euler or euler a
3. generate

### What should have happened?

image should have output with no corruption, this was working fine yesterday. i changed nothing

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-06-18-02-40.json](https://github.com/user-attachments/files/20787614/sysinfo-2025-06-18-02-40.json)

### Console logs

```Shell
don't know how to do this, but there's no obvious errors
```

### Additional information

_No response_",2025-06-18T02:41:01Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035
auto1111_webui,comment,17035,,"![Image](https://github.com/user-attachments/assets/1c13ad36-4d29-473e-8799-4e7228e4c218)
^^ this is what i see while generating^^

![Image](https://github.com/user-attachments/assets/a2b01fb9-4336-41b4-a822-f81b1eaec4cf)
^^ this is what happens after generation is complete ^^",2025-06-18T02:41:47Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982452957
auto1111_webui,comment,17035,,"i tried restarting my computer, same problem. idk what happened, it was working fine yesterday",2025-06-18T02:48:09Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982465100
auto1111_webui,comment,17035,,"did some more testing, euler ONLY works with 25 steps, no more, no less. my friend tested different values and he has no issues. what's happening?
",2025-06-18T03:40:49Z,lands39,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-2982560712
auto1111_webui,comment,17035,,"Might be a VAE issue.  Often you'll have a good preview until the final step and then you'll get distortion.  Also, you might be able to try changing the scheduler type and fix it that way.",2025-08-10T03:25:40Z,ThatFuckingPanda,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17035#issuecomment-3172334042
auto1111_webui,issue,17032,[Bug]: Firewall issue causes SSLError when attempting to generate,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Using QBittorrent, I've installed the NAI4 model; with the models and attempting to use settings given to recreate a given image.

### Steps to reproduce the problem

No steps known.

### What should have happened?

The image should've generated.

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

[sysinfo-2025-06-13-16-53.json](https://github.com/user-attachments/files/20730124/sysinfo-2025-06-13-16-53.json)

### Console logs

```Shell
Due to Pastebin not accepting the file due to its sheer size (552 KB, 512 KB max) I have posted it to Drive.

https://drive.google.com/file/d/1Y1MR81VtIbUlljOF3gulo3CPGfJAiJjr/view?usp=sharing
```

### Additional information

This is the first run of the UI; I'm running an NVIDIA RTX 3060, I have 32 GB of RAM and a WD_BLACK SN770 1TB disk.",2025-06-13T17:00:59Z,Krmailence,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17032
auto1111_webui,issue,17031,[Bug]: Error 403 trying to install pytorch,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The webui.sh gives an error trying to install pytorch



### Steps to reproduce the problem

1. Clone the repo
2. Execute webui.sh
3. The error is there

### What should have happened?

Webui should have been installed.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I cannot install it, but I have:

ArchLinux
Python 3.10
Ryzen 7 5800X3D, RX 5700XT, 32GB RAM, 240GB NVME with 140GB of free space. 

### Console logs

```Shell
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
./webui.sh: line 258: bc: command not found
./webui.sh: line 258: [: -eq: unary operator expected
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4
fatal: No names found, cannot describe anything.
Python 3.10.18 (main, Jun 12 2025, 18:48:45) [GCC 15.1.1 20250425]
Version: f2.0.1v1.10.1-1.10.1
Commit hash: e07be6a48fc0ae1840b78d5e55ee36ab78396b30
ROCm: no agent was found
ROCm: version=None
Installing torch and torchvision
Collecting torch==2.0.0.dev20230209+rocm5.2
  ERROR: HTTP error 403 while getting https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
ERROR: Could not install requirement torch==2.0.0.dev20230209+rocm5.2 from https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl for URL https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Traceback (most recent call last):
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 54, in <module>
    main()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/launch.py"", line 42, in main
    prepare_environment()
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 543, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/jaime/stable-diffusion-webui-amdgpu-forge/modules/launch_utils.py"", line 126, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/jaime/stable-diffusion-webui-amdgpu-forge/venv/bin/python"" -m pip install https://download.pytorch.org/whl/nightly/rocm5.2/torch-2.0.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/nightly/rocm5.2/torchvision-0.15.0.dev20230209%2Brocm5.2-cp310-cp310-linux_x86_64.whl
Error code: 1
```

### Additional information

_No response_",2025-06-12T20:03:12Z,Ciberbago,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031
auto1111_webui,comment,17031,,"same error here with practically the same specs and same steps, I also reproduced this error with a stable version `v1.10.1` or cloning the `master` branch",2025-06-18T19:59:15Z,FabioNevesRezende,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-2985531510
auto1111_webui,comment,17031,,same error on OpenSuSe seems like pytorch changed the download location,2025-06-26T23:48:14Z,Exzellius,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3010694922
auto1111_webui,comment,17031,,Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url,2025-08-09T22:23:41Z,tk-1001,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3172140041
auto1111_webui,comment,17031,,"> Had same error with 5.7 rocm [this](https://www.reddit.com/r/StableDiffusion/comments/1fzcx7y/automatic1111_torch_rocm_57_is_giving_403/) reddit post fixes it by removing nightly from url

Thanks. It works.",2025-08-18T13:31:08Z,metalg0su,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17031#issuecomment-3196906315
auto1111_webui,issue,17030,[Bug]: handrefinerportable: cannot import 'setuptools.build_meta' on ControlNet install,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing ControlNet, whenever I start Stable Diffusion, the installation of handrefinerportable==2024.2.12.0 begins. However, it always fails with the following error message:

Cannot import 'setuptools.build_meta'

I have already tried reinstalling ControlNet, but the error persists. 

### Steps to reproduce the problem

1. Install ControlNet.
2. Start Stable Diffusion: run.bat
3. The installation of handrefinerportable==2024.2.12.0 begins.
4. The error occurs: Cannot import 'setuptools.build_meta'. Warning: Failed to install handrefinerportable. Some processors will not work.

### What should have happened?

The installation of handrefinerportable should complete successfully without errors.

### What browsers do you use to access the UI ?

Google Chrome, Other

### Sysinfo

[sysinfo-2025-06-12-06-50.json](https://github.com/user-attachments/files/20703595/sysinfo-2025-06-12-06-50.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Installing sd-webui-controlnet requirement: mediapipe
Installing sd-webui-controlnet requirement: changing albumentations version from None to 1.4.3
Installing sd-webui-controlnet requirement: changing controlnet_aux version from None to 0.0.9
Installing sd-webui-controlnet requirement: insightface
Installing sd-webui-controlnet requirement: handrefinerportable
Couldn't install sd-webui-controlnet requirement: handrefinerportable.
Command: ""D:\SD\system\python\python.exe"" -m pip install -U https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl --prefer-binary
Error code: 2
stdout: Collecting handrefinerportable==2024.2.12.0
  Downloading https://github.com/huchenlei/HandRefinerPortable/releases/download/v1.0.1/handrefinerportable-2024.2.12.0-py2.py3-none-any.whl (13.1 MB)
     -------------------------------------- 13.1/13.1 MB 448.4 kB/s eta 0:00:00
Requirement already satisfied: mediapipe in d:\sd\system\python\lib\site-packages (from handrefinerportable==2024.2.12.0) (0.10.21)
Collecting rtree (from handrefinerportable==2024.2.12.0)
  Using cached rtree-1.4.0-py3-none-win_amd64.whl.metadata (2.1 kB)
Collecting trimesh[easy] (from handrefinerportable==2024.2.12.0)
  Using cached trimesh-4.6.12-py3-none-any.whl.metadata (18 kB)
Requirement already satisfied: absl-py in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (2.3.0)
Requirement already satisfied: attrs>=19.1.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.3.0)
Requirement already satisfied: flatbuffers>=2.0 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (25.2.10)
Requirement already satisfied: jax in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: jaxlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.6.1)
Requirement already satisfied: matplotlib in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (3.10.3)
Requirement already satisfied: numpy<2 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (1.26.2)
Requirement already satisfied: opencv-contrib-python in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.11.0.86)
Requirement already satisfied: protobuf<5,>=4.25.3 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (4.25.8)
Requirement already satisfied: sounddevice>=0.4.4 in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.5.2)
Requirement already satisfied: sentencepiece in d:\sd\system\python\lib\site-packages (from mediapipe->handrefinerportable==2024.2.12.0) (0.2.0)
Requirement already satisfied: CFFI>=1.0 in d:\sd\system\python\lib\site-packages (from sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (1.17.1)
Requirement already satisfied: pycparser in d:\sd\system\python\lib\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->handrefinerportable==2024.2.12.0) (2.22)
Requirement already satisfied: ml_dtypes>=0.5.0 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (0.5.1)
Requirement already satisfied: opt_einsum in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (3.4.0)
Requirement already satisfied: scipy>=1.11.1 in d:\sd\system\python\lib\site-packages (from jax->mediapipe->handrefinerportable==2024.2.12.0) (1.15.3)
Requirement already satisfied: contourpy>=1.0.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.3.2)
Requirement already satisfied: cycler>=0.10 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (4.58.2)
Requirement already satisfied: kiwisolver>=1.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.4.8)
Requirement already satisfied: packaging>=20.0 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (25.0)
Requirement already satisfied: pillow>=8 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (9.5.0)
Requirement already satisfied: pyparsing>=2.3.1 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (3.2.3)
Requirement already satisfied: python-dateutil>=2.7 in d:\sd\system\python\lib\site-packages (from matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in d:\sd\system\python\lib\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe->handrefinerportable==2024.2.12.0) (1.17.0)
Collecting colorlog (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)
Collecting manifold3d>=2.3.0 (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached manifold3d-3.1.1-cp310-cp310-win_amd64.whl.metadata (18 kB)
Requirement already satisfied: charset-normalizer in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Requirement already satisfied: lxml in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (5.4.0)
Requirement already satisfied: jsonschema in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (4.24.0)
Requirement already satisfied: networkx in d:\sd\system\python\lib\site-packages (from trimesh[easy]->handrefinerportable==2024.2.12.0) (3.4.2)
Collecting svg.path (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached svg.path-6.3-py2.py3-none-any.whl.metadata (13 kB)
Collecting pycollada (from trimesh[easy]->handrefinerportable==2024.2.12.0)
  Using cached pycollada-0.9.tar.gz (109 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'

stderr: ERROR: Exception:
Traceback (most recent call last):
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 105, in _run_wrapper
    status = _inner_run()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\base_command.py"", line 96, in _inner_run
    return self.run(options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\cli\req_command.py"", line 68, in wrapper
    return func(self, options, args)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\commands\install.py"", line 387, in run
    requirement_set = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 96, in resolve
    result = self._result = resolver.resolve(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 515, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 444, in resolve
    failure_criterion = self._attempt_to_pin_criterion(name)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 211, in _attempt_to_pin_criterion
    criteria = self._get_updated_criteria(candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 202, in _get_updated_criteria
    self._add_to_criteria(criteria, requirement, parent=candidate)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\resolvers\resolution.py"", line 141, in _add_to_criteria
    if not criterion.candidates:
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\resolvelib\structs.py"", line 194, in __bool__
    return bool(self._sequence)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 163, in __bool__
    self._bool = any(self)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 147, in <genexpr>
    return (c for c in iterator if id(c) not in self._incompatible_ids)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 37, in _iter_built
    candidate = func()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 187, in _make_candidate_from_link
    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 233, in _make_base_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 306, in __init__
    super().__init__(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 159, in __init__
    self.dist = self._prepare()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 236, in _prepare
    dist = self._prepare_distribution()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 317, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 532, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 647, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\operations\prepare.py"", line 71, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 56, in prepare_distribution_metadata
    self._install_build_reqs(finder)
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 126, in _install_build_reqs
    build_reqs = self._get_build_requires_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\distributions\sdist.py"", line 103, in _get_build_requires_wheel
    return backend.get_requires_for_build_wheel()
  File ""D:\SD\system\python\lib\site-packages\pip\_internal\utils\misc.py"", line 702, in get_requires_for_build_wheel
    return super().get_requires_for_build_wheel(config_settings=cs)
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 196, in get_requires_for_build_wheel
    return self._call_hook(
  File ""D:\SD\system\python\lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py"", line 402, in _call_hook
    raise BackendUnavailable(
pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'

Warning: Failed to install handrefinerportable. Some processors will not work.
Launching Web UI with arguments:
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: D:\SD\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-06-12 11:49:26,544 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [879db523c3] from D:\SD\webui\models\Stable-diffusion\dreamshaper_8.safetensors
Creating model from config: D:\SD\webui\configs\v1-inference.yaml
D:\SD\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-06-12 11:49:27,344 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 135.6s (prepare environment: 92.3s, import torch: 22.5s, import gradio: 9.2s, setup paths: 3.2s, initialize shared: 1.0s, other imports: 1.4s, load scripts: 4.4s, create ui: 0.7s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 3.5s (create model: 0.8s, apply weights to model: 2.2s, calculate empty prompt: 0.2s).
```

### Additional information

_No response_",2025-06-12T06:51:25Z,svnsnln,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17030
auto1111_webui,comment,17030,,"Having the same issue, but with fvcore instead of handrefinerportable.

Edit: Following a tip from https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17162 and manually running the install with --no-build-isolation added to the command seems to have fixed my issue. I'm not entirely aware of any risks involved using that option, I just tried it 'blindly'.",2025-12-03T09:33:43Z,KatonRyu,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17030#issuecomment-3605910721
auto1111_webui,issue,17029,[Bug]: in hires. fix infinity loading,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Infinity loading with try use upscale ESRGAN_4x and 4x-UltraSharp. Loading to 49% and stoped.

My PC: 
MSI 4070 TI Super 16 gb VRAM
64gb DDR5
AMD Ryzen 9 7950X3D
ssd 1tb

![Image](https://github.com/user-attachments/assets/53bf0bf8-cb53-4360-99f5-a3340da79067)


### Steps to reproduce the problem

1. PNG info
2. Upload generated image
3. TextToImage
4. Setup setting from image
5. Generate with hires. fix
6. Ininity loading

### What should have happened?

Should ganarated image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-06-11-17-57.json](https://github.com/user-attachments/files/20695843/sysinfo-2025-06-11-17-57.json)

### Console logs

```Shell
venv ""D:\Git\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
D:\Git\stable-diffusion-webui\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [aaee0efd7c] from D:\Git\stable-diffusion-webui\models\Stable-diffusion\nova3DCGXL_illustriousV30.safetensors
Running on local URL:  http://127.0.0.1:7860
Creating model from config: D:\Git\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml

To create a public link, set `share=True` in `launch()`.
D:\Git\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Startup time: 6.8s (prepare environment: 1.5s, import torch: 2.5s, import gradio: 0.6s, setup paths: 0.4s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.5s, create ui: 0.2s, gradio launch: 0.5s).
Applying attention optimization: Doggettx... done.
Model loaded in 4.1s (load weights from disk: 0.4s, create model: 0.3s, apply weights to model: 3.0s, calculate empty prompt: 0.1s).
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:08<00:00,  5.60it/s]
==========================================================================================0/75 [00:09<00:04,  5.60it/s]
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
==========================================================================================
tiled upscale: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.63it/s]
```

### Additional information

_No response_",2025-06-11T17:59:32Z,ostryzhnyi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17029
auto1111_webui,comment,17029,,"likely a case of running low on vram

99% (and 49% when hires fix) is where webui dose VAE decode stage of the sd image gen process
because we don't have a progress showing the VAE decode stage if it taks a long time performing VAE decode it will seems like it 
so it might loosk like it's frozen

VAE decode is notorious in causing a vram usage spike

I have a 3090 with 24GB VRAM, so in order to test what happens on 16GB VRAM, I ran a script to fill my VRAM with 10 GB of junk and keep the junk in active use
> I filled 10 GB of junk and not 8G to compensate for other programs using vram on your system

then I ran a XL model at 768x768 + 2x hires pass
whill my run did not completely froze at 49% and 99%, it does take significantly longer during that stage then it usual would whithout the 10GB of junk that stage 

so I concluded that you're likely running out of VRAM

---

### suggestions to resolve the issue

there are ways to reduce the VRAM usage

method built-in to webui include 

- try some optimizations
for example `--xformers`
also see settings > optimizations > Cross attention optimization
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings

- try `--medvram` or `--lowvram`
this reduce vram usage at the cose of performance

- alternatively you can try Tiled VAE from Tiled Diffusion & VAE extension
https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111 

from there [wiki](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111/wiki/Tiled-VAE)
> Dramatically save your VRAM usage on VAE encoding / decoding
> It saves your VRAM at nearly no cost.
> You may not need --lowvram or --medvram anymore.
> You may not need --lowvram or --medv

---

other info
- XL models uses significantly more VRAM than 1.5
- generateing smaller images also has a smaller vram requirements

---

other issues you are getting

```
A tensor with all NaNs was produced in VAE.
Web UI will now convert VAE into 32-bit float and retry.
To disable this behavior, disable the 'Automatically revert VAE to 32-bit floats' setting.
To always start with 32-bit VAE, use --no-half-vae commandline flag.
```

if webui is froced to switchs from 16 bit to 32-bit for VAE it also increase VRAM usage (webui use 16bit by default)
so when using XL models it is generally recommended that you switch your VAE to the SDXL 16bit fix VAE form https://huggingface.co/madebyollin/sdxl-vae-fp16-fix
https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors
",2025-06-12T12:15:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17029#issuecomment-2966460988
auto1111_webui,issue,17025,[Bug]: automatic install for AMD with ROCm throws CUDA error.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The automatic install script for AMD as said in https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs#automatic-installation 
Calls out for a CUDA GPU
```
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

The wiki says
```
(As of 1/15/23 you can just run webui.sh and pytorch+rocm should be automatically installed for you.)
```
So I would expect to not run into CUDA issues.

### Steps to reproduce the problem

1. Get a fresh installation of Linux (I use WSL with Ubuntu-24.04)
2. Install Python, git, python-env, etc. (Just setup your system)
3. clone the Webui and go to its directory
4. run `./webui.sh`

### What should have happened?

Installation should have continued without CUDA related issues.

### What browsers do you use to access the UI ?

Other

### Sysinfo

N/A

### Console logs

[logs.txt](https://github.com/user-attachments/files/20640281/logs.txt)
```Shell
// Full log uploaded here ^^

Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-11.2.1 requests-2.32.3 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0 typing-extensions-4.14.0 urllib3-2.4.0
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```

### Additional information

I have the latest GPU driver and ROCm supports my GPU.
Environment is a WSL2 environment.
WSL can see my GPU as `rocminfo | grep 'Name'` proves.",2025-06-07T19:24:16Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025
auto1111_webui,comment,17025,,"Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))

`source venv/bin/activate`
`pip3 uninstall torch torch vision`
`pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 
the last line will be the code from pytorch website of whatever the lastest version is`

",2025-06-30T00:54:39Z,shimzini,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3017385578
auto1111_webui,comment,17025,,"> Dunno if you still have this error, but if you're already in python 3.10.6 (if not, you can use pyenv to switch), you need to uninstall torch from the venv and reinstall the latest rocm version of it, this worked for me. basically go to the SD folder, open terminal, and do the following commands. ([you can find the latest version of pytorch for rocm here](https://pytorch.org/get-started/locally/))
> 
> `source venv/bin/activate` `pip3 uninstall torch torch vision` `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` the last line will be the code from pytorch website of whatever the lastest version is`

Thank you, I'll try it out the next time I can.",2025-07-01T11:42:27Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3023593181
auto1111_webui,comment,17025,,"> `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3` 

You wouldn't happen to know how to fix `ValueError: Memoryview is too large` error, would you?
I checked with `free -mh` and I got `47Gi` of memory available in WSL2.

",2025-07-02T21:01:15Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3029314173
auto1111_webui,comment,17025,,"Well I managed to install it with this command
`python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.org/whl/rocm6.3`

Full log:
```
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ source venv/bin/activate
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ python3.10 -m pip install torch torchvision torchaudio  --no-cache-dir --index-url https://download.pytorch.or
g/whl/rocm6.3
Looking in indexes: https://download.pytorch.org/whl/rocm6.3
Collecting torch
  Downloading https://download.pytorch.org/whl/rocm6.3/torch-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (4543.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 GB 30.8 MB/s eta 0:00:00
Collecting torchvision
  Downloading https://download.pytorch.org/whl/rocm6.3/torchvision-0.22.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (3.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1/3.1 MB 31.6 MB/s eta 0:00:00
Collecting torchaudio
  Downloading https://download.pytorch.org/whl/rocm6.3/torchaudio-2.7.1%2Brocm6.3-cp310-cp310-manylinux_2_28_x86_64.whl (1.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 36.1 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.10/site-packages (from torch) (4.14.0)
Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2025.5.1)
Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.18.0)
Collecting pytorch-triton-rocm==3.3.1
  Downloading https://download.pytorch.org/whl/pytorch_triton_rocm-3.3.1-cp310-cp310-linux_x86_64.whl (254.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 254.2/254.2 MB 25.2 MB/s eta 0:00:00
Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch) (1.14.0)
Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from pytorch-triton-rocm==3.3.1->torch) (63.2.0)
Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from torchvision) (2.2.6)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (11.3.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)
Installing collected packages: pytorch-triton-rocm, torch, torchvision, torchaudio
Successfully installed pytorch-triton-rocm-3.3.1 torch-2.7.1+rocm6.3 torchaudio-2.7.1+rocm6.3 torchvision-0.22.1+rocm6.3
WARNING: There was an error checking the latest version of pip.
```

But it would seem that with the ROCm supported Torch, it still cannot use the GPU.
Since now I am getting this error.
```
(venv) ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ deactivate
ralkey@DESKTOP-407OQ69:~/stable-diffusion-webui$ ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on ralkey user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.6 (main, Jul  2 2025, 20:48:19) [GCC 13.3.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/ralkey/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/ralkey/stable-diffusion-webui/modules/launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
```",2025-07-03T19:01:57Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3033313842
auto1111_webui,comment,17025,,"I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
```sh
location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
cd ${location}/torch/lib/
rm libhsa-runtime64.so*
```",2025-07-04T17:35:31Z,PKBeam,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3036943049
auto1111_webui,comment,17025,,"> I had this problem and solved it with step 4 on the [AMD PyTorch install guide](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-pytorch.html):
> 
> location=$(pip show torch | grep Location | awk -F "": "" '{print $2}')
> cd ${location}/torch/lib/
> rm libhsa-runtime64.so*

Thank you so much, after months of working on this issue and talking with more people than I can count, I got proper 100% support on A1111 with my 9070XT!

And I managed to get up to 8 it/s, which is the fastest I have ever gotten!.

I documented my entire installation process, for other people to follow:
https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b",2025-07-05T12:42:54Z,RalkeyOfficial,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3038884508
auto1111_webui,comment,17025,,"> I documented my entire installation process, for other people to follow: https://gist.github.com/RalkeyOfficial/9fd97373d3c0dfa71519b89ff8ac7a8b

I'm running Arch, but I followed most of your steps and was able to get this running utilising my GPU to its fullest.
I have an AMD 7800XT.

As you suggested, I installed python3.10 (though I got it from the AUR), then used your suggested wgets. I also do not need the additional flags when running the main script.",2025-12-26T17:40:33Z,Nikolai5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17025#issuecomment-3693155817
auto1111_webui,issue,17024,webui.shæŠ¥é”™ï¼Œæœ‰æ²¡æœ‰é€‚åˆä¸­å›½å®å®ä½“è´¨çš„å®‰è£…æ–¹å¼å’Œè¿è¡Œæ–¹å¼,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

rtï¼Œè°¢è°¢

### Steps to reproduce the problem

rtï¼Œè°¢è°¢

### What should have happened?

rtï¼Œè°¢è°¢

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

rtï¼Œè°¢è°¢

### Console logs

```Shell
rtï¼Œè°¢è°¢
```

### Additional information

rtï¼Œè°¢è°¢",2025-06-03T07:43:39Z,XuJianzhi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024
auto1111_webui,comment,17024,,è¿™è¾¹å»ºè®®ä½ å»æ‰¾ç°æˆçš„akiåšçš„ä¸œè¥¿,2025-06-10T04:26:43Z,jsy061030,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024#issuecomment-2957639942
auto1111_webui,comment,17024,,æˆ‘å†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œä½¿ç”¨æœ€æ–°ä»£ç æˆåŠŸè¿è¡ŒæˆåŠŸã€‚https://blog.csdn.net/qq_40938217/article/details/149111568?spm=1001.2014.3001.5502,2025-07-04T09:42:00Z,djdll,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024#issuecomment-3035233485
auto1111_webui,comment,17024,,"> æˆ‘å†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œä½¿ç”¨æœ€æ–°ä»£ç æˆåŠŸè¿è¡ŒæˆåŠŸã€‚https://blog.csdn.net/qq_40938217/article/details/149111568?spm=1001.2014.3001.5502

è°¢è°¢ï¼Œæˆ‘åç»­è¯•è¯•",2025-07-04T09:44:13Z,XuJianzhi,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17024#issuecomment-3035242315
auto1111_webui,issue,17014,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Installed Ollama, Docker, Open-webui, pyenv, phyton 3.10, Automatic1111 and stable diffusion.
Worked perfectly. install even opened up the browser on 127.0.0.1:7860 and it jsut worked.
i generated a couple of images.

After a reboot the webui do not start 
tried ./webui.sh --listen --api and it will not start

### Steps to reproduce the problem

try to start webui.sh

### What should have happened?

webui should start ! ???

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

cant start so i cant generate ! ?

### Console logs

```Shell
bluescreentt@pop-os:~/stablediff$ ./webui.sh --listen --api

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on bluescreentt user
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.35
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python: No module named pip
Traceback (most recent call last):
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/bluescreentt/stablediff/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/bluescreentt/stablediff/stable-diffusion-webui/venv/bin/python"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

what am i missing ?
",2025-05-30T21:11:57Z,BlueScreenTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17014
auto1111_webui,comment,17014,,"so now i am thinking it have to do with python.
if i remove the myenv and env directories and run the webui again it works ! :-/",2025-05-30T21:49:43Z,BlueScreenTT,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17014#issuecomment-2923581102
auto1111_webui,issue,17013,[Feature Request]: Native Regional Prompting Support in txt2img/img2img UI (Like Regional Prompter Extension),"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

## Summary

Please consider implementing **native support for regional prompting** (such as the system used by the Regional Prompter extension) into the main txt2img/img2img UI. 

Right now, A1111 only supports a **global prompt** system, which causes huge complications when generating scenes with multiple subjects (such as a man and a woman). The lack of prompt separation leads to **pose confusion, identity blending, or prompt leakage across characters**, and is a major frustration for many creators.

---

## The Problem

When trying to generate scenes involving **two characters** (e.g., erotic, romantic, or narrative poses involving a man and a woman), A1111 only provides one prompt field and one negative prompt field. This means:

- Descriptions of male and female characters **get merged**.
- Poses or attributes **bleed into each other** (e.g., ""woman with left hand raised"" might apply to both).
- You **cannot assign individual poses, traits, or styles** reliably to specific characters.

This limitation wastes **hours of trial-and-error** and often results in inconsistent or broken images (e.g., multiple hands, flipped body parts, incorrect skin tones, etc.).

---

## Benefits

- Better control over **individual characters** in multi-subject scenes.
- Reduces time wasted on prompt tuning.
- Makes A1111 **more user-friendly for storytelling, erotic, couple, or narrative artwork**.
- Encourages creators to stick with A1111 rather than moving to node-based tools like ComfyUI.

---

## Real-World Use Case

As an artist/storyteller, Iâ€™m creating highly specific images involving custom LoRA characters (e.g., one male, one female) in various intimate positions.

Due to lack of regional prompting:

- Prompt confusion constantly occurs (e.g., wrong hand poses, skin tone merging).
- Even with `ControlNet`, the system often overrides the intent due to prompt ambiguity.
- I eventually discovered the **Regional Prompter Extension**, but most users **don't even know this exists**.

Native regional prompt support would make A1111 feel **complete**, even for power users.

---

## Supporting Screenshots & Results

Note: Due to the explicit nature of the art involved (erotic storytelling), I'm not attaching sample images. But the issue is reproducible with any prompt involving two characters and conflicting pose definitions.

---

## Thank You

Thanks for your amazing work. Just wanted to highlight how much this one addition could drastically reduce frustration and unlock a huge amount of use cases.


### Proposed workflow

## Suggested Solution

Integrate a simplified version of **Regional Prompter** into the base UI:

- Add the ability to define **at least two separate prompt regions** in txt2img and img2img.
- Provide region-specific **Prompt+ and Prompt- fields**.
- Allow region-based prompt weighting and masking (optional but helpful).
- Maintain compatibility with `lock seed`, `hires fix`, etc.

This doesn't need to be as complex as full compositional masking â€” just **prompt isolation between subjects** would already be a massive quality-of-life improvement.

---

### Additional information

_No response_",2025-05-28T22:55:54Z,lovenderdeleon,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17013
auto1111_webui,issue,17010,[Bug]: IPEX - Native API Error -997 (Command Failed to Enqueue/Execute),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When generating images using `--use-ipex`, I intermittently receive the error `Native API returns: -997`, which corresponds to a failure in command execution under IPEX. While generation occasionally works, it's inconsistent and mostly fails. I attempted using SD1.5 models as well, but encountered the same issue. This problem started only after I reset my PC and recloned the repository.



### Steps to reproduce the problem

Clone the stable-diffusion-webui repository

Modify webui-user.bat to include the --use-ipex flag

Launch WebUI and complete installation

Attempt to generate an image via txt2img or img2img

Observe that image generation either succeeds or fails with error -997

### What should have happened?

Image generation should work normally when using IPEX.



### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

GPU: Intel Arc A770

Driver Version: 31.0.101.5379

CPU: Intel Core i7-12700K

RAM: 32 GB DDR5

OS: Windows 11 Pro 22H2 (64-bit)

Toolkits Installed: Intel OneAPI Base Toolkit, OneAPI HPC Toolkit

Resizable BAR: Enabled

### Console logs

```Shell
venv ""R:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --use-ipex --opt-split-attention --medvram-sdxl
no module 'xformers'. Processing without...
No SDP backend available, likely because you are running in pytorch versions < 2.0. In fact, you are using PyTorch 2.0.0a0+gite9ebda2. You might want to consider upgrading.
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
==============================================================================
You are running torch 2.0.0a0+gite9ebda2.
The program is tested to work with torch 2.1.2.
To reinstall the desired version, run with commandline flag --reinstall-torch.
Beware that this will cause a lot of large files to be downloaded, as well as
there are reports of issues with training tab on the latest version.

Use --skip-version-check commandline argument to disable this check.
==============================================================================
Loading weights [b8d425c720] from R:\stable-diffusion-webui\models\Stable-diffusion\AOM3B4_orangemixs.safetensors
Creating model from config: R:\stable-diffusion-webui\configs\v1-inference.yaml
R:\stable-diffusion-webui\venv\lib\site-packages\huggingface_hub\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 7.6s (prepare environment: 0.4s, import torch: 2.2s, import gradio: 0.6s, setup paths: 0.7s, initialize shared: 1.1s, other imports: 0.3s, load scripts: 1.2s, create ui: 0.8s, gradio launch: 0.4s).
Loading VAE weights specified in settings: R:\stable-diffusion-webui\models\VAE\orangemix.vae.pt
Applying attention optimization: Doggettx... done.
Model loaded in 40.9s (load weights from disk: 0.4s, create model: 0.8s, apply weights to model: 2.1s, load VAE: 33.5s, calculate empty prompt: 3.8s).
  0%|                                                                                           | 0/31 [00:08<?, ?it/s]
*** Error completing request
*** Arguments: ('task(knvvwltwmsj4455)', <gradio.routes.Request object at 0x000001C39F2CE9E0>, 0, '1girl, bangs, bed, bed sheet, blush, breasts, cleavage, earrings, green eyes, indoors, jewelry, large breasts, long hair, looking at viewer, navel, on bed, shirt, shorts, solo, thighs, window', '(worst quality, low quality:1.4), (bad-hands-5:1.5), easynegative', [], <PIL.Image.Image image mode=RGBA size=768x1344 at 0x1C39351E080>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.75, 0.0, 910, 512, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 40, 'DPM++ 2M', 'Align Your Steps', False, '', 0.8, -1, False, -1, 0, 0, 0, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=""margin-bottom:0.75em"">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=""margin-bottom:0.75em"">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\img2img.py"", line 242, in img2img
        processed = process_images(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 988, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""R:\stable-diffusion-webui\modules\processing.py"", line 1774, in sample
        samples = self.sampler.sample_img2img(self, self.init_latent, x, conditioning, unconditional_conditioning, image_conditioning=self.image_conditioning)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in sample_img2img
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""R:\stable-diffusion-webui\modules\sd_samplers_kdiffusion.py"", line 184, in <lambda>
        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\utils\_contextlib.py"", line 115, in decorate_context
        return func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""R:\stable-diffusion-webui\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 36, in __call__
        return self.__orig_func(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 858, in apply_model
        x_recon = self.model(x_noisy, t, **cond)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 1335, in forward
        out = self.diffusion_model(x, t, context=cc)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 802, in forward
        h = module(h, emb, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 84, in forward
        x = layer(x, context)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""R:\stable-diffusion-webui\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_unet.py"", line 96, in spatial_transformer_forward
        x = block(x, context=context[i])
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 269, in forward
        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\util.py"", line 123, in checkpoint
        return func(*inputs)
      File ""R:\stable-diffusion-webui\repositories\stable-diffusion-stability-ai\ldm\modules\attention.py"", line 272, in _forward
        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
      File ""R:\stable-diffusion-webui\modules\sd_hijack_optimizations.py"", line 278, in split_cross_attention_forward
        r2 = rearrange(r1, '(b h) n d -> b n (h d)', h=h)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 487, in rearrange
        return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 410, in reduce
        return _apply_recipe(recipe, tensor, reduction_type=reduction)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\einops.py"", line 239, in _apply_recipe
        return backend.reshape(tensor, final_shapes)
      File ""R:\stable-diffusion-webui\venv\lib\site-packages\einops\_backends.py"", line 84, in reshape
        return x.reshape(shape)
    RuntimeError: Native API failed. Native API returns: -997 (Command failed to enqueue/execute) -997 (Command failed to enqueue/execute)

---
```

### Additional information

_No response_",2025-05-26T13:51:46Z,Parvezkhan0,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17010
auto1111_webui,comment,17010,,"You could try to update your Graphics driver to the latest version https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html 

You could also use [SD.Next](https://vladmandic.github.io/sdnext-docs/Intel-ARC/) as an alternative, which has built-in support for both OpenVINO and IPEX.",2025-07-10T06:39:58Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17010#issuecomment-3055839947
auto1111_webui,issue,17009,[Bug]: `history.json is not created/written to in v1.10.1 despite successful image generation`,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

**Description of the problem**:
Images are generated successfully, but the `history.json` file is neither created nor found anywhere (e.g., in the Web UI root directory or `outputs` directory).
Manually creating a `history.json` file does not result in generation history being written to it.
The issue persisted across a clean reinstallation.
File write permissions for the directory seem to be correct. (Please attach output of `ls -ld .` and `ls -ld outputs`).
Checked Web UI settings (`Settings` tab) thoroughly, but no explicit option for history saving was found. (Please attach screenshot PDF if relevant sections are visible).
The `--dump-gradio-config` option resulted in an ""unrecognized arguments"" error.
The presence or absence of the `--xformers` option did not affect the issue.
A VAE NaN error occurred with `v1-5-pruned.safetensors` but not with `v1-5-pruned-emaonly.safetensors` or `sd_xl_base_1.0.safetensors`. However, `history.json` was not created regardless of the model used.

**Expected behavior**:
The generated image history should be automatically recorded in a `history.json` file.

### Steps to reproduce the problem

1. starrt webui-user.sh
2. access via a browser, and generate images.
3. find <webui dir> -name history.json

### What should have happened?

 history.json file should be in <webui dir>

### What browsers do you use to access the UI ?

Apple Safari

### Sysinfo

[sysinfo-2025-05-26-10-48.json](https://github.com/user-attachments/files/20439930/sysinfo-2025-05-26-10-48.json)

### Console logs

```Shell
./webui.sh 

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tovy user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.39
Cannot locate TCMalloc. Do you have tcmalloc or google-perftool installed on your system? (improves CPU memory usage)
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --medvram --xformers --listen
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
Loading weights [31e35c80fc] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/sd_xl_base_1.0.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 5.6s (prepare environment: 1.1s, import torch: 2.0s, import gradio: 0.5s, setup paths: 0.8s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.2s).
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/repositories/generative-models/configs/inference/sd_xl_base.yaml
/home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Applying attention optimization: xformers... done.
Model loaded in 2.4s (load weights from disk: 0.6s, create model: 0.3s, apply weights to model: 1.2s, calculate empty prompt: 0.3s).
Reusing loaded model sd_xl_base_1.0.safetensors [31e35c80fc] to load v1-5-pruned-emaonly.safetensors [6ce0161689]
Loading weights [6ce0161689] from /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/tovy/AIs/stable-diffusion-webui-new/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: xformers... done.
Model loaded in 9.2s (create model: 0.2s, apply weights to model: 8.5s, apply half(): 0.3s).
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.57it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.86it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.68it/s]
^CInterrupted with signal 2 in <frame at 0x729b1000e690, file '/home/tovy/miniconda3/envs/sd_env_new/lib/python3.10/threading.py', line 324, code wait>

$ find . -name history.json
 nothing
```

### Additional information

**Environment**:
* Web UI Version: `v1.10.1` (Commit hash: `82a973c04367123ae98bd9abdf80d9eda9b910e2`)
* Python Version: `3.10.16` (Conda environment `sd_env_new`)
* OS: `Ubuntu 24.04.2 LTS`
* Kernel: `Linux germany 6.11.0-26-generic #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC`
* GPU: `NVIDIA GeForce RTX 2070 SUPER`
* GPU VRAM: `8GB`
* NVIDIA Driver Version: `570.133.07`
* System CUDA Version: `12.8`
* PyTorch CUDA Version: `2.7.0+cu128`
* `webui-user.sh` `COMMANDLINE_ARGS`: `export COMMANDLINE_ARGS=""--medvram --xformers --listen""` (or your current arguments)
",2025-05-26T10:51:30Z,tovytovy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009
auto1111_webui,comment,17009,,"I'm not sure where you get this `history.json` from but as far as I'm with this is not a part of the base web UI
perhaps you're confusing something else
maybe
`params.txt`
`settings > infotext > Create a text file with infotext next to every generated image`

or maybe your referencing an extension

similar for `--dump-gradio-config` it is not a thing in AUTOMATIC1111/stable-diffusion-webui

are you sure you are not reading documentation about some other software and confusing it with this software?",2025-05-26T16:07:19Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2910187743
auto1111_webui,comment,17009,,"![Image](https://github.com/user-attachments/assets/2e407a24-3b0a-4e53-981b-ef1d60636648)

Yes, you're right. Thank you for pointing that out.

It seems the history.json I referred to isn't part of the standard Stable Diffusion Web UI. I might have confused it with other information.

The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.
I speculated that these arrows weren't showing up because a file for recording history data (which I tentatively called history.json) was either missing or not being written correctly. It seems my initial assumption about the file name was incorrect.

Should I close bug report #17009 and resubmit it with a more direct title like 'History reference arrows are not displayed'?
",2025-05-26T22:21:50Z,tovytovy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2910704313
auto1111_webui,comment,17009,,"> The actual issue I'm facing is that the left and right arrow icons, which should appear at the right end of the prompt input field to browse generated image prompt history, are completely missing.

there no are histroy button in the base webui
it only displays the images from the current task

I think you're confusing it with some other aspects of UI
for example when you generate multiple images in a single task such as batch count or size > 1
or using scripts such as XYZ gird
but there is no left and right buttons
> you can either directly click on the image or using the keyboard arrow keys to navigate between images

you could also be confusing it with the full screen image viewer which does have left and right buttons

https://github.com/user-attachments/assets/1bab785d-9571-4c97-b905-6b7f2f4e13b1
> notice that the seed parameter does change when I flip through images


but these are not ""history""
> by ""history"" referring to images form past tasks, it only shows image from the current task

---

there's no history view in the basement you
however there are some extensions that add such a feature

couple of ""history"" extentions that can be found on the extensions tab
https://github.com/MINENEMA/sd-webui-quickrecents
https://github.com/namkazt/sd-webui-prompt-history
https://github.com/zanllp/sd-webui-infinite-image-browsing
> note: I don't use these extensions myself so this is not a endorsement",2025-05-27T07:14:43Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17009#issuecomment-2911421734
auto1111_webui,issue,17002,"[Bug]: webui.sh start failed on macos, ValueError: When localhost is not accessible, a shareable link must be created.","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

webui.sh start failed on macos


### Steps to reproduce the problem

Follow steps from `Installation on Apple Silicon`

### What should have happened?

WebUi should started

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

Can't go webui

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on xxx user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
python venv already activate or run without venv: /Users/xxx/.pyenv/versions/3.10.6/envs/stable-diffusion
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.6 (main, May 22 2025, 10:51:10) [Clang 17.0.0 (clang-1700.0.13.3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
Loading weights [ad2a33c361] from /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.ckpt
Running on local URL:  http://127.0.0.1:7860
Creating model from config: /Users/xxx/code/llm/stable-diffusion-webui/models/Stable-diffusion/v2-1_768-ema-pruned.yaml
Traceback (most recent call last):
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/modules/launch_utils.py"", line 469, in start
    webui.webui()
  File ""/Users/xxx/code/llm/stable-diffusion-webui/webui.py"", line 79, in webui
    app, local_url, share_url = shared.demo.launch(
  File ""/Users/xxx/.pyenv/versions/stable-diffusion/lib/python3.10/site-packages/gradio/blocks.py"", line 1971, in launch
    raise ValueError(
ValueError: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.
 1 .env +                                                                                                                                                                                                          
Applying attention optimization: sub-quadratic... done.
```

### Additional information

Fixed after upgrade gradio
```sh
pip install --upgrade gradio

Successfully installed fastapi-0.115.12 gradio-5.30.0 pydantic-2.11.4 starlette-0.46.2
```",2025-05-22T05:48:32Z,waitpigfly,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17002
auto1111_webui,comment,17002,,You can try with my step by step [guide](https://github.com/viking1304/a1111-setup/discussions/2) or my install script (faster and easier).,2025-07-01T17:51:03Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/17002#issuecomment-3024994296
auto1111_webui,issue,16997,[Bug]: Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Steps to reproduce the problem

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### Console logs

```Shell
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant
```

### Additional information

_No response_",2025-05-18T14:57:32Z,wzgrx,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16997
auto1111_webui,comment,16997,,"

### What happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

### What should have happened?
Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant

_sarcasm_
""good"", so it's working as intended?

---

Please fill out the book report form as requested
important information is include
`Steps to reproduce the problem`: we need information on what you did otherwise we can't start debugging let alone fixing it
`Sysinfo`: we need to know what your status of your installation is, read the template to know how to upload this
`Console logs`: need to see the full trace of the error not just a single line


",2025-05-19T03:54:34Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16997#issuecomment-2889534362
auto1111_webui,issue,16991,Trouble launching webui,"When i run `./webui.sh`, even after i deleted the `venv` folder (i don't have a `repositories` folder), I get this error :


################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on tristanpichard user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################
Traceback (most recent call last):
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py"", line 110, in _get_module_details
    __import__(pkg_name)
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/__init__.py"", line 1, in <module>
    from typing import List, Optional
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__
    self._abc_registry = extra._abc_registry
AttributeError: type object 'Callable' has no attribute '_abc_registry'

################################################################
Launching launch.py...
################################################################
Traceback (most recent call last):
  File ""/Users/tristanpichard/stable-diffusion-webui/launch.py"", line 1, in <module>
    from modules import launch_utils
  File ""/Users/tristanpichard/stable-diffusion-webui/modules/launch_utils.py"", line 9, in <module>
    import importlib.metadata
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/__init__.py"", line 17, in <module>
    from . import _adapters, _meta
  File ""/opt/homebrew/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/metadata/_meta.py"", line 1, in <module>
    from typing import Any, Dict, Iterator, List, Protocol, TypeVar, Union
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1359, in <module>
    class Callable(extra=collections_abc.Callable, metaclass=CallableMeta):
  File ""/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/typing.py"", line 1007, in __new__

Does anyone know how to resolve that ?",2025-05-14T22:17:59Z,XxpintelxX,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16991
auto1111_webui,issue,16990,[Bug]: SD was running fast and slowed down a lot,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

On the first day after I installed it, SD worked very fast, it took no more than 40 seconds for one picture to be fully generated. The next day, it started spending more than 5-6 minutes on ONE picture. I changed the checkpoint and it started working normally again. The next day, the same thing happened, it started requiring 5-6 minutes to generate, and now both checkpoints. I tried to write different arguments to the .bat file that I could find on the Internet - the problem did not disappear. I tried different drivers for the video card - it did not help. Video card RTX 4060 8GB, processor Ryzen 7 5700X.

### Steps to reproduce the problem

Normal launch of SD via .bat file

### What should have happened?

I can't say anything in this field because my problem doesn't imply anything that could be written here.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-05-12-07-05.json](https://github.com/user-attachments/files/20156299/sysinfo-2025-05-12-07-05.json)

### Console logs

```Shell
Loading weights [bdb59bac77] from C:\Users\CoteLo\Desktop\sd.webui\webui\models\Stable-diffusion\waiNSFWIllustrious_v140.safetensors
Creating model from config: C:\Users\CoteLo\Desktop\sd.webui\webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:100: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  model.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:112: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_1.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:114: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_2.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\webui\extensions\stable-diffusion-webui-stable-horde\scripts\main.py:116: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.
  post_processing_3.style(container=False)
C:\Users\CoteLo\Desktop\sd.webui\system\python\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 11.1s (prepare environment: 2.1s, import torch: 3.7s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 1.0s, create ui: 2.0s, gradio launch: 0.2s).
Applying attention optimization: xformers... done.
Model loaded in 6.2s (load weights from disk: 0.1s, create model: 1.9s, apply weights to model: 3.7s, move model to device: 0.1s, calculate empty prompt: 0.1s).
```

### Additional information

Please help me figure out what happened, I want to continue my work in SD, but I have to wait 5-6 minutes for one generation each time, especially when the final result does not always meet the requirement",2025-05-12T07:22:56Z,bzelenkov,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990
auto1111_webui,comment,16990,,"I also tried using v1.0.0-pre for Nvidia cards, but it makes no difference",2025-05-12T07:28:22Z,bzelenkov,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990#issuecomment-2871214788
auto1111_webui,comment,16990,,"what is your VRAM usage?

my guess of what's happening is that you VRAM is near full

in nvidia settings there is something called CUDA - Sysmem Fallback Policy
basically this is something that would tell the GPU to use system RAM as VRAM when VRAM is near full
this would sometimes prevent out of memory issues but at the cost of drastically reducing speed
this can be disabled changeing the CUDA - Sysmem Fallback Policy. Set the value to Prefer No Sysmem Fallback in nvidia settings settings, see
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/11063

---

if you are faceing out of memory issues, try [Tiled VAE](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111)
",2025-05-12T22:03:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16990#issuecomment-2874305266
auto1111_webui,issue,16986,"[Bug]: WebUI won't start (fresh copy, macOS on Apple Silicon)","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

As I could not find the issue with the search, I hope this is the right place to report it. Today I tried to run the WebUI as a fresh install on a new Mac (about a week old, so System is also a fresh install) with Apple Silicon (M4 Max). 

When running `./webui.sh` I get the following (tried to re-run the same sh after it fails the first time with the same issue): 

```
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Steps to reproduce the problem

1. Fresh copy of this repo on macOS
2. Run `./webui.sh`

### What should have happened?

It should run?

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't, application won't launch.

### Console logs

```Shell
sebastian@Sebastians-MacBookPro2025 stable-diffusion-webui % ./webui.sh

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on sebastian user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
Python 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Launching Web UI with arguments: --skip-torch-cuda-test --upcast-sampling --no-half-vae --use-cpu interrogate
Traceback (most recent call last):
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/launch.py"", line 44, in main
    start()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/launch_utils.py"", line 465, in start
    import webui
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/webui.py"", line 13, in <module>
    initialize.imports()
  File ""/Volumes/External/Stable Diffusion/stable-diffusion-webui/modules/initialize.py"", line 17, in imports
    import pytorch_lightning  # noqa: F401
ModuleNotFoundError: No module named 'pytorch_lightning'
```

### Additional information

_No response_",2025-05-07T19:58:45Z,Sebastian1989101,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986
auto1111_webui,comment,16986,,"I delete venv folder and works, however extremely slow on M4.",2025-06-30T09:49:24Z,ach1llea,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986#issuecomment-3018508210
auto1111_webui,comment,16986,,"> I delete venv folder and works, however extremely slow on M4.

You can try some alternative command lines I posted [here](https://github.com/viking1304/a1111-setup/discussions/2), but do not expect drastic improvements.",2025-07-01T17:43:07Z,viking1304,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16986#issuecomment-3024971482
auto1111_webui,issue,16974,[Bug]: Help installation stable diffusion en linux Ubuntu/PopOS with rtx 5070,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Hello, I have been trying to install stable diffusion webui in PopOS, similar to Ubuntu, but every time I click on generate image I get this error in the graphical interface

error RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.

I get this error in the terminal:

https://pastebin.com/N9E7ERWY

This is my nvidia-smi

https://pastebin.com/3nbmjAKb

I have Python 3.10.6

So, has anyone on Linux managed to get SD WebUI working with the Nvidia 50xx series? It works on Windows, but in my opinion, given the cost of the graphics card, it's not fast enough, and it's always been faster on Linux. If anyone could do it or help me, it would be a great help. Thanks.

### Steps to reproduce the problem

1. Install Ubuntu, PopOs, or similar
2. Make sure you have the NVIDIA drivers, Python 3.10.6, and Git
3. Download stable diffusion webui
4. Run ./webui.sh
5. Click the Generate Image button and the error message will appear.

### What should have happened?

The image has been generated

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2025-04-30-01-13.json](https://github.com/user-attachments/files/19969546/sysinfo-2025-04-30-01-13.json)

### Console logs

```Shell
https://pastebin.com/N9E7ERWY
```

### Additional information

_No response_",2025-04-30T01:16:48Z,Arion107,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974
auto1111_webui,comment,16974,,"My setup:
- Debian 12 x86_64, Linux kernel 6.14.3
- NVIDIA drivers 570.144
- Geforce RTX 5060 Ti with 16 GB RAM

I received a similar error message:

```
NVIDIA Graphics Device with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
```

I was able to get it working with the commands below:

```
git switch dev
webui.sh --reinstall-torch
webui.sh --reinstall-xformers
webui.sh
```

Hope it helps. And thanks to w-e-w for the patches!",2025-04-30T18:29:53Z,semolina5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974#issuecomment-2842925084
auto1111_webui,comment,16974,,"I'm not sure if this is correct information but base of the below on linux you will need drivers `>= 570.26`
https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html

cuDNN PackageÂ | CUDA Toolkit Version | Supports static linking?  | NVIDIA Driver Version for Linux | NVIDIA Driver Version for Windows | CUDA Compute Capability | Supported NVIDIA GPU Architectures
-- | -- | -- | -- | -- | -- | --
cuDNN 9.8.0 for CUDA 12.x | 12.8 | Yes | >=570.26 | >=570.65 | 12.0<br>10.0<br>9.0<br>8.9<br>8.6<br>8.0<br>7.5<br>7.0<br>6.1<br>6.0<br>5.0 | NVIDIA Blackwell<br>NVIDIA Hopper<br>NVIDIA Ada Lovelace<br>NVIDIA Ampere<br>NVIDIA Turing<br>NVIDIA Volta<br>NVIDIA Pascal<br>NVIDIA Maxwell

both of you have drivers `< 570.2` specifically `570.133.07` `570.144`
so maybe try updating your drivers
also 50 series cards should switch to dev branch
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818#discussion-7893258",2025-05-02T11:05:00Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16974#issuecomment-2846951142
auto1111_webui,issue,16973,[Bug]: I cant create any images,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I should probably let you know that I'm extremely new to this and i could very well just be an idiot

I got everything installed, ran into the `connection errored out` issue, it fixed itself, then i selected my model of choice, keyed in my prompt, then hit generate.

It didn't seem to be doing anything at all, considering the loading bar wasn't moving, then it just stopped.
I tried re-running it and i got the same issue.
I then checked the console logs and found `Error completing request` followed by a long wall of directories.

### Steps to reproduce the problem

-> Start the program with `webui_user.bat`
-> Let it hitch and chug my pc before i begin prompting, lol
-> I selected my chosen model, which is `ntrMIXIllustriousXL`
-> Keyed in my prompt
-> Then finally hit generate

### What should have happened?

It should have began generating an image

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

""Platform"": ""Windows-10-10.0.22631-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1-amd-36-g679c645e"",
    ""Commit"": ""679c645ec84e40dd14d527dbeb03fab259087187"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \""git add <file>...\"" to update what will be committed)\n  (use \""git restore <file>...\"" to discard changes in working directory)\n\tmodified:   requirements.txt\n\tmodified:   requirements_versions.txt\n\nUntracked files:\n  (use \""git add <file>...\"" to include in what will be committed)\n\t.zluda/\n\nno changes added to commit (use \""git add\"" and/or \""git commit -a\"")"",
    ""Script path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Data path"": ""C:\\Users\\User\\stable-diffusion-webui-directml"",
    ""Extensions dir"": ""C:\\Users\\User\\stable-diffusion-webui-directml\\extensions"",
    ""Checksum"": ""39d8fc504e48a17308a3bebd7503c5b9eec367af4f0226bf40c43749482f0848"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.4.1+cpu"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""N/A"",
        ""gcc_version"": null,
        ""clang_version"": ""19.0.0git (git@github.amd.com:Compute-Mirrors/llvm-project b3dbdf4f03718d63a3292f784216fddb3e73d521)"",
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 11 Pro"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.22631-SP0"",
        ""is_cuda_available"": ""False"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""N/A"",
        ""nvidia_driver_version"": null,
        ""nvidia_gpu_models"": null,
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""onnx==1.16.2"",
            ""onnxruntime==1.21.1"",
            ""onnxruntime-directml==1.18.0"",
            ""onnxscript==0.2.5"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.4.1"",
            ""torch-directml==0.2.5.dev240914"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.7.1"",
            ""torchsde==0.2.6"",
            ""torchvision==0.19.1""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""6.1"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Architecture=9"",
            ""CurrentClockSpeed=3400"",
            ""DeviceID=CPU0"",
            ""Family=206"",
            ""L2CacheSize=5120"",
            ""L2CacheSpeed="",
            ""Manufacturer=GenuineIntel"",
            ""MaxClockSpeed=3400"",
            ""Name=13th Gen Intel(R) Core(TM) i3-13100"",
            ""ProcessorType=3"",
            ""Revision=""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"",
            ""traceback"": [
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 831, load_model"",
                    ""sd_model = instantiate_from_config(sd_config.model, state_dict)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_models.py, line 775, instantiate_from_config"",
                    ""return constructor(**params)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\models\\diffusion.py, line 61, __init__"",
                    ""self.conditioner = instantiate_from_config(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 88, __init__"",
                    ""embedder = instantiate_from_config(embconfig)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\util.py, line 175, instantiate_from_config"",
                    ""return get_obj_from_str(config[\""target\""])(**config.get(\""params\"", dict()))""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\repositories\\generative-models\\sgm\\modules\\encoders\\modules.py, line 361, __init__"",
                    ""self.transformer = CLIPTextModel.from_pretrained(version)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\modules\\sd_disable_initialization.py, line 68, CLIPTextModel_from_pretrained"",
                    ""res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 262, _wrapper"",
                    ""return func(*args, **kwargs)""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\modeling_utils.py, line 3540, from_pretrained"",
                    ""resolved_config_file = cached_file(""
                ],
                [
                    ""C:\\Users\\User\\stable-diffusion-webui-directml\\venv\\lib\\site-packages\\transformers\\utils\\hub.py, line 365, cached_file"",
                    ""raise EnvironmentError(""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""Intel64 Family 6 Model 191 Stepping 5, GenuineIntel"",
        ""count logical"": 8,
        ""count physical"": 4
    },
    ""RAM"": {
        ""total"": ""7GB"",
        ""used"": ""5GB"",
        ""free"": ""2GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""ntrMIXIllustriousXL_xiii.safetensors [1207404b17]"",
        ""sd_checkpoint_hash"": ""1207404b1705a026eaa2896b66953dbef8be5ccde5340e4fd940b674aecb8cf8""
    },
    ""Startup"": {
        ""total"": 55.028228521347046,
        ""records"": {
            ""initial startup"": 0.020017385482788086,
            ""prepare environment/checks"": 0.011029243469238281,
            ""prepare environment/git version info"": 1.6748936176300049,
            ""prepare environment/clone repositores"": 26.568973779678345,
            ""prepare environment/run extensions installers"": 0.001995563507080078,
            ""prepare environment"": 58.2568564414978,
            ""launcher"": 0.002000093460083008,
            ""import torch"": 0.0,
            ""import gradio"": 0.0,
            ""setup paths"": 0.0010006427764892578,
            ""import ldm"": 0.0031473636627197266,
            ""import sgm"": 0.0,
            ""initialize shared"": 9.239458799362183,
            ""other imports"": 0.4272043704986572,
            ""opts onchange"": 0.0010008811950683594,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0020225048065185547,
            ""setup gfpgan"": 0.015314340591430664,
            ""set samplers"": 0.0,
            ""list extensions"": 0.0010004043579101562,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.019205570220947266,
            ""list localizations"": 0.0,
            ""load scripts/custom_code.py"": 0.003504514694213867,
            ""load scripts/img2imgalt.py"": 0.0010044574737548828,
            ""load scripts/loopback.py"": 0.0010004043579101562,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_codeformer.py"": 0.0009992122650146484,
            ""load scripts/postprocessing_gfpgan.py"": 0.0,
            ""load scripts/postprocessing_upscale.py"": 0.0010013580322265625,
            ""load scripts/prompt_matrix.py"": 0.0009980201721191406,
            ""load scripts/prompts_from_file.py"": 0.0,
            ""load scripts/sd_upscale.py"": 0.0009992122650146484,
            ""load scripts/xyz_grid.py"": 0.0020020008087158203,
            ""load scripts/ldsr_model.py"": 0.23322319984436035,
            ""load scripts/lora_script.py"": 0.16320395469665527,
            ""load scripts/scunet_model.py"": 0.02911067008972168,
            ""load scripts/swinir_model.py"": 0.025522232055664062,
            ""load scripts/hotkey_config.py"": 0.0005097389221191406,
            ""load scripts/extra_options_section.py"": 0.0010046958923339844,
            ""load scripts/hypertile_script.py"": 0.047042131423950195,
            ""load scripts/postprocessing_autosized_crop.py"": 0.001504659652709961,
            ""load scripts/postprocessing_caption.py"": 0.0010068416595458984,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.0019991397857666016,
            ""load scripts/postprocessing_split_oversized.py"": 0.0009989738464355469,
            ""load scripts/soft_inpainting.py"": 0.0,
            ""load scripts/comments.py"": 0.025876283645629883,
            ""load scripts/refiner.py"": 0.001188516616821289,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0009989738464355469,
            ""load scripts"": 0.5457000732421875,
            ""load upscalers"": 0.0035028457641601562,
            ""refresh VAE"": 0.0010051727294921875,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0009996891021728516,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0009996891021728516,
            ""initialize extra networks"": 0.25032877922058105,
            ""scripts before_ui_callback"": 0.0031523704528808594,
            ""create ui"": 1.0891542434692383,
            ""gradio launch"": 0.15899944305419922,
            ""add APIs"": 0.006510496139526367,
            ""app_started_callback/lora_script.py"": 0.0,
            ""app_started_callback"": 0.0
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.16"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.6.1"",
        ""aiohttp==3.11.18"",
        ""aiosignal==1.3.2"",
        ""alembic==1.15.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.3.0"",
        ""blendmodes==2022"",
        ""certifi==2025.4.26"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""coloredlogs==15.0.1"",
        ""colorlog==6.9.0"",
        ""contourpy==1.3.2"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diffusers==0.29.2"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.18.0"",
        ""filterpy==1.4.5"",
        ""flatbuffers==25.2.10"",
        ""fonttools==4.57.0"",
        ""frozenlist==1.6.0"",
        ""fsspec==2025.3.2"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""greenlet==3.2.1"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.30.2"",
        ""humanfriendly==10.0"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_metadata==8.6.1"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2025.4.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.3"",
        ""llvmlite==0.44.0"",
        ""Mako==1.3.10"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""ml_dtypes==0.5.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.4.3"",
        ""narwhals==1.36.0"",
        ""networkx==3.4.2"",
        ""numba==0.61.2"",
        ""numpy==1.26.2"",
        ""olive-ai==0.8.0"",
        ""omegaconf==2.2.3"",
        ""onnx==1.16.2"",
        ""onnxruntime==1.21.1"",
        ""onnxruntime-directml==1.18.0"",
        ""onnxscript==0.2.5"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""optimum==1.24.0"",
        ""optuna==4.3.0"",
        ""orjson==3.10.16"",
        ""packaging==25.0"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.1"",
        ""propcache==0.3.1"",
        ""protobuf==3.20.2"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.22"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.3"",
        ""pyreadline3==3.5.4"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.2"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.24.0"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""SQLAlchemy==2.0.40"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.3.30"",
        ""timm==1.0.15"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""torch==2.4.1"",
        ""torch-directml==0.2.5.dev240914"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.19.1"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""typing_extensions==4.13.2"",
        ""tzdata==2025.2"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
venv ""C:\Users\User\stable-diffusion-webui-directml\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1-amd-36-g679c645e
Commit hash: 679c645ec84e40dd14d527dbeb03fab259087187
ROCm: agents=['gfx1031']
ROCm: version=6.1, using agent gfx1031
ZLUDA support: experimental
ZLUDA load: path='C:\Users\User\stable-diffusion-webui-directml\.zluda' nightly=False
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\timm\models\layers\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\pytorch_lightning\utilities\distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.
  rank_zero_deprecation(
Launching Web UI with arguments:
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
ONNX failed to initialize: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.
Loading weights [1207404b17] from C:\Users\User\stable-diffusion-webui-directml\models\Stable-diffusion\ntrMIXIllustriousXL_xiii.safetensors
Creating model from config: C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 49.1s (prepare environment: 54.1s, initialize shared: 10.3s, other imports: 0.5s, load scripts: 0.5s, initialize extra networks: 0.2s, create ui: 1.4s, gradio launch: 0.3s).
creating model quickly: OSError
Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 409, in hf_raise_for_status
    response.raise_for_status()
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\requests\models.py"", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 342, in cached_file
    resolved_file = hf_hub_download(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_validators.py"", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 285, in _request_wrapper
    response = _request_wrapper(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\file_download.py"", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\huggingface_hub\utils\_http.py"", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68110227-167031112a31fc012a3e021f;d725f8d3-a1c3-463e-bdb6-5d09c72f2a1c)

Repository Not Found for url: https://huggingface.co/None/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\shared_items.py"", line 190, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 831, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\models\diffusion.py"", line 61, in __init__
    self.conditioner = instantiate_from_config(
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 88, in __init__
    embedder = instantiate_from_config(embconfig)
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\util.py"", line 175, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\encoders\modules.py"", line 361, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(None, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 262, in _wrapper
    return func(*args, **kwargs)
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\modeling_utils.py"", line 3540, in from_pretrained
    resolved_config_file = cached_file(
  File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\transformers\utils\hub.py"", line 365, in cached_file
    raise EnvironmentError(
OSError: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

Failed to create model quickly; will retry using slow method.
C:\Users\User\stable-diffusion-webui-directml\modules\safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return unsafe_torch_load(filename, *args, **kwargs)
Applying attention optimization: InvokeAI... done.
Model loaded in 1123.0s (calculate hash: 1.4s, load weights from disk: 1.5s, create model: 439.9s, apply weights to model: 599.1s, apply half(): 14.8s, apply dtype to VAE: 0.2s, load VAE: 0.1s, load weights from state dict: 0.2s, move model to device: 0.1s, hijack: 10.5s, load textual inversion embeddings: 0.4s, scripts callbacks: 0.2s, calculate empty prompt: 54.6s).
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(njs4goici10ce24)', <gradio.routes.Request object at 0x0000021451A90C40>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
  0%|                                                                         | 0/5 [00:00<?, ?it/s]
*** Error completing request
*** Arguments: ('task(fx01jbd3ltger2l)', <gradio.routes.Request object at 0x0000021451A50460>, 'Yep', '', [], 1, 1, 7, 256, 264, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 5, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 849, in process_images
        res = process_images_inner(p)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1083, in process_images_inner
        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\processing.py"", line 1441, in sample
        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in sample
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_common.py"", line 272, in launch_sampling
        return func()
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_kdiffusion.py"", line 233, in <lambda>
        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\utils\_contextlib.py"", line 116, in decorate_context
        return func(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\sampling.py"", line 594, in sample_dpmpp_2m
        denoised = model(x, sigmas[i] * s_in, **extra_args)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_samplers_cfg_denoiser.py"", line 249, in forward
        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 112, in forward
        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\k-diffusion\k_diffusion\external.py"", line 138, in get_eps
        return self.inner_model.apply_model(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_models_xl.py"", line 43, in apply_model
        return self.model(x, t, cond)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 22, in <lambda>
        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_utils.py"", line 34, in __call__
        return self.__sub_func(self.__orig_func, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_hijack_unet.py"", line 50, in apply_model
        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\wrappers.py"", line 28, in forward
        return self.diffusion_model(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 993, in forward
        h = module(h, emb, context)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 98, in forward
        x = layer(x, emb)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 317, in forward
        return checkpoint(
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 167, in checkpoint
        return func(*inputs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\openaimodel.py"", line 329, in _forward
        h = self.in_layers(x)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\container.py"", line 219, in forward
        input = module(input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1553, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\module.py"", line 1562, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\User\stable-diffusion-webui-directml\repositories\generative-models\sgm\modules\diffusionmodules\util.py"", line 275, in forward
        return super().forward(x.float()).type(x.dtype)
      File ""C:\Users\User\stable-diffusion-webui-directml\extensions-builtin\Lora\networks.py"", line 614, in network_GroupNorm_forward
        return originals.GroupNorm_forward(self, input)
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\modules\normalization.py"", line 288, in forward
        return F.group_norm(
      File ""C:\Users\User\stable-diffusion-webui-directml\venv\lib\site-packages\torch\nn\functional.py"", line 2606, in group_norm
        return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
    RuntimeError: mixed dtype (CPU): expect parameter to have scalar type of Float

---
```

### Additional information

If theres an issue with the tutorial i used, its https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs",2025-04-29T17:48:52Z,Nowman2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973
auto1111_webui,comment,16973,,Did you install cuda? Your torch is compiled with cpu and  you may check your cuda version and reinstall torch that compiled with your cuda version. ,2025-04-30T11:02:51Z,AUTOMATIC2222,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2841612075
auto1111_webui,comment,16973,,"> Did you install cuda? Your torch is compiled with cpu and you may check your cuda version and reinstall torch that compiled with your cuda version.

Because im using an amd gpu (rx6700xt), i dont use cuda, i use zluda.
How do i reinstall torch on the cpu?",2025-04-30T15:50:25Z,Nowman2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2842455304
auto1111_webui,comment,16973,,"you are using stable-diffusion-webui-amdgpu aka stable-diffusion-webui-directml
so please report your issue over at https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu
",2025-05-02T17:14:45Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16973#issuecomment-2847716795
auto1111_webui,issue,16971,[Bug]: zluda resolution bug,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

When I'm trying to generate an image rather 800x800 or higher the pc will freeze and it give me

OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation. See documentation for Memory Management (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Time taken: 22 min. 58.9 sec.

I tried a lot to fix it but no avail,  I re installed the wepui multiple times and zluda + hip too 

Is there any fix for that? Or should I go to comfy ai?
Well I got the same problem if I went to comfy?

My gpu rx6700xt 12GB vram I installed gfx1031 the image generation gose well if I low down the resolution but I don't want to

### Steps to reproduce the problem

Low down resolution, disable upscale

### What should have happened?

Normal image generation without freezing on 99%

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

""starlette==0.26.1"",
        ""svg.path==6.3"",
        ""svglib==1.5.1"",
        ""sympy==1.13.1"",
        ""tabulate==0.9.0"",
        ""termcolor==3.0.1"",
        ""threadpoolctl==3.6.0"",
        ""tifffile==2025.3.30"",
        ""timm==0.6.7"",
        ""tinycss2==1.4.0"",
        ""tokenizers==0.21.1"",
        ""tomesd==0.1.3"",
        ""tomli==2.2.1"",
        ""torch==2.6.0+cu118"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.7.1"",
        ""torchsde==0.2.6"",
        ""torchvision==0.21.0+cu118"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.49.0"",
        ""trimesh==4.6.8"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.2"",
        ""ultralytics==8.3.119"",
        ""ultralytics-thop==2.0.14"",
        ""urllib3==2.4.0"",
        ""uvicorn==0.34.2"",
        ""vhacdx==0.0.8.post2"",
        ""wcwidth==0.2.13"",
        ""webencodings==0.5.1"",
        ""websockets==11.0.3"",
        ""win32_setctime==1.2.0"",
        ""xxhash==3.5.0"",
        ""yacs==0.1.8"",
        ""yapf==0.43.0"",
        ""yarl==1.20.0"",
        ""zipp==3.21.0""
    ]
}

### Console logs

```Shell
File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\repositories\generative-models\sgm\modules\diffusionmodules\model.py"", line 132, in forward
        h = self.conv1(h)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1739, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\module.py"", line 1750, in _call_impl
        return forward_call(*args, **kwargs)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""C:\Users\Owner\stable diffusion\webui\stable-diffusion-webui-amdgpu\venv\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 11.98 GiB of which 0 bytes is free. Of the allocated memory 13.91 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```

### Additional information

When I mentioned freezing at 99% I mean the whole pc freezes not only the browser ",2025-04-29T05:44:05Z,Neko21421,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16971
auto1111_webui,issue,16965,[Bug]: Better Tutorials for Running with AMD,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

the libs need to be set up in the zip files like this:

ROCm\6.2\bin\rocblas\library
and
ROCm\6.2\bin\rocblas.dll

with the directories intact. this is what's causing the confusion and frustration when ppl are attempting to install ais. no one's tutorial mentions what to do with the rocblas.dll so this is the majority of ppls errors. i had to comb zluda forums just to see if even using the dll was supposed to happen. you need to tell users after this fix to drag and drop these files into the main amd directory in program files in the tutorials after backing the files up.

### Steps to reproduce the problem

better tutorial

### What should have happened?

better tutorial

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

better tutorial

### Console logs

```Shell
better tutorial
```

### Additional information

_No response_",2025-04-27T19:57:49Z,shinra358,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16965
auto1111_webui,comment,16965,,"I'd just like to add that things seem to be just as messed up on Linux, at least with AMD hardware.

I had A1111 working perfectly on Arch (Garuda) with a 7900 XT, but at some point it stopped recognizing my card, likely due to an update, and all of my attempts to fix it with a reinstall have failed. 

I've tried, in vain, to get it working with different versions of Python and Torch, and nothing has succeeded. I've spent hours and hours messing around with venv and pyenv and nothing works. 

I think the problem is that my system ROCm libraries are too new. I messed around with Docker, too, but that was too much of a mess, and I got nowhere.

I should note that I can get Invoke and CozyUI to work with no trouble, but I cannot get the same results with them no matter how much I try. They just flat out prompt worse. So don't tell me to switch front ends, I have tried already.",2025-05-12T03:40:12Z,NessusIgnis,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16965#issuecomment-2870713922
auto1111_webui,issue,16961,"[Bug]: Does not store ""Use old karras scheduler sigmas (0.1 to 10)."" in metadata","### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

if you check ""Use old karras scheduler sigmas (0.1 to 10)."" it is not stored in the image metadata. So when you try to reproduce the image ""Use old karras scheduler sigmas (0.1 to 10)."" is not checked.

### Steps to reproduce the problem

1. Enable ""Use_old_karras_scheduler_sigmas"" in the: Settings > Userinterface >Quicksettings List
2. Reload interface
3. Create an image while checking ""Use old karras scheduler sigmas (0.1 to 10)""
4. Drag and drop created image in PNG info window. 
5. The use old karras scheduler sigma settings is not stored.

### What should have happened?

Should have stored the ""Use old karras scheduler sigmas (0.1 to 10)"" flag.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-26-17-22.json](https://github.com/user-attachments/files/19924222/sysinfo-2025-04-26-17-22.json)

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments:
No module 'xformers'. Proceeding without it.
CHv1.8.13: Get Custom Model Folder
CivitAI Browser+: Aria2 RPC started
Using sqlite file: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-agent-scheduler\task_scheduler.sqlite3
ControlNet preprocessor location: P:\SD\sd-webui-1.10\webui\extensions\sd-webui-controlnet\annotator\downloads
2025-04-26 18:25:04,633 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [42546b14d2] from P:\SD\sd-webui-1.10\webui\models\Stable-diffusion\SD\SardonyxBlend_v12_â´42546B14D2âµ.safetensors
CHv1.8.13: Set Proxy:
Creating model from config: P:\SD\sd-webui-1.10\webui\configs\v1-inference.yaml
C:\Users\Saber\AppData\Local\Programs\Python\Python310\lib\site-packages\huggingface_hub\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-04-26 18:25:05,369 - ControlNet - INFO - ControlNet UI callback registered.
[ERROR]: Config states P:\SD\sd-webui-1.10\webui\config_states\civitai_subfolders.json, ""created_at"" does not exist
Running on local URL:  http://127.0.0.1:7860

Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB

To create a public link, set `share=True` in `launch()`.
IIB Database file has been successfully backed up to the backup folder.
Startup time: 15.9s (prepare environment: 3.0s, import torch: 4.0s, import gradio: 0.8s, setup paths: 0.6s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 2.8s, create ui: 1.8s, gradio launch: 0.2s, app_started_callback: 1.9s).
Loading VAE weights specified in settings: P:\SD\sd-webui-1.10\webui\models\VAE\vae-ft-mse-840000-ema-pruned_â´735E4C3A44âµ.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 4.6s (create model: 0.5s, apply weights to model: 3.1s, apply half(): 0.3s, load VAE: 0.2s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.1s).
```

### Additional information

_No response_",2025-04-26T17:26:31Z,ShardM,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16961
auto1111_webui,issue,16960,"[Bug]: checkpoint merger missing ""none"" option","### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

there is no ""None"" option in the checkpoint merger selector, i have to restart the Stable difussion ui in order to clear the dropdown menues in order to merge 2 checkpoints

### Steps to reproduce the problem

1. go to checkpoint merger
2. select any checkpoints/safetensor files in the 3 dropdown menues
3. merge into new checkpoint/safetensor file
4. restart the UI
5. go to step 1

### What should have happened?

please add a ""none"" at the top of the dropdown menues

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

sys info not required

### Console logs

```Shell
console log not required
```

### Additional information

![Image](https://github.com/user-attachments/assets/a0e75f24-9515-4763-8964-d859817c3752)",2025-04-26T13:43:16Z,johnjacquier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16960
auto1111_webui,issue,16958,[Feature Request]: Toggle to disable editing generation settings,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello! I use A1111 a lot from my mobile device and when it is on landscape mode it is very common I missclick image width or height since those are very close left edge of the screen. Sometimes I don't even notice before generating a gibberish image. I wish there was a toggle somewhere that would allow me to disable editing or freeze those fields. Prompt fields aren't a problem since those at least trigger the keyboard to pop up.

### Proposed workflow

1. In a sensible place there is a checkbox/etc to disable inputs inside `#txt2img_settings`
2. Toggle it to control if generation settings, like image width, should be editable


### Additional information

As a dirty quick fix for myself I did this addition `footer.html` before all other links. It does the job but is not the prererable way to go.

`<a href=""#"" onclick=""javascript:document.getElementById('txt2img_settings').style.display === 'none' ? document.getElementById('txt2img_settings').style.display = 'flex' : document.getElementById('txt2img_settings').style.display = 'none'"">Toggle Gen Info</a> â€ƒâ€¢â€ƒ`",2025-04-24T16:26:09Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958
auto1111_webui,comment,16958,,I am sorry if this is a duplicate. Honestly there is just too many issues to go through even with filtering.,2025-04-24T16:57:20Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-2828278918
auto1111_webui,comment,16958,,"In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` *(like the `Hires. fix` thingy)*. So you can just collapse the settings when you're generating to avoid touching them.",2025-05-29T01:30:24Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-2917974789
auto1111_webui,comment,16958,,"> In the meantime, you can use this [setting](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/shared_options.py#L326), which moves most parameters into an `Accordion` _(like the `Hires. fix` thingy)_. So you can just collapse the settings when you're generating to avoid touching them.

This has worked well but I still wish for an option to ""lock"" or ""freeze"" the various sliders etc. inputs so they would still be visible.",2025-12-06T14:04:06Z,pxnk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16958#issuecomment-3620433958
auto1111_webui,issue,16957,[Feature Request]: Docker compose example,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Can you add in the README an example of ready to use docker-compose.yml to run Stable Diffusion with Nvidia acceleration and API enabled?
I try to run forge as a backend for OpenWebUI, but have some difficulties to make it work.
I need CUDA 12.8 for RTX 5000 support

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-04-24T16:03:49Z,SuperPat45,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16957
auto1111_webui,comment,16957,,I have done a quick docker setup here: https://github.com/VladFlorinIlie/sd-docker,2025-08-24T13:24:53Z,VladFlorinIlie,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16957#issuecomment-3218103751
auto1111_webui,issue,16955,[Bug]: Inpaint and page zoom causes image to dissapear,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I zoom in on img2img canvus using shift and wheel, then come out again, the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place. It works most of the time, but sometimes this bug ruins my workflow and i have to do it agian.

### Steps to reproduce the problem

import an image into img2img, use shift and mouse wheel to zoom in, then zoom out, the image will not be centered, so if you do CRTL + mouse wheel it will change the web browser zoom (im on edge), which puts the image back where it should be. then in some cases the image dissapears. It will still generate but cant do any more inpainting after that. You may have to do it 10 times and it should happen a few times.
Cant remember if it does it on inpaint-sketch, it might.

### What should have happened?

The page zoom should put the image back in the right place.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

Sorry unable to do right now.

### Console logs

```Shell
Nothing in logs other than image generations I was doing.
```

### Additional information

_No response_",2025-04-23T00:34:52Z,palentir,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16955
auto1111_webui,comment,16955,,">  the image is not in the right place. so i do a Edge web browser page zoom using CTRL+wheel, which puts it back in its correct place

why not use hotkey `R` to Reset zoom and canvas position?
> note your mouse needs to be hovering over the canvas",2025-05-03T20:36:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16955#issuecomment-2848798858
auto1111_webui,issue,16954,[Bug]: ROCm version turns stupid (super low quality as if skipping steps),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

The output when using ROCm is severely degraded from what it should be.  Even with maximum steps specified it is as if it has use very few (as if 4 or so) steps.  This happens on multiple installs in multiple systems.  (Please see the greater details below.)

### Steps to reproduce the problem

1. Run with ROCm.
2. Generate an image.
3. Resist the urge to vomit.

### What should have happened?

It should produce an image of standard quality.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

[sysinfo-2025-04-22-15-01.json](https://github.com/user-attachments/files/19852125/sysinfo-2025-04-22-15-01.json)

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on nazo user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.41
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --no-progressbar-hiding --theme dark --listen --medvram
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Loading weights [6ce0161689] from /media/2tbssd/ml/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 22.5s (prepare environment: 6.8s, import torch: 7.0s, import gradio: 0.9s, setup paths: 4.5s, initialize shared: 0.1s, other imports: 0.4s, load scripts: 0.3s, initialize extra networks: 0.3s, create ui: 0.4s, gradio launch: 1.7s).
Creating model from config: /media/2tbssd/ml/stable-diffusion-webui/configs/v1-inference.yaml
/media/2tbssd/ml/stable-diffusion-webui/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
warnings.warn(
Applying attention optimization: Doggettx... done.
Model loaded in 263.3s (load weights from disk: 94.4s, create model: 5.5s, apply weights to model: 87.6s, apply half(): 61.9s, apply dtype to VAE: 2.2s, hijack: 0.5s, load textual inversion embeddings: 0.1s, calculate empty prompt: 10.8s).
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [01:17<00:00,  1.93it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [01:05<00:00,  2.28it/s]
Total progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [01:05<00:00,  6.82it/s]
```

### Additional information

First, to clarify, I use the term stupid because when I first saw this occur I was on Arch and I also was having issues with KoboldCPP (LLM engine built on llama.cpp) where it would produce output that could only be described as stupid.  Failing to follow directions well, almost nonsense output, etc etc.  The intriguing thing about that was I also have a Linux Mint installation as a stable backup and when I ran Stable Diffusion within it at that time it was fine (as was KoboldCPP.)  So I filed Mint away as my stable backup.  I assumed the issue was the ROCm installation itself since Arch is not really supported at all by AMD and is just sort of manually ported by the AUR community.

However, I recently switched to Debian and wanted to try again.  Debian is sort of unofficially supported by AMD (they even have official setup instructions for Debian 12 now.)  In Debian, KoboldCPP was fine, so I tried StableDiffusion and at first it was fine.  I messed something up somewhere along the way of installing a bunch of stuff on the Debian system, so I decided to reinstall StableDiffusion (and accidentally deleted the old one instead of backing it up.  Turns out if you accidentally mv a folder to the same name as another folder it just quietly disappears into the void instead.)  When I reinstalled StableDiffusion it was broken like this again.  So I gave up and tried it in Mint, but it was broken in Mint too.  I tried deleting the folder and reinstalling in Mint, but it was still broken.  I also tried completely redoing my Debian system from scratch without the stuff StableDiffusion didn't seem to like last time on a fresh clean install and it's _still_ broken.  I want to add here that since the Mint setup is intended to be my ""stable"" backup, I don't update it.  Nothing has changed in it since the last time StableDiffusion worked.  So first I want to strongly emphasize that this setup was working as-is before and it is now failing where it worked before with a fresh installation.

Now, I want to add here that in both Mint and Debian, KoboldCPP works fine with ROCm.  The LLM acts completely normal.  The issue I saw outside of StableDiffusion is not present in Debian.  Thus I believe it is safe to say the issue here is _not_ the ROCm installation after all.  (I just assumed it was since I had such similar results in two different things back on Arch, but after all pytorch is separate.)  I've reinstalled several times in either the Mint setup or the Debian setup, but the results are the same every time.  I've tried a number of different parameters including the suggested --precision full and --no-half or alternately --upcast-sampling and various combinations of the three with no change in results.  Those weren't needed before anyway.  (Yes, it worked fine before without any of them.  No crash, no errors.)  I've tried a completely clean setup with no extensions or themes or anything and I've tried going through every single setting I could think of that could in _any_ way affect output quality.  I've tried with the system Python (3.11 in the case of Debian Bookworm, so I was surprised it worked as-is) and with Miniconda3 (since it seems to prefer 3.10.)  I've even tried manually installing different pytorch installations into the venv just to see what would happen (even the official AMD pytorch release just to see.)  Note that the above logs and etc are all made with just a fresh clean install (I only downloaded a few extensions so they'd be available offline) and the default venv, I am only saying that I tried it.  Yes, I even tried it without forcing dark mode on the theme and through all of my eye bleeding I could see the image output was still horrible.

I am not sure if it is related or not, but I should add here that it takes strangely long even to load the model.  As in quite a number of minutes (close to six or so for a non-XL model, even longer for XL) even without --medvram or --lowvram.  First gen takes incredibly long to start too.  Something is definitely going on there, but I don't know if it is related or not.  It doesn't take remotely close to as long to load on my old 3070Ti.  Even swapping models is still faster than six minutes on it.

I've attached a sample of an image generated with 150 (maximum!) steps using the default SD1.5 model.  You wouldn't expect it to be super great since it's only SD1.5, but you'll note that it looks like parts of it were produced at an incredibly low number of steps (like 4 or so) despite me setting the maximum.  (No, low numbers don't produce a good image either, I'm just demonstrating that 150 doesn't produce remotely close to what it should.)  The prompt was just a simple positive ""a person standing in a park and waving"" / negative ""from behind"" (I had to do the negative so it would show the face) which is as simple as it gets.

![Image](https://github.com/user-attachments/assets/38e61cae-5c1b-4f56-af2f-846208762811)",2025-04-22T15:33:21Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16954
auto1111_webui,comment,16954,,"Ok, so this is strange, but I had it working correctly for like two days.  I had gone through messing with all kinds of settings and have no clue whatsoever what did it.  Now it's broken again.  I messed with some setting I guess.  I'm not even sure anymore.

On the parts that get really slow sometimes, I've often noticed git --version hanging in the task list for long periods of time sometimes.  There are all those warnings about resume_download being depreciated showing up a lot.  I tried messing with some of the settings and arguments like --do-not-download-clip and I notice that despite these settings it's still doing a lot of online connections.  It really didn't like it if I tried to make it go all offline.  I'm starting to wonder if maybe Huggingface or one of the other things it's constantly accessing might be limiting connections.  I don't know if that is in any way related or not, but if it requires connections to a server for every single use, that's a problem waiting to happen anyway.  If so, perhaps it broke because I was having connection problems earlier and things were timing out a lot.

I'll keep messing with settings and see if I can narrow something down, but at least I have proved it _can_ work in this setup by having it actually do so for a time.",2025-04-26T05:38:37Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16954#issuecomment-2831873557
auto1111_webui,issue,16950,[Bug]: ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file`,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

it all just happened, because I haven't used A1111 for a long time. Lately I've been experimenting a lot with ComfyUi.

### Steps to reproduce the problem

since the application started.

### What should have happened?

Idk, I have done a clean install, but this still happens.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-04-16-05-27.json](https://github.com/user-attachments/files/19770960/sysinfo-2025-04-16-05-27.json)

### Console logs

```Shell
Creating model from config: E:\AI\TensorRT\webui\configs\v1-inference.yaml
creating model quickly: ValueError
Traceback (most recent call last):
  File ""threading.py"", line 973, in _bootstrap
  File ""threading.py"", line 1016, in _bootstrap_inner
  File ""E:\AI\TensorRT\system\python\lib\site-packages\anyio\_backends\_asyncio.py"", line 807, in run
    result = context.run(func, *args)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\gradio\utils.py"", line 707, in wrapper
    response = f(*args, **kwargs)
  File ""contextlib.py"", line 78, in inner
  File ""E:\AI\TensorRT\webui\extensions\sd-webui-EasyPhoto\scripts\sdwebui.py"", line 64, in __exit__
    sd_models.reload_model_weights()
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 820, in load_model
    sd_model = instantiate_from_config(sd_config.model, state_dict)
  File ""E:\AI\TensorRT\webui\modules\sd_models.py"", line 775, in instantiate_from_config
    return constructor(**params)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 563, in __init__
    self.instantiate_cond_stage(cond_stage_config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\models\diffusion\ddpm.py"", line 630, in instantiate_cond_stage
    model = instantiate_from_config(config)
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\util.py"", line 89, in instantiate_from_config
    return get_obj_from_str(config[""target""])(**config.get(""params"", dict()))
  File ""E:\AI\TensorRT\webui\repositories\stable-diffusion-stability-ai\ldm\modules\encoders\modules.py"", line 104, in __init__
    self.transformer = CLIPTextModel.from_pretrained(version)
  File ""E:\AI\TensorRT\webui\modules\sd_disable_initialization.py"", line 68, in CLIPTextModel_from_pretrained
    res = self.CLIPTextModel_from_pretrained(pretrained_model_name_or_path, *model_args, config=pretrained_model_name_or_path, state_dict={}, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 279, in _wrapper
    return func(*args, **kwargs)
  File ""E:\AI\TensorRT\system\python\lib\site-packages\transformers\modeling_utils.py"", line 3994, in from_pretrained
    raise ValueError(
ValueError: `state_dict` cannot be passed together with a model name or a `gguf_file`. Use one of the two loading strategies.

Failed to create model quickly; will retry using slow method.
Loading VAE weights specified in settings: E:\AI\TensorRT\webui\models\VAE\madebyollin-sdxl-vae-fp16-fix.safetensors
Applying attention optimization: Doggettx... done.
Model loaded in 10.6s (create model: 1.6s, apply weights to model: 8.1s, load VAE: 0.5s, move model to device: 0.2s).
Restoring base VAE
Applying attention optimization: Doggettx... done.
VAE weights loaded.
```

### Additional information

_No response_",2025-04-16T05:28:46Z,farizy4n,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16950
auto1111_webui,comment,16950,,"I also encountered the same problem, how did you solve it in the end?",2025-06-18T08:28:59Z,duzhixing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16950#issuecomment-2983214927
auto1111_webui,issue,16946,[Feature Request]: image size settings presets,"I really appreciate all the work thatâ€™s gone into this projectâ€”itâ€™s an amazing tool. That said, Iâ€™d love to request a small but impactful quality-of-life feature: the ability to create and quickly switch between image size presets. (or have a ready made one in place)

Why This Would Be Helpful:
When generating large batches of images, especially in different resolutions, it can get frustrating having to manually re-enter the width and height values every time. It would be extremely helpful to have a few preset sizes (e.g. 512x512, 768x1024, 1024x1024) that we can select with a single click.

Even just having the ability to define and save custom image size presetsâ€”either in the UI or a config fileâ€”would make the workflow a lot smoother.

Suggested Features:
A dropdown or button group in the UI to select from commonly used image sizes.

Option to define and save custom presets.

Selecting a preset would automatically fill the Width and Height fields.

Manual entry should still be available as a fallback.

Benefits:
Speeds up batch workflows and experimentation.

Reduces repetitive steps and input errors.

Makes the user experience cleaner and more efficient.

Thanks again for your hard work on this project. This small feature would really go a long way for those of us generating lots of content regularly.",2025-04-13T22:13:51Z,ajayeola,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946
auto1111_webui,comment,16946,,"You're wasting your time. A1111 is dead.  Jump to ComfyUI, InvokeAI or whatever takes your fancy",2025-04-13T23:23:28Z,yushan777,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946#issuecomment-2800176291
auto1111_webui,comment,16946,,"on Extention tab > Available tab > search for keyword `Ratio` or `Preset`
you can find a bunch of extensions that does pretty much exactly what you are asking

https://github.com/gutris1/sd-simple-dimension-preset
https://github.com/altoiddealer/--sd-webui-ar-plusplus
https://github.com/xhoxye/sd-webui-ar_xhox
https://github.com/LEv145/--sd-webui-ar-plus
https://github.com/thomasasfk/sd-webui-aspect-ratio-helper
https://github.com/bit9labs/sd-ratio-lock
https://github.com/alemelis/sd-webui-ar
https://github.com/Zyin055/Config-Presets",2025-05-03T20:17:34Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16946#issuecomment-2848789868
auto1111_webui,issue,16945,[Feature Request]: Architecture change support,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

After purchasing the 5080, I ran into the problem of not being able to run my version of webUi. After searching the discussions, I found a working version for my configuration and successfully launched it. However, now I can't change the architecture, being able to use only sd (switching to flux or xl from the previous version doesn't work, because the switchover switch is missing in the UI)

My build is 

![Image](https://github.com/user-attachments/assets/56a4f690-6971-4d33-83c6-b722bb476a55)

### Proposed workflow

1. Install last version from https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16818
2. Launh app
3. No tool to change the architecture 


### Additional information

_No response_",2025-04-12T19:36:58Z,LoksliSpb,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16945
auto1111_webui,issue,16942,VAE,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Hello, I tried to modify the number of output channels of the decoder but failed, the display does not match, can you explain why, I tried to retrain or fine-tune the VAE

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-04-11T06:53:58Z,smy123666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16942
auto1111_webui,issue,16941,[Bug]: Torch is not able to use GPU,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Failed to open

### Steps to reproduce the problem

Click on run.bat dosnt open

### What should have happened?

Open

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

..

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Traceback (most recent call last):
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\steve\Desktop\Stable Diffusion\webui\modules\launch_utils.py"", line 387, in prepare_environment
    raise RuntimeError(
RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
Press any key to continue . . .
```

### Additional information

How do i fix this ?

System info:
AMD Ryzen 7 7800X3D 8-Core Processor              4.20 GHz
32,0 GB RAM
4070 TI Nvidia GPU",2025-04-10T19:32:26Z,Sirfluffykinz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16941
auto1111_webui,comment,16941,,"It may be trying to use the CPU's integrated graphics. You should be able to disable it the motherboard's BIOS settings,

Otherwise, try adding `--device-id 0` or `--device-id 1` to [webui-user.bat](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L6).

> ### Sysinfo
> ..

If you can't open webui, sysinfo can be obtained by adding `--dump-sysinfo` to webui-user.bat.",2025-04-10T21:07:52Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16941#issuecomment-2795170575
auto1111_webui,issue,16939,[Feature Request]: Allow DBclient Connection Port Override for UserLAnd Compatibility,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When launching Stable Diffusion WebUI in a UserLAnd environment on my smartphone, DBclient fails to connect and shows a ""Connection refused"" error. The issue occurs because DBclient is trying to use port 2022 rather than port 22, which is used by the SSH server in UserLAnd.


### Steps to reproduce the problem

1. Install Stable Diffusion WebUI on a smartphone using UserLAnd.
2. Start the webui on a clean installation with no extensions enabled.
3. Launch DBclient from within the WebUI.
4. Observe that DBclient attempts to connect on port 2022 and fails, displaying a ""Connection refused"" error.


### What should have happened?

DBclient should either automatically detect the correct port or provide an option to override the hard-coded port. In a UserLAnd environment, it should be able to connect using port 22, allowing the WebUI to function correctly without throwing a connection error.


### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[Attach the sysinfo file generated from the WebUI settings here. Please ensure that the file does not contain any sensitive information.]


### Console logs

```Shell
[Attach the full command-line/terminal logs from when you started the UI until the error occurred. If the logs are too long, provide a link to a pastebin or similar service.]
```

### Additional information

- The issue exists on a clean installation of the WebUI with all extensions disabled.
- I have encountered this problem on the current version of the WebUI.
- This bug appears to be related to DBclient being hardcoded to use port 2022, which is incompatible with UserLAnd's default SSH configuration on port 22.
ï¼ˆ",2025-04-09T18:48:00Z,yuuki-0723,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939
auto1111_webui,comment,16939,,I fail to follow how this has to do stable-diffusion-webu,2025-05-03T20:32:41Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939#issuecomment-2848796720
auto1111_webui,comment,16939,,"> I fail to follow how this has to do stable-diffusion-webu

Thank you very much for your opinion.
As you pointed out, the problem is not a bug in ""Stable Diffusion WebUI"", but rather is due to a restriction in UserLAnd. The only way to solve it is to find a way to change the port settings used by DBclient on the UserLAnd side, or to have Dropbear wait on port 2022.
However, I thought I'd post this in case any of my comrades who are trying to launch ""Stable Diffusion WebUI"" using a smartphone and UserLAnd are facing the same problem.",2025-05-05T03:25:19Z,yuuki-0723,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16939#issuecomment-2849816531
auto1111_webui,issue,16938,[Bug]: Python version is too recent,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I've just installed required dependencies for Uubuntu (64 bits 24.04.2) as described in the readme. Gave permissions to webui.sh and started it. But it seems that my Python version is too recent.

### Steps to reproduce the problem

1. Install Ubuntu 24.04.2 on your 64bits machine
2. Installed required dependencies as described in the readme
3. Run webui.sh from the terminal

### What should have happened?

WebUi should have installed the stable diffusion program.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't access to WebUi yet.

### Console logs

[pastebin](https://pastebin.com/pNwVgkUG)

### Additional information

This is my configuration

![Image](https://github.com/user-attachments/assets/6f053f34-4578-470b-a30a-72eeca413513)",2025-04-07T13:45:23Z,loloof64,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938
auto1111_webui,comment,16938,,"The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.",2025-04-07T19:30:59Z,ZephyrCodesStuff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2784428022
auto1111_webui,comment,16938,,"A1111 is dead, move to another platform.  ComfUI, Invoke.. you choose",2025-04-13T23:13:37Z,yushan777,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2800172541
auto1111_webui,comment,16938,,"> The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.

2hours to add this to .bat? i think you should step away from the terminal 
:: Force use of Python 3.10.6 explicitly
set PYTHON=",2025-04-19T10:07:00Z,MyNuggets666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2816640484
auto1111_webui,comment,16938,,"> > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> 
> 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=

â€œStep away from the terminalâ€, please do yourself a favour and google what the meaning of â€œrolling releaseâ€ is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.",2025-04-19T19:56:30Z,ZephyrCodesStuff,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2816845740
auto1111_webui,comment,16938,,"> > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > 
> > 
> > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> 
> â€œStep away from the terminalâ€, please do yourself a favour and google what the meaning of â€œrolling releaseâ€ is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.

go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer ' ",2025-04-22T01:04:43Z,MyNuggets666,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2819804622
auto1111_webui,comment,16938,,"> > > > The fact this repo in 2025 still needs Python from 2021 is ridiculous. I've wasted around 2 hours just trying to get it to install the dependencies and start because of this, and I just gave up and went to InvokeAI which worked **beautifully**.
> > > 
> > > 
> > > 2hours to add this to .bat? i think you should step away from the terminal :: Force use of Python 3.10.6 explicitly set PYTHON=
> > 
> > 
> > â€œStep away from the terminalâ€, please do yourself a favour and google what the meaning of â€œrolling releaseâ€ is, and maybe accept that not everyone has as flexible of an environment as you do, to be able to have multiple Python versions installed at once, or have no necessity to use the latest updates.
> 
> go watch a youtube video on what the venv is and than how to use more than 1 version, nothing to do with ' newer '

How about  not being so condescending and provide some help for those that may not be as up to speed as you.  I'm having the same issue as well.  I'd love to be able to install Python 3.10 and torch to support this application, however it appears that they have all been taken down an are no longer available.  So is this thing dead and no longer supported or just behind on updates?  It's looking for old versions of torch and Python.  If you have a place to get Python 3.10, torch 2.0.0, and torchvision 0.15.1 let me know.  Currently oldest version of torch are 2.5.0 and torchvision 0.21.0.   Tks, Jeff.... ",2025-05-13T18:14:54Z,jonesjl,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16938#issuecomment-2877520399
auto1111_webui,issue,16930,[Bug]: Extensions list (lora list sometimes) not properly showing,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After startup the extensions list is not showing up and after hitting ""refresh"" the extension list shows up but is still greyed out. Same thing sometimes happens to the lora/checkpoint list. It then looks like this:
[https://imgur.com/a/gs9hjMx](url)


### Steps to reproduce the problem

1. startup 1111
2. wait for startup to finish
3. open http://127.0.0.1:7860/
4. go to extensions tab or lora/checkpoint list

### What should have happened?

Webui should list all loras/checkpoints and extensions installed

### What browsers do you use to access the UI ?

Chrome

### Sysinfo

Sysinfo:
https://pastebin.com/ievDm8vk

### Console logs

```Shell
CMD log:
https://pastebin.com/hzrE1u7v
```

### Additional information

I believe it's any of my extensions that causes this behaviour as i previusly encountered this. But previously either the cmd log or the sysinfo gave hints on what is going wrong. This time everything appears to load properly",2025-04-01T19:34:14Z,DHow2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16930
auto1111_webui,issue,16924,[Feature Request]: EXTRA_INDEX_URL env var for pip,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have a `EXTRA_INDEX_URL` environment variable like the `INDEX_URL` environment var used in [modules/launch_utils.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/launch_utils.py) to set the pip `--extra-index-url` argument.

Alternative : Deprecate `INDEX_URL` and document using the pip env vars `PIP_INDEX_URL` and `PIP_EXTRA_INDEX_URL`

### Proposed workflow

Set the `EXTRA_INDEX_URL` to something like `https://download.pytorch.org/whl/rocm6.2.4`
Run `launch.py` and let it install requirements using the extra index url and the default implicit one

### Additional information

https://pip.pypa.io/en/stable/cli/pip_install/#cmdoption-extra-index-url",2025-03-28T00:28:01Z,AR2000AR,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16924
auto1111_webui,issue,16917,[Bug]: FINISH ISSUE,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Steps to reproduce the problem

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What should have happened?

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.


### Console logs

```Shell
venv ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in c:\users\krisz\desktop\web ui\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5.zip (177 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'

stderr:   error: subprocess-exited-with-error

  Getting requirements to build wheel did not run successfully.
  exit code: 1

  [27 lines of output]
  Traceback (most recent call last):
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 389, in <module>
      main()
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 373, in main
      json_out[""return_val""] = hook(**hook_input[""kwargs""])
    File ""C:\Users\krisz\Desktop\web ui\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 143, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 334, in get_requires_for_build_wheel
      return self._get_build_requires(config_settings, requirements=[])
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 304, in _get_build_requires
      self.run_setup()
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 522, in run_setup
      super().run_setup(setup_script=setup_script)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\build_meta.py"", line 320, in run_setup
      exec(code, locals())
    File ""<string>"", line 12, in <module>
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 116, in setup
      _install_setup_requires(attrs)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\__init__.py"", line 87, in _install_setup_requires
      dist.parse_config_files(ignore_option_errors=True)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 730, in parse_config_files
      self._parse_config_files(filenames=inifiles)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 599, in _parse_config_files
      opt = self._enforce_underscore(opt, section)
    File ""C:\Users\krisz\AppData\Local\Temp\pip-build-env-fw7gzotl\overlay\Lib\site-packages\setuptools\dist.py"", line 629, in _enforce_underscore
      raise InvalidConfigError(
  setuptools.errors.InvalidConfigError: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.
  [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Getting requirements to build wheel did not run successfully.
exit code: 1

See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
```

### Additional information

_No response_",2025-03-24T19:41:09Z,krisz2333,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16917
auto1111_webui,comment,16917,,https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/16919,2025-03-25T05:06:35Z,paras-B,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16917#issuecomment-2750094436
auto1111_webui,issue,16912,[Feature Request]: about  webui-user.bat,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

when i  have run the  file of  webui-user.bat,  The download speed is too slowã€‚so ,I have already downloaded Partial files  through other means and installed it via pipã€‚next, when i  run  the file  of  webui-user.bat, It still requires downloading the file I've already installedã€‚

### Proposed workflow

Can webui-user.bat skip already installed files


### Additional information

_No response_",2025-03-22T15:15:59Z,KaiXin1977,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912
auto1111_webui,comment,16912,,"Make sure you're installing it in a [venv](https://docs.python.org/3.10/library/venv.html).

Create a venv with `python -m venv venv`
Activate it with `venv\scripts\activate`
Then install your packages with pip

Alternatively, you can use it without a venv by setting [`VENV_DIR`](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/webui-user.bat#L5) to `-`",2025-03-22T23:08:00Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-2745907896
auto1111_webui,comment,16912,,"ĞšĞ¾Ğ³Ğ´Ğ° Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ webui-user.bat Ñƒ Ğ¼ĞµĞ½Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ : unable to create venv directory "" ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ Ğ½Ğµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ. Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ?
",2025-04-03T04:24:46Z,Andryrich,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-2774459307
auto1111_webui,comment,16912,,"> ĞšĞ¾Ğ³Ğ´Ğ° Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ webui-user.bat Ñƒ Ğ¼ĞµĞ½Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ : unable to create venv directory "" ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ Ğ½Ğµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ. Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ?

ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ² webui-user.bar  ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğº ven. Ğ’ Ğ¼Ğ¾ĞµĞ¼  ÑĞ»ÑƒÑ‡Ğ°Ğµ ""set VENV_DIR=E:\stable-diffusion-webui\venv""",2025-10-27T18:50:04Z,N1K0D4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16912#issuecomment-3452815521
auto1111_webui,issue,16910,Someone is impersonating AUTOMATIC1111 for crypto,"Thanks to @Jessiebase and users on Discord
It has been brought to our attention that someone on Twitter (X) is impersonating @AUTOMATIC1111 and using project to promote a crypto wallet
- for details see orignal post #16908

We have not set up any form of donation to this project, nor am I aware that @AUTOMATIC1111 have any personal donation means
As far as I'm aware no one hase been in contact @AUTOMATIC1111 since 2024/10/19

Consider any announcement that did not come directly from GitHub to be a impersonation of some kind",2025-03-21T19:57:32Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16910
auto1111_webui,issue,16908,[Bug]: Someone use your project luanching a token. Is it yourself?,"### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Steps to reproduce the problem

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What should have happened?

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### What browsers do you use to access the UI ?

_No response_

### Sysinfo

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)


### Console logs

```Shell
https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)
```

### Additional information

https://x.com/seiscomo?s=21&t=YG4zKcfDffXGfHUaOo_j-Q
Hi, is this your twitter?
They luanched a token and rug.
![Image](https://github.com/user-attachments/assets/c9658845-2696-4165-8efe-b8f5411c3489)
",2025-03-21T06:59:47Z,Jessiebase,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16908
auto1111_webui,comment,16908,,"99.999999% sure this is not @AUTOMATIC1111 
for context, last I have any communication is on 2024/10/19",2025-03-21T19:22:35Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16908#issuecomment-2744259638
auto1111_webui,issue,16907,[Feature Request]: Newer version of Python,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I was getting a little bit of help from Arch Linux community and when they saw I am installing Python 310 they frowned. I argued: ""Big apps can't really catch up that fast to newer versions of libraries they are using. It break compatibility in nasty ways and there is tradeoff between fixing that and other stuff""
They said: ""That argument falls kinda flat being python 310 is dead and eol for nearly 2 years already and even things like blender are on python 3.13""

### Proposed workflow

I is a software dependency related issue.

### Additional information

_No response_",2025-03-20T06:11:52Z,siakc,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907
auto1111_webui,comment,16907,,"https://devguide.python.org/versions/

Python 3.10 doesn't EOL until 2026.
",2025-03-20T23:10:51Z,jagauthier,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-2741858990
auto1111_webui,comment,16907,,"I did manage to get the whole thing working on a 5090 with Python 3.12... however, not without blood, sweat and tears..
If you are prepared to manually modify filenames, wait for your computer to compile flash attention wheels (that took 5 hours on a 9800X3D) and wanting to go through LOADS of .py files and manually modify very specific lines due to incompatibilities between old python code and new code... be my guest :P

Otherwise, stick to the version advised or wait for the guys that created this and other modules to update everything :)",2025-03-21T10:40:59Z,KickAssDave,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-2742982185
auto1111_webui,comment,16907,,How does one install an older version of Python on linux without clobbering their system-wide Python version?,2025-10-18T10:50:03Z,jasonculligan,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16907#issuecomment-3418212092
auto1111_webui,issue,16902,[Bug]: Unable to install older versions of SD,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Unable to successfully launch older version of SD after installation. Specifically version 1.4.0, 1.5.2 and I think I also tried 1.6.0.

### Steps to reproduce the problem

1. Delete all folders in: %LocalAppData%\pip\Cache
2. Download 1.5.2 from [releases page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases)
3. Install [Python 3.10.6](https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe) (64-bit) (ticking Add to PATH), and [git](https://github.com/git-for-windows/git/releases/download/v2.39.2.windows.1/Git-2.39.2-64-bit.exe)
4. Unzip the 1.5.2 zip file
5. Set the correct paths in the webui-user.bat and then run

### What should have happened?

Get error:

> Launching Web UI with arguments:
> Traceback (most recent call last):
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
>     main()
>   File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
>     start()
>   File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
>     import webui
>   File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
>     import gradio  # noqa: F401
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
>     import gradio.components as components
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
>     from gradio import processing_utils, utils
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
>     class AsyncRequest:
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
>     client = httpx.AsyncClient()
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
>     self._transport = self._init_transport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
>     return AsyncHTTPTransport(
>   File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
>     self._pool = httpcore.AsyncConnectionPool(
> TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
> Press any key to continue . . .

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

NA

### Console logs

```Shell
Creating venv in directory Z:\stable-diffusion-webui-1.5.2\venv using python ""C:\Users\Saber\AppData\Local\Programs\Python\Python310\python.exe""
venv ""Z:\stable-diffusion-webui-1.5.2\venv\Scripts\Python.exe""
fatal: not a git repository (or any of the parent directories): .git
fatal: not a git repository (or any of the parent directories): .git
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: 1.5.2
Commit hash: <none>
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118
Collecting torch==2.0.1
  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-win_amd64.whl (2619.1 MB)
Collecting torchvision==0.15.2
  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-win_amd64.whl (4.9 MB)
Collecting typing-extensions
  Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting filelock
  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
Collecting jinja2
  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Collecting networkx
  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Collecting sympy
  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting pillow!=8.3.*,>=5.3.0
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Collecting numpy
  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)
Collecting MarkupSafe>=2.0
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.10-py3-none-any.whl (70 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Collecting mpmath<1.4,>=1.1.0
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.0.1+cu118 torchvision-0.15.2+cu118 typing-extensions-4.12.2 urllib3-2.3.0

[notice] A new release of pip available: 22.2.1 -> 25.0.1
[notice] To update, run: Z:\stable-diffusion-webui-1.5.2\venv\Scripts\python.exe -m pip install --upgrade pip
Installing gfpgan
Installing clip
Installing open_clip
Cloning Stable Diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)Receiving objects:  77% (447/580), 71.79 MiB | Receiving objects:  79% (459/580), 71.79 MiB | 11.12 MiB/s
Receiving objects: 100% (580/580), 73.44 MiB | 11.03 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into Z:\stable-diffusion-webui-1.5.2\repositories\generative-models...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (499/499), done.
remote: Compressing objects: 100% (136/136), done.
remote: Total 1064 (delta 399), reused 363 (delta 363), pack-reused 565 (from 1)Receiving objects:  95% (1011/1064), 52.Receiving objects:
Receiving objects: 100% (1064/1064), 53.60 MiB | 10.50 MiB/s, done.
Resolving deltas: 100% (560/560), done.
Cloning K-diffusion into Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 4.49 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning CodeFormer into Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\CodeFormer'...
remote: Enumerating objects: 614, done.
remote: Counting objects: 100% (292/292), done.

remote: Total 614 (delta 202), reused 176 (delta 176), pack-reused 322 (from 3)Receiving objects:  98% (602/614), 16.06 MiB | 10.70 MiB/s
Receiving objects: 100% (614/614), 17.31 MiB | 10.72 MiB/s, done.
Resolving deltas: 100% (296/296), done.
Cloning BLIP into Z:\stable-diffusion-webui-1.5.2\repositories\BLIP...
Cloning into 'Z:\stable-diffusion-webui-1.5.2\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 10.35 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements for CodeFormer
Installing requirements
Launching Web UI with arguments:
Traceback (most recent call last):
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 39, in <module>
    main()
  File ""Z:\stable-diffusion-webui-1.5.2\launch.py"", line 35, in main
    start()
  File ""Z:\stable-diffusion-webui-1.5.2\modules\launch_utils.py"", line 390, in start
    import webui
  File ""Z:\stable-diffusion-webui-1.5.2\webui.py"", line 44, in <module>
    import gradio  # noqa: F401
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\__init__.py"", line 3, in <module>
    import gradio.components as components
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\components.py"", line 55, in <module>
    from gradio import processing_utils, utils
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 339, in <module>
    class AsyncRequest:
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\gradio\utils.py"", line 358, in AsyncRequest
    client = httpx.AsyncClient()
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1397, in __init__
    self._transport = self._init_transport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_client.py"", line 1445, in _init_transport
    return AsyncHTTPTransport(
  File ""Z:\stable-diffusion-webui-1.5.2\venv\lib\site-packages\httpx\_transports\default.py"", line 275, in __init__
    self._pool = httpcore.AsyncConnectionPool(
TypeError: AsyncConnectionPool.__init__() got an unexpected keyword argument 'socket_options'
Press any key to continue . . .
```

### Additional information

_No response_",2025-03-19T03:34:46Z,JingJang,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16902
auto1111_webui,issue,16896,"same issue, fixed?","same issue, fixed?

_æœ€åˆç”± Sensanko52123 åœ¨ https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2725201568 å‘å¸ƒ_



It can be opened now, but itâ€™s not completely working. Currently, I can only open it using the following method:

1. Open Command Prompt as Administrator (press Win + R, type cmd, and then press Ctrl + Shift + Enter).


2. Type cd and navigate to the folder where your sd-web-ui is located.


3. Then type webui-user.bat to launch the program.



I can only open it this way at the moment; clicking directly on the file causes an error.


---

This is the error log when trying to start directly:

venv ""C:\stable-diffusion-webui\venv\Scripts\Python.exe""

Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug 1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]

Version: v1.10.1

Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2

Couldn't determine Stable Diffusion XL's hash: 45c443b316737a4ab6e40413d7794a7f5657c19f, attempting autofix...

Fetching all contents for Stable Diffusion XL

warning: safe.directory ''C:/Users/jerem/OneDrive/æ¡Œé¢/å·¥å…·/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/æ¡Œé¢/å·¥å…·/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/æ¡Œé¢/å·¥å…·/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/æ¡Œé¢/å·¥å…·/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

warning: safe.directory ''C:/Users/jerem/OneDrive/æ¡Œé¢/å·¥å…·/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'' not absolute

fatal: detected dubious ownership in repository at 'C:/stable-diffusion-webui/repositories/generative-models'

'C:/stable-diffusion-webui/repositories/generative-models' is owned by:

BUILTIN/Administrators (S-1-5-32-544)

but the current user is:

DESKTOP-9PK31L6/jerem (S-1-5-21-2914250175-1236065574-3379173521-1001)

To add an exception for this directory, call:

git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models

Traceback (most recent call last):

File ""C:\stable-diffusion-webui\launch.py"", line 48, in <module>

main()

File ""C:\stable-diffusion-webui\launch.py"", line 39, in main

prepare_environment()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 413, in prepare_environment

git_clone(stable_diffusion_xl_repo, repo_dir('generative-models'), ""Stable Diffusion XL"", stable_diffusion_xl_commit_hash)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 178, in git_clone

current_hash = run_git(dir, name, 'rev-parse HEAD', None, f""Couldn't determine {name}'s hash: {commithash}"", live=False).strip()

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 166, in run_git

git_fix_workspace(dir, name)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 153, in git_fix_workspace

run(f'""{git}"" -C ""{dir}"" fetch --refetch --no-auto-gc', f""Fetching all contents for {name}"", f""Couldn't fetch {name}"", live=True)

File ""C:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run

raise RuntimeError(""\n"".join(error_bits))

RuntimeError: Couldn't fetch Stable Diffusion XL.

Command: ""git"" -C ""C:\stable-diffusion-webui\repositories\generative-models"" fetch --refetch --no-auto-gc

Error code: 128

Press any key to continue...",2025-03-16T04:20:54Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896
auto1111_webui,comment,16896,,"Hey, I am not a contributor here but I think this issue appears to be related to Git safe directory settings and ownership conflicts in Windows.
To fix it, try running:

`git config --global --add safe.directory C:/stable-diffusion-webui/repositories/generative-models`
If the issue persists, running Command Prompt as Administrator and launching webui-user.bat may help.
Additionally, manually resetting the repo using:

```
cd C:\stable-diffusion-webui\repositories\generative-models
git fetch --all
git reset --hard origin/main
```
might resolve the issue.",2025-03-18T17:57:43Z,minhaj3,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896#issuecomment-2734237948
auto1111_webui,comment,16896,,is this fixed? i'm facing the same problem and i tried the solution mentioned upper but still not fixed...,2025-06-27T22:19:21Z,emai24volts,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16896#issuecomment-3014487979
auto1111_webui,issue,16891,[Bug]:,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

torch don't istalling

### Steps to reproduce the problem

1. Start UI
2. Wait

### What should have happened?

WebUI should start

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

can't generate

### Console logs

```Shell
venv ""V:\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    torch==2.1.2 from https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl#sha256=9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9:
        Expected sha256 9925143dece0e63c5404a72d59eb668ef78795418e96b576f94d75dcea6030b9
             Got        3edee9eaa79a7a477e6dbd294393416de5527aac9d81ce5a9b37df6759cda4b8

Traceback (most recent call last):
  File ""V:\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""V:\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""V:\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""V:\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

added git pull and --autolaunch",2025-03-14T16:33:29Z,Sensanko52123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891
auto1111_webui,comment,16891,,It looks like the cached copy of torch is corrupt. Run `pip cache remove torch` or `pip cache purge` and try again.,2025-03-17T23:09:50Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891#issuecomment-2731158540
auto1111_webui,comment,16891,,"After doing `pip cache purge`, you can install torch with something like this:
`pip install --no-cache-dir torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121`
 
Or you can also try some earlier version of torch",2025-03-18T18:02:23Z,minhaj3,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16891#issuecomment-2734258856
auto1111_webui,issue,16890,[Bug]: Could not find a version that satisfies the requirement torch==2.0.0a0 on --use-ipex,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when launching webui with python3.10 i get torch cannot be install when usng --use-ipex option, why is that? i dont see that option even in documentation, i only found out about ipex is here 
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/13853

### Steps to reproduce the problem

1. install
2. try with --use-ipex

### What should have happened?

WORK

### What browsers do you use to access the UI ?

Other

### Sysinfo

cant

### Console logs

```Shell
./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
Clone stable-diffusion-webui
################################################################
Cloning into 'stable-diffusion-webui'...
remote: Enumerating objects: 34945, done.
remote: Counting objects: 100% (26/26), done.
remote: Compressing objects: 100% (16/16), done.
remote: Total 34945 (delta 18), reused 10 (delta 10), pack-reused 34919 (from 3)
Receiving objects: 100% (34945/34945), 35.48 MiB | 40.60 MiB/s, done.
Resolving deltas: 100% (24389/24389), done.

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.10.1/venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/usr/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
ERROR: Could not find a version that satisfies the requirement torch==2.0.0a0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0a0+git6c9b55e, 1.13.0a0+gitb1dde16, 1.13.0, 1.13.1, 2.0.0, 2.0.1a0+cxx11.abi, 2.0.1, 2.1.0a0+cxx11.abi, 2.1.0, 2.1.0.post0+cxx11.abi, 2.1.0.post2+cxx11.abi, 2.1.0.post3+cxx11.abi, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.3.1+cxx11.abi, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.5.1+cxx11.abi, 2.6.0)
ERROR: No matching distribution found for torch==2.0.0a0
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 48, in <module>
    main()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/launch.py"", line 39, in main
    prepare_environment()
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""/home/picarica/git/stable-diffusion-webui-1.10.1/stable-diffusion-webui/modules/launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""/home/picarica/git/stable-diffusion-webui-1.10.1/venv/bin/python3.10"" -m pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
Error code: 1
```

### Additional information

_No response_",2025-03-12T19:11:46Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890
auto1111_webui,comment,16890,,"tried renaming fbroken link versions 

-            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.0.0a0 intel-extension-for-pytorch==2.0.110+gitba7f6c1 --extra-index-url {torch_index_url}"")
+            torch_command = os.environ.get('TORCH_COMMAND', f""pip install torch==2.1.0 intel-extension-for-pytorch==2.1.10 --extra-index-url {torch_index_url}"")^M
     requirements_file = os.environ.get('REQS_FILE', ""requirements_versions.txt"")
     requirements_file_for_npu = os.environ.get('REQS_FILE_FOR_NPU', ""requirements_npu.txt"")

but still doeesnt work 
```

$ ./webui.sh --use-ipex

################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on picarica user
################################################################

################################################################
python venv already activate or run without venv: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv
################################################################

################################################################
Launching launch.py...
################################################################
Using TCMalloc: libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec 18 2024, 15:03:22) [GCC 14.2.1 20241116]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing open_clip
Cloning assets into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 2.07 MiB/s, done.
Cloning Stable Diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 3)
Receiving objects: 100% (580/580), 73.44 MiB | 45.91 MiB/s, done.
Resolving deltas: 100% (281/281), done.
Cloning Stable Diffusion XL into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (483/483), done.
remote: Compressing objects: 100% (126/126), done.
remote: Total 1064 (delta 380), reused 357 (delta 357), pack-reused 581 (from 1)
Receiving objects: 100% (1064/1064), 53.60 MiB | 40.44 MiB/s, done.
Resolving deltas: 100% (562/562), done.
Cloning K-diffusion into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (1350/1350), done.
remote: Compressing objects: 100% (444/444), done.
remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)
Receiving objects: 100% (1350/1350), 233.36 KiB | 3.65 MiB/s, done.
Resolving deltas: 100% (951/951), done.
Cloning BLIP into /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP...
Cloning into '/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/repositories/BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 30.40 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Launching Web UI with arguments: --use-ipex
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx', memory monitor disabled
Downloading: ""https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors"" to /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.97G/3.97G [01:11<00:00, 60.0MB/s]
Calculating sha256 for /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 119.9s (prepare environment: 42.0s, import torch: 3.0s, import gradio: 0.5s, setup paths: 0.7s, initialize shared: 0.1s, other imports: 0.3s, list SD models: 72.3s, load scripts: 0.3s, create ui: 0.3s, gradio launch: 0.3s).
6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading weights [6ce0161689] from /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
Creating model from config: /home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/configs/v1-inference.yaml
Applying attention optimization: InvokeAI... done.
loading stable diffusion model: RuntimeError
Traceback (most recent call last):
  File ""/usr/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/usr/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 868, in load_model
    with devices.autocast(), torch.no_grad():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
    if has_xpu() or has_mps() or cuda_no_autocast():
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
    device_id = get_cuda_device_id()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
    ) or torch.cuda.current_device()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
    _lazy_init()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx


Stable diffusion model failed to load
changing setting sd_model_checkpoint to v1-5-pruned-emaonly.safetensors: RuntimeError
Traceback (most recent call last):
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/options.py"", line 165, in set
    option.onchange()
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 14, in f
    res = func(*args, **kwargs)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/initialize_util.py"", line 181, in <lambda>
    shared.opts.onchange(""sd_model_checkpoint"", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 977, in reload_model_weights
    load_model(checkpoint_info, already_loaded_state_dict=state_dict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 845, in load_model
    load_model_weights(sd_model, checkpoint_info, state_dict, timer)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_models.py"", line 440, in load_model_weights
    model.load_state_dict(state_dict, strict=False)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 223, in <lambda>
    module_load_state_dict = self.replace(torch.nn.Module, 'load_state_dict', lambda *args, **kwargs: load_state_dict(module_load_state_dict, *args, **kwargs))
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/sd_disable_initialization.py"", line 221, in load_state_dict
    original(module, state_dict, strict=strict)
  File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for LatentDiffusion:
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.input_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.middle_block.2.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.0.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.1.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.2.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([2560]) and whose dimensions in the checkpoint are torch.Size([2560]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.norm.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1920]) and whose dimensions in the checkpoint are torch.Size([1920]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([1280]) and whose dimensions in the checkpoint are torch.Size([1280]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.norm.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([960]) and whose dimensions in the checkpoint are torch.Size([960]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.weight"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.in_layers.0.bias"", whose dimensions in the model are torch.Size([640]) and whose dimensions in the checkpoint are torch.Size([640]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.0.out_layers.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.norm.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.weight"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""model.diffusion_model.out.0.bias"", whose dimensions in the model are torch.Size([320]) and whose dimensions in the checkpoint are torch.Size([320]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.down.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.encoder.norm_out.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.attn_1.norm.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.mid.block_2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.0.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.1.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm1.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.0.block.2.norm2.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.0.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.1.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm1.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.weight"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.1.block.2.norm2.bias"", whose dimensions in the model are torch.Size([256]) and whose dimensions in the checkpoint are torch.Size([256]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.2.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.0.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.1.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm1.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.weight"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.up.3.block.2.norm2.bias"", whose dimensions in the model are torch.Size([512]) and whose dimensions in the checkpoint are torch.Size([512]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.weight"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""first_stage_model.decoder.norm_out.bias"", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([128]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_ids"", whose dimensions in the model are torch.Size([1, 77]) and whose dimensions in the checkpoint are torch.Size([1, 77]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.token_embedding.weight"", whose dimensions in the model are torch.Size([49408, 768]) and whose dimensions in the checkpoint are torch.Size([49408, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.embeddings.position_embedding.weight"", whose dimensions in the model are torch.Size([77, 768]) and whose dimensions in the checkpoint are torch.Size([77, 768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.weight"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).
	While copying the parameter named ""cond_stage_model.transformer.text_model.final_layer_norm.bias"", whose dimensions in the model are torch.Size([768]) and whose dimensions in the checkpoint are torch.Size([768]), an exception occurred : ('Cannot copy out of meta tensor; no data!',).

Using already loaded model v1-5-pruned-emaonly.safetensors [6ce0161689]: done in 0.0s
*** Error completing request
*** Arguments: ('task(j9egb4adhyrywz0)', <gradio.routes.Request object at 0x792d6e8bcd00>, 'smal little girlyu dancing aaay', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/processing.py"", line 920, in process_images_inner
        with devices.autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 228, in autocast
        if has_xpu() or has_mps() or cuda_no_autocast():
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 28, in cuda_no_autocast
        device_id = get_cuda_device_id()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/stable-diffusion-webui/modules/devices.py"", line 40, in get_cuda_device_id
        ) or torch.cuda.current_device()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 971, in current_device
        _lazy_init()
      File ""/home/picarica/git/stable-diffusion-webui-1.7.0-RC/venv/lib/python3.10/site-packages/torch/cuda/__init__.py"", line 319, in _lazy_init
        torch._C._cuda_init()
    RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx

---
^CInterrupted with signal 2 in <frame at 0x5923c2036250, file '/usr/lib/python3.10/threading.py', line 324, code wait>


```",2025-03-12T20:48:39Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-2719091658
auto1111_webui,comment,16890,,this issue still presists,2025-03-28T10:59:46Z,picarica,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-2761008956
auto1111_webui,comment,16890,,"https://discuss.pytorch.org/t/solved-pytorch-2-7-1-xpu-intel-arc-graphics-complete-setup-guide-linux/220821

Don't know if this helps. I got it to Work but SD is still using CPU onstead of GPU 

Edit: I've got it working. Please also consider #17047 ",2025-06-28T03:06:43Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3014876020
auto1111_webui,comment,16890,,"In my opinion, SD.Next is a better experience right now if you're using Intel Arc GPUs. I followed the guide here: https://vladmandic.github.io/sdnext-docs/Intel-ARC/

Once I had the driver and Python environment set up, I was generating 512x512 images in about 1 second. Very stable, and no Torch version headaches.",2025-07-10T06:25:59Z,desmondsow,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3055792878
auto1111_webui,comment,16890,,"I tried SD.Next and would agree, BUT SD.Next has a huge downside (for me): it does not support chunking of tokens so you're limited to 75 Tokens. If you don't need more then SD.Next is surely a very good alternative.",2025-07-10T14:27:03Z,DrThodt2021,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16890#issuecomment-3057685464
auto1111_webui,issue,16883,[Bug]: SD 2.1 not working: NansException: A tensor with NaNs was produced in Unet.,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

SD 1.5 is working fine, but 2.1 always gives this error:

NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.

I tried using the ""Upcast cross attention layer to float32"", it just produces random colors junk images.
I tried using the --no-half commandline argument, it gives a different error: ""RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same""
Using the --disable-nan-check just produces completely black images.

I had this issue both on my previous GPU (1080 ti) and my current GPU (5070 ti) on the latest 1111 version. The issue is somewhat fixed by using the commandline argument --opt-sdp-attention but it randomly starts producing junk images again after a while.

### Steps to reproduce the problem

Launch 1111, load SD 2.1 model and try to generate any image at all.

### What should have happened?

No error and the image generating correctly and no requiring workarounds that still don't quite work well.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

```
{
    ""Platform"": ""Windows-10-10.0.19045-SP0"",
    ""Python"": ""3.10.6"",
    ""Version"": ""v1.10.1"",
    ""Commit"": ""82a973c04367123ae98bd9abdf80d9eda9b910e2"",
    ""Git status"": ""On branch master\nYour branch is up to date with 'origin/master'.\n\nnothing to commit, working tree clean"",
    ""Script path"": ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui"",
    ""Data path"": ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui"",
    ""Extensions dir"": ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\extensions"",
    ""Checksum"": ""c3cc7fd239dd28b2e8e8bb58895e72cc061397318d61485fb53c42005a5a2b0b"",
    ""Commandline"": [
        ""launch.py""
    ],
    ""Torch env info"": {
        ""torch_version"": ""2.7.0"",
        ""is_debug_build"": ""False"",
        ""cuda_compiled_version"": ""12.8"",
        ""gcc_version"": null,
        ""clang_version"": null,
        ""cmake_version"": null,
        ""os"": ""Microsoft Windows 10 Pro (10.0.19045 64 bits)"",
        ""libc_version"": ""N/A"",
        ""python_version"": ""3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] (64-bit runtime)"",
        ""python_platform"": ""Windows-10-10.0.19045-SP0"",
        ""is_cuda_available"": ""True"",
        ""cuda_runtime_version"": null,
        ""cuda_module_loading"": ""LAZY"",
        ""nvidia_driver_version"": ""572.70"",
        ""nvidia_gpu_models"": ""GPU 0: NVIDIA GeForce RTX 5070 Ti"",
        ""cudnn_version"": null,
        ""pip_version"": ""pip3"",
        ""pip_packages"": [
            ""numpy==1.26.2"",
            ""open-clip-torch==2.20.0"",
            ""pytorch-lightning==1.9.4"",
            ""torch==2.7.0.dev20250306+cu128"",
            ""torchdiffeq==0.2.3"",
            ""torchmetrics==1.6.2"",
            ""torchsde==0.2.6"",
            ""torchvision==0.22.0.dev20250307+cu128""
        ],
        ""conda_packages"": null,
        ""hip_compiled_version"": ""N/A"",
        ""hip_runtime_version"": ""N/A"",
        ""miopen_runtime_version"": ""N/A"",
        ""caching_allocator_config"": """",
        ""is_xnnpack_available"": ""True"",
        ""cpu_info"": [
            ""Name: AMD Ryzen 7 3800X 8-Core Processor             "",
            ""Manufacturer: AuthenticAMD"",
            ""Family: 107"",
            ""Architecture: 9"",
            ""ProcessorType: 3"",
            ""DeviceID: CPU0"",
            ""CurrentClockSpeed: 3901"",
            ""MaxClockSpeed: 3901"",
            ""L2CacheSize: 4096"",
            ""L2CacheSpeed: None"",
            ""Revision: 28928""
        ]
    },
    ""Exceptions"": [
        {
            ""exception"": ""A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the \""Upcast cross attention layer to float32\"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check."",
            ""traceback"": [
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 74, f"",
                    ""res = list(func(*args, **kwargs))""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 53, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\call_queue.py, line 37, f"",
                    ""res = func(*args, **kwargs)""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\txt2img.py, line 109, txt2img"",
                    ""processed = processing.process_images(p)""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 847, process_images"",
                    ""res = process_images_inner(p)""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\processing.py, line 998, process_images_inner"",
                    ""devices.test_for_nans(samples_ddim, \""unet\"")""
                ],
                [
                    ""A:\\Sin SincronizaciÃ³n\\Chrome\\sd.webui\\webui\\modules\\devices.py, line 265, test_for_nans"",
                    ""raise NansException(message)""
                ]
            ]
        }
    ],
    ""CPU"": {
        ""model"": ""AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD"",
        ""count logical"": 16,
        ""count physical"": 8
    },
    ""RAM"": {
        ""total"": ""64GB"",
        ""used"": ""14GB"",
        ""free"": ""50GB""
    },
    ""Extensions"": [],
    ""Inactive extensions"": [],
    ""Environment"": {
        ""GRADIO_ANALYTICS_ENABLED"": ""False""
    },
    ""Config"": {
        ""ldsr_steps"": 100,
        ""ldsr_cached"": false,
        ""SCUNET_tile"": 256,
        ""SCUNET_tile_overlap"": 8,
        ""SWIN_tile"": 192,
        ""SWIN_tile_overlap"": 8,
        ""SWIN_torch_compile"": false,
        ""hypertile_enable_unet"": false,
        ""hypertile_enable_unet_secondpass"": false,
        ""hypertile_max_depth_unet"": 3,
        ""hypertile_max_tile_unet"": 256,
        ""hypertile_swap_size_unet"": 3,
        ""hypertile_enable_vae"": false,
        ""hypertile_max_depth_vae"": 3,
        ""hypertile_max_tile_vae"": 128,
        ""hypertile_swap_size_vae"": 3,
        ""sd_model_checkpoint"": ""v2-1_768-nonema-pruned.safetensors [ff144a4984]"",
        ""sd_checkpoint_hash"": ""ff144a49841cf383adbc68841272ce639e1032b0a1f0f6586347feb953c244f4"",
        ""outdir_samples"": """",
        ""outdir_txt2img_samples"": ""outputs\\txt2img-images"",
        ""outdir_img2img_samples"": ""outputs\\img2img-images"",
        ""outdir_extras_samples"": ""outputs\\extras-images"",
        ""outdir_grids"": """",
        ""outdir_txt2img_grids"": ""outputs\\txt2img-grids"",
        ""outdir_img2img_grids"": ""outputs\\img2img-grids"",
        ""outdir_save"": ""log\\images"",
        ""outdir_init_images"": ""outputs\\init-images"",
        ""samples_save"": true,
        ""samples_format"": ""png"",
        ""samples_filename_pattern"": """",
        ""save_images_add_number"": true,
        ""save_images_replace_action"": ""Replace"",
        ""grid_save"": true,
        ""grid_format"": ""png"",
        ""grid_extended_filename"": false,
        ""grid_only_if_multiple"": true,
        ""grid_prevent_empty_spots"": false,
        ""grid_zip_filename_pattern"": """",
        ""n_rows"": -1,
        ""font"": """",
        ""grid_text_active_color"": ""#000000"",
        ""grid_text_inactive_color"": ""#999999"",
        ""grid_background_color"": ""#ffffff"",
        ""save_images_before_face_restoration"": false,
        ""save_images_before_highres_fix"": false,
        ""save_images_before_color_correction"": false,
        ""save_mask"": false,
        ""save_mask_composite"": false,
        ""jpeg_quality"": 80,
        ""webp_lossless"": false,
        ""export_for_4chan"": true,
        ""img_downscale_threshold"": 4.0,
        ""target_side_length"": 4000.0,
        ""img_max_size_mp"": 200.0,
        ""use_original_name_batch"": true,
        ""use_upscaler_name_as_suffix"": false,
        ""save_selected_only"": true,
        ""save_write_log_csv"": true,
        ""save_init_img"": false,
        ""temp_dir"": """",
        ""clean_temp_dir_at_start"": false,
        ""save_incomplete_images"": false,
        ""notification_audio"": true,
        ""notification_volume"": 100,
        ""save_to_dirs"": true,
        ""grid_save_to_dirs"": true,
        ""use_save_to_dirs_for_ui"": false,
        ""directories_filename_pattern"": ""[date]"",
        ""directories_max_prompt_words"": 8,
        ""auto_backcompat"": true,
        ""use_old_emphasis_implementation"": false,
        ""use_old_karras_scheduler_sigmas"": false,
        ""no_dpmpp_sde_batch_determinism"": false,
        ""use_old_hires_fix_width_height"": false,
        ""hires_fix_use_firstpass_conds"": false,
        ""use_old_scheduling"": false,
        ""use_downcasted_alpha_bar"": false,
        ""refiner_switch_by_sample_steps"": false,
        ""lora_functional"": false,
        ""extra_networks_show_hidden_directories"": true,
        ""extra_networks_dir_button_function"": false,
        ""extra_networks_hidden_models"": ""When searched"",
        ""extra_networks_default_multiplier"": 1,
        ""extra_networks_card_width"": 0.0,
        ""extra_networks_card_height"": 0.0,
        ""extra_networks_card_text_scale"": 1,
        ""extra_networks_card_show_desc"": true,
        ""extra_networks_card_description_is_html"": false,
        ""extra_networks_card_order_field"": ""Path"",
        ""extra_networks_card_order"": ""Ascending"",
        ""extra_networks_tree_view_style"": ""Dirs"",
        ""extra_networks_tree_view_default_enabled"": true,
        ""extra_networks_tree_view_default_width"": 180.0,
        ""extra_networks_add_text_separator"": "" "",
        ""ui_extra_networks_tab_reorder"": """",
        ""textual_inversion_print_at_load"": false,
        ""textual_inversion_add_hashes_to_infotext"": true,
        ""sd_hypernetwork"": ""None"",
        ""sd_lora"": ""None"",
        ""lora_preferred_name"": ""Alias from file"",
        ""lora_add_hashes_to_infotext"": true,
        ""lora_bundled_ti_to_infotext"": true,
        ""lora_show_all"": false,
        ""lora_hide_unknown_for_versions"": [],
        ""lora_in_memory_limit"": 0,
        ""lora_not_found_warning_console"": false,
        ""lora_not_found_gradio_warning"": false,
        ""cross_attention_optimization"": ""Automatic"",
        ""s_min_uncond"": 0,
        ""s_min_uncond_all"": false,
        ""token_merging_ratio"": 0,
        ""token_merging_ratio_img2img"": 0,
        ""token_merging_ratio_hr"": 0,
        ""pad_cond_uncond"": false,
        ""pad_cond_uncond_v0"": false,
        ""persistent_cond_cache"": true,
        ""batch_cond_uncond"": true,
        ""fp8_storage"": ""Disable"",
        ""cache_fp16_weight"": false,
        ""hide_samplers"": [],
        ""eta_ddim"": 0,
        ""eta_ancestral"": 1,
        ""ddim_discretize"": ""uniform"",
        ""s_churn"": 0,
        ""s_tmin"": 0,
        ""s_tmax"": 0,
        ""s_noise"": 1,
        ""sigma_min"": 0.0,
        ""sigma_max"": 0.0,
        ""rho"": 0.0,
        ""eta_noise_seed_delta"": 0,
        ""always_discard_next_to_last_sigma"": false,
        ""sgm_noise_multiplier"": false,
        ""uni_pc_variant"": ""bh1"",
        ""uni_pc_skip_type"": ""time_uniform"",
        ""uni_pc_order"": 3,
        ""uni_pc_lower_order_final"": true,
        ""sd_noise_schedule"": ""Default"",
        ""skip_early_cond"": 0,
        ""beta_dist_alpha"": 0.6,
        ""beta_dist_beta"": 0.6,
        ""sd_checkpoints_limit"": 1,
        ""sd_checkpoints_keep_in_cpu"": true,
        ""sd_checkpoint_cache"": 0,
        ""sd_unet"": ""Automatic"",
        ""enable_quantization"": false,
        ""emphasis"": ""Original"",
        ""enable_batch_seeds"": true,
        ""comma_padding_backtrack"": 20,
        ""sdxl_clip_l_skip"": false,
        ""CLIP_stop_at_last_layers"": 1,
        ""upcast_attn"": false,
        ""randn_source"": ""GPU"",
        ""tiling"": false,
        ""hires_fix_refiner_pass"": ""second pass"",
        ""enable_prompt_comments"": true,
        ""sd3_enable_t5"": false,
        ""sdxl_crop_top"": 0.0,
        ""sdxl_crop_left"": 0.0,
        ""sdxl_refiner_low_aesthetic_score"": 2.5,
        ""sdxl_refiner_high_aesthetic_score"": 6.0,
        ""sd_vae_checkpoint_cache"": 0,
        ""sd_vae"": ""Automatic"",
        ""sd_vae_overrides_per_model_preferences"": true,
        ""auto_vae_precision_bfloat16"": false,
        ""auto_vae_precision"": true,
        ""sd_vae_encode_method"": ""Full"",
        ""sd_vae_decode_method"": ""Full"",
        ""inpainting_mask_weight"": 1,
        ""initial_noise_multiplier"": 1,
        ""img2img_extra_noise"": 0,
        ""img2img_color_correction"": false,
        ""img2img_fix_steps"": false,
        ""img2img_background_color"": ""#ffffff"",
        ""img2img_editor_height"": 720,
        ""img2img_sketch_default_brush_color"": ""#ffffff"",
        ""img2img_inpaint_mask_brush_color"": ""#ffffff"",
        ""img2img_inpaint_sketch_default_brush_color"": ""#ffffff"",
        ""return_mask"": false,
        ""return_mask_composite"": false,
        ""img2img_batch_show_results_limit"": 32,
        ""overlay_inpaint"": true,
        ""return_grid"": true,
        ""do_not_show_images"": false,
        ""js_modal_lightbox"": true,
        ""js_modal_lightbox_initially_zoomed"": true,
        ""js_modal_lightbox_gamepad"": false,
        ""js_modal_lightbox_gamepad_repeat"": 250.0,
        ""sd_webui_modal_lightbox_icon_opacity"": 1,
        ""sd_webui_modal_lightbox_toolbar_opacity"": 0.9,
        ""gallery_height"": """",
        ""open_dir_button_choice"": ""Subdirectory"",
        ""enable_pnginfo"": true,
        ""save_txt"": false,
        ""add_model_name_to_info"": true,
        ""add_model_hash_to_info"": true,
        ""add_vae_name_to_info"": true,
        ""add_vae_hash_to_info"": true,
        ""add_user_name_to_info"": false,
        ""add_version_to_infotext"": true,
        ""disable_weights_auto_swap"": true,
        ""infotext_skip_pasting"": [],
        ""infotext_styles"": ""Apply if any"",
        ""show_progressbar"": true,
        ""live_previews_enable"": true,
        ""live_previews_image_format"": ""png"",
        ""show_progress_grid"": true,
        ""show_progress_every_n_steps"": 10,
        ""show_progress_type"": ""Approx NN"",
        ""live_preview_allow_lowvram_full"": false,
        ""live_preview_content"": ""Prompt"",
        ""live_preview_refresh_period"": 1000.0,
        ""live_preview_fast_interrupt"": false,
        ""js_live_preview_in_modal_lightbox"": false,
        ""prevent_screen_sleep_during_generation"": true,
        ""keyedit_precision_attention"": 0.1,
        ""keyedit_precision_extra"": 0.05,
        ""keyedit_delimiters"": "".,\\/!?%^*;:{}=`~() "",
        ""keyedit_delimiters_whitespace"": [
            ""Tab"",
            ""Carriage Return"",
            ""Line Feed""
        ],
        ""keyedit_move"": true,
        ""disable_token_counters"": false,
        ""include_styles_into_token_counters"": true,
        ""extra_options_txt2img"": [],
        ""extra_options_img2img"": [],
        ""extra_options_cols"": 1,
        ""extra_options_accordion"": false,
        ""compact_prompt_box"": false,
        ""samplers_in_dropdown"": true,
        ""dimensions_and_batch_together"": true,
        ""sd_checkpoint_dropdown_use_short"": false,
        ""hires_fix_show_sampler"": false,
        ""hires_fix_show_prompts"": false,
        ""txt2img_settings_accordion"": false,
        ""img2img_settings_accordion"": false,
        ""interrupt_after_current"": true,
        ""localization"": ""None"",
        ""quicksettings_list"": [
            ""sd_model_checkpoint""
        ],
        ""ui_tab_order"": [],
        ""hidden_tabs"": [],
        ""ui_reorder_list"": [],
        ""gradio_theme"": ""Default"",
        ""gradio_themes_cache"": true,
        ""show_progress_in_title"": true,
        ""send_seed"": true,
        ""send_size"": true,
        ""enable_reloading_ui_scripts"": false,
        ""api_enable_requests"": true,
        ""api_forbid_local_requests"": true,
        ""api_useragent"": """",
        ""prioritized_callbacks_app_started"": [],
        ""prioritized_callbacks_model_loaded"": [],
        ""prioritized_callbacks_ui_settings"": [],
        ""prioritized_callbacks_infotext_pasted"": [],
        ""prioritized_callbacks_script_unloaded"": [],
        ""prioritized_callbacks_before_ui"": [],
        ""prioritized_callbacks_list_optimizers"": [],
        ""prioritized_callbacks_before_token_counter"": [],
        ""prioritized_callbacks_script_before_process"": [],
        ""prioritized_callbacks_script_process"": [],
        ""prioritized_callbacks_script_post_sample"": [],
        ""prioritized_callbacks_script_on_mask_blend"": [],
        ""prioritized_callbacks_script_postprocess_maskoverlay"": [],
        ""profiling_enable"": false,
        ""profiling_activities"": [
            ""CPU""
        ],
        ""profiling_record_shapes"": true,
        ""profiling_profile_memory"": true,
        ""profiling_with_stack"": true,
        ""profiling_filename"": ""trace.json"",
        ""auto_launch_browser"": ""Local"",
        ""enable_console_prompts"": false,
        ""show_warnings"": false,
        ""show_gradio_deprecation_warnings"": true,
        ""memmon_poll_rate"": 8,
        ""samples_log_stdout"": false,
        ""multiple_tqdm"": true,
        ""enable_upscale_progressbar"": true,
        ""print_hypernet_extra"": false,
        ""list_hidden_files"": true,
        ""disable_mmap_load_safetensors"": false,
        ""hide_ldm_prints"": true,
        ""dump_stacks_on_signal"": false,
        ""face_restoration"": false,
        ""face_restoration_model"": ""CodeFormer"",
        ""code_former_weight"": 0.5,
        ""face_restoration_unload"": false,
        ""postprocessing_enable_in_main_ui"": [],
        ""postprocessing_disable_in_extras"": [],
        ""postprocessing_operation_order"": [],
        ""upscaling_max_images_in_cache"": 5,
        ""postprocessing_existing_caption_action"": ""Ignore"",
        ""ESRGAN_tile"": 192,
        ""ESRGAN_tile_overlap"": 8,
        ""realesrgan_enabled_models"": [
            ""R-ESRGAN 4x+"",
            ""R-ESRGAN 4x+ Anime6B""
        ],
        ""dat_enabled_models"": [
            ""DAT x2"",
            ""DAT x3"",
            ""DAT x4""
        ],
        ""DAT_tile"": 192,
        ""DAT_tile_overlap"": 8,
        ""set_scale_by_when_changing_upscaler"": false,
        ""unload_models_when_training"": false,
        ""pin_memory"": false,
        ""save_optimizer_state"": false,
        ""save_training_settings_to_txt"": true,
        ""dataset_filename_word_regex"": """",
        ""dataset_filename_join_string"": "" "",
        ""training_image_repeats_per_epoch"": 1,
        ""training_write_csv_every"": 500.0,
        ""training_xattention_optimizations"": false,
        ""training_enable_tensorboard"": false,
        ""training_tensorboard_save_images"": false,
        ""training_tensorboard_flush_every"": 120.0,
        ""canvas_hotkey_zoom"": ""Alt"",
        ""canvas_hotkey_adjust"": ""Ctrl"",
        ""canvas_hotkey_shrink_brush"": ""Q"",
        ""canvas_hotkey_grow_brush"": ""W"",
        ""canvas_hotkey_move"": ""F"",
        ""canvas_hotkey_fullscreen"": ""S"",
        ""canvas_hotkey_reset"": ""R"",
        ""canvas_hotkey_overlap"": ""O"",
        ""canvas_show_tooltip"": true,
        ""canvas_auto_expand"": true,
        ""canvas_blur_prompt"": false,
        ""canvas_disabled_functions"": [
            ""Overlap""
        ],
        ""interrogate_keep_models_in_memory"": false,
        ""interrogate_return_ranks"": false,
        ""interrogate_clip_num_beams"": 1,
        ""interrogate_clip_min_length"": 24,
        ""interrogate_clip_max_length"": 48,
        ""interrogate_clip_dict_limit"": 1500.0,
        ""interrogate_clip_skip_categories"": [],
        ""interrogate_deepbooru_score_threshold"": 0.5,
        ""deepbooru_sort_alpha"": true,
        ""deepbooru_use_spaces"": true,
        ""deepbooru_escape"": true,
        ""deepbooru_filter_tags"": """",
        ""disabled_extensions"": [],
        ""disable_all_extensions"": ""none""
    },
    ""Startup"": {
        ""total"": 13.905688762664795,
        ""records"": {
            ""initial startup"": 0.02599954605102539,
            ""prepare environment/checks"": 0.011003732681274414,
            ""prepare environment/git version info"": 0.04699993133544922,
            ""prepare environment/torch GPU test"": 2.5370242595672607,
            ""prepare environment/clone repositores"": 0.14800119400024414,
            ""prepare environment/run extensions installers"": 0.0,
            ""prepare environment"": 2.791030168533325,
            ""launcher"": 0.0029985904693603516,
            ""import torch"": 6.068175315856934,
            ""import gradio"": 1.115126132965088,
            ""setup paths"": 1.5516905784606934,
            ""import ldm"": 0.00800013542175293,
            ""import sgm"": 0.0,
            ""initialize shared"": 0.24499988555908203,
            ""other imports"": 0.3900015354156494,
            ""opts onchange"": 0.0,
            ""setup SD model"": 0.0,
            ""setup codeformer"": 0.0019998550415039062,
            ""setup gfpgan"": 0.019559144973754883,
            ""set samplers"": 0.0,
            ""list extensions"": 0.002000093460083008,
            ""restore config state file"": 0.0,
            ""list SD models"": 0.02800130844116211,
            ""list localizations"": 0.0009987354278564453,
            ""load scripts/custom_code.py"": 0.006000041961669922,
            ""load scripts/img2imgalt.py"": 0.0,
            ""load scripts/loopback.py"": 0.0009999275207519531,
            ""load scripts/outpainting_mk_2.py"": 0.0,
            ""load scripts/poor_mans_outpainting.py"": 0.0010004043579101562,
            ""load scripts/postprocessing_codeformer.py"": 0.0,
            ""load scripts/postprocessing_gfpgan.py"": 0.0009996891021728516,
            ""load scripts/postprocessing_upscale.py"": 0.0,
            ""load scripts/prompt_matrix.py"": 0.0,
            ""load scripts/prompts_from_file.py"": 0.0009996891021728516,
            ""load scripts/sd_upscale.py"": 0.0,
            ""load scripts/xyz_grid.py"": 0.002000093460083008,
            ""load scripts/ldsr_model.py"": 0.2525498867034912,
            ""load scripts/lora_script.py"": 0.15400195121765137,
            ""load scripts/scunet_model.py"": 0.026000261306762695,
            ""load scripts/swinir_model.py"": 0.02499985694885254,
            ""load scripts/hotkey_config.py"": 0.0010001659393310547,
            ""load scripts/extra_options_section.py"": 0.00099945068359375,
            ""load scripts/hypertile_script.py"": 0.04699850082397461,
            ""load scripts/postprocessing_autosized_crop.py"": 0.0,
            ""load scripts/postprocessing_caption.py"": 0.0010008811950683594,
            ""load scripts/postprocessing_create_flipped_copies.py"": 0.0,
            ""load scripts/postprocessing_focal_crop.py"": 0.003002166748046875,
            ""load scripts/postprocessing_split_oversized.py"": 0.0,
            ""load scripts/soft_inpainting.py"": 0.0010004043579101562,
            ""load scripts/comments.py"": 0.02399754524230957,
            ""load scripts/refiner.py"": 0.0010001659393310547,
            ""load scripts/sampler.py"": 0.0,
            ""load scripts/seed.py"": 0.0010013580322265625,
            ""load scripts"": 0.5495524406433105,
            ""load upscalers"": 0.004997968673706055,
            ""refresh VAE"": 0.0009999275207519531,
            ""refresh textual inversion templates"": 0.0,
            ""scripts list_optimizers"": 0.0019996166229248047,
            ""scripts list_unets"": 0.0,
            ""reload hypernetworks"": 0.0010006427764892578,
            ""initialize extra networks"": 0.015000581741333008,
            ""scripts before_ui_callback"": 0.002999544143676758,
            ""create ui"": 0.5135579109191895,
            ""gradio launch"": 0.6030018329620361,
            ""add APIs"": 0.00899815559387207,
            ""app_started_callback/lora_script.py"": 0.0010001659393310547,
            ""app_started_callback"": 0.0010001659393310547
        }
    },
    ""Packages"": [
        ""accelerate==0.21.0"",
        ""aenum==3.1.15"",
        ""aiofiles==23.2.1"",
        ""aiohappyeyeballs==2.5.0"",
        ""aiohttp==3.11.13"",
        ""aiosignal==1.3.2"",
        ""altair==5.5.0"",
        ""antlr4-python3-runtime==4.9.3"",
        ""anyio==3.7.1"",
        ""async-timeout==5.0.1"",
        ""attrs==25.1.0"",
        ""blendmodes==2022"",
        ""certifi==2025.1.31"",
        ""charset-normalizer==3.4.1"",
        ""clean-fid==0.1.35"",
        ""click==8.1.8"",
        ""clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a"",
        ""colorama==0.4.6"",
        ""contourpy==1.3.1"",
        ""cycler==0.12.1"",
        ""deprecation==2.1.0"",
        ""diskcache==5.6.3"",
        ""einops==0.4.1"",
        ""exceptiongroup==1.2.2"",
        ""facexlib==0.3.0"",
        ""fastapi==0.94.0"",
        ""ffmpy==0.5.0"",
        ""filelock==3.17.0"",
        ""filterpy==1.4.5"",
        ""fonttools==4.56.0"",
        ""frozenlist==1.5.0"",
        ""fsspec==2025.2.0"",
        ""ftfy==6.3.1"",
        ""gitdb==4.0.12"",
        ""GitPython==3.1.32"",
        ""gradio==3.41.2"",
        ""gradio_client==0.5.0"",
        ""h11==0.12.0"",
        ""httpcore==0.15.0"",
        ""httpx==0.24.1"",
        ""huggingface-hub==0.29.2"",
        ""idna==3.10"",
        ""imageio==2.37.0"",
        ""importlib_resources==6.5.2"",
        ""inflection==0.5.1"",
        ""Jinja2==3.1.6"",
        ""jsonmerge==1.8.0"",
        ""jsonschema==4.23.0"",
        ""jsonschema-specifications==2024.10.1"",
        ""kiwisolver==1.4.8"",
        ""kornia==0.6.7"",
        ""lark==1.1.2"",
        ""lazy_loader==0.4"",
        ""lightning-utilities==0.14.0"",
        ""llvmlite==0.44.0"",
        ""MarkupSafe==2.1.5"",
        ""matplotlib==3.10.1"",
        ""mpmath==1.3.0"",
        ""multidict==6.1.0"",
        ""narwhals==1.29.1"",
        ""networkx==3.4.2"",
        ""numba==0.61.0"",
        ""numpy==1.26.2"",
        ""omegaconf==2.2.3"",
        ""open-clip-torch==2.20.0"",
        ""opencv-python==4.11.0.86"",
        ""orjson==3.10.15"",
        ""packaging==24.2"",
        ""pandas==2.2.3"",
        ""piexif==1.1.3"",
        ""Pillow==9.5.0"",
        ""pillow-avif-plugin==1.4.3"",
        ""pip==25.0.1"",
        ""propcache==0.3.0"",
        ""protobuf==3.20.0"",
        ""psutil==5.9.5"",
        ""pydantic==1.10.21"",
        ""pydub==0.25.1"",
        ""pyparsing==3.2.1"",
        ""python-dateutil==2.9.0.post0"",
        ""python-multipart==0.0.20"",
        ""pytorch-lightning==1.9.4"",
        ""pytz==2025.1"",
        ""PyWavelets==1.8.0"",
        ""PyYAML==6.0.2"",
        ""referencing==0.36.2"",
        ""regex==2024.11.6"",
        ""requests==2.32.3"",
        ""resize-right==0.0.2"",
        ""rpds-py==0.23.1"",
        ""safetensors==0.4.2"",
        ""scikit-image==0.21.0"",
        ""scipy==1.15.2"",
        ""semantic-version==2.10.0"",
        ""sentencepiece==0.2.0"",
        ""setuptools==69.5.1"",
        ""six==1.17.0"",
        ""smmap==5.0.2"",
        ""sniffio==1.3.1"",
        ""spandrel==0.3.4"",
        ""spandrel_extra_arches==0.1.1"",
        ""starlette==0.26.1"",
        ""sympy==1.13.3"",
        ""tifffile==2025.2.18"",
        ""timm==1.0.15"",
        ""tokenizers==0.13.3"",
        ""tomesd==0.1.3"",
        ""torch==2.7.0.dev20250306+cu128"",
        ""torchdiffeq==0.2.3"",
        ""torchmetrics==1.6.2"",
        ""torchsde==0.2.6"",
        ""torchvision==0.22.0.dev20250307+cu128"",
        ""tqdm==4.67.1"",
        ""trampoline==0.1.2"",
        ""transformers==4.30.2"",
        ""typing_extensions==4.12.2"",
        ""tzdata==2025.1"",
        ""urllib3==2.3.0"",
        ""uvicorn==0.34.0"",
        ""wcwidth==0.2.13"",
        ""websockets==11.0.3"",
        ""wheel==0.45.1"",
        ""yarl==1.18.3""
    ]
}
```

### Console logs

```Shell
*** Arguments: ('task(p553ty28wmhx6g8)', <gradio.routes.Request object at 0x0000021D9031B7C0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\processing.py"", line 847, in process_images
        res = process_images_inner(p)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\processing.py"", line 998, in process_images_inner
        devices.test_for_nans(samples_ddim, ""unet"")
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\devices.py"", line 265, in test_for_nans
        raise NansException(message)
    modules.devices.NansException: A tensor with NaNs was produced in Unet. This could be either because there's not enough precision to represent the picture, or because your video card does not support half type. Try setting the ""Upcast cross attention layer to float32"" option in Settings > Stable Diffusion or using the --no-half commandline argument to fix this. Use --disable-nan-check commandline argument to disable this check.


Stable diffusion model failed to load
*** Error completing request
*** Arguments: ('task(hua4dyxcv2tgm0o)', <gradio.routes.Request object at 0x00000204D07008B0>, '', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}
    Traceback (most recent call last):
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 74, in f
        res = list(func(*args, **kwargs))
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 53, in f
        res = func(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\call_queue.py"", line 37, in f
        res = func(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\txt2img.py"", line 109, in txt2img
        processed = processing.process_images(p)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\processing.py"", line 830, in process_images
        sd_models.reload_model_weights()
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\sd_models.py"", line 969, in reload_model_weights
        checkpoint_config = sd_models_config.find_checkpoint_config(state_dict, checkpoint_info)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 125, in find_checkpoint_config
        return guess_model_config_from_state_dict(state_dict, info.filename)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 98, in guess_model_config_from_state_dict
        elif is_using_v_parameterization_for_sd2(sd):
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\sd_models_config.py"", line 67, in is_using_v_parameterization_for_sd2
        out = (unet(x_test, torch.asarray([999], device=device), context=test_cond) - x_test).mean().cpu().item()
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\modules\sd_unet.py"", line 91, in UNetModel_forward
        return original_forward(self, x, timesteps, context, *args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 797, in forward
        h = module(h, emb, context)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\repositories\stable-diffusion-stability-ai\ldm\modules\diffusionmodules\openaimodel.py"", line 86, in forward
        x = layer(x)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1751, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\module.py"", line 1762, in _call_impl
        return forward_call(*args, **kwargs)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\webui\extensions-builtin\Lora\networks.py"", line 599, in network_Conv2d_forward
        return originals.Conv2d_forward(self, input)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 554, in forward
        return self._conv_forward(input, self.weight, self.bias)
      File ""A:\Sin SincronizaciÃ³n\Chrome\sd.webui\system\python\lib\site-packages\torch\nn\modules\conv.py"", line 549, in _conv_forward
        return F.conv2d(
    RuntimeError: Input type (float) and bias type (struct c10::Half) should be the same
```

### Additional information

As already mentioned, I already had this bug on my 1080 ti and now have it again on 5070 ti. I made a fresh install, but it's still no use.",2025-03-08T06:25:05Z,fireYtail,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16883
auto1111_webui,comment,16883,,"This bug has apparently existed for months, SD 2.1 is really old now, is it ever gonna be fixed?",2025-03-11T15:38:09Z,fireYtail,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16883#issuecomment-2714802080
auto1111_webui,issue,16882,"[Bug]: Stable Diffusion WebUI Startup Error: Insufficient Memory, Unable to Install Torch","### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When I try to open webui-user.bat in stable-diffusion-webui, I repeatedly encounter the error ""Error code: 1,"" indicating that there is insufficient memory. However, I have 25.6GB/32GB of RAM and 11.4GB/12GB of VRAM, which should be sufficient. I have also tried installing PyTorch and pip, and both were installed correctly, but the problem persists. I also tried running webui-user.bat as an administrator, but this causes it to fail to start, briefly flashing and closing without doing anything.               



### Steps to reproduce the problem

Go to the [Stable Diffusion WebUI] folder (e.g., C:\Users\jerem\stable-diffusion-webui).
Locate and run the webui-user.bat file.
Observe the error message stating ""Insufficient memory"" and that torch cannot be installed, even though there is enough system RAM and GPU memory.
Try running webui-user.bat as an administrator, but the window flashes and disappears without launching properly.
Check the startup logs and find the error message: ""Could not install packages due to an OSError: ('Connection broken: OSError(12, 'Insufficient memory, cannot process this command')"".

### What should have happened?

Under normal circumstances, when I run the webui-user.bat file, Stable Diffusion WebUI should start successfully, and the necessary packages (such as PyTorch and torchvision) should be installed or initialized without any errors. There should be no ""insufficient memory"" error even though the system has sufficient RAM and GPU memory. The startup process should complete smoothly, and I should be able to access the WebUI interface and begin using Stable Diffusion.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

I can't open the web UI, and when I try using --dump-sysinfo, it also throws an error. 

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Requirement already satisfied: torch==2.1.2 in c:\users\jerem\stable-diffusion-webui\venv\lib\site-packages (2.1.2+cu121)
ERROR: Could not install packages due to an OSError: (""Connection broken: OSError(12, 'è¨˜æ†¶é«”è³‡æºä¸è¶³ï¼Œç„¡æ³•è™•ç†æ­¤å‘½ä»¤ã€‚', None, 8, None)"", OSError(12, 'è¨˜æ†¶é«”è³‡æºä¸è¶³ï¼Œç„¡æ³•è™•ç†æ­¤å‘½ä»¤ã€‚', None, 8, None))

WARNING: There was an error checking the latest version of pip.
Traceback (most recent call last):
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""C:\Users\jerem\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""C:\Users\jerem\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""C:\Users\jerem\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
```

### Additional information

_No response_",2025-03-08T04:19:41Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882
auto1111_webui,comment,16882,,"python: 3.10.6

OS: WIN11 23H2

CPU:  i5 14500

GPU:  RTX 4070

RAM:  32G

SSD:  1T+2T



",2025-03-08T14:49:15Z,yakura-OWO,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2708336360
auto1111_webui,comment,16882,,"same issue, fixed?",2025-03-14T16:36:04Z,Sensanko52123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16882#issuecomment-2725201568
auto1111_webui,issue,16881,[Bug]: Failed to install requirements,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

After installing sd.webui, running update.bat and run.bat, run.bat tells me that it can't install the requirements

### Steps to reproduce the problem

1. Download sd.webui.zip
2. Extract it into the clean folder
3. Run update.bat
4. Run run.bat

### What should have happened?

Should have installed the requirements, i guess...

### What browsers do you use to access the UI ?

Other

### Sysinfo

uh... I can't do that until it downloads the requirements

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing requirements
Traceback (most recent call last):
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 48, in <module>
    main()
  File ""G:\Stable_Diffusion\sd.webui\webui\launch.py"", line 39, in main
    prepare_environment()
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""G:\Stable_Diffusion\sd.webui\webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""G:\Stable_Diffusion\sd.webui\system\python\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 1
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0.tar.gz (26 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in g:\stable_diffusion\sd.webui\system\python\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)

stderr: ERROR: Could not install packages due to an OSError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))
```

### Additional information

_No response_",2025-03-06T05:55:42Z,Kylada,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881
auto1111_webui,comment,16881,,"OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?",2025-03-07T17:50:35Z,gaggid,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881#issuecomment-2707056447
auto1111_webui,comment,16881,,"Try `pip cache purge` from the venv?

python packages are distributed via gzip-compressed tarballs. It looks like one of the cached packages contained a malformed tarball. At least that's my theory.",2025-04-02T16:33:56Z,richardsonnick,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16881#issuecomment-2773134592
auto1111_webui,issue,16879,[Bug]: Error code:1 Could't install torch,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Unable to launch webui

### Steps to reproduce the problem

1. Open webui-user.bat
2. Check console

### What should have happened?

Launch the WebUI

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Worked on same PC before just did new clean windows install

### Console logs

```Shell
git: 'PULL' is not a git command. See 'git --help'.
'""E:\A1111\stable-diffusion-webui\venv\Scripts\activate.bat""' is not recognized as an internal or external command,
operable program or batch file.
venv ""E:\A1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Traceback (most recent call last):
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Users\NotDuy\AppData\Local\Programs\Python\Python310\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\__main__.py"", line 29, in <module>
    from pip._internal.cli.main import main as _main
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main.py"", line 9, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\autocompletion.py"", line 10, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\main_parser.py"", line 8, in <module>
    from pip._internal.cli import cmdoptions
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\cmdoptions.py"", line 24, in <module>
    from pip._internal.cli.parser import ConfigOptionParser
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\cli\parser.py"", line 12, in <module>
    from pip._internal.configuration import Configuration, ConfigurationError
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\configuration.py"", line 20, in <module>
    from pip._internal.exceptions import (
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\exceptions.py"", line 13, in <module>
    from pip._vendor.requests.models import Request, Response
  File ""E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\requests\__init__.py"", line 43, in <module>
    from pip._vendor import urllib3
ImportError: cannot import name 'urllib3' from 'pip._vendor' (E:\A1111\stable-diffusion-webui\venv\lib\site-packages\pip\_vendor\__init__.py)
Traceback (most recent call last):
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""E:\A1111\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 381, in prepare_environment
    run(f'""{python}"" -m {torch_command}', ""Installing torch and torchvision"", ""Couldn't install torch"", live=True)
  File ""E:\A1111\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install torch.
Command: ""E:\A1111\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu121
Error code: 1
Press any key to continue . . .
```

### Additional information

_No response_",2025-03-05T02:33:29Z,kazumaduy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16879
auto1111_webui,comment,16879,,"Seems to work if I put the A1111 folder in my C: drive, but would like it to work in my bigger drive",2025-03-05T02:38:46Z,kazumaduy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16879#issuecomment-2699608279
auto1111_webui,issue,16876,[Bug]: function parse_generation_parameter removes lastline if multiple loras are embedded in final text,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

File: modules/infotext_utils.py 
Line(s): 255 -> if len(re_param.findall(lastline)) < 3:

The function parse_generation_parameters from modules/infotext_utils.py has a built in functionality to ignore the last line of a text passed in if len(re_param.findall(lastline)) < 3, when this criteria is met the last line will not be added to the lines variable list.

### Steps to reproduce the problem

Under the scenario a standalone prompt text such as this below is passed in, the last line will be ignored:

promptDescription1, promptDescription2,
<lora: loraname1 v1:1>, <lora: loraname2 v1:1>, <lora: loraname3 v1:1>, extraDescription, etc

### What should have happened?

I believe the loras format <lora: loraname> should be included in the regex so it does not ignore it when multiple ones are called in the last line.

### What browsers do you use to access the UI ?

Mozilla Firefox

### Sysinfo

Could not generate file

### Console logs

```Shell
no console log errors for this bug
```

### Additional information

More curious as to if this is intended to not detect multiple lora formats for a last line in text since most geninfo are not composed of only the prompt.",2025-03-02T09:50:19Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876
auto1111_webui,comment,16876,,"The specific line you are talking about is meant to detect if the infotext contains parameters, such as `Steps:`, `Sampler:`, `Seed:`, etc.

A normal infotext will contain an arbitary number of lines of positive prompts and negative prompts, but the parameters will always be in the last line, hence this script. Also, immediately under that line, it gets added back into the `lines` if the check passes anyway...

**TL;DR:** This does not do what you think it does",2025-03-06T09:05:54Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703230473
auto1111_webui,comment,16876,,"@Haoming02 yeah, real question was if this method ever had a use-case for parsing a text composed of only the prompt info and without the additional geninfo (steps: seed: etc..). this could be transitioned to a feature request if its beyond intended functionality.",2025-03-06T09:58:25Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703361927
auto1111_webui,comment,16876,,"Again, if the `last_line` does not contain parameters, then it is added back into regular `lines` ",2025-03-06T10:00:18Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703366782
auto1111_webui,comment,16876,,"@Haoming02 that is not the case in this scenario, the example I showed the 3 loras on the last line will lead it to be ignored and not added back based on the regex match.
let me know if you get a different result from the text example provided. ğŸ‘",2025-03-06T10:37:09Z,thundaga,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703459037
auto1111_webui,comment,16876,,"Ah, I finally get what you meant

<hr>

**TL;DR:** The current ""[re_param_code](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/v1.10.1/modules/infotext_utils.py#L16)"" also matches the LoRA syntax. So if your last line contains 3 or more LoRAs, then the line will be considered parameters instead.",2025-03-06T13:09:59Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703810335
auto1111_webui,comment,16876,,But... when would this become a problem though?,2025-03-06T13:10:35Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16876#issuecomment-2703811873
auto1111_webui,issue,16874,[Feature Request]: fp16 accumulation,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

The Torch nightly version supports FP16 acceleration (up to the NVIDIA RTX 3000 series).
Users will need to manually manage the Torch nightly version and Xformers,
but it will improve generation speed.

It seems that it is already available in forge&ReForge and ComfyUI.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

https://github.com/bedovyy/stable-diffusion-webui-forge/commit/9f84043
https://github.com/comfyanonymous/ComfyUI/commit/43a74c0",2025-03-01T16:42:29Z,namemechan,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16874
auto1111_webui,issue,16871,[Feature Request]: Add warning when extensions cannot be installed to Extensions > Available tab,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be good for the UI to indicate that extensions cannot currently be installed because --enable-insecure-extension-access wasn't specified at startup.

from log:
AssertionError: extension access disabled because of command line flags



### Proposed workflow

1. Run  webui.sh
2. Select [Extension] tab
3. Select [Available] sub-tab

A warning should precede the list of available extensions. Moreover, the [Install] buttons should be grayed out.

### Additional information

_No response_",2025-03-01T06:05:28Z,tomasohara,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16871
auto1111_webui,issue,16868,[Bug]: loading stable diffusion model: UnpicklingError,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.
Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Stable diffusion model failed to load, exiting

I searched the web for this error and got mostly answers that would add 'weights_only=True', but I don't know where to add this line of code

### Steps to reproduce the problem

1. run run.bat
2. Error occurs

### What should have happened?

WebUI should run successfully.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

I couldn't generate the file.

### Console logs

```Shell
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Commit hash: 48a15821de768fea76e66f26df83df3fddf18f4b
Installing requirements for Web UI
Launching Web UI with arguments: --lowvram --precision full --no-half
F:\AI\stable-diffusion-webui\system\python\lib\site-packages\urllib3\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.gradio.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(
No module 'xformers'. Proceeding without it.
Warning: caught exception 'Torch not compiled with CUDA enabled', memory monitor disabled
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Loading weights [e1441589a6] from F:\AI\stable-diffusion-webui\webui\models\Stable-diffusion\v1-5-pruned.ckpt
loading stable diffusion model: UnpicklingError
Traceback (most recent call last):
  File ""F:\AI\stable-diffusion-webui\webui\webui.py"", line 104, in initialize
    modules.sd_models.load_model()
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 392, in load_model
    load_model_weights(sd_model, checkpoint_info)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 247, in load_model_weights
    sd = read_state_dict(checkpoint_info.filename)
  File ""F:\AI\stable-diffusion-webui\webui\modules\sd_models.py"", line 222, in read_state_dict
    pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 106, in load
    return load_with_extra(filename, extra_handler=global_extra_handler, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\webui\modules\safe.py"", line 151, in load_with_extra
    return unsafe_torch_load(filename, *args, **kwargs)
  File ""F:\AI\stable-diffusion-webui\system\python\lib\site-packages\torch\serialization.py"", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ModelCheckpoint])` or the `torch.serialization.safe_globals([ModelCheckpoint])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.


Stable diffusion model failed to load, exiting
è¯·æŒ‰ä»»æ„é”®ç»§ç»­. . .
```

### Additional information

_No response_",2025-02-26T13:54:45Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868
auto1111_webui,comment,16868,,"I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem ğŸ˜„ ",2025-02-26T14:25:11Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2685179569
auto1111_webui,comment,16868,,"Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...",2025-02-27T06:42:49Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2687050399
auto1111_webui,comment,16868,,"> Well, you shouldn't be using a `.ckpt` checkpoint nowadays anyway, much less the base `v1-5-pruned` checkpoint which is like 3 years old at this point...

Thank you, I just started using this and am not familiar with the model, can you tell me what model I should use ï¼šï¼‰",2025-02-27T10:28:14Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2687530408
auto1111_webui,comment,16868,,"If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)

btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there",2025-02-27T13:42:08Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2688003154
auto1111_webui,comment,16868,,"> If you're just starting out, try the good ol' reliable [Realistic Vision](https://civitai.com/models/4201?modelVersionId=130072)
> 
> btw, CivitAI is a site that hosts a lot of other checkpoints, you can take a look there

thank you ï¼šï¼‰",2025-02-27T14:19:16Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2688099772
auto1111_webui,comment,16868,,You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.,2025-02-28T02:35:06Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2689573154
auto1111_webui,comment,16868,,"> You're also using a webui version from [January 2023](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/48a15821de768fea76e66f26df83df3fddf18f4b). Update with `git pull` and delete the venv folder.

thanks, I just use [this](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.10.1) to download it",2025-02-28T14:55:02Z,Yeeeeeee123,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2690845776
auto1111_webui,comment,16868,,"> I change sd_models.py:line 222 to `pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location, weights_only=False)`,and I solved my problem ğŸ˜„

yes, modify to False,not True. My line is  323",2025-03-02T04:38:47Z,lapertme2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16868#issuecomment-2692554154
auto1111_webui,issue,16861,[Bug]: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check,"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

The error message is not intuitive. It's a batch file, not an executable. I am a developer but not versed in anything being used. I had the impression that Automatic1111 would just work. Here is the dump for AMD 3800 / 32GB /  RX 6800 / 10 x64 22H2:

> Creating venv in directory D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv using python ""C:\Users\John\AppData\Local\Programs\Python\Python310\python.exe""
> Requirement already satisfied: pip in d:\my documents\desktop\stable-diffusion-webui-1.10.1\venv\lib\site-packages (22.2.1)
> Collecting pip
>   Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)
> Installing collected packages: pip
>   Attempting uninstall: pip
>     Found existing installation: pip 22.2.1
>     Uninstalling pip-22.2.1:
>       Successfully uninstalled pip-22.2.1
> Successfully installed pip-25.0.1
> venv ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\venv\Scripts\Python.exe""
> fatal: not a git repository (or any of the parent directories): .git
> fatal: not a git repository (or any of the parent directories): .git
> Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
> Version: 1.10.1
> Commit hash: <none>
> Installing torch and torchvision
> Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
> Collecting torch==2.1.2
>   Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
> Collecting torchvision==0.16.2
>   Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
> Collecting filelock (from torch==2.1.2)
>   Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
> Collecting typing-extensions (from torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
> Collecting sympy (from torch==2.1.2)
>   Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
> Collecting networkx (from torch==2.1.2)
>   Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
> Collecting jinja2 (from torch==2.1.2)
>   Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
> Collecting fsspec (from torch==2.1.2)
>   Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)
> Collecting numpy (from torchvision==0.16.2)
>   Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl.metadata (60 kB)
> Collecting requests (from torchvision==0.16.2)
>   Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
> Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
>   Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
> Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
>   Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
> Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
>   Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
> Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
>   Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
> Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
>   Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
> Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
>   Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
> Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
>   Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
> Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
> Using cached filelock-3.17.0-py3-none-any.whl (16 kB)
> Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)
> Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
> Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
> Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl (12.9 MB)
> Using cached requests-2.32.3-py3-none-any.whl (64 kB)
> Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
> Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
> Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
> Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
> Using cached idna-3.10-py3-none-any.whl (70 kB)
> Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
> Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
> Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
> Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.2.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.3 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
> Traceback (most recent call last):
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 48, in <module>
>     main()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\launch.py"", line 39, in main
>     prepare_environment()
>   File ""D:\My Documents\Desktop\stable-diffusion-webui-1.10.1\modules\launch_utils.py"", line 387, in prepare_environment
>     raise RuntimeError(
> RuntimeError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check
> Press any key to continue . . .

### Steps to reproduce the problem

Open webui-user.bat

### What should have happened?

The program should make an attempt to not bomb out on this error or at least provide a useful and up-to-date debugging suggestion.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

N/A because it never successfully installed!

### Console logs

```Shell
N/A
```

### Additional information

_No response_",2025-02-23T05:33:01Z,jabcreations,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861
auto1111_webui,comment,16861,,"AMD + Windows not supported, only on linux
please read the installation instructions
https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs
> Windows+AMD support has not officially been made for webui,
but you can install lshqqytiger's fork of webui that uses Direct-ml. https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu

",2025-02-23T09:25:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2676736395
auto1111_webui,comment,16861,,"AMD GPUs are listed, then the index page should probably be updated to say ""AMD on Linux only"" or you'll just keep getting lot of disappointed people posting bugs.

On the upside thank you for the fork recommendation.",2025-02-23T19:02:00Z,jabcreations,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2677064006
auto1111_webui,comment,16861,,"the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 

Windows 10
Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
RTX 2060 12 GB my gpu has been fine with this before 
32GB of ram 

I've done hundreds of clean installs same error
it wont even load  lol this thing a completely dead and garbage project",2025-02-25T12:11:14Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681755463
auto1111_webui,comment,16861,,"> the funny thing is this thing is so broken nothing works anymore im on a RTX 2060 same error nothing i try fixes it he really needs to do a full code rewrite but seeing as there has been no activity at months I highly doubt that's going to be the case 
> 
> Windows 10
> Cuda 11.8 even tried it with Cuda 12.6 and 12.8 
> RTX 2060 12 GB my gpu has been fine with this before 
> 32GB of ram 
> 
> I've done hundreds of clean installs same error
> it wont even load  lol this thing a completely dead and garbage project

I got similar error on windows + rtx3060 several days ago, the problem was in the python version missmatch. (warning appears if this is the case) 

After downgrading python works just fine 

Anyway, I moved to ComfyUI shortly after ",2025-02-25T12:14:33Z,vptyp,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681763336
auto1111_webui,comment,16861,,"i have been using the same Python version  ""3.10.6"" as what was always in the docs
",2025-02-25T12:16:46Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681770103
auto1111_webui,comment,16861,,the other problem is I primarily use it to train models and I haven't found anything else that will allow me,2025-02-25T12:18:41Z,LuciRift,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16861#issuecomment-2681774626
auto1111_webui,issue,16859,[Bug]: Error code: 128,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128

### Steps to reproduce the problem

1. Use webui-user.bat

### What should have happened?

I don't know

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

operagx

### Console logs

```Shell
Traceback (most recent call last):
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 48, in <module>
    main()
  File ""C:\Soft\stable-diffusion-webui-master\launch.py"", line 39, in main
    prepare_environment()
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 412, in prepare_environment
    git_clone(stable_diffusion_repo, repo_dir('stable-diffusion-stability-ai'), ""Stable Diffusion"", stable_diffusion_commit_hash)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 192, in git_clone
    run(f'""{git}"" clone --config core.filemode=false ""{url}"" ""{dir}""', f""Cloning {name} into {dir}..."", f""Couldn't clone {name}"", live=True)
  File ""C:\Soft\stable-diffusion-webui-master\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't clone Stable Diffusion.
Command: ""git"" clone --config core.filemode=false ""https://github.com/Stability-AI/stablediffusion.git"" ""C:\Soft\stable-diffusion-webui-master\repositories\stable-diffusion-stability-ai""
Error code: 128
Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Ğ»ÑĞ±ÑƒÑ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆÑƒ . . .
```

### Additional information

I deleted repositories, not help",2025-02-21T19:15:27Z,PavelVLasovich,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16859
auto1111_webui,comment,16859,,"This might be related to your network.  You can try to see if the network can connect to GitHub.
Then I think what's even more important is that your PyCharm environment has not been set up properly.  
I solved this problem by setting the path for the downloaded git.exe in the Git of Version Control.
",2025-06-19T03:00:24Z,ausch11,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16859#issuecomment-2986429278
auto1111_webui,issue,16858,[Feature Request]: AI Assistant for Prompt Optimization in A1111,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

Iâ€™d like to propose an AI-powered assistant integrated into Automatic1111's WebUI to help users optimize their prompts, troubleshoot issues, and improve image generation results.

Many users struggle with:

Getting the AI to follow instructions like (full-body images, specific poses, avoiding unwanted elements).
Understanding the best settings for samplers, CFG scale, and resolution.
Fixing common issues (bad hands, incorrect poses, composition problems).
Having an AI assistant built into A1111 could help automate prompt improvements, suggest better settings, and troubleshoot generation issues in real time.

How It Could Work
Prompt Optimization:

Suggests refinements to user prompts for better accuracy.
Detects vague or weak prompts and provides improvements.
Example: If a user types ""girl laying on her back,"" but the model struggles, the AI can suggest adding ""top-down view, lying supine, arms resting on ground.""
Smart Setting Recommendations:

Suggests ideal sampling steps, CFG scale, and samplers based on the prompt.
Recommends resolution changes like (if a full-body image is requested but the resolution is too low).
Troubleshooting Mode:

Detects common mistakes (like using a high CFG scale that causes overbaked results).
Offers fixes for weird anatomy, poor hands, awkward compositions.
Integrates with ControlNet/OpenPose to guide users on using pose references.
Why This Would Be a Game-Changer
 Makes A1111 more beginner-friendly.
 Improves accuracy and consistency of image generations.
 Saves users time by automating trial-and-error prompt adjustments.
 Bridges the gap between casual users and advanced features (like ControlNet).

Would love to hear feedback from the community! If thereâ€™s interest, maybe this could be explored as a built-in feature or an extension.


If the A1111 team is open to this, Iâ€™d love for this to be implemented. Maybe it could work as an AI-powered chatbot inside the UI or as a ""Prompt Optimization"" button next to the Generate button.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

i am still a beginner to this (started about a week ago) and you have NO IDEA ! how much ChatGPT helped me on my journey, from guiding my Automatic1111 installation step by step to helping me with setting a good prompts, good CFG scale, using the right sampling method, schedule type, resolution, how to use hires.fix,  refiner, inpaint, and today i installed and used ControlNet successfully for the first time! along with making a styles.csv file and adding all those amazing styles to use and so on, AI has been a god-send for me and helping me on my learning journey, so i thought to myself imagine if everyone can have ChatGPT or any AI at their side to help them get their imagination to life in the right way.
(Sorry for typing too much, tried to make this request clear, simple and informative, I hope everyone love this request)
Much Love and Respect.",2025-02-21T17:06:08Z,4MagicLight4,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16858
auto1111_webui,issue,16856,"[Bug]:sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?","### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [x] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

I installed the WebUI on my newly purchased Macbookï¼ŒAfter the installation, when I executed./webui.sh again, there was an issue,Then I selected a model in the WebUI, but it failed to load.


### Steps to reproduce the problem

1. Execute ./webui.sh in the Shell.
2. Load models in the WebUI.

### What should have happened?

The WebUI can load models normally.

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-19-23-43.json](https://github.com/user-attachments/files/18877124/sysinfo-2025-02-19-23-43.json)

### Console logs

```Shell
reading metadata for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 83, in __init__
    self.metadata = cache.cached_data_for_file('safetensors-metadata', ""checkpoint/"" + name, filename, read_metadata)
  File ""/Users/waylon/stable-diffusion-webui/modules/cache.py"", line 119, in cached_data_for_file
    existing_cache[title] = entry
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?

Calculating sha256 for /Users/waylon/stable-diffusion-webui/models/Stable-diffusion/AnythingV5Ink_v5RE.ckpt: Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Startup time: 3.5s (prepare environment: 0.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 0.3s, initialize shared: 0.1s, other imports: 0.3s, load scripts: 0.1s, create ui: 0.1s, gradio launch: 0.2s).
5b12f296e7577a3e0c832ba60d79d5bfbae0df9f692a00834f97f86283a9c332
loading stable diffusion model: OperationalError
Traceback (most recent call last):
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 973, in _bootstrap
    self._bootstrap_inner()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
    self.run()
  File ""/Users/waylon/miniforge3/envs/py310-sd/lib/python3.10/threading.py"", line 953, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/waylon/stable-diffusion-webui/modules/initialize.py"", line 149, in load_model
    shared.sd_model  # noqa: B018
  File ""/Users/waylon/stable-diffusion-webui/modules/shared_items.py"", line 175, in sd_model
    return modules.sd_models.model_data.get_sd_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 693, in get_sd_model
    load_model()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 802, in load_model
    state_dict = get_checkpoint_state_dict(checkpoint_info, timer)
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 333, in get_checkpoint_state_dict
    sd_model_hash = checkpoint_info.calculate_shorthash()
  File ""/Users/waylon/stable-diffusion-webui/modules/sd_models.py"", line 108, in calculate_shorthash
    self.sha256 = hashes.sha256(self.filename, f""checkpoint/{self.name}"")
  File ""/Users/waylon/stable-diffusion-webui/modules/hashes.py"", line 59, in sha256
    hashes[title] = {
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 823, in __setitem__
    self.set(key, value, retry=True)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 808, in set
    self._row_insert(db_key, raw, now, columns)
  File ""/Users/waylon/stable-diffusion-webui/venv/lib/python3.10/site-packages/diskcache/core.py"", line 857, in _row_insert
    sql(
sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?
```

### Additional information

It seems that other AI tools also have this problem.
- https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669
- https://github.com/easydiffusion/easydiffusion/issues/1905",2025-02-19T23:51:15Z,waylonwang,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856
auto1111_webui,comment,16856,,"the URL to issues you linked is broken so I fixed via editing your post

as of now I'm not able to reproduce the issue
investigate later when I have time",2025-02-20T04:28:42Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670435177
auto1111_webui,comment,16856,,+1,2025-02-20T06:41:38Z,TheShy2024,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670596686
auto1111_webui,comment,16856,,"can someone who is experiencing this issue upload their `cache` dir directory in webui root and upload it here
this might help figuring out what's going on
> I belive you would need to compress it into a zip archive

note: by uploaded this you would essentially upload a list of your all your models info (not the actual models just information about the models) and extensions infos, they could potentially be other things as well created by extensions
normally they shouldn't be anything I personally would consider sensitive in it, but if you're not comfortable with someone knowing what models you have or what extensions you're using, don't upload it.
",2025-02-20T08:41:48Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670814371
auto1111_webui,comment,16856,,"I also experience the same error. ""sqlite3.OperationalError: no such column: ""size"" - should this be a string literal in single-quotes?"". I have extracted the corresponding cache as requested.

[cache.zip](https://github.com/user-attachments/files/18883839/cache.zip)",2025-02-20T09:12:29Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2670885243
auto1111_webui,comment,16856,,"@m-balcewicz 
I looked at your cache and it seems normal (other then it's empty so I'm guessing this is a new installation)
currently I bleive the cache files itself is likely not the issue

can you also share your sysinfo.json
goto: webui setting tab > sysinfo > download sysinfo",2025-02-20T10:21:58Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671067547
auto1111_webui,comment,16856,,"Yes, you're right. It's a new installation. Here is the sysinfoâ€¦

[sysinfo-2025-02-20-10-25.json](https://github.com/user-attachments/files/18884967/sysinfo-2025-02-20-10-25.json)",2025-02-20T10:26:45Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671078997
auto1111_webui,comment,16856,,"someone have a theroy about sqlite 3.49.1 beeing the issue
I wish to know your sqlite version

you should be about to find out by running these command
1. cd to webui root
for you it should be
```
cd ""/Users/martin/Library/Mobile Documents/com~apple~CloudDocs/MYDATA/CODING_WORLD/GITHUB_WORLD/stable-diffusion-webui""
```

2. activate the venv
```
source venv/bin/activate
```
3. run python and read version
```
python -c ""import sqlite3; print(sqlite3.sqlite_version)""
```
this should out put a version number like 3.49.1 or 3.42.0
",2025-02-20T11:22:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671211067
auto1111_webui,comment,16856,,"Well, this looks fine I guess.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
>> 3.49.1
```",2025-02-20T11:28:00Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671222613
auto1111_webui,comment,16856,,"> Well, this looks fine I guess.
> 
> ```
> (venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
> >> 3.49.1
> ```

I think there might be a miscommunication

it is likely that sqlite3 3.49.1 is the cause
base on https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2670889693

3.49.1 was was released around 2 days ago https://www.sqlite.org/changes.html
",2025-02-20T11:36:42Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671241217
auto1111_webui,comment,16856,,"I'm not sure how would you do so but maybe you could try downgrading `sqlite` on mac
note: it may not be called `sqlite`",2025-02-20T11:45:58Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671260902
auto1111_webui,comment,16856,,"It worked out. Now, I am using sqlite 3.42.0.

```
(venv) martin@martins-mbp:stable-diffusion-webui python -c ""import sqlite3; print(sqlite3.sqlite_version)""
3.42.0
```",2025-02-20T12:26:31Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671352257
auto1111_webui,comment,16856,,"seems like it's confirmed to be an issue with sqlite 3.49.1

do you mind testing which version of sqlite works and which doesn't
> I only wrote version 3.42.0 above because my is using this version

also if possible can you write down the instructions on how to downgread on Mac
so that other people can follow your instructions",2025-02-20T12:39:53Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671381528
auto1111_webui,comment,16856,,"I tried to reproduce my error and checked a few settings. 
**Conclusion: sqlite=3.49.1 was no problem, but python=3.12.9 seems to create some errors.** 

I am working with conda environments and use only the conda-forge channel.

The prompt will always be: ""Create an image of the sunrise in the Alpes with a lake in the foreground.""

## sqlite3-42-0
```
conda create --name sqlite3-42-0 python=3.10
conda activate sqlite3-42-0
conda install sqlite=3.42.0
>> 3.42.0 2023-05-16 12:36:15 831d0fb2836b71c9bc51067c49fee4b8f18047814f2ff22d817d25195cf350b0
```
*works fine!*

## sqlite3-43-0
```
conda create --name sqlite3-43-0 python=3.10
conda activate sqlite3-43-0
conda install sqlite=3.43.0
>> 3.43.0 2023-08-24 12:36:59 0f80b798b3f4b81a7bb4233c58294edd0f1156f36b6ecf5ab8e83631d468778c (64-bit)
```
*works fine!*

## sqlite3-44-0
```
conda create --name sqlite3-44-0 python=3.10
conda activate sqlite3-44-0
conda install sqlite=3.44.0
>> 3.44.0 2023-11-01 11:23:50 17129ba1ff7f0daf37100ee82d507aef7827cf38de1866e2633096ae6ad81301 (64-bit)
```
*works fine!

## sqlite3-45-0
```
conda create --name sqlite3-45-0 python=3.10
conda activate sqlite3-45-0
conda install sqlite=3.45
>> 3.45.3 2024-04-15 13:34:05 8653b758870e6ef0c98d46b3ace27849054af85da891eb121e9aaa537f1e8355 (64-bit)
```
*works fine!

## sqlite3-46-0
```
conda create --name sqlite3-46-0 python=3.10
conda activate sqlite3-46-0
conda install sqlite=3.46
>> 3.46.1 2024-08-13 09:16:08 c9c2ab54ba1f5f46360f1b4f35d849cd3f080e6fc2b6c60e91b16c63f69a1e33 (64-bit)
```
*works fine!

## sqlite3-47-0
```
conda create --name sqlite3-47-0 python=3.10
conda activate sqlite3-47-0
conda install sqlite=3.47
>> 3.47.2 2024-12-07 20:39:59 2aabe05e2e8cae4847a802ee2daddc1d7413d8fc560254d93ee3e72c14685b6c (64-bit)
```
*works fine!

## sqlite3-48-0
```
conda create --name sqlite3-48-0 python=3.10
conda activate sqlite3-48-0
conda install sqlite=3.48
>> 3.48.0 2025-01-14 11:05:00 d2fe6b05f38d9d7cd78c5d252e99ac59f1aea071d669830c1ffe4e8966e84010 (64-bit)
```
*works fine!

## sqlite3-49-0
```
conda create --name sqlite3-49-0 python=3.10
conda activate sqlite3-49-0
conda install sqlite=3.49
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!

**The sqlite seems not to be an error during this testing. So I upgraded python.**

## Python Version for sqlite 3-49-0
### Python 3.11
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.11.11
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```
*works fine!*

### Python 3.12
```
conda activate sqlite3-49-0
conda install python=3.11
>> Python 3.12.9
>> 3.49.1 2025-02-18 13:38:58 873d4e274b4988d260ba8354a9718324a1c26187a4ab4c1cc0227c03d0f10e70 (64-bit)
```

This is what I get when I try to reinstall requirements with python==3.12.9
```
pip install -r requirements.txt
```
```
If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for tokenizers
Failed to build tokenizers
ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)
```


Maybe someone else can go through the different python versions. This is one of the created outputs - enjoy.

![Image](https://github.com/user-attachments/assets/16b1998f-b54f-4796-bf08-4f70dbcfccde)",2025-02-20T14:51:07Z,m-balcewicz,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671729533
auto1111_webui,comment,16856,,"@m-balcewicz thanks for testing

for your info
according to https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/2669#issuecomment-2671431755 `@cocktailpeanut` seems to have found the root cause
but you said `3.4.91` works, so maybe they're are some factors at play, I'm not entirely sure at this point.
either way glad that you got it working

---

as for OP well I'm not sure he hasn't replied...
",2025-02-20T15:15:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2671803877
auto1111_webui,comment,16856,,"I had the same issue, I was running sqlite 3.49.1 on python 3.10.16. Downgrading to 3.42.0 solved the issue:

```
The following packages will be DOWNGRADED:

  libsqlite                               3.49.1-h67fdade_1 --> 3.42.0-hcfcfb64_0
  python                         3.10.16-h37870fc_1_cpython --> 3.10.12-h4de0772_0_cpython

```

",2025-02-23T14:59:03Z,iolairus,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2676910082
auto1111_webui,comment,16856,,"
Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need",2025-02-24T07:22:49Z,KazmaBlack,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2677606835
auto1111_webui,comment,16856,,"> Hi, im pretty new to Pinokio and ForgeUI, how do you downgrade? im using windows 11, feel free to ask me whatever you need

I am using anaconda on windows 11. Within the environment I was using, I ran `conda install sqlite=3.42.0` which resulted in the above prompt, then on confirmation the package was downgraded.",2025-02-24T07:42:14Z,iolairus,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2677637940
auto1111_webui,comment,16856,,I ran into the same issue on a fresh install on Windows 10 when installing into a conda environment. Downgrading to 3.42.0 resolves the issue. Seems like the sqllite version needs to be fixed to that version until a PR formally upgrades it.,2025-03-09T18:37:38Z,Ddasch,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2709008508
auto1111_webui,comment,16856,,"If you are here because of https://github.com/mateo-cogeanu/local-ai-mac-setup?tab=readme-ov-file instruction, trying to set up things on MacOS, then:

1. open conda shell
```
eval ""$(/Users/$(whoami)/miniforge3/bin/conda shell.zsh hook)""
```
2. switch to 'stable' venv
```
conda activate stable
```
3. install previous stable libsqlite version(NOTE: 3.49.0 is marked as broken and will not work, but 3.48.0 is ok)
```
 conda install libsqlite=3.48.0
```
4. run ```sh webui.sh``` as stated in the initial manual and enjoy",2025-03-10T22:33:44Z,kkulbatskiy,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2711996376
auto1111_webui,comment,16856,,"I received this error when using diskcache with plotly dash, downgrading sqlite fixed the problem.",2025-03-12T23:34:53Z,aeslaughter,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2719352342
auto1111_webui,comment,16856,,"ONLY for Chinese Users
å¯¹äºä½¿ç”¨ç»˜ä¸–å¯åŠ¨å™¨ï¼Œæ— æ³•é€šè¿‡condaé™çº§çš„æƒ…å†µï¼Œå¯ä»¥é€šè¿‡æ›¿æ¢â€œç»˜ä¸–å¯åŠ¨å™¨_path\.ext\pkgs\libsqlite-3.49.1-h67fdade_1\Library\binâ€ä¸‹çš„dllæ–‡ä»¶è§£å†³

[sqlite3.zip](https://github.com/user-attachments/files/19219843/sqlite3.zip) æ¥è‡ªsqlite3 3.46ç‰ˆæœ¬",2025-03-13T01:09:38Z,yamosin,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2719486320
auto1111_webui,comment,16856,,ç»˜ä¸–å¯åŠ¨å™¨å¯ä»¥ä½¿ç”¨å‘½ä»¤ç«¯ micromamba  install sqlite=3.42.0 ,2025-03-20T14:02:08Z,lemon123789,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2740565896
auto1111_webui,comment,16856,,"åœ¨ä»Šå¤©, å¯ä»¥é€šè¿‡å‡çº§åˆ° 3.49.1 build hee588c1_2 ä¿®å¤, conda-forgeå›¢é˜Ÿä¼¼ä¹åšäº†hotfix
As of today, it can be fixed by upgrading to `3.49.1 build hee588c1_2`, it seems conda-forge team fixed it by patch.

`conda install ""libsqlite>=3.49.1=hee588c1_2""`",2025-04-30T08:34:51Z,aploium,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16856#issuecomment-2841229407
auto1111_webui,issue,16854,[Bug]: Inpainting Mask does not support alpha-white pixels (over API),"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Hi guys,
I'm using Inpainting over the API and want to ask if it's possible to transmit a mask with semi-transparent pixels (alpha channel). This would be very useful for my workflow, and maybe it's just a small bug in Auto1111 that could be fixed easily.

A similar request was already made by Physeo, but it was closed without a solution: https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13089

Currently, if I pass a mask with a black background and pixels with an alpha value between 0 and 255, Automatic1111 does not process them correctly. Instead of interpreting semi-transparent areas as a soft mask, it seems to completely invert or overwrite the mask with solid white, affecting the entire image.

Thanks in advance for your answer! And of course, a huge thanks if this could be fixed :-)

### Steps to reproduce the problem

1. Send an image to the Img2Img Inpainting API.
2. Provide a mask with an alpha channel, where some pixels are semi-transparent.
3. Observe that Automatic1111 incorrectly fills or inverts the mask instead of using the alpha values properly.

### What should have happened?

If I pass a mask with a black background and semi-white pixels (Alpha > 0 && Alpha < 255), those pixels should influence the result less than fully opaque (Alpha = 255) areas. The inpainting process should respect the alpha transparency instead of converting the entire mask to solid white.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-02-18-20-45.json](https://github.com/user-attachments/files/18854281/sysinfo-2025-02-18-20-45.json)

### Console logs

```Shell
---
```

### Additional information

_No response_",2025-02-18T20:59:56Z,peterpernhofer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16854
auto1111_webui,issue,16850,[Bug]:,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i can generate pictures, i have a clean instalattion

### Steps to reproduce the problem

1. I Write Prompt
2. Click on Generate

### What should have happened?

It should have created a picture

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

[sysinfo-2025-02-18-09-57.json](https://github.com/user-attachments/files/18842724/sysinfo-2025-02-18-09-57.json)

### Console logs

```Shell
Traceback (most recent call last):â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.08it/s]
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\routes.py"", line 488, in run_predict
    output = await app.get_blocks().process_api(
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1434, in process_api
    data = self.postprocess_data(fn_index, result[""prediction""], state)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\blocks.py"", line 1335, in postprocess_data
    prediction_value = block.postprocess(prediction_value)
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\components\gallery.py"", line 197, in postprocess
    file_path = str(utils.abspath(file))
  File ""C:\Users\aleja\Downloads\Programs\IA\sd\venv\lib\site-packages\gradio\utils.py"", line 938, in abspath
    if is_symlink or path == path.resolve():  # in case path couldn't be resolved
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 1215, in resolve
    s = self._flavour.resolve(self, strict=strict)
  File ""C:\Users\aleja\anaconda3\lib\pathlib.py"", line 215, in resolve
    s = self._ext_to_normal(_getfinalpathname(s))
OSError: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: 'outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917'
```

### Additional information

_No response_",2025-02-18T09:58:06Z,StreamHubHub,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16850
auto1111_webui,comment,16850,,"I believe the image is currently generated and saved to `outputs\txt2img-images\2025-02-18\00002-1888406001.png`
the issue occurs when it's trying to send the image to the browser

from what I can tell the cause is for some reason on your computer
```py
from pathlib import Path
Path('outputs\\txt2img-images\\2025-02-18\\00002-1888406001.png?1739872343.8075917').resolve()
```
this errors, as a result preventing it from being displayed in the browser
> this works on other computers I have tested

unfortunately I wasn't able to reproduce the issue even using python 3.9.13
I suspect there's something ""different"" at the low level on your computer but I'm not sure what's going on

I would suggest you try python 3.10
or try using our standalone package see [wiki Windows (method 1)](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) ",2025-02-19T03:54:10Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16850#issuecomment-2667448136
auto1111_webui,issue,16847,[Bug]: ERROR: Could not find a version that satisfies the requirement torch==2.3.1 (from versions: 2.6.0),"### Checklist

- [x] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [x] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

While trying to get webui working on my AMD Ryzen 9 7950x, I kept running into the same error everytime I tried to run the `webui-user.bat` that the install guide had as one of the steps. I saw the part that said

> If it looks like it is stuck when installing or running, press enter in the terminal and it should continue.

In my head though, it would be more of a frozen terminal which we've all seen plenty of times. Instead it filled the window with errors complaining about not being able to install torch. I tried everything to get the right version of torch installed, even tried 3 different python versions. Right as I was about to give up, I accidentally mistyped while the `webui-user.bat` window was focused, and it sprang back to life. 

I understand if this bug is hard to track down or something, I'm a dev myself, but the wording on the installation guide **needs** to be more descriptive/clear. At least put something mentioning that it ""freezing"" is actually it acting like it failed with errors.

![Image](https://github.com/user-attachments/assets/cd8b251a-41a1-410b-bb88-f373216f5065)

### Steps to reproduce the problem

1. Install Python 3.10.6
2. Clone the repo: `git clone https://github.com/lshqqytiger/stable-diffusion-webui-directml && cd stable-diffusion-webui-directml && git submodule init && git submodule update`
3. Run `webui-user.bat`
4. Assume installation has failed, because it indicated so

### What should have happened?

It should've just continued on with the installation process, after it provided the warnings and errors as opposed to just sitting there waiting on input.

### What browsers do you use to access the UI ?

Other

### Sysinfo

[sys.txt](https://github.com/user-attachments/files/18814926/sys.txt)

### Console logs

```Shell
webui-user.bat
```

### Additional information

_No response_",2025-02-16T14:09:28Z,lukecp5,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16847
auto1111_webui,comment,16847,,"well you may have installed python 3.10
but because your also have python 3.13.1 installed and have it set as default
it will use the default unless told otherwise

to fix this you should
1. delete venv dir (in your webui root)
2. then edit `webui-user.bat` -> `set PYTHON=<path to your python 3.10 exe>`
3. run again


~~alternatively you could use [method 1 see wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1) it comes with python instide, which means it doesn't care about whether or not you have install python on your system~~
this does not apply to you because you're on a AMD card
I don't know whether or not if the AMD fork has a standalone package similar to us

---

looks like your have a AMD Radeon RX 7800 XT
and your are using https://github.com/lshqqytiger/stable-diffusion-webui-directml
so if it still doesn't work after following the above instructions, you should report your issues to the fork
> I believe they have different installation instructions

---

okay I'm not entire show what's going on with your installation logs now
the first section which they error happens is on python 3.13
but it is Then followed by exception that I'm not sure has succeed or not using python 3.10

with an error of `it's not recognized as a internal or external command`

I'm going to take a guess did you edit `webui-user.bat while `webui-user.bat is being executed

don't quote me on this but if I understand things correct
windows batch script is is is read from storage line by line during runtime
which means if you edit the file while the file is being used some strange behaviors can occur
> different from most other languages that I'm aware of that reads the entire script into memory on load

this may be the cause of
>  it sprang back to life.


you can try this if you want, save this as a `.bat` and run it, edit the file well it is being used
```bat
echo 1 edit the line echo 2 and echo 3 and save, then press any key to continue
pause
echo 2 edit me while paused
pause
echo 3 edit me while paused
pause
```
",2025-02-16T14:55:49Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16847#issuecomment-2661468146
auto1111_webui,issue,16843,[Bug]: stable diffusion not using gpu,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

When using stable diffusion, the gpu of my rtx 3060 is not used, and when opening task manager, it does not appear when extracting images that it is being used ,, I want to use the gpu more since I have 12 GB of vram
Is there a solution to using the gpu so that I can appreciate the fastest image extraction process ØŸ

![Image](https://github.com/user-attachments/assets/3e7a7702-b414-4740-865e-0280eebb377f)

### Steps to reproduce the problem

1

### What should have happened?

1

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

1

### Console logs

```Shell
1
```

### Additional information

1",2025-02-14T23:45:26Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843
auto1111_webui,comment,16843,,"> when opening task manager, it does not appear when extracting images that it is being used

task manager not showing GPU 3D activity is could be normal
> seems to be related to the driver version

most likely it's using GPU but you just don't realize it

> assuming that the screenshot was taken immediately after the image generation finishes

if your instance is indeed NOT using GPU then it should be using CPU, but as you can see there is not spike in CPU activity, so it's most likely using GPU

your post does not contain any other information that would indicate whether or not it is using GPU
no sysinfo.json no logs no time takes to complet the job

if you wish someone to look into this further provide more information",2025-02-15T03:49:57Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2660703232
auto1111_webui,comment,16843,,"
> your post does not contain any other information that would indicate whether or not it is using GPU no sysinfo.json no logs no time takes to complet the job
> 
> if you wish someone to look into this further provide more information

how could i contain the log ,, through terminal screen ? 
@w-e-w 

",2025-02-15T18:23:12Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661034407
auto1111_webui,comment,16843,,"![Image](https://github.com/user-attachments/assets/b9d60fca-b2a2-46d0-beea-2e2d0f4596e7)
@w-e-w  
is this log ? ",2025-02-15T18:30:32Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661037453
auto1111_webui,comment,16843,,"I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 
the speed is around 0.28 it/s

assuming that you're generating with similar settings
3.8 it/s is 13 times faster then 0.28 it/s

you are using GPU",2025-02-15T22:29:11Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2661130257
auto1111_webui,comment,16843,,"> I have a 13700k CPU, if I use CPU to generating 512x512 image with sd1.5 the speed is around 0.28 it/s
> 
> assuming that you're generating with similar settings 3.8 it/s is 13 times faster then 0.28 it/s
> 
> you are using GPU


@w-e-w  but it's not show on my GPU in task manager ,, why ? ",2025-02-19T12:50:51Z,Aivoice96,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2668564610
auto1111_webui,comment,16843,,"> but it's not show on my GPU in task manager ,, why ?

I don't know why GPU activity in task manager is broken
I have my guesses but I don't have any actual proof If those guesses are true
if you want a definitive answer you have to look somewhere else

---

my guess on why task manager does not show the acture load activity in 3D field is purely based on my observations and should not be taken as fact

I believe the 3D activity in task manager only shows when there is some accompanying graphical activity and not just CUDA

the reason of my speculation

my laptop with a discrete GPU (dGPU) GTX 1650, with a Intel internal GPU (iGPU)
the laptop display connect to the iGPU
so the main GPU is the iGPU which handles most of the light weight rendering tasks
the dGPU is only used for heavy tasks such as 3D applications such as games or for CUDA taks such as stable diffusion, the GPU is ""off"" most of the time

the task manager displays 3D activity, which most likely means that they will be some graphical output of some type
when running games it seems to work
but when running stable diffusion which doesn't have a graphical output so I think task manager decides to ignore it
> note by ""task manager"" I'm referring to itself and its dependencies on how it retrieves information such as drivers not just task manager alone

this hypothesis is strengthened by the testing on my main PC, which has a 3090 and iGPU
if I plug my monitors on the dGPU, the 3D activity inside task managner seems to correspond to stable diffusion
but if I plug my monitors on the iGPU (meaning that lightweight tasks suach as desktop rendering are performed by iGPU and dGPU is ""off"" most of the time), when running stable diffusion the task managner only spikes for a brief moment at the beginning of the job then drops to 0%, even though clearly that the dGPU is working

---

a long time ago (possibly 6~9 years ago) I recall there used to be a dedicated CUDA graph in task manager
I think it got removed either by driver update or something

---

I suggest you use HWiNFO if you want to see more reliable GPU activity ",2025-02-19T14:07:14Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2668761592
auto1111_webui,comment,16843,,"
> 
> [@w-e-w](https://github.com/w-e-w) but it's not show on my GPU in task manager ,, why ?

Use the dropdown and pick cuda. You're welcome.

https://gyazo.com/5790f142cd4f10308043dab0604ac709",2025-02-21T08:41:42Z,TheVertexDoctor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2673924147
auto1111_webui,comment,16843,,"> Use the dropdown and pick cuda. You're welcome.

well I did mention that there is CUDA in task manager but it's just not showing on lots of systems for some reason
this has been something that has been bothering me for lots of years

found one answer today that checks out on my system
https://answers.microsoft.com/en-us/windows/forum/all/cuda-not-in-task-manager/a65eed92-828f-4d92-b9c9-cb2666bdd87f

it turns out it's apparently has something to do with `Hardware-accelerated GPU scheduling (HAGS)` 

with HAGS on CUDA and lots of other graphs don't show
| On | Off |
|--------|--------|
| ![Image](https://github.com/user-attachments/assets/86f3e5ca-4380-4bc7-b43b-7b5dee976973) | ![Image](https://github.com/user-attachments/assets/0c44ed13-ce35-40c7-bde6-37d1ba43028a) | 

---

note 1: they could factors other then HAGS that enable of disable thoses graphs

note 2: this is not a recommendation to turn HAGS on or off
some claims that enabling it helps performance while others claim the contrary
",2025-02-21T10:53:31Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2674227716
auto1111_webui,comment,16843,,"AH I see. I have HAGS off, never felt i needed it as I have a 3090 and really haven't had any issues.
",2025-02-21T13:27:16Z,TheVertexDoctor,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16843#issuecomment-2674553509
auto1111_webui,issue,16810,[Bug]: I can't install xFormers,"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i just want to install xformers for make faster images on StableDiffusion but i cant, no matter what i do i cant generate anything

### Steps to reproduce the problem

1. --xformers in webui-user.sh
2. generate a image

### What should have happened?

Xformers should be build for Cuda support

### What browsers do you use to access the UI ?

Other

### Sysinfo

RTX 3060TI
64gb ram

### Console logs

```Shell
raise NotImplementedError(msg)
    NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:
         query       : shape=(2, 1024, 10, 64) (torch.float32)
         key         : shape=(2, 1024, 10, 64) (torch.float32)
         value       : shape=(2, 1024, 10, 64) (torch.float32)
         attn_bias   : <class 'NoneType'>
         p           : 0.0
    `decoderF` is not supported because:
        xFormers wasn't build with CUDA support
        attn_bias type is <class 'NoneType'>
        operator wasn't built - see `python -m xformers.info` for more info
    `flshattF@0.0.0` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
    `tritonflashattF` is not supported because:
        xFormers wasn't build with CUDA support
        dtype=torch.float32 (supported: {torch.float16, torch.bfloat16})
        operator wasn't built - see `python -m xformers.info` for more info
        triton is not available
    `cutlassF` is not supported because:
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
    `smallkF` is not supported because:
        max(query.shape[-1] != value.shape[-1]) > 32
        xFormers wasn't build with CUDA support
        operator wasn't built - see `python -m xformers.info` for more info
        unsupported embed per head: 64
```

### Additional information

NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs: query : shape=(2, 1024, 10, 64) (torch.float32) key : shape=(2, 1024, 10, 64) (torch.float32) value : shape=(2, 1024, 10, 64) (torch.float32) attn_bias : <class 'NoneType'> p : 0.0 `decoderF` is not supported because: xFormers wasn't build with CUDA support attn_bias type is <class 'NoneType'> operator wasn't built - see `python -m xformers.info` for more info `flshattF@0.0.0` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info `tritonflashattF` is not supported because: xFormers wasn't build with CUDA support dtype=torch.float32 (supported: {torch.bfloat16, torch.float16}) operator wasn't built - see `python -m xformers.info` for more info triton is not available `cutlassF` is not supported because: xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info `smallkF` is not supported because: max(query.shape[-1] != value.shape[-1]) > 32 xFormers wasn't build with CUDA support operator wasn't built - see `python -m xformers.info` for more info unsupported embed per head: 64

(Stable Diffusion)",2025-01-26T22:27:23Z,Franches13,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16810
auto1111_webui,comment,16810,,"> I can't install xFormers

I don't believe that's the case ""xformers wasn't build with CUDA support""
if it isn't installed then it will be a completely different error message
I believe it is installed just not correctly

I may have seen similar error messages cause by a a miss match of version between xformers and pytorch
if you want people to actually help you then you would want to provide your sysinfo
> sysinfo is a json file generated by web UI, not two lines, read the issue template instructions

---

because you did not provide sysinfo, the following is pure guesswork
my guess some distro of linux with python 3.12~ as default, irrc the default pytorch that the default version we use is not support on 3.12 and so you install a new version manually
then you use `--xformers` which by default installs a version of xformers meant for the old version of pytorch

if my guess is correct then I will try 
I will try installing xformers yourself manually, overriding what web UI does automatically
or install an old version of python, 3.11 or 3.10 then run web ui usin it",2025-02-04T17:57:51Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16810#issuecomment-2634687587
auto1111_webui,issue,16809,"[Bug]: random crash with ""press any key to continue""","### Checklist

- [x] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

i get a random crash with no error other than ""Press any key to continue..."" popping up, it seems to happen regardless of extensions being active or not, it happens at completely random times (even with zero activity with the program) but much more often during startup or generation. 

### Steps to reproduce the problem

random

### What should have happened?

shoudnt crash

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

[sysinfo-2025-01-25-00-25.json](https://github.com/user-attachments/files/18544173/sysinfo-2025-01-25-00-25.json)

### Console logs

```Shell
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers --ckpt-dir 'J:\Ai\checkpoint' --embeddings-dir 'J:\Ai\embeddings' --autolaunch
*** ""Disable all extensions"" option was set, will only load built-in extensions ***
Press any key to continue . . .
```

### Additional information

_No response_",2025-01-25T00:26:22Z,cain666-4u,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809
auto1111_webui,comment,16809,,"i tried a fresh install of both auto1111 and python, and got this during install:

> Creating venv in directory J:\Ai\stable-diffusion-webui\venv using python ""C:\Users\cain6\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\python.exe""
Requirement already satisfied: pip in j:\ai\stable-diffusion-webui\venv\lib\site-packages (23.0.1)
Collecting pip
  Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.0.1
    Uninstalling pip-23.0.1:
      Successfully uninstalled pip-23.0.1
Successfully installed pip-24.3.1
WARNING: There was an error checking the latest version of pip.
venv ""J:\Ai\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Installing torch and torchvision
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121
Collecting torch==2.1.2
  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl (2473.9 MB)
Collecting torchvision==0.16.2
  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl (5.6 MB)
Collecting filelock (from torch==2.1.2)
  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions (from torch==2.1.2)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting sympy (from torch==2.1.2)
  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.1.2)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.1.2)
  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)
Collecting fsspec (from torch==2.1.2)
  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting numpy (from torchvision==0.16.2)
  Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting requests (from torchvision==0.16.2)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)
  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)
  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)
Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.16.2)
  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.16.2)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)
  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)
Downloading filelock-3.17.0-py3-none-any.whl (16 kB)
Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)
Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl (12.9 MB)
   --------------------------- 12.9/12.9 MB 8.5 MB/s eta 0:00:00
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)
Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
ERROR: Error while checking for conflicts. Please file an issue on pip's issue tracker: https://github.com/pypa/pip/issues/new
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\commands\install.py"", line 584, in _determine_conflicts
    return check_install_conflicts(to_install)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 119, in check_install_conflicts
    would_be_installed = _simulate_installation_of(to_install, package_set)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\operations\check.py"", line 158, in _simulate_installation_of
    dist = abstract_dist.get_metadata_distribution()
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\distributions\wheel.py"", line 34, in get_metadata_distribution
    return get_wheel_distribution(wheel, canonicalize_name(self.req.name))
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\__init__.py"", line 106, in get_wheel_distribution
    return select_backend().Distribution.from_wheel(wheel, canonical_name)
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\pkg_resources.py"", line 139, in from_wheel
    with wheel.as_zipfile() as zf:
  File ""J:\Ai\stable-diffusion-webui\venv\lib\site-packages\pip\_internal\metadata\base.py"", line 679, in as_zipfile
    return zipfile.ZipFile(self.location, allowZip64=True)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1269, in __init__
    self._RealGetContents()
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\zipfile.py"", line 1391, in _RealGetContents
    x.date_time = ( (d>>9)+1980, (d>>5)&0xF, d&0x1F,
TypeError: unsupported operand type(s) for >>: 'ZipInfo' and 'int'
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision
Successfully installed MarkupSafe-3.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2024.12.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 typing-extensions-4.12.2 urllib3-2.3.0
Installing clip
Installing open_clip
Cloning assets into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-webui-assets'...
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (18/18), done.
remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (20/20), 132.70 KiB | 1.98 MiB/s, done.
Cloning Stable Diffusion into J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\stable-diffusion-stability-ai'...
remote: Enumerating objects: 580, done.
remote: Counting objects: 100% (2/2), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 2)
Receiving objects: 100% (580/580), 73.44 MiB | 8.33 MiB/s, done.
Resolving deltas: 100% (283/283), done.
Cloning Stable Diffusion XL into J:\Ai\stable-diffusion-webui\repositories\generative-models...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\generative-models'...
remote: Enumerating objects: 1064, done.
remote: Counting objects: 100% (57/57), done.
remote: Compressing objects: 100% (29/29), done.
remote: Total 1064 (delta 35), reused 28 (delta 28), pack-reused 1007 (from 3)
Receiving objects: 100% (1064/1064), 53.61 MiB | 7.16 MiB/s, done.
Resolving deltas: 100% (544/544), done.
Cloning K-diffusion into J:\Ai\stable-diffusion-webui\repositories\k-diffusion...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\k-diffusion'...
remote: Enumerating objects: 1350, done.
remote: Counting objects: 100% (651/651), done.
remote: Compressing objects: 100% (87/87), done.
remote: Total 1350 (delta 608), reused 566 (delta 564), pack-reused 699 (from 1)
Receiving objects: 100% (1350/1350), 239.59 KiB | 2.75 MiB/s, done.
Resolving deltas: 100% (948/948), done.
Cloning BLIP into J:\Ai\stable-diffusion-webui\repositories\BLIP...
Cloning into 'J:\Ai\stable-diffusion-webui\repositories\BLIP'...
remote: Enumerating objects: 277, done.
remote: Counting objects: 100% (183/183), done.
remote: Compressing objects: 100% (46/46), done.
remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)
Receiving objects: 100% (277/277), 7.04 MiB | 7.50 MiB/s, done.
Resolving deltas: 100% (152/152), done.
Installing requirements
Traceback (most recent call last):
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 48, in <module>
    main()
  File ""J:\Ai\stable-diffusion-webui\launch.py"", line 39, in main
    prepare_environment()
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 423, in prepare_environment
    run_pip(f""install -r \""{requirements_file}\"""", ""requirements"")
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 144, in run_pip
    return run(f'""{python}"" -m pip {command} --prefer-binary{index_url_line}', desc=f""Installing {desc}"", errdesc=f""Couldn't install {desc}"", live=live)
  File ""J:\Ai\stable-diffusion-webui\modules\launch_utils.py"", line 116, in run
    raise RuntimeError(""\n"".join(error_bits))
RuntimeError: Couldn't install requirements.
Command: ""J:\Ai\stable-diffusion-webui\venv\Scripts\python.exe"" -m pip install -r ""requirements_versions.txt"" --prefer-binary
Error code: 3221225477
stdout: Collecting setuptools==69.5.1 (from -r requirements_versions.txt (line 1))
  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)
Collecting GitPython==3.1.32 (from -r requirements_versions.txt (line 2))
  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)
Collecting Pillow==9.5.0 (from -r requirements_versions.txt (line 3))
  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl.metadata (9.7 kB)
Collecting accelerate==0.21.0 (from -r requirements_versions.txt (line 4))
  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)
Collecting blendmodes==2022 (from -r requirements_versions.txt (line 5))
  Using cached blendmodes-2022-py3-none-any.whl.metadata (12 kB)
Collecting clean-fid==0.1.35 (from -r requirements_versions.txt (line 6))
  Using cached clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)
Collecting diskcache==5.6.3 (from -r requirements_versions.txt (line 7))
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting einops==0.4.1 (from -r requirements_versions.txt (line 8))
  Using cached einops-0.4.1-py3-none-any.whl.metadata (10 kB)
Collecting facexlib==0.3.0 (from -r requirements_versions.txt (line 9))
  Using cached facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)
Collecting fastapi==0.94.0 (from -r requirements_versions.txt (line 10))
  Using cached fastapi-0.94.0-py3-none-any.whl.metadata (25 kB)
Collecting gradio==3.41.2 (from -r requirements_versions.txt (line 11))
  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)
Collecting httpcore==0.15 (from -r requirements_versions.txt (line 12))
  Using cached httpcore-0.15.0-py3-none-any.whl.metadata (15 kB)
Collecting inflection==0.5.1 (from -r requirements_versions.txt (line 13))
  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting jsonmerge==1.8.0 (from -r requirements_versions.txt (line 14))
  Using cached jsonmerge-1.8.0-py3-none-any.whl
Collecting kornia==0.6.7 (from -r requirements_versions.txt (line 15))
  Using cached kornia-0.6.7-py2.py3-none-any.whl.metadata (12 kB)
Collecting lark==1.1.2 (from -r requirements_versions.txt (line 16))
  Using cached lark-1.1.2-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting numpy==1.26.2 (from -r requirements_versions.txt (line 17))
  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)
Collecting omegaconf==2.2.3 (from -r requirements_versions.txt (line 18))
  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)
Collecting open-clip-torch==2.20.0 (from -r requirements_versions.txt (line 19))
  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)
Collecting piexif==1.1.3 (from -r requirements_versions.txt (line 20))
  Using cached piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: protobuf==3.20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 21)) (3.20.0)
Collecting psutil==5.9.5 (from -r requirements_versions.txt (line 22))
  Using cached psutil-5.9.5-cp36-abi3-win_amd64.whl.metadata (21 kB)
Collecting pytorch_lightning==1.9.4 (from -r requirements_versions.txt (line 23))
  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)
Collecting resize-right==0.0.2 (from -r requirements_versions.txt (line 24))
  Using cached resize_right-0.0.2-py3-none-any.whl.metadata (551 bytes)
Collecting safetensors==0.4.2 (from -r requirements_versions.txt (line 25))
  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl.metadata (3.9 kB)
Collecting scikit-image==0.21.0 (from -r requirements_versions.txt (line 26))
  Using cached scikit_image-0.21.0-cp310-cp310-win_amd64.whl.metadata (14 kB)
Collecting spandrel==0.3.4 (from -r requirements_versions.txt (line 27))
  Using cached spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)
Collecting spandrel-extra-arches==0.1.1 (from -r requirements_versions.txt (line 28))
  Using cached spandrel_extra_arches-0.1.1-py3-none-any.whl.metadata (3.0 kB)
Collecting tomesd==0.1.3 (from -r requirements_versions.txt (line 29))
  Using cached tomesd-0.1.3-py3-none-any.whl.metadata (9.1 kB)
Requirement already satisfied: torch in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from -r requirements_versions.txt (line 30)) (2.1.2+cu121)
Collecting torchdiffeq==0.2.3 (from -r requirements_versions.txt (line 31))
  Using cached torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)
Collecting torchsde==0.2.6 (from -r requirements_versions.txt (line 32))
  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)
Collecting transformers==4.30.2 (from -r requirements_versions.txt (line 33))
  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)
Collecting httpx==0.24.1 (from -r requirements_versions.txt (line 34))
  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)
Collecting pillow-avif-plugin==1.4.3 (from -r requirements_versions.txt (line 35))
  Using cached pillow_avif_plugin-1.4.3-cp310-cp310-win_amd64.whl.metadata (1.7 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.32->-r requirements_versions.txt (line 2))
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: packaging>=20.0 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (24.2)
Requirement already satisfied: pyyaml in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from accelerate==0.21.0->-r requirements_versions.txt (line 4)) (6.0.2)
Collecting aenum<4,>=3.1.7 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)
Collecting deprecation<3,>=2.1.0 (from blendmodes==2022->-r requirements_versions.txt (line 5))
  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)
Requirement already satisfied: torchvision in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (0.16.2+cu121)
Collecting scipy>=1.0.1 (from clean-fid==0.1.35->-r requirements_versions.txt (line 6))
  Using cached scipy-1.15.1-cp310-cp310-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: tqdm>=4.28.1 in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (4.67.1)
Requirement already satisfied: requests in j:\ai\stable-diffusion-webui\venv\lib\site-packages (from clean-fid==0.1.35->-r requirements_versions.txt (line 6)) (2.32.3)
Collecting filterpy (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Using cached filterpy-1.4.5-py3-none-any.whl
Collecting numba (from facexlib==0.3.0->-r requirements_versions.txt (line 9))
  Downloading numba-0.61.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)

Press any key to continue . . .",2025-01-26T04:32:34Z,cain666-4u,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2614207355
auto1111_webui,comment,16809,,"I get these a lot when generating with hires fix, and since it mostly happens with many other programs open at the same time, I suspect this is caused by out of RAM",2025-02-04T10:22:38Z,Zueuk,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2633470853
auto1111_webui,comment,16809,,Have you tried this in other browsers because often enough cached information and tabs from your browser can take up memory on your computer over time. I would uninstall all extensions unless you know what extension is corrupt and clear the cache if it persists. This is if your browser is crashing.,2025-02-09T11:08:31Z,Jman3755,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2646179635
auto1111_webui,comment,16809,,"See [this](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1474)

**TL;DR:** You're running out of RAM. Try increasing your System Swap.",2025-02-14T08:48:21Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16809#issuecomment-2658634067
auto1111_webui,issue,16807,[Bug]: Updated installation instructions for installing Stable Diffusion using ROCm (Linux) (Documentation and webui.sh needs updating),"### Checklist

- [ ] The issue exists after disabling all extensions
- [x] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [x] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

Run the same instructions as the documentation says for the first part.
(Debian): `sudo apt install git python3.10-venv -y`
(Fedora): `sudo dnf install python-3.10`
`git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui`
`python3.10 -m venv venv`

Then update line 156 in webui.sh
`pip install torch torchvision --index-url https://download.pytorch.org/whl/nightly/rocm5.7` --> `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2`

Run webui.sh with this command
`HSA_OVERRIDE_GFX_VERSION=11.0.0 HIP_VISIBLE_DEVICES=0 ./webui.sh --precision full --no-half`

VERSION=11.0.0 is specific to the 7900XTX, version number may change depending on GPU model so check ROCm documentation just in case. If you have a 7900XTX, follow instructions exactly.



### Steps to reproduce the problem

1. Follow the official documentation

### What should have happened?

Documentation and ROCm in webui.sh needs updating to make webui.sh work error free.

### What browsers do you use to access the UI ?

Brave

### Sysinfo

Not needed as the program is running with all features when instructions above is followed.

### Console logs

```Shell
################################################################
Install script for stable-diffusion + Web UI
Tested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.
################################################################

################################################################
Running on user user
################################################################

################################################################
Repo already cloned, using it as install directory
################################################################

################################################################
Create and activate python venv
################################################################

################################################################
Launching launch.py...
################################################################
glibc version is 2.40
Check TCMalloc: libtcmalloc_minimal.so.4
libtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib64/libtcmalloc_minimal.so.4
Python 3.10.16 (main, Dec  4 2024, 00:00:00) [GCC 14.2.1 20240912 (Red Hat 14.2.1-3)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.
Launching Web UI with arguments: --precision full --no-half
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
ControlNet preprocessor location: /home/user/AI/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads
2025-01-21 14:56:37,167 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [a31be20e08] from /home/user/AI/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors
2025-01-21 14:56:37,546 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: /home/user/AI/stable-diffusion-webui/configs/v1-inference.yaml
Startup time: 12.6s (prepare environment: 7.1s, import torch: 1.7s, import gradio: 0.4s, setup paths: 1.6s, other imports: 0.3s, load scripts: 0.6s, create ui: 0.4s, gradio launch: 0.3s).
```

### Additional information

_No response_",2025-01-21T20:02:02Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807
auto1111_webui,comment,16807,,"You might be better off using this fork that is made to support AMD GPU's and ROCm:

https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu-forge

I'm using it with RX 6700 and some user compiled ROCm libs etc. It works well for me.",2025-02-19T09:00:21Z,the-real-vortex-v,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2667967277
auto1111_webui,comment,16807,,"I second this with an AMD 7800XT.  The rom5.7 nightly is not currently available anyway (403 error) and even installing rocm5.7 stable into the venv manually with pip doesn't work.  For me, launch.py (and by extension webui.sh) will launch assuming there is a CUDA card involved, even with the HSA_GFX_OVERRIDE.  Skipping the cuda check just causes more errors and the webui won't launch.  Using pip to install torch and torchvision using the --index-url https://download.pytorch.org/whl/rocm6.2 argument was the only thing that worked.  After installing those versions, I can launch using ./webui.sh without any arguments and image generation works.

As for @the-real-vortex-v recommendation to using stable-diffusion-webui-amdgpu-forge, I tried it and it doesn't work. Following the automatic installation instructions still yields the same issue where it assumes I have a CUDA card unless I install rocm6.2.4 manually. I believe this issue is specific to the RX7800 / Navi 3x series cards.  I had a 6700xt and had no issues with webui. Everything went wrong when I upgraded my card to the 7800xt.

",2025-02-22T16:47:06Z,hapwizard,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2676300015
auto1111_webui,comment,16807,,"Thank you for finding a solution for this, I haven't started Webui for a few months and suddenly i got an error when launching the webui.sh script: `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check`

Trying a new installation of webui failed too with a 403 error when downloading the rocm5.7 torch version.

Then I found your post and got my installation working again:

I changed the script from rocm5.7 to 6.2, manually uninstalled torch, torchvision and  torchaudio with pip in the venv and manually installed the 6.2 version. The manuall part was probably unnecessary and changing the script and launching it would have been enough, but it's working again and I'm happy.

Hopefully this will be updated soon.",2025-03-01T10:32:52Z,hanspetzer,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2692130153
auto1111_webui,comment,16807,,"Same issue with : version: [v1.10.1](https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2) â€€â€¢â€€ python: 3.10.12 â€€â€¢â€€ torch: 2.6.0+rocm6.2.4 â€€â€¢â€€ xformers: 0.0.29.post3 â€€â€¢â€€ gradio: 3.41.2 â€€â€¢â€€ checkpoint: 6ce0161689
[dockerlog.txt](https://github.com/user-attachments/files/19496272/dockerlog.txt)

Dockerfile :
```dockerfile
FROM rocm/dev-ubuntu-22.04

RUN apt update && apt install libgoogle-perftools-dev libgl1 git python3 python3-pip python3-venv libglib2.0-0 --no-install-recommends -y
ENV LD_PRELOAD=libtcmalloc.so

RUN adduser app --uid 1000

USER app:app
WORKDIR /app
RUN git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git /app
ENV TORCH_COMMAND=""pip install torch torchvision --index-url https://download.pytorch.org/whl/rocm6.2.4""
ENV XFORMERS_PACKAGE=""xformers --index-url https://download.pytorch.org/whl/rocm6.2.4""
RUN --mount=type=cache,target=/home/app/.cache/pip,uid=1000,gid=1000 /app/webui.sh --skip-torch-cuda-test --exit

EXPOSE 7860/tcp
ENTRYPOINT [ ""/app/webui.sh"", ""--enable-insecure-extension-access"",""--listen"", ""--data-dir=/data"" ]
```

docker-compose.yml
```yml
name: stablediffusionwebui-test
services:
  sdwui:
    build: .
    image: dockerstablediffusionwebui:test
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.0
    devices:
      - /dev/dri
      - /dev/kfd
    group_add:
      - video
      - 110 #render
    user: 1000:1000
    ports:
      - 7861:7860
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    ipc: host
    command: --api --disable-console-progressbars --xformers
    # entrypoint: bash
    # tty: true
    # stdin_open: true
    volumes:
      - ./data-test:/data
```",2025-03-28T00:51:19Z,AR2000AR,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-2759904208
auto1111_webui,comment,16807,,"I just edited the webui.sh script to fetch rocm7.0 instead as rocm5.7 does not exist.

Not really the devs fault but would be good, if the latest, was just called latest instead of a version number, or called nightly, as this will be an ongoing issue, version numbers are constantly changing, including Python, instructions say install Python 3 which will allways be the latest, but it tells use we need 3.10.6, but directly under that, its telling me to install 3.11, all a little ""fly by the seat of my pants"" or lets ""yolo it"" :)",2025-11-03T23:45:00Z,NexGen-3D-Printing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483045766
auto1111_webui,comment,16807,,"Rocm versions are tied to the python version you are running. The old 5.7 (Python 3.10) can't handle some newer model so thus the tutorial. I can't remember off the top of my head which Python version you need to run to make the above work but I assume I was using 3.12 or 3.13 at the time. The newer Rocm 7+ requires the lastest Python version to work. If you are trying to get this to work on the new Strix Halo chips, use a different repo. I am pretty sure TheRock has a Docker image that makes A1111 work with Strix Halo in his repos.",2025-11-04T00:21:34Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483171301
auto1111_webui,comment,16807,,Update: I was using 3.10. I guess Rocm 5.7 must be for an even earlier version of Python.,2025-11-04T00:24:08Z,theman23290,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483180306
auto1111_webui,comment,16807,,"Im using a 7900 GRE, I seen there is some special experimental builds currently for the 7000 series, RDNA 3.5 and 4, all seperate branches of ROCM, in my opinion, its a bit of dogs breakfast, no wonder all these tools are so touchy, its quite scattered, probably why everyone just goes with nVidia, as Cuda is a little more universal.

I just wanted to test some ROCM workloads to see if its worth my time using some MI50 cards, but it looks quite futile, I have RDNA 2, 3 and 4 at my disposal, so I might have to do some testing on the other cards as well to see what is going to work before I purchase anything more, just trying to avoid nVidia, and Intel Arc if I can.",2025-11-04T01:15:53Z,NexGen-3D-Printing,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16807#issuecomment-3483287105
auto1111_webui,issue,16806,[Feature Request]: Hide specific directory buttons when viewing extra networks in Dirs view style,"### Is there an existing issue for this?

- [x] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

I would like there to be a setting that lets you select available directories in your extra networks tab to hide individually.

I like to keep my LoRAs organized in folders by their supported checkpoints and categories. For instance, my checkpoints are SDXL, Pony, and Illustrious. Then within those folders I have Characters (Male, Female, Non-Human), Styles, and Concepts. Then I have even more specific folders within those.

The result is I get every possible directory as a button I can click to filter the cards. There's the feature that hides folders and models from being shown if the folder starts with a period, but it hides _all_ the subfolders and models within that folder.

I know I could simply have fewer folders to reduce the amount of directory buttons, but I think the ability to hide specific ones to have a personalized list would be a good feature overall.

Alongside this, I think being able to save presets of hidden buttons would be great when going between different checkpoint versions.

### Proposed workflow

1. Go to .... 
2. Press ....
3. ...


### Additional information

_No response_",2025-01-21T07:45:51Z,DecodeTalker1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806
auto1111_webui,comment,16806,,"switch to tree view?
- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16803#discussioncomment-11890409",2025-01-22T03:06:18Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806#issuecomment-2606189108
auto1111_webui,comment,16806,,I like the filters being on the top. I gave the tree view a try but it feels too clunky having to navigate to each folder I want to quickly view. I was hoping for a solution with the directory buttons,2025-01-23T04:20:15Z,DecodeTalker1,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16806#issuecomment-2608821519
auto1111_webui,issue,16802,[Bug]: Installing K diffusion,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [x] The issue has been reported before but has not been fixed yet

### What happened?

Tried to install k diffusion but gives me an error, it used to have many errors now am stuck with is one (RROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion')

### Steps to reproduce the problem

Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.

### What should have happened?

It should have installed k diffusion 

### What browsers do you use to access the UI ?

Google Chrome, Microsoft Edge

### Sysinfo

IDK?

### Console logs

```Shell
(base) PS C:\WINDOWS\system32> cd C:\1111\stable-diffusion-cpuonly
(base) PS C:\1111\stable-diffusion-cpuonly> git clone git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
Obtaining k_diffusion from git+https://github.com/hlky/k-diffusion-sd#egg=k_diffusion
  Cloning https://github.com/hlky/k-diffusion-sd to c:\1111\stable-diffusion-cpuonly\src\k-diffusion
ERROR: Command errored out with exit status 128: git clone -q https://github.com/hlky/k-diffusion-sd 'C:\1111\stable-diffusion-cpuonly\src\k-diffusion' Check the logs for full command output.
        1 file(s) copied.
        1 file(s) copied.
```

### Additional information

_No response_",2025-01-17T12:42:50Z,the2unix,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16802
auto1111_webui,comment,16802,,"I'm not sure what instructions are you following but I'm pretty sure you're not using https://github.com/AUTOMATIC1111/stable-diffusion-webui
if you're trying to get whatever you're currently using to work then you're asking in the wrong place
if you're trying to install AUTOMATIC1111/stable-diffusion-webui then read https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs

---

also this https://github.com/hlky/k-diffusion-sd leads to a 404 page
whatever it was before it was deleted",2025-01-18T03:21:55Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16802#issuecomment-2599496838
auto1111_webui,issue,16797,[Bug]: Bad API auth with certain passwords,"### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

```
Jan 14 13:14:03 roxanne.dragonfear stable-diffusion-webui[1682746]: ValueError: too many values to unpack (expected 2)
```
The routine in api.py is using auth.split("":"")

It should be using auth.partition("":"") to avoid double-splits.

### Steps to reproduce the problem

Just run the thing with an API password that contains colons.

### What should have happened?

Should start normally.

### What browsers do you use to access the UI ?

_No response_

### Sysinfo

Doesn't matter.  It's a code bug.

### Console logs

```Shell
Above.
```


### Additional information

_No response_",2025-01-14T13:15:50Z,Rudd-O,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797
auto1111_webui,comment,16797,,"> It should be using auth.partition("":"") to avoid double-splits.

sure, `partition` or `str.split(':', maxsplit=1)`
but maybe it's better to just not use the second colon in your password",2025-01-17T06:43:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2597544730
auto1111_webui,comment,16797,,"Design Request Summary for BeautyPlus:

Text:

English only (BeautyPlus or B+).
Promotional phrases:
""Discover the best salons and spas.""
""Book appointments and find offers.""
""Contact us for details.""
Images:

App interface screenshots.
Simple visuals like hair or nails.
Icons: 3 only (Search, Home, Account).

Contact Information:

Email: info@beautyplusapp.com
WhatsApp: 0561688990
Colors:

Background: #899F93 (green-gray).
Text: White.
Sizes:

1080x1080 px.
400x400 px.
350x420 px.
Presentation:

Show design within an iPhone mockup.",2025-01-17T12:49:03Z,manea19,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2598297100
auto1111_webui,comment,16797,,"I worked around by changing the password, but this is a basic bug that should be fixed and might even have security implications.",2025-01-18T22:34:24Z,Rudd-O,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16797#issuecomment-2600217958
auto1111_webui,issue,16781,[Bug]: Dreambooth installed but tab is not viewed on UI,"### Checklist

- [X] The issue exists after disabling all extensions
- [X] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [X] The issue has not been reported before recently
- [X] The issue has been reported before but has not been fixed yet

### What happened?

No Dreambooth Tab

### Steps to reproduce the problem

just install the extension and fully restart UI

### What should have happened?

it should show the tab

### What browsers do you use to access the UI ?

Microsoft Edge

### Sysinfo

I do know how to do it


### Console logs

```Shell
https://pastebin.com/acPkiMTZ
```


### Additional information

nothing",2025-01-10T22:02:04Z,Hi1603,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16781
auto1111_webui,comment,16781,,Just use [kohya_ss](https://github.com/bmaltais/kohya_ss) or [OneTrainer](https://github.com/Nerogar/OneTrainer),2025-01-13T05:55:25Z,Haoming02,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16781#issuecomment-2586222604
auto1111_webui,issue,16762,[Feature Request]: prepare host for specific gpu (needed for containers) without starting api/ui,"### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

It would be nice to have some option to initializen the current installation for a specific gpu
right now I exploit the script to ""simulate"" my amd gpu

```
root@ollama:~/ollama# cat Dockerfile.automatic1111
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (exploits webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    sed 's/start()/# start()/g' launch.py >_init.py \
 && bash -ec ""function lspci { echo '03:00.0 VGA compatible controller: Advanced Micro Devices, Inc. [AMD/ATI] XXXXXX'; } \
 && export -f lspci \
 && LAUNCH_SCRIPT=_init.py ./webui.sh -f --data-dir /data --skip-torch-cuda-test"" \
 && rm -rf /data/* _init.py

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"" ]
```

### Proposed workflow

maybe a separate script or argument would be nice

### Additional information
if someome is interessted this is my docker-compose.yml
```
services:
  ollama:
    image: ollama/ollama:rocm
    ports:
      - ""11434:11434""
    volumes:
      #- ./ollama:/root/.ollama
      - /usr/share/ollama/.ollama:/root/.ollama
    restart: unless-stopped
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - 44
      - 993

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    volumes:
      - ./open-webui:/app/backend/data
    ports:
      - ""8080:8080""
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      AUTOMATIC1111_BASE_URL: http://automatic1111:7860
      ENABLE_OLLAMA_API: true
      ENABLE_OPENAI_API: false
      YOUTUBE_LOADER_LANGUAGE: de
      ENABLE_RAG_WEB_SEARCH: true
      RAG_WEB_SEARCH_ENGINE: duckduckgo
      ENABLE_IMAGE_GENERATION: true
      IMAGE_GENERATION_ENGINE: automatic1111
      IMAGE_GENERATION_MODEL: v1-5-pruned-emaonly.safetensors [6ce0161689]
      SCARF_NO_ANALYTICS: true
      DO_NOT_TRACK: true
      ANONYMIZED_TELEMETRY: false

  automatic1111:
    build:
      context: .
      dockerfile: Dockerfile.automatic1111
    volumes:
      - ./automatic1111:/data
    restart: unless-stopped
    ports:
      - ""7860:7860""
    group_add:
      - 44
      - 993
    devices:
      - /dev/kfd
      - /dev/dri
```",2024-12-30T01:12:12Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762
auto1111_webui,comment,16762,,"I think what you asking is already supported
> I don't use AMD GPU so I'm not exactly familiar with the situation but from my understanding

there should be no need to simulate a GPU
unless there is something that I'm not aware the difference is the different GPU is what version of torch that it installs

the environment variable `TORCH_COMMAND` is the actual thing that defines what version of torch that we installed
so you should just set the appropriate command for your desired platform without the heck simulation stuff
if the user already defines `TORCH_COMMAND` then auto platform detection is disabled
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/webui.sh#L130-L152

alternatively you could always manually install torch, if torch is already installed webui won't auto install a different version for you (unless you pass `--reinstall-torch`) in whitch case it will try to install what's defined by `TORCH_COMMAND`

---

also there is no need to modify launch.py to prevent webui from starting
just pass `--exit` and it will exit after installing requirements
https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/021154d8b1fb9b921e4d2c5552525d164b4e715a/modules/launch_utils.py#L442-L444

---

wiki

https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings",2024-12-30T04:29:59Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565014551
auto1111_webui,comment,16762,,"`--exit` seems to work - II completely overlooked it.

Also setting the `TORCH_COMMAND` works - I already spotted this but in this case I need to know the correct packages, versions and urls.
My goal was to use the ""suggested"" settings from webui.sh
e.g. in my case `export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7""` is the command to use but if you change the rocm version, add a package or set a specific version I would have to do the same in the Dockerfile.

it would be nice to have an option or environment variable to define the gpu type which results in the ""correct"" TORCH_COMMAMD

this is my current docker-file
```
FROM rocm/pytorch:rocm6.3_ubuntu22.04_py3.10_pytorch_release_2.4.0

WORKDIR /automatic1111

# install packages
RUN apt update \
 && apt install google-perftools bc -y --no-install-recommends \
 && apt clean

# clone repo
RUN mkdir -p /data \
 && git clone --depth 1 https://github.com/AUTOMATIC1111/stable-diffusion-webui .

# prepare environment (TORCH_COMMAND from webui.sh)
RUN --mount=type=cache,target=/root/.cache/pip \
    export TORCH_COMMAND=""pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7"" \
 && bash -e ./webui.sh -f --data-dir /data --skip-torch-cuda-test --exit \
 && rm -rf /data/*

EXPOSE 7860

VOLUME /data

CMD [""/automatic1111/webui.sh"", ""-f"", ""--api"", ""--listen"", ""--skip-prepare-environment"", ""--data-dir"", ""/data"", ""--precision"", ""full"", ""--no-half"", ""--medvram"" ]
```",2024-12-30T13:33:51Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565492097
auto1111_webui,comment,16762,,"so are you asking for something like
if `gpu_info` is pre defined
then don't run the gpu test like `lspci 2>/dev/null | grep -E ""VGA|Display""` ` grep -q ""NVIDIA""` ` grep -q ""AMD""`
but still sets `TORCH_COMMAND` base on the pre defined value of `gpu_info`",2024-12-30T22:22:01Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565968020
auto1111_webui,comment,16762,,"something like this would be nice.
or maybe a new variable or arguments like --amd-gpu and --nvidia-gpu (maybe more depending on the count of TORCH_COMMAND)",2024-12-30T23:07:26Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2565995771
auto1111_webui,comment,16762,,"if you really have a clear idea of what you want
then it's better that you make a PR and see if others agree with your addition",2024-12-30T23:49:36Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2566014634
auto1111_webui,comment,16762,,"I think the easiest change would be something like this
```
if [[ -z ""${TORCH_GPU}"" ]]
then
    gpu_info=$(lspci 2>/dev/null | grep -E ""VGA|Display"")
else
    gpu_info=$TORCH_GPU
fi
```",2024-12-31T00:24:44Z,AlBundy33,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16762#issuecomment-2566031879
auto1111_webui,issue,16760,[Bug]: LORAs installed does not show up at Lora tab ,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [ ] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [X] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

LORAs installed does not show up at Lora tab 
![Lora didnt show up](https://github.com/user-attachments/assets/86796bf9-3c27-4da5-bdbd-3cab74e02649)


### Steps to reproduce the problem

I have installed some LORAs but not idea why it won't show up at Lora Tab. Please help.

### What should have happened?

Under Lora tab should display all the Lora I have installed.

### What browsers do you use to access the UI ?

Google Chrome

### Sysinfo

[sysinfo-2024-12-29-13-11.json](https://github.com/user-attachments/files/18269696/sysinfo-2024-12-29-13-11.json)


### Console logs

```Shell
venv ""C:\Auto1111\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 13:09:10.222780: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 13:09:10.947711: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 13:09:16,846 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 13:09:16,848 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 13:09:16,948 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 13:09:18,551 - ControlNet - INFO - ControlNet v1.1.448
13:09:19 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 13:09:21,984 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
AnimateDiffScript init
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 42.9s (prepare environment: 23.5s, import torch: 4.1s, import gradio: 1.1s, setup paths: 3.4s, initialize shared: 0.3s, other imports: 0.7s, setup codeformer: 0.2s, load scripts: 7.1s, create ui: 1.6s, gradio launch: 0.7s).
Applying attention optimization: Doggettx... done.
Model loaded in 11.8s (load weights from disk: 1.5s, create model: 0.9s, apply weights to model: 7.8s, apply half(): 0.1s, move model to device: 0.4s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.8s).
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
Version: v1.7.0
Commit hash: cf2772fab0af5573da775e7437e6acdca424f26e
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
Installing requirements for Face Editor
is_installed check for tensorflow-cpu failed as 'spec is None'
Installing requirements for easyphoto-webui
Installing requirements for tensorflow
CUDA 11.8
Launching Web UI with arguments:
2024-12-29 20:56:32.029570: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-29 20:56:32.754525: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
no module 'xformers'. Processing without...
no module 'xformers'. Processing without...
No module 'xformers'. Proceeding without it.
*** Extension ""sd-webui-replacer"" requires ""sd-webui-segment-anything"" which is not installed.
2024-12-29 20:56:40,169 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.
2024-12-29 20:56:40,173 - modelscope - INFO - TensorFlow version 2.15.0 Found.
2024-12-29 20:56:40,174 - modelscope - INFO - Loading ast index from C:\Users\fion77\.cache\modelscope\ast_indexer
2024-12-29 20:56:40,322 - modelscope - INFO - Loading done! Current index file version is 1.9.3, with md5 01e332cc9936f5d9ebf43a61d251b61f and a total number of 943 components indexed
ControlNet preprocessor location: C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-29 20:56:43,388 - ControlNet - INFO - ControlNet v1.1.448
20:56:45 - ReActor - STATUS - Running v0.7.0-b7 on Device: CUDA
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
Loading weights [678b70fd2d] from C:\Auto1111\stable-diffusion-webui\models\Stable-diffusion\sdxlYamersAnime_stageAnima.safetensors
AnimateDiffScript init
AnimateDiffScript init
2024-12-29 20:56:49,154 - ControlNet - INFO - ControlNet UI callback registered.
[FACEFUSION.CORE] FFMpeg is not installed
Creating model from config: C:\Auto1111\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
AnimateDiffScript init
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
*** Error executing callback app_started_callback for C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_callbacks.py"", line 139, in app_started_callback
        c.callback(demo, app)
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_api.py"", line 18, in replacer_api
        from scripts.sam import sam_model_list
    ModuleNotFoundError: No module named 'scripts.sam'

---
Startup time: 61.0s (prepare environment: 36.6s, import torch: 4.1s, import gradio: 1.0s, setup paths: 3.2s, initialize shared: 0.3s, other imports: 1.6s, setup codeformer: 0.2s, load scripts: 11.6s, create ui: 2.0s, gradio launch: 0.6s).
Applying attention optimization: Doggettx... done.
activating extra network lora: TypeError
Traceback (most recent call last):
  File ""C:\Auto1111\stable-diffusion-webui\modules\extra_networks.py"", line 145, in activate
    extra_network.activate(p, [])
  File ""C:\Auto1111\stable-diffusion-webui\extensions-builtin\Lora\extra_networks_lora.py"", line 18, in activate
    p.all_prompts = [x + f""<lora:{additional}:{shared.opts.extra_networks_default_multiplier}>"" for x in p.all_prompts]
TypeError: 'NoneType' object is not iterable

Model loaded in 15.2s (load weights from disk: 1.6s, create model: 1.1s, apply weights to model: 11.1s, apply half(): 0.1s, move model to device: 0.4s, calculate empty prompt: 0.8s).
```


### Additional information

_No response_",2024-12-29T13:13:10Z,fion0412,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760
auto1111_webui,comment,16760,,"By default, it'll only display LORAs compatible with the loaded checkpoint. Make sure you have SDXL LORAs.

Other than that, not all of the files you have in there are LORAs.
`cuteCartoon_v10.safetensors` is a checkpoint. Put it in `models/Stable-diffusion`.
`canny-modified.safetensors` is a controlnet model. It goes in `models/ControlNet`.

```
*** Error loading script: replacer_main_ui.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_main_ui.py"", line 8, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)

---
*** Error loading script: replacer_script.py
    Traceback (most recent call last):
      File ""C:\Auto1111\stable-diffusion-webui\modules\scripts.py"", line 469, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Auto1111\stable-diffusion-webui\modules\script_loading.py"", line 10, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\scripts\replacer_script.py"", line 6, in <module>
        from replacer.ui import replacer_tab_ui
      File ""C:\Auto1111\stable-diffusion-webui\extensions\sd-webui-replacer\replacer\ui\replacer_tab_ui.py"", line 2, in <module>
        from modules import shared, ui_settings, errors, infotext_utils
    ImportError: cannot import name 'infotext_utils' from 'modules' (unknown location)
```
This one is due to your webui version being too old. Update with `git pull`

```json
{
    ""name"": ""stable-diffusion-webui"",
    ""path"": ""C:\\Auto1111\\stable-diffusion-webui\\extensions\\stable-diffusion-webui"",
    ""version"": ""1c0a0c4c"",
    ""branch"": ""master"",
    ""remote"": ""https://github.com/AUTOMATIC1111/stable-diffusion-webui""
},
```
How did that happen? Delete `C:\Auto1111\stable-diffusion-webui\extensions\stable-diffusion-webui`

You might also try it without extensions. You can do that with the `--disable-all-extensions` argument.",2024-12-30T01:37:50Z,missionfloyd,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2564939931
auto1111_webui,comment,16760,,Let me try first git pull and see whether can appear all installed LORA in my LORA tab,2024-12-31T05:45:52Z,fion0412,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2566152281
auto1111_webui,comment,16760,,I've encountered the same situation; has this been resolved?,2025-01-02T14:02:44Z,ropz12138,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2567822563
auto1111_webui,comment,16760,,"I've encountered the same issue, I'm using Norton 365, wondering if that may have had something to do with it???
I've uninstalled, re-installed: Python 3.10.6, SD1.5, A1111, Even loaded it on a non-system drive, still no fix. 
This happened suddenly, on New Years Eve.  All Loras were working and suddenly, nothing. They just disapeared from the UI, but were still in the Lora folder when examined in file explorer.

Error Message when I refresh:
Nothing here. Add some content to the following directories:
E:\stable-diffusion-webui\models\Lora
E:\stable-diffusion-webui\models\LyCORIS
",2025-01-02T16:26:51Z,turkeelurkee,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2568039359
auto1111_webui,comment,16760,,"Found what got my Loras back from another forum:

Hello! If you are using Stable Diffusion 1111 â€” All you need to do is:

**1 â€” Go to the ""Settings"" menu.
2 â€” Click on the sub-menu ""Extra Networks"".
3 â€” Scroll down and click on the option ""Always show all networks on the Lora page"".
4 â€” Click on the ""Apply Settings"" button (at the top of the page).
5 â€” Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**

ALL your Loras appear or are back!",2025-01-02T18:37:10Z,turkeelurkee,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2568202959
auto1111_webui,comment,16760,,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 â€” All you need to do is:
> 
> **1 â€” Go to the ""Settings"" menu. 2 â€” Click on the sub-menu ""Extra Networks"". 3 â€” Scroll down and click on the option ""Always show all networks on the Lora page"". 4 â€” Click on the ""Apply Settings"" button (at the top of the page). 5 â€” Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works!",2025-03-26T21:11:30Z,Eeoneguy356,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2755757187
auto1111_webui,comment,16760,,I met same problem,2025-05-28T19:48:22Z,fan9704,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2917439725
auto1111_webui,comment,16760,,"> Found what got my Loras back from another forum:
> 
> Hello! If you are using Stable Diffusion 1111 â€” All you need to do is:
> 
> **1 â€” Go to the ""Settings"" menu. 2 â€” Click on the sub-menu ""Extra Networks"". 3 â€” Scroll down and click on the option ""Always show all networks on the Lora page"". 4 â€” Click on the ""Apply Settings"" button (at the top of the page). 5 â€” Go to your Extra Network tab, click the ""Refresh"" button, and TA-DAAA ... IT WORKS!**
> 
> ALL your Loras appear or are back!

Thanks! it's works for me!",2025-05-28T19:50:01Z,fan9704,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16760#issuecomment-2917442958
auto1111_webui,issue,16759,[Bug]: Error loading script: main.py,"### Checklist

- [ ] The issue exists after disabling all extensions
- [ ] The issue exists on a clean installation of webui
- [X] The issue is caused by an extension, but I believe it is caused by a bug in the webui
- [ ] The issue exists in the current version of the webui
- [ ] The issue has not been reported before recently
- [ ] The issue has been reported before but has not been fixed yet

### What happened?

when started webui-user.bat, I got this error message:

*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

When I try to send to txt2img the openpose s pose , nothing happened, when I manually set up the pose pictures, the picture isnt posed with the pose I setup....

Sorry I am a bit lost, If someone can help me I would be gratefull

### Steps to reproduce the problem

1.l auch webui-user.bat

2. get the error:

Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

3. 3dopenpose doesnt want to send the pose and other controlnet such as depht for example to the txt2img or img2img.

4. after setting up the pose pictuer into controlnet parameter and setting up the options. it doesnt follow the pose...

### What should have happened?

1. No error on startting webui-user.bat

2. Openpose can send the picures to img2img or txt2img

3. I got the result with a picture with the pose I set up

### What browsers do you use to access the UI ?

Mozilla Firefox, Google Chrome

### Sysinfo

[sysinfo-2024-12-28-17-43.json](https://github.com/user-attachments/files/18267048/sysinfo-2024-12-28-17-43.json)


### Console logs

```Shell
off ""C:\Users\netwo\AppData\Local\Programs\Python\Python310\python.exe

C:\Users\netwo\stable-diffusion-webui>set PYTHON=

C:\Users\netwo\stable-diffusion-webui>set GIT=

C:\Users\netwo\stable-diffusion-webui>set VENV_DIR=

C:\Users\netwo\stable-diffusion-webui>set COMMANDLINE_ARGS= ""--xformers""

C:\Users\netwo\stable-diffusion-webui>call webui.bat
venv ""C:\Users\netwo\stable-diffusion-webui\venv\Scripts\Python.exe""
Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
Version: v1.10.1
Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2
Launching Web UI with arguments: --xformers
*** Error loading script: main.py
    Traceback (most recent call last):
      File ""C:\Users\netwo\stable-diffusion-webui\modules\scripts.py"", line 515, in load_scripts
        script_module = script_loading.load_module(scriptfile.path)
      File ""C:\Users\netwo\stable-diffusion-webui\modules\script_loading.py"", line 13, in load_module
        module_spec.loader.exec_module(module)
      File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""C:\Users\netwo\stable-diffusion-webui\extensions\openpose-editor\scripts\main.py"", line 14, in <module>
        from basicsr.utils.download_util import load_file_from_url
    ModuleNotFoundError: No module named 'basicsr'

---
ControlNet preprocessor location: C:\Users\netwo\stable-diffusion-webui\extensions\sd-webui-controlnet\annotator\downloads
2024-12-28 18:45:35,296 - ControlNet - INFO - ControlNet v1.1.455
Loading weights [d803b444ed] from C:\Users\netwo\stable-diffusion-webui\models\Stable-diffusion\disneyrealcartoonmix_v10.safetensors
2024-12-28 18:45:36,849 - ControlNet - INFO - ControlNet UI callback registered.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
Creating model from config: C:\Users\netwo\stable-diffusion-webui\repositories\generative-models\configs\inference\sd_xl_base.yaml
Startup time: 21.3s (prepare environment: 9.4s, import torch: 4.1s, import gradio: 1.6s, setup paths: 0.8s, import ldm: 0.1s, initialize shared: 0.3s, other imports: 0.5s, load scripts: 3.2s, create ui: 0.7s, gradio launch: 0.6s).
```


### Additional information

_No response_",2024-12-28T17:46:16Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16759
auto1111_webui,comment,16759,,- https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/16587,2024-12-29T12:43:27Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16759#issuecomment-2564713284
auto1111_webui,comment,16759,,"
Thaanks I fixed the issue by uploading ... install packages

but no I have no more message error, but 3dopenpose seems not working
",2024-12-29T13:21:25Z,ghost,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16759#issuecomment-2564724201
auto1111_webui,issue,16750,[Feature Request]: è¯·é—®ä¸‹ï¼Œwebuiæ˜¯æ”¾å¼ƒæ›´æ–°äº†å—ï¼Ÿæ„Ÿè§‰å·²ç»å¥½ä¹…æ²¡æœ‰æ›´æ–°äº†ï¼,"### Is there an existing issue for this?

- [X] I have searched the existing issues and checked the recent builds/commits

### What would your feature do ?

 è¯·é—®ä¸‹ï¼Œwebuiæ˜¯æ”¾å¼ƒæ›´æ–°äº†å—ï¼Ÿæ„Ÿè§‰å·²ç»å¥½ä¹…æ²¡æœ‰æ›´æ–°äº†ï¼

### Proposed workflow

è¯·é—®ä¸‹ï¼Œwebuiæ˜¯æ”¾å¼ƒæ›´æ–°äº†å—ï¼Ÿæ„Ÿè§‰å·²ç»å¥½ä¹…æ²¡æœ‰æ›´æ–°äº†ï¼

### Additional information

 è¯·é—®ä¸‹ï¼Œwebuiæ˜¯æ”¾å¼ƒæ›´æ–°äº†å—ï¼Ÿæ„Ÿè§‰å·²ç»å¥½ä¹…æ²¡æœ‰æ›´æ–°äº†ï¼",2024-12-25T07:35:32Z,BannyLon,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16750
auto1111_webui,comment,16750,,"https://github.com/AUTOMATIC1111/stable-diffusion-webui/pulse
people are working in the background",2024-12-31T01:31:27Z,w-e-w,https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/16750#issuecomment-2566058703
